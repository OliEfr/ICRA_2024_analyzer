<!DOCTYPE HTML>
<html>
 <head>
  <meta content="en-us" http-equiv="Content-Language"/>
  <meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
  <meta content="width=device-width" name="viewport"/>
  <script src="https://ras.papercept.net/conferences/scripts/dom-drag.js" type="text/javascript">
  </script>
  <script src="jquery-1.11.1.min.js">
  </script>
  <title>
   IROS 2024 Program | Wednesday October 16, 2024
  </title>
  <style type="text/css">
   body, table, td, th{
	Font-Family : sans-serif;
	Font-Size : 10pt;
}
.r {text-align: right}
.blue {color: #0000FF;}
td {vertical-align: top; text-align: left}
.c {text-align: center}
table.s {
	border-collapse:collapse;
	border-width: 1px;
}
table.s td{
	border-width: 1px;
	padding: 4px;
	border-style: solid;
	border-color: gray;
}
table.t {
	border-collapse: collapse;
	border-width: 0px;
}
table.t td{
	border-width: 0px;
	padding: 4px;
	border-style: solid;
	border-color: gray;
}
.dots {
    background:url('./images/dot.gif') repeat-x center;
}
.field {
    background-color: #FFFFFF;
}
#pTitle { /* Page title */
   font-size: 14pt;
   line-height: 1.5em;
}
#pSubTitle { /* Page subtitle */
   color: #909090;
   font-size: 10pt; 
   line-height: 1.5em;
}
#container {
	position: absolute;
	width: 100%;
	margin-top: 2px;
/*	overflow: hidden; */
}

.sHdr {   /* Session header Content list */
   background-color: #F0E68C
}
      
.sSHdr {   /* Subsession header Content list */
   background-color: #f8f3c6 
}
      
table.trk { /* Track table Content list */
   border-collapse: collapse;
   border-width: 0px;
   margin: auto;
/**   width: 640px; **/
   width: 720px;
}
table.trk td{
   border-width: 0px;
   padding: 4px;
   border-style: solid;
   border-color: gray;
 }
      
.pHdr {  /* Paper header Content list */
   background-color: #E6E6FA;
   color: black;
}
hr.thin { /* Horizontal rule content list */
   border: 0px; 
   height: .8px; 
   background-color: #8888FF;
}
      
.pTtl {  /* Paper title Content list */
   font-size: 11pt;
   font-style: italic;
}
      
.ssHdr {  /* Subsession header container session Content list */
   background-color: #DDDDDD;
   color: black;
}
      
.ssTtl {  /* Subsession title container session Content list */
   font-size: 10pt;
   font-style: normal;
   font-weight: bold;
}
  </style>
  <script language="JavaScript">
   function initXMLHttp(){
   var oRequest = false;
   try {
      oRequest = new XMLHttpRequest();
   }  catch (trymicrosoft) {
      try {
         oRequest = new ActiveXObject("Msxml2.XMLHTTP");
      }  catch (othermicrosoft) {
         try {
            oRequest = new ActiveXObject("Microsoft.XMLHTTP");
         }  catch (failed) {
            oRequest = false;
         }
      }
   }
   if (!oRequest){
      alert("Error initializing XMLHttpRequest! Your browser does not support AJAX");
   }
   return oRequest;
}
function modify(number,kk){
   var check = document.getElementById('mod' + kk).checked;
   if (check){
      action = 'Add';
   }
   else{
      action = 'Delete';
   }
   
//   url = 'https://ras.papercept.net/conferences/scripts/myprogram.pl?ConfID=425&' + action + number;
//   window.open(url,'myprogrampage');

   modifyItem("https://ras.papercept.net/conferences/scripts/myprogram_aja.pl","425",action,number)

}


function modifyItem(url,ConfID,action,number){
   var oRequest = initXMLHttp();
   if (!oRequest){return;}
   
   // Send the request

   oRequest.open("post",url, true);
   var sParams = 'ConfID=' + ConfID + '&Action=' + action + '&Number=' + number;
   document.body.style.cursor = 'wait';
   oRequest.send(sParams);

   // Process the response
   
   oRequest.onreadystatechange = function(){ 
      if (oRequest && oRequest.readyState && oRequest.readyState == 4){
         document.body.style.cursor = 'auto';
         var responseText = oRequest.responseText;
         if (responseText.substring(0,5) == 'Error'){
            alert(responseText);
         }
         else{
         
//            alert(responseText);

         }
      }
   } 
}

var iIntervalId;  // Global variable
function modsession(id,kk){
   var check = document.getElementById('mod' + kk).checked;
   if (check){
      action = 'AddSession';
   }
   else{
      action = 'DelSession';
   }

//   url = 'https://ras.papercept.net/conferences/scripts/myprogram.pl?ConfID=425&' + action + id;
//   window.open(url,'myprogrampage');

   modifySession("https://ras.papercept.net/conferences/scripts/myprogram_aja.pl","425",action,id)

}

function modifySession(url,ConfID,action,id){
   var oRequest = initXMLHttp();
   if (!oRequest){return;}
   
   // Send the request

   oRequest.open("post",url, true);
   var sParams = 'ConfID=' + ConfID + '&Action=' + action + '&ID=' + id;
   document.body.style.cursor = 'wait';
   oRequest.send(sParams);

   // Process the response
   
   oRequest.onreadystatechange = function(){ 
      if (oRequest && oRequest.readyState && oRequest.readyState == 4){
         document.body.style.cursor = 'auto';
         var responseText = oRequest.responseText;
         if (responseText.substring(0,5) == 'Error'){
            alert(responseText);
         }
         else{
         
//            alert(responseText);

         }
      }
   } 
}

function getCookie(sName){
   var sRE = "(?:; )?" + sName + "=([^;]*);?";   
   var oRE = new RegExp(sRE);
   if (oRE.test(document.cookie)){
      return decodeURIComponent(RegExp["$1"]);}
   else{
      return null;
   }
}
function loadprogram(){
   var list = getCookie("IROS24");
   if (list){
      var List = list.split(",");
      for (var i=0; i<List.length; i++){
         var names = document.getElementsByName('modify' + List[i]);
         if (names.length){
            for (var j=0; j<names.length; j++){
               names[j].checked = true;
            }
         }
      }
   }
}
function reset(){

   // Uncheck all modify and addsession checkboxes

   var ins = document.getElementsByTagName('input');
   for (var i=0; i<ins.length; i++){
      if (ins[i].type == 'checkbox' && ins[i].id && ins[i].id.substring(0,3) == 'mod'){
         ins[i].checked = false;
      }
   }
   
   // Reload the program
   
   loadprogram();
}
function startreset(){
   iIntervalId = setInterval(reset,2000);
}
function viewAbstract(number){
   var box = document.getElementById('Ab' + number);
   if (box.style.display == 'block'){
      box.style.display = 'none';
   }
   else if (box && box.style.display == 'none'){
      box.style.display = 'block';
   }
}
function openAllAbstracts(){
   var d = document.getElementsByTagName('div');
   var count = d.length;
   if (count == 0){return;}
   for (var i=0; i<d.length; i++){
      if (d[i].id && d[i].id.substring(0,2) == 'Ab' && d[i].style.display == 'none'){
         d[i].style.display = 'block';
      }
   }
}
function closeAllAbstracts(){
   var d = document.getElementsByTagName('div');
   for (var i=0; i<d.length; i++){
      if (d[i].id && d[i].id.substring(0,2) == 'Ab'){
         d[i].style.display = 'none';
      }
   }
}
var uhash;
var pColor;
$(function() { 

   // Check for URL hash

   uhash = location.hash.substring(1);
   if (uhash.slice(-1) == '_'){
      uhash = null;
   }
   if (uhash){
   
      // Mark the session
   
      pColor = $('#' + uhash).parent().css('backgroundColor');
      $('#' + uhash).parent().css('backgroundColor','#FF8888');
   }
});


$(function() { 

   // Check for URL hash

   uhash = location.hash.substring(1);
   if (uhash.slice(-1) == '_'){
      uhash = null;
   }
   if (uhash){

      // Set the widths
      
      setwidth();
      
      // If claasical view is required then return

      if (!ghit){return;} 
      
      // Reset left margin for FF

      document.getElementById('container').scrollLeft = 0;;

      // Discover the table and the block and determine the block Id
   
      var rt = $('#' + uhash);
      var done = false;
      while (!done){
         rt = rt.parent();    
         var etype = rt.get(0).tagName;  
         if (rt.is("table")){      
            done = true;
         }
      }
      rt = rt.parent().parent().parent();
      var iid = rt.attr('id')

      // Show the block

      initialize();
      $('#' + iid).show();
      $( '#A' + iid ).focus();
      var ypos = $('#' + iid).offset().top;      
      window.scrollTo(0,ypos);

      // Cancel the scroll to uhash

      var url = location.href;
      url += '_';
      location.href = url;
      
      // Scroll into view

      var leftPosition = $('#' + uhash).parent().position().left;
      var topOffset = $('#' + uhash).parent().offset().top;
      var divOffset = $('#' + iid).find('div').offset().top;
      var topPosition = topOffset-divOffset;
      $('#' + iid).find('div').scrollLeft(leftPosition);
      $('#' + iid).find('div').scrollTop(topPosition);
   }
   else{
      setwidth();
      initialize();
   }
});

var ghit = false;
function setwidth(){
   var viewportwidth = $( window ).width();
   var viewportheight = $( window ).height();
   var sdiv = $( ".sdiv" );
   for (var i=0; i<sdiv.length; i++){
      $(sdiv[i]).css({width: .98*viewportwidth + 'px'});
      $(sdiv[i]).css("height", .9*viewportheight-50 + 'px');      
   }

   // Detect horizontal overflow on any of the divs
   
   var divs = document.getElementsByTagName('div');
   for (var i=0; i<divs.length; i++){
      if (divs[i].id && divs[i].id.substring(0,3) == 'div'){
         if (divs[i].scrollWidth > divs[i].clientWidth){
            ghit = true;
            break;
         }
      }
   }
   if (!ghit){
      for (var i=0; i<divs.length; i++){
         divs[i].style.height = 'auto';
      }
   }
}

function selfollowing(hsh){
   $('#' + uhash).parent().css('backgroundColor',pColor);
   setwidth();
   initialize();
   if (hsh == 'TheTop'){
      var ypos = $('#container').offset().top;
      window.scrollTo(0,ypos)
   }
   else{
      $('#' + hsh).show();
      $( '#A' + hsh ).focus();
      var ypos = $('#' + hsh).offset().top;
      window.scrollTo(0,ypos)
   }
}

function initialize(){

   // Show all day blocks
   
   var blcks = $('.blck');
   for (var i=0; i<blcks.length; i++){
      blcks[i].style.display = 'block';
   }

   // Detect horizontal overflow on any of the divs
   
   var hit = false;
   var divs = document.getElementsByTagName('div');
   for (var i=0; i<divs.length; i++){
      if (divs[i].id && divs[i].id.substring(0,3) == 'div'){
         if (divs[i].scrollWidth > divs[i].clientWidth || divs[i].scrollHeight > divs[i].clientHeight){
            hit = true;
            break;
         }
      }
   }
   if (hit){
   
      // Set overflow hidden on body. This will prevent it from scrolling
      
      $("body").css("overflow", "hidden");
      document.getElementById('start').style.display = 'inline';
      
      // Hide all day blocks
   
      var blcks = $('.blck');
      for (var i=0; i<blcks.length; i++){
         blcks[i].style.display = 'none';
      }
      var scrlis = $('.scrlis');
      for (var i=0; i<scrlis.length; i++){
         scrlis.show();
      }
   }
   else{
      $("body").css("overflow", "auto");
      document.getElementById('start').style.display = 'none';
      var blcks = $('.sdiv');
      for (var i=0; i<blcks.length; i++){
        blcks[i].style.height = 'auto';
      }
      var scrlis = $('.scrlis');
      for (var i=0; i<scrlis.length; i++){
         scrlis.hide();
      }
   }
   return;
}
  </script>
 </head>
 <body onresize="setwidth(); initialize()">
  <form action="https://ras.papercept.net/conferences/scripts/myprogram.pl" name="myprogram">
   <div id="container">
    <body leftmargin="0" marginheight="0" marginwidth="0" topmargin="0">
     <table border="0" cellpadding="0" cellspacing="0" width="100%">
      <tr>
       <td border="0" height="140" style="background:linear-gradient(to right,#53A8E5,#F78B00);" width="100%">
        <img alt="" border="0" height="140" src="/images/iros/iros24_l.png" style="position:absolute;left:200px;top:0px;"/>
        <img alt="" border="0" height="130" src="/images/iros/iros24_r.png" style="position:absolute;right:200px;top:5px;"/>
       </td>
      </tr>
     </table>
     <table border="0" cellpadding="0" cellspacing="0" height="80%" width="100%">
      <tr>
       <td height="100%" style="background-color:#9F7F59;" width="5">
       </td>
       <td width="5">
       </td>
       <td height="100%" valign="top" width="100%">
        <br/>
        <div class="c" id="TheTop">
         <span id="pTitle">
          <a href="http://iros2024-abudhabi.org" target="_blank">
           <b>
            2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
           </b>
          </a>
          <br/>
         </span>
         <span id="pSubTitle">
          <b>
           October 14-18, 2024, Abu Dhabi, UAE
          </b>
         </span>
         <br/>
         <br/>
        </div>
        <div class="c" style="position: relative">
         <a href="IROS24_ProgramAtAGlanceWeb.html">
          Program at a Glance
         </a>
         <a href="IROS24_ContentListWeb_1.html">
          Monday
         </a>
         <a href="IROS24_ContentListWeb_2.html">
          Tuesday
         </a>
         <a href="IROS24_ContentListWeb_3.html">
          Wednesday
         </a>
         <a href="IROS24_ContentListWeb_4.html">
          Thursday
         </a>
         <a href="IROS24_ContentListWeb_5.html">
          Friday
         </a>
         <a href="IROS24_AuthorIndexWeb.html">
          Author Index
         </a>
         <a href="IROS24_KeywordIndexWeb.html">
          Keyword Index
         </a>
        </div>
        <div class="c">
         <p style="color: gray">
          Last updated on October 5, 2024. This conference program is tentative and subject to change
         </p>
        </div>
        <div class="c">
         <h3>
          Technical Program for Wednesday October 16, 2024
         </h3>
        </div>
        <p class="c">
        </p>
        <div class="c">
         <span style="color:gray ">
          To show or hide the keywords and abstract (text summary) of a paper (if available), click on the paper title
         </span>
         <br/>
         <a href="javascript:openAllAbstracts()" title="Click to open all abstracts">
          Open all abstracts
         </a>
         <a href="javascript:closeAllAbstracts()" title="Click to close all abstracts">
          Close all abstracts
         </a>
        </div>
        <div class="c">
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wepi2t1">
             <b>
              WePI2T1
             </b>
            </a>
           </td>
           <td class="r">
            Room 1
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wepi2t1" title="Click to go to the Program at a Glance">
             <b>
              Robotics and Automation II
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#257267" title="Click to go to the Author Index">
             Sahoo, Soumya Ranjan
            </a>
           </td>
           <td class="r">
            Indian Institute of Technology Kanpur
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t1_01">
             09:00-10:00, Paper WePI2T1.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2377'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robust Backstepping Controller with Adaptive Sliding Mode Observer for a Tilt-Augmented Quadrotor with Uncertainty Using SO(3)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395959" title="Click to go to the Author Index">
             Seshasayanan, Sathyanarayanan
            </a>
           </td>
           <td class="r">
            Indian Institute of Technology Kanpur
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#257267" title="Click to go to the Author Index">
             Sahoo, Soumya Ranjan
            </a>
           </td>
           <td class="r">
            Indian Institute of Technology Kanpur
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2377" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#robust_adaptive_control" title="Click to go to the Keyword Index">
               Robust/Adaptive Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#space_robotics_and_automation" title="Click to go to the Keyword Index">
               Space Robotics and Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The conventional quadrotor is incapable of controlling position and orientation independently. To mitigate this deficiency, we use a tilt-augmented quadrotor for greater mobility in a constrained environment. When the rotors tilt in a tilt-augmented quadrotor, it leads to changes in moment-of-inertia. These changes in the moment-of-inertia and external disturbances introduce uncertainty terms into the model. In this paper, we design an adaptive super-twisting sliding mode observer that guarantees the finite time estimation of uncertain terms with unknown maximum bounds. With the help of this observer, a backstepping controller using SO(3) is developed to establish exponential convergence to the desired trajectory. The exponential convergence of the backstepping controller and finite time convergence of the observer are established using the Lyapunov approach. Experiments are performed to compare the performance of both the existing controller and our proposed controller and corresponding videos are at https://www.youtube.com/watch?v=brTd5UYvciM.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t1_02">
             09:00-10:00, Paper WePI2T1.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2695'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Design, Prototype, and Performance Assessment of an Autonomous Manipulation System for Mars Sample Recovery Helicopter
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#116659" title="Click to go to the Author Index">
             Kalantari, Arash
            </a>
           </td>
           <td class="r">
            NASA JPL
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#286272" title="Click to go to the Author Index">
             Brinkman, Alexander
            </a>
           </td>
           <td class="r">
            Jet Propulsion Laboratory, California Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#164285" title="Click to go to the Author Index">
             Carpenter, Kalind
            </a>
           </td>
           <td class="r">
            Jet Propulsion Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#245051" title="Click to go to the Author Index">
             Gildner, Matthew
            </a>
           </td>
           <td class="r">
            Jet Propulsion Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397964" title="Click to go to the Author Index">
             Jenkins, Justin
            </a>
           </td>
           <td class="r">
            Jet Propulsion Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397962" title="Click to go to the Author Index">
             Newill-Smith, David
            </a>
           </td>
           <td class="r">
            NASA Jet Propulsion Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398007" title="Click to go to the Author Index">
             Seiden, Jeffrey
            </a>
           </td>
           <td class="r">
            NASA Jet Propulsion Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397983" title="Click to go to the Author Index">
             Umali, Allen
            </a>
           </td>
           <td class="r">
            NASA Jet Propulsion Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#146884" title="Click to go to the Author Index">
             McCormick, Ryan
            </a>
           </td>
           <td class="r">
            University of Nebraska - Lincoln
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2695" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#mobile_manipulation" title="Click to go to the Keyword Index">
               Mobile Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#space_robotics_and_automation" title="Click to go to the Keyword Index">
               Space Robotics and Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents the design, prototype, and testing of a 150 g (current best estimate) manipulation system that enables Mars Sample Recovery Helicopter (SRH) concept to autonomously pickup, stow, and drop-off Returnable Sample Tube and Glove Assemblies (RGAs) on the surface of Mars next to the Sample Retrieval Lander (SRL). It consists of a 3 DOF planar Robotic Arm (RA), a novel 2 DOF Gripper with compliant fingers, and a Stow Mechanism. Within the planned Mars Sample Return (MSR) campaign, two SRHs would operate in parallel to retrieve and transfer total of 10 RGAs (146g each) to the SRL, as the backup to the Perseverance Rover. Once SRH arrives at the target pickup location, the RA places the Gripper precisely over the RGA. The gripper grabs and picks up RGAs using a linkage based non-back-drivable mechanism and its compliant fingers. Subsequently, the RA is secured into the stow features, following dislodging rocks and pebbles, by going through a specific sequence of joint trajectories. This ensures the RA and RGA are stable and secure during transit to the SRL while all Manipulation System actuators are powered off. The whole sequence of manipulation is performed autonomously using feedback of a pair of stereo-cameras and absolute encoders. Experimental evaluation of the Manipulation System performance has proved its robustness and consistency in successful RGA pickup, stow, and drop-off.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t1_03">
             09:00-10:00, Paper WePI2T1.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2288'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              The Control Strategy for Vehicle Transfer Robots in RO/RO Terminal Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#365299" title="Click to go to the Author Index">
             Liu, Zhi
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#272950" title="Click to go to the Author Index">
             Xu, Yongkang
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#386772" title="Click to go to the Author Index">
             Zhang, Lin
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#214783" title="Click to go to the Author Index">
             Wang, Shoukun
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#214782" title="Click to go to the Author Index">
             Wang, Junzheng
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2288" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#industrial_robots" title="Click to go to the Keyword Index">
               Industrial Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_based_control" title="Click to go to the Keyword Index">
               Sensor-based Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In the labor-intensive Roll-On/Roll-Off (RO/RO) terminal environment, research on vehicle transport robots with mobility, stability, and reliability is receiving increasing attention. This paper presents a novel control framework for a Straddle-Type Dual-Body vehicle transfer robot. Initially, fine segmentation and processing of point clouds from different areas of the robot are performed, switching perception strategies for different areas based on event triggers. For target pose estimation, a traversal-based point cloud matrix fitting algorithm is designed. Additionally, for loading and unloading operations, a docking controller based on real-time target detection is developed to ensure minimal lateral and angular errors during target docking. Finally, the proposed control framework is validated through operations of the vehicle transfer robot in outdoor RO/RO terminal yards. Experimental results indicate that the average docking error remains within 3 cm, with a 6.5% reduction in docking time under the same conditions. The docking precision and stability performance of the vehicle transfer robot surpass traditional methods, demonstrating satisfactory performance.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t1_04">
             09:00-10:00, Paper WePI2T1.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1152'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Visuo-Tactile Exploration of Unknown Rigid 3D Curvatures by Vision-Augmented Unified Force-Impedance Control
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#256527" title="Click to go to the Author Index">
             Karacan, Kübra
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391308" title="Click to go to the Author Index">
             Zhang, Anran
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#145067" title="Click to go to the Author Index">
             Sadeghian, Hamid
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#212176" title="Click to go to the Author Index">
             Wu, Fan
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#108317" title="Click to go to the Author Index">
             Haddadin, Sami
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1152" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#energy_and_environment_aware_automation" title="Click to go to the Keyword Index">
               Energy and Environment-Aware Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_based_control" title="Click to go to the Keyword Index">
               Sensor-based Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#factory_automation" title="Click to go to the Keyword Index">
               Factory Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Despite recent advancements in torque-controlled tactile robots, integrating them into manufacturing settings remains challenging, particularly in complex environments. Simplifying robotic skill programming for non-experts is crucial for increasing robot deployment in manufacturing. This work proposes an innovative approach, Vision-Augmented Unified Force-Impedance Control (VA-UFIC), aimed at intuitive visuo-tactile exploration of unknown 3D curvatures. VA-UFIC stands out by seamlessly integrating vision and tactile data, enabling the exploration of diverse contact shapes in three dimensions, including point contacts, flat contacts with concave and convex curvatures, and scenarios involving contact loss. A pivotal component of our method is a robust online contact alignment monitoring system that considers tactile error, local surface curvature, and orientation, facilitating adaptive adjustments of robot stiffness and force regulation during exploration. We introduce virtual energy tanks within the control framework to ensure safety and stability, effectively addressing inherent safety concerns in visuo-tactile exploration. Evaluation using a Franka Emika research robot demonstrates the efficacy of VA-UFIC in exploring unknown 3D curvatures while adhering to arbitrarily defined force-motion policies. By seamlessly integrating vision and tactile sensing, VA-UFIC offers a promising avenue for intuitive exploration of complex environments, with potential applications spanning manufacturing, inspection, and beyond.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t1_05">
             09:00-10:00, Paper WePI2T1.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1329'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Time-Optimal TCP and Robot Base Placement for Pick-And-Place Tasks in Highly Constrained Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392788" title="Click to go to the Author Index">
             Wachter, Alexander
            </a>
           </td>
           <td class="r">
            TU Wien
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#115936" title="Click to go to the Author Index">
             Kugi, Andreas
            </a>
           </td>
           <td class="r">
            TU Wien
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#273720" title="Click to go to the Author Index">
             Hartl-Nesic, Christian
            </a>
           </td>
           <td class="r">
            TU Wien
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1329" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#factory_automation" title="Click to go to the Keyword Index">
               Factory Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#industrial_robots" title="Click to go to the Keyword Index">
               Industrial Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#manufacturing__maintenance_and_supply_chains" title="Click to go to the Keyword Index">
               Manufacturing, Maintenance and Supply Chains
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This work proposes a highly parallelized optimization scheme to simultaneously optimize the robot base and tool center point (TCP) placement within a robotic work cell for a sequence of pick-and-place tasks. The placement is optimized for minimum cycle time by considering the scenario holistically, including point-to-point trajectory planning while respecting the kinodynamic constraints of the robot, collision avoidance in highly constrained environments, redundancy in grasp configurations and inverse kinematic solutions, and the cyclic constraint of the process. The proposed algorithm is applied to optimize the robot base and TCP placements in a spatially constrained packaging scenario, demonstrating a cycle time reduction of 41 % compared to state-of-the-art approaches. The results are validated experimentally using a KUKA LBR iiwa with 7 degrees of freedom, where the TCP placement is realized using topology optimization and 3D printing.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t1_06">
             09:00-10:00, Paper WePI2T1.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1563'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Evaluation of the Design of a Tool for the Automated Assembly of Preconfigured Wires
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#253954" title="Click to go to the Author Index">
             Bartelt, Stefanie
            </a>
           </td>
           <td class="r">
            Ruhr-Universität Bochum
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#150737" title="Click to go to the Author Index">
             Kuhlenkötter, Bernd
            </a>
           </td>
           <td class="r">
            Ruhr-Universität Bochum, Chair of Production Systems
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1563" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#factory_automation" title="Click to go to the Keyword Index">
               Factory Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The assembly of control cabinets is highly affected by manual processes. For reasons such as the shortage of skilled workers, there is a considerable need to automate the production steps. The automated wiring of prefabricated wires, which is a mayor process step in the manufacturing, is not automated yet. Besides different sensor technologies, a reliable tool for assembly must be developed. This article discusses the challenges and criteria for the development of such a tool. The most important functions of the tool include the handling of wires with different lengths, cross-sections, and colors as well as the consideration of close mounting positions. Based on a morphological box, a tool concept is derived and validated via tests on a demonstrator.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t1_07">
             09:00-10:00, Paper WePI2T1.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('253'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Image to Patterning: Density-Specified Patterning of Micro-Structured Surfaces with a Mobile Robot
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#315252" title="Click to go to the Author Index">
             Taylor, Annalisa T.
            </a>
           </td>
           <td class="r">
            Northwestern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391194" title="Click to go to the Author Index">
             Landis, Malachi
            </a>
           </td>
           <td class="r">
            Northwestern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391205" title="Click to go to the Author Index">
             Wang, Yaoke
            </a>
           </td>
           <td class="r">
            Northwestern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104560" title="Click to go to the Author Index">
             Murphey, Todd
            </a>
           </td>
           <td class="r">
            Northwestern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391218" title="Click to go to the Author Index">
             Guo, Ping
            </a>
           </td>
           <td class="r">
            Northwestern University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab253" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#intelligent_and_flexible_manufacturing" title="Click to go to the Keyword Index">
               Intelligent and Flexible Manufacturing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#control_architectures_and_programming" title="Click to go to the Keyword Index">
               Control Architectures and Programming
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#engineering_for_robotic_systems" title="Click to go to the Keyword Index">
               Engineering for Robotic Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Micro-structured surfaces possess useful properties such as friction modification, anti-fouling, and hydrophobicity. However, manufacturing these surfaces in an affordable, scalable, and efficient manner remains challenging. Standard coverage methods for surface patterning require precise placement of micro-scale features over meter-scale surfaces with expensive tooling for support. In this work, we address the scalability challenge in surface patterning by designing a mobile robot with a credit-card-sized footprint to generate micro-scale divots using a modulated tool tip. We provide a control architecture with a target feature density to specify surface coverage, eliminating the dependence on individual indentation locations. Our robot produces high-fidelity surface patterns and achieves automatic coverage of a surface from sophisticated target images. We validate an exemplary application of such micro-structured surfaces by controlling the friction coefficients at different locations according to the density of indentations. These results show the potential for compact robots to perform scalable manufacturing of functional surfaces, switching the focus from precision machines to small-footprint devices tasked with matching only the density of features.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t1_08">
             09:00-10:00, Paper WePI2T1.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1667'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Modernising Delivery: A Low-Energy Tethered Package System Using Fixed-Wing Drones
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396005" title="Click to go to the Author Index">
             Ord, Samuel
            </a>
           </td>
           <td class="r">
            RMIT University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#240110" title="Click to go to the Author Index">
             Marino, Matthew
            </a>
           </td>
           <td class="r">
            RMIT University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#140641" title="Click to go to the Author Index">
             Wiley, Timothy Colin
            </a>
           </td>
           <td class="r">
            RMIT University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1667" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#logistics" title="Click to go to the Keyword Index">
               Logistics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#product_design__development_and_prototyping" title="Click to go to the Keyword Index">
               Product Design, Development and Prototyping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#dynamics" title="Click to go to the Keyword Index">
               Dynamics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Fixed-wing Uncrewed Aerial Vehicles (UAVs) can be used for remote package delivery missions by connecting a package to a UAV via a long tether. With a circular flight path at a calculated loiter radius, tether length and orbiting velocity, a package can be lowered to the ground in a quasi-stationary manner. This method achieves this with significantly less energy than hybrid hovering aircraft, which are currently used. UAV operating limitations pose a challenge for this method as ensuring the package stabilises such that it can be safely deployed without damage or posing a risk to people or property is challenging in most environmental conditions. To offer improved tether and package stabilisation, we introduce a novel Mid-Tether Drag Device (MTDD) that improves the stability of the package and enables compliant delivery missions within regulatory frameworks.	We present a mathematical model of the delivery with a UAV and MTDD. We verify the accuracy of our model with real-world flight tests in low wind conditions without the MTDD, which have not been previously conducted at this scale in literature. Further validation is presented with flight tests at a flight range using a UAV instrumented with a package deployment system with both UAV and package tracking data acquisition. Our work enhances the abilities of UAVs to conduct aerial package delivery.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t1_09">
             09:00-10:00, Paper WePI2T1.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2062'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              IDF-MFL: Infrastructure-Free and Drift-Free Magnetic Field Localization for Mobile Robot
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#281401" title="Click to go to the Author Index">
             Shen, Hongming
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#253105" title="Click to go to the Author Index">
             Wu, Zhenyu
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#339463" title="Click to go to the Author Index">
             Wang, Wei
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#311043" title="Click to go to the Author Index">
             Lyu, Qiyang
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396410" title="Click to go to the Author Index">
             Zhou, Huiqin
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100565" title="Click to go to the Author Index">
             Wang, Danwei
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2062" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#logistics" title="Click to go to the Keyword Index">
               Logistics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#factory_automation" title="Click to go to the Keyword Index">
               Factory Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In recent years, infrastructure-based localization methods have achieved significant progress thanks to their reliable and drift-free localization capability. However, the pre-installed infrastructures suffer from inflexibilities and high maintenance costs. This poses an interesting problem of how to develop a drift-free localization system without using the pre-installed infrastructures. In this paper, an infrastructure-free and drift-free localization system is proposed using the ambient magnetic field (MF) information, namely IDF-MFL. IDF-MFL is infrastructure-free thanks to the high distinctiveness of the ambient MF information produced by inherent ferromagnetic objects in the environment, such as steel and reinforced concrete structures of buildings, and underground pipelines. The MF-based localization problem is defined as a stochastic optimization problem with the consideration of the non-Gaussian heavy-tailed noise introduced by MF measurement outliers (caused by dynamic ferromagnetic objects), and an outlier-robust state estimation algorithm is derived to find the optimal distribution of robot state that makes the expectation of MF matching cost achieves its lower bound. The proposed method is evaluated in multiple scenarios, including experiments on high-fidelity simulation, and real-world environments. The results demonstrate that the proposed method can achieve high-accuracy, reliable, and real-time localization without any pre-installed infrastructures.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t1_10">
             09:00-10:00, Paper WePI2T1.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1402'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Data-Driven Modeling of Cable Slab Dynamics Via Neural Networks
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#194102" title="Click to go to the Author Index">
             Al-Rawashdeh, Yazan
            </a>
           </td>
           <td class="r">
            Memorial University of Newfoundland
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#234351" title="Click to go to the Author Index">
             Al Saaideh, Mohammad
            </a>
           </td>
           <td class="r">
            Memorial University of Newfoundland
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#290998" title="Click to go to the Author Index">
             Pumphrey, Michael Joseph
            </a>
           </td>
           <td class="r">
            Memorial University of Newfoundland
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#257001" title="Click to go to the Author Index">
             Alatawneh, Natheer
            </a>
           </td>
           <td class="r">
            Cysca Technologies
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#132899" title="Click to go to the Author Index">
             Al Janaideh, Mohammad
            </a>
           </td>
           <td class="r">
            University of Guelph
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1402" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#semiconductor_manufacturing" title="Click to go to the Keyword Index">
               Semiconductor Manufacturing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#actuation_and_joint_mechanisms" title="Click to go to the Keyword Index">
               Actuation and Joint Mechanisms
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#force_control" title="Click to go to the Keyword Index">
               Force Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             A novel method for analyzing the dynamics and bend geometry of a cable slab via trained neural networks is introduced. Neural networks are trained from real-time visual feedback capture via a high-speed camera during cyclic motion to track the positions of multiple markers affixed to the cable slab through image processing techniques. Experimental parameters are systematically varied to ensure a diverse range of training patterns. Consequently, two distinct data-driven neural network models are developed: a coupled model and a decoupled model. These models accurately predict the two-dimensional positions of the markers, even during non-cyclic motion profiles. Subsequently, the marker positions are utilized as waypoints to generate a cubic spline curve with time-varying coefficients, approximating the spatiotemporal solution of the cable slab dynamics. Notably, this spline can be segmented into smaller sections tailored to specific research objectives. Experimental results validate the effectiveness of the proposed methodology.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t1_11">
             09:00-10:00, Paper WePI2T1.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('564'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              One Problem, One Solution: Unifying Robot Design and Cell Layout Optimization
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#367846" title="Click to go to the Author Index">
             Baumgärtner, Jan
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#367847" title="Click to go to the Author Index">
             Puchta, Alexander
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#298566" title="Click to go to the Author Index">
             Fleischer, Jürgen
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology (KIT)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab564" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#industrial_robots" title="Click to go to the Keyword Index">
               Industrial Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The task-specific optimization of robotic systems has since the inception of the field been divided into the optimization of the robot and the optimization of the layout of its workstations. In this letter, we argue that these two problems are interdependent and should be treated as such. To this end, we present a unified problem formulation that enables for the simultaneous optimization of both the robot kinematics and the workstation layout. We demonstrate the effectiveness of our approach by jointly optimizing a robotic milling system. To compare our approach to the state of the art, we optimize the robot's kinematics and layout separately. The results show that our approach outperforms the state of the art and that simultaneous optimization leads to up to eight times better solutions.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t1_12">
             09:00-10:00, Paper WePI2T1.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('428'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Soft Task Planning with Hierarchical Temporal Logic Specifications
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#330115" title="Click to go to the Author Index">
             Chen, Ziyang
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#304443" title="Click to go to the Author Index">
             Zhou, Zhangli
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#348815" title="Click to go to the Author Index">
             Li, Lin
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#206291" title="Click to go to the Author Index">
             Kan, Zhen
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab428" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#formal_methods_in_robotics_and_automation" title="Click to go to the Keyword Index">
               Formal Methods in Robotics and Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This works exploits soft constraints in linear temporal logic task planning to enhance the agent’s capability in handling potentially conflicting or even infeasible tasks. Different from most existing works that focus on sticking to the original plan and trying to find a relaxed plan if the workspace does not permit, we augment the soft constraints to represent possible candidate sub-tasks that can be selected to fulfill the global task. Specifically, a hierarchical temporal logic specification is developed to represent LTL tasks with soft constraints and preferences. The hierarchical structure consists of an outer and inner layer, where the outer layer uses co-safe LTL to specify the task-level specifications and the inner layer specifies the low- level task-related atomic propositions via soft constraints. To cope with the hierarchical temporal logic specification, a hierarchical iterative search (HIS) algorithm is developed, which incrementally searches feasible atomic propositions and automaton states, and returns a task plan with minimum cost. Rigorous analysis shows that HIS based planning is feasible (i.e., the generated plan is applicable and satisfactory with respect to the task specification) and optimal (i.e, with minimum cost). Extensive simulation demonstrates the effectiveness of the proposed soft task planning approach.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t1_13">
             09:00-10:00, Paper WePI2T1.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2403'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Efficiently Obtaining Reachset Conformance for the Formal Analysis of Robotic Contact Tasks
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375035" title="Click to go to the Author Index">
             Tang, Chencheng
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#114506" title="Click to go to the Author Index">
             Althoff, Matthias
            </a>
           </td>
           <td class="r">
            Technische Universität München
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2403" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#formal_methods_in_robotics_and_automation" title="Click to go to the Keyword Index">
               Formal Methods in Robotics and Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Formal verification of robotic tasks requires a simple yet conformant model of the used robot. We present the first work on generating reachset conformant models for robotic contact tasks considering hybrid (mixed continuous and discrete) dynamics. Reachset conformance requires that the set of reachable outputs of the abstract model encloses all previous measurements to transfer safety properties. Aiming for industrial applications, we describe the system using a simple hybrid automaton with linear dynamics. We inject non-determinism into the continuous dynamics and the discrete transitions, and we optimally identify all model parameters together with the non-determinism required to capture the recorded behaviors. Using two 3-DOF robots, we show that our approach can effectively generate models to capture uncertainties in system behavior and substantially reduce the required testing effort in industrial applications.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t1_14">
             09:00-10:00, Paper WePI2T1.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2162'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Stick Roller: Precise In-Hand Stick Rolling with a Sample-Efficient Tactile Model
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#281098" title="Click to go to the Author Index">
             Du, Yipai
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397902" title="Click to go to the Author Index">
             Zhou, Pokuang
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100161" title="Click to go to the Author Index">
             Wang, Michael Yu
            </a>
           </td>
           <td class="r">
            Mywang@gbu.edu.cn
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#270486" title="Click to go to the Author Index">
             Lian, Wenzhao
            </a>
           </td>
           <td class="r">
            Google X
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#184771" title="Click to go to the Author Index">
             She, Yu
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2162" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#contact_modeling" title="Click to go to the Keyword Index">
               Contact Modeling
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#in_hand_manipulation" title="Click to go to the Keyword Index">
               In-Hand Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In-hand manipulation is challenging in robotics due to the intricate contact dynamics and high degrees of control freedom. Precise manipulation with high accuracy often requires tactile perception, which adds further complexity to the system. Despite the challenges in perception and control, the rolling stick problem is an essential and practical motion primitive with many demanding industrial applications. This work aims to learn the high-resolution tactile dynamics of the rolling stick. Specifically, we try manipulating a small stick using the Allegro hand equipped with the Digit vision-based tactile sensor. The learning framework includes an action filtering module, tactile perception module, and learning with uncertainty module, all designed to operate in low data regimes. With only 2.3% amount of data and 5.7% model complexity of previous similar work, our learned contact dynamics model achieves better grasp stability, sub-millimeter precision, and promising zero-shot generalizability across novel objects. The proposed framework demonstrates the potential for precise in-hand manipulation with tactile feedback on real hardware. The project source code is available at: https://github.com/duyipai/Allegro Digit.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t1_15">
             09:00-10:00, Paper WePI2T1.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1653'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robotic Measurement for Electrical Property of Polymers by Force-Sensing Robot Toward Materials Lab-Automation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#151588" title="Click to go to the Author Index">
             Asano, Yuki
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106350" title="Click to go to the Author Index">
             Okada, Kei
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#338746" title="Click to go to the Author Index">
             Shiomi, Junichiro
            </a>
           </td>
           <td class="r">
            University of Tokyo
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1653" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#engineering_for_robotic_systems" title="Click to go to the Keyword Index">
               Engineering for Robotic Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#software_hardware_integration_for_robot_systems" title="Click to go to the Keyword Index">
               Software-Hardware Integration for Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             With the background of research on materials laboratory automation, this study aims to construct an automation system for measuring dielectric property, which is an electrical property of materials. The automation system is composed of the combination of a manipulation by a forcesensing robot and a control system for the measurement instrument. As challenges for the automation system, we worked on stabilizing a polymer film placement during insertion into the measurement instrument, implementing a communication control system between different platforms, and constructing a polymer film transfer environment. In the measurement experiment using the automation system, it was confirmed that the dielectric properties could be measured as well as that of a human.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t1_16">
             09:00-10:00, Paper WePI2T1.16
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3291'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Lang2LTL-2: Grounding Spatiotemporal Navigation Commands Using Large Language and Vision-Language Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#218879" title="Click to go to the Author Index">
             Liu, Jason Xinyu
            </a>
           </td>
           <td class="r">
            Brown University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#192198" title="Click to go to the Author Index">
             Shah, Ankit
            </a>
           </td>
           <td class="r">
            Brown University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106428" title="Click to go to the Author Index">
             Konidaris, George
            </a>
           </td>
           <td class="r">
            Brown University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#136380" title="Click to go to the Author Index">
             Tellex, Stefanie
            </a>
           </td>
           <td class="r">
            Brown
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#192313" title="Click to go to the Author Index">
             Paulius, David
            </a>
           </td>
           <td class="r">
            Brown University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3291" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#formal_methods_in_robotics_and_automation" title="Click to go to the Keyword Index">
               Formal Methods in Robotics and Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Grounding spatiotemporal navigation commands to structured task specifications enables autonomous robots to understand a broad range of natural language and solve long-horizon tasks with safety guarantees. Prior works mostly focus on grounding spatial or temporally extended language for robots. We propose Lang2LTL-2, a modular system that leverages pretrained large language and vision-language models and multimodal semantic information to ground spatiotemporal navigation commands in novel city-scaled environments without retraining. Lang2LTL-2 achieves 93.53% language grounding accuracy on a dataset of 21,780 semantically diverse natural language commands in unseen environments. We run an ablation study to validate the need for different modalities. We also show that a physical robot equipped with the same system without modification can execute 50 semantically diverse natural language commands in both indoor and outdoor environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t1_17">
             09:00-10:00, Paper WePI2T1.17
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('409'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Scheduling of Robotic Cellular Manufacturing Systems with Timed Petri Nets and Reinforcement Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#389806" title="Click to go to the Author Index">
             Yao, ZhuTao
            </a>
           </td>
           <td class="r">
            Nanjing University of Sci &amp; Tech
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#279869" title="Click to go to the Author Index">
             Huang, Bo
            </a>
           </td>
           <td class="r">
            Nanjing University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#389916" title="Click to go to the Author Index">
             Lv, Jianyong
            </a>
           </td>
           <td class="r">
            Nanjing University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392247" title="Click to go to the Author Index">
             Lu, Xiaoyu
            </a>
           </td>
           <td class="r">
            Nanjing University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#416643" title="Click to go to the Author Index">
             Cui, MeiJi
            </a>
           </td>
           <td class="r">
            Nanjing University of Sciencen and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#416644" title="Click to go to the Author Index">
             Yu, ShaoHua
            </a>
           </td>
           <td class="r">
            Nanjing University of Sciencen and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab409" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#planning__scheduling_and_coordination" title="Click to go to the Keyword Index">
               Planning, Scheduling and Coordination
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#petri_nets_for_automation_control" title="Click to go to the Keyword Index">
               Petri Nets for Automation Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#intelligent_and_flexible_manufacturing" title="Click to go to the Keyword Index">
               Intelligent and Flexible Manufacturing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Scheduling of robotic cellular manufacturing (RCM) systems belongs to NP-hard problems. In this paper, we propose a Petri-net-based Q-learning scheduling method to efficiently schedule RCM systems. First, we use generalized and place-timed Petri nets to model RCM systems, since they can naturally and concisely model system structures, such as conflict, concurrency, and synchronization. Then, we formulate a reinforcement learning method with a sparse Q-table to evaluate state-transition pairs of the net's reachability graph. It uses the negative transition firing time as a reward for an action selection and a large penalty for any encountered deadlock, and it balances the state exploration the experience exploitation using a dynamic epsilon-greedy policy to update the state values with an accumulative reward. It provides a new method to efficiently schedule such systems based on Petri nets. Some benchmark RCM systems are tested with the proposed method and popular PN-based online dispatching rules, such as FIFO and SRPT. Simulation results indicate that the designed method can schedule RCM systems as quickly as the online dispatching rules while outperforming them in terms of result quality.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wepi2t2">
             <b>
              WePI2T2
             </b>
            </a>
           </td>
           <td class="r">
            Room 2
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wepi2t2" title="Click to go to the Program at a Glance">
             <b>
              Robotics in Healthcare I
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#190490" title="Click to go to the Author Index">
             Alambeigi, Farshid
            </a>
           </td>
           <td class="r">
            University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#104138" title="Click to go to the Author Index">
             Tavakoli, Mahdi
            </a>
           </td>
           <td class="r">
            University of Alberta
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t2_01">
             09:00-10:00, Paper WePI2T2.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2962'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Feasibility Study of a Soft, Low-Cost, 6-Axis Load Cell for Haptics
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398807" title="Click to go to the Author Index">
             Veliky, Madison
            </a>
           </td>
           <td class="r">
            Vanderbilt University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#237899" title="Click to go to the Author Index">
             Johnston, Garrison
            </a>
           </td>
           <td class="r">
            Vanderbilt University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398825" title="Click to go to the Author Index">
             Yildiz, Ahmet
            </a>
           </td>
           <td class="r">
            Vanderbilt University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105803" title="Click to go to the Author Index">
             Simaan, Nabil
            </a>
           </td>
           <td class="r">
            Vanderbilt University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2962" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#haptics_and_haptic_interfaces" title="Click to go to the Keyword Index">
               Haptics and Haptic Interfaces
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#surgical_robotics__laparoscopy" title="Click to go to the Keyword Index">
               Surgical Robotics: Laparoscopy
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Haptic devices have shown to be valuable in supplementing surgical training, especially when providing haptic feedback based on user performance metrics such as wrench applied by the user on the tool. However, current 6-axis force/torque sensors are prohibitively expensive. This paper presents the design and calibration of a low-cost, six-axis force/torque sensor specially designed for laparoscopic haptic training applications. The proposed design uses Hall-effect sensors to measure the change in the position of magnets embedded in a silicone layer that results from an applied wrench to the device. Preliminary experimental validation demonstrates that these sensors can achieve an accuracy of 0.45 N and 0.014 Nm, and a theoretical XY range of +/-50N, Z range of +/-20N, and torque range of +/-0.2Nm. This study indicates that the proposed low-cost 6-axis force/torque sensor can accurately measure user force and provide useful feedback during laparoscopic training on a haptic device.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t2_02">
             09:00-10:00, Paper WePI2T2.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('570'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Dung Beetle Optimizer-Based High-Precision Localization for Magnetic-Controlled Capsule Robot
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#348627" title="Click to go to the Author Index">
             Zeng, Zijin
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#332990" title="Click to go to the Author Index">
             Wang, Fengwu
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#364425" title="Click to go to the Author Index">
             Li, Chan
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#351583" title="Click to go to the Author Index">
             Tan, Menglu
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#374408" title="Click to go to the Author Index">
             Wang, Shengyuan
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#132243" title="Click to go to the Author Index">
             Feng, Lin
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab570" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             As a medical microrobot, magnetic-controlled capsule robots (MCRs) are pivotal in internal diagnostics and therapeutic interventions. Achieving high-precision localization of MCRs is essential for the successful execution of medical procedures. This paper introduces a novel Dung Beetle Optimizer (DBO)-based localization method for MCR, demonstrating high localization accuracy and flexibility in static magnetic field environments and under the control of existing magnetic control systems. With the aid of an FPGA-based parallel measurement system, it can effectively eliminate measurement distortion. The average position and orientation errors could achieve 0.53 mm and 0.60° when performing 600 iterations per computation, and further increasing the number of iterations reduces the errors, which is superior to existing methods. Experimental validations underscore the method’s robust performance and compatibility with existing magnetic control systems.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t2_03">
             09:00-10:00, Paper WePI2T2.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('781'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              3D Ultrasound Image Acquisition and Diagnostic Analysis of the Common Carotid Artery with a Portable Robotic Device
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393949" title="Click to go to the Author Index">
             Tan, Longyue
            </a>
           </td>
           <td class="r">
            Institute of Automation, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#350603" title="Click to go to the Author Index">
             Deng, Zhaokun
            </a>
           </td>
           <td class="r">
            Institute of Automation, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#363717" title="Click to go to the Author Index">
             Hao, Mingrui
            </a>
           </td>
           <td class="r">
            Institute of Automation, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#363719" title="Click to go to the Author Index">
             Zhang, Pengcheng
            </a>
           </td>
           <td class="r">
            Institute of Automation, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#350606" title="Click to go to the Author Index">
             Hou, Xilong
            </a>
           </td>
           <td class="r">
            Centre for Artificial Intelligence and Robotics, Hong Kong Insti
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#363720" title="Click to go to the Author Index">
             Chen, Chen
            </a>
           </td>
           <td class="r">
            Institute of Automation, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393944" title="Click to go to the Author Index">
             Gu, Xiaolin
            </a>
           </td>
           <td class="r">
            Lingshu Medical Company
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#255507" title="Click to go to the Author Index">
             Zhou, Xiao-Hu
            </a>
           </td>
           <td class="r">
            Institute of Automation, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#108240" title="Click to go to the Author Index">
             Hou, Zeng-Guang
            </a>
           </td>
           <td class="r">
            Chinese Academy of Science
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#194523" title="Click to go to the Author Index">
             Wang, Shuangyi
            </a>
           </td>
           <td class="r">
            Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab781" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_medical_robotics" title="Click to go to the Keyword Index">
               Computer Vision for Medical Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Ultrasound (US) imaging of the carotid artery (CA) is a non-invasive diagnostic tool widely used in the medical field to assess the condition of the carotid artery, thereby predicting the risk of cardiovascular and cerebrovascular diseases. However, implementing this method in primary healthcare can be challenging due to the requirement for professionally trained sonographers. With the adoption of US robotic devices,the probe pose can be acquired while scanning, offering the possibility for 3D reconstruction and providing analyses that are not dependent on operator experience. This article introduces a method to semi-automatically acquire serialized ultrasound images of the common carotid artery (CCA). The method involves a specially designed robotic device built with a 6-RSU parallel mechanism, which is controlled according to robot pos, force sensor data and synchronous ultrasound images. To validate the images acquired, a method is proposed to segment the intima-media of CCA and calculate the intima-media thickness (IMT), which is a key indicator for cerebrovascular events prediction. After that, we propose an algorithm to reconstruct CCA into a 3D voxel with patient movement and cardiac cycle compensated, and a longitudinal view US image of CCA can be resliced from the voxel. The methods are tested on human subjects and the results indicate that the system and workflow can provide both quantitative and qualitative information of CCA for further diagnosis.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t2_04">
             09:00-10:00, Paper WePI2T2.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1087'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robot-Enabled Machine Learning-Based Diagnosis of Gastric Cancer Polyps Using Partial Surface Tactile Imaging
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#345778" title="Click to go to the Author Index">
             Kapuria, Siddhartha
            </a>
           </td>
           <td class="r">
            University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#347101" title="Click to go to the Author Index">
             Bonyun, Jeff
            </a>
           </td>
           <td class="r">
            University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#354989" title="Click to go to the Author Index">
             Kulkarni, Yash
            </a>
           </td>
           <td class="r">
            The University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#313482" title="Click to go to the Author Index">
             Ikoma, Naruhiko
            </a>
           </td>
           <td class="r">
            The University of Texas MD Anderson Cancer Center
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#133556" title="Click to go to the Author Index">
             Chinchali, Sandeep
            </a>
           </td>
           <td class="r">
            The University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#190490" title="Click to go to the Author Index">
             Alambeigi, Farshid
            </a>
           </td>
           <td class="r">
            University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1087" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_medical_robotics" title="Click to go to the Keyword Index">
               Computer Vision for Medical Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_sensors_and_actuators" title="Click to go to the Keyword Index">
               Soft Sensors and Actuators
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, to collectively address the existing limitations on endoscopic diagnosis of Advanced Gastric Cancer (AGC) Tumors, for the first time, we propose (i) utilization and evaluation of our recently developed Vision-based Tactile Sensor (VTS), and (ii) a complementary Machine Learning (ML) algorithm for classifying tumors using their textural features. Leveraging a seven DoF robotic manipulator and unique custom-designed and additively-manufactured realistic AGC tumor phantoms, we demonstrated the advantages of automated data collection using the VTS addressing the problem of data scarcity and biases encountered in traditional ML-based approaches. Our synthetic-data-trained ML model was successfully evaluated and compared with traditional ML models utilizing various statistical metrics even under mixed morphological characteristics and partial sensor contact.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t2_05">
             09:00-10:00, Paper WePI2T2.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1515'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Development of a Low Pressure Pouch Sensor for Force Measurement in Colonoscopy Procedures
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#202141" title="Click to go to the Author Index">
             Borvorntanajanya, Korn
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#377932" title="Click to go to the Author Index">
             Ahmed, Jabed F
            </a>
           </td>
           <td class="r">
            Department of Surgery &amp; Cancer, Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#238162" title="Click to go to the Author Index">
             Runciman, Mark
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#168612" title="Click to go to the Author Index">
             Franco, Enrico
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#184609" title="Click to go to the Author Index">
             Patel, Nisha
            </a>
           </td>
           <td class="r">
            Imperial College London, Department of Surgery and Cancer
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#108147" title="Click to go to the Author Index">
             Rodriguez y Baena, Ferdinando
            </a>
           </td>
           <td class="r">
            Imperial College, London, UK
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1515" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_sensors_and_actuators" title="Click to go to the Keyword Index">
               Soft Sensors and Actuators
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a novel pneumatic pouch sensor, designed to mount on a colonoscope, that can effectively estimate the contact forces with the environment. The pouch sensor was designed to maximize the sensing range, and it was fabricated using a 2D laser welding technique from our track record. A flow compensation (FC) algorithm was introduced to improve the accuracy of the sensor in the presence of static load. The proposed system can reliably measure external forces up to 9.5 N with high repeatability. The system allows discriminating between different levels of force which are typically associated with increasing patient discomfort in colonoscopy: low (0-4 N), medium (4-6 N), and high (&gt;6 N). This system achieves over 80% accuracy in comparison to the ground truth under steady state conditions (P ≤ 0.05) and maintains over 68% accuracy in dynamic scenarios. Index Terms—Force measurement, Pneumatic sensor, Colonoscopy.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t2_06">
             09:00-10:00, Paper WePI2T2.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1788'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Thermal Ablation Therapy Control with Tissue Necrosis-Driven Temperature Feedback Enabled by Neural State Space Model with Extended Kalman Filter
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#192021" title="Click to go to the Author Index">
             Murakami, Ryo
            </a>
           </td>
           <td class="r">
            Worcester Polytechnic Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#191768" title="Click to go to the Author Index">
             Mori, Satoshi
            </a>
           </td>
           <td class="r">
            NA
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#192441" title="Click to go to the Author Index">
             Zhang, Haichong
            </a>
           </td>
           <td class="r">
            Worcester Polytechnic Institute
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1788" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#model_learning_for_control" title="Click to go to the Keyword Index">
               Model Learning for Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_medical_robotics" title="Click to go to the Keyword Index">
               Computer Vision for Medical Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Thermal ablation therapy is a major minimally invasive treatment. One of the challenges is that the targeted region and therapeutic progression are often invisible to clinicians, requiring feedback provided in numerical information or imaging. Several emerging imaging modalities offer visualization of the ablation-induced necrosis formation; however, relying solely on necrosis monitoring can result in tissue overheating and endangering patients. Some of the necrosis monitoring modalities are known for their capabilities in temperature sensing, but the principles on which they are based have several limitations, such as sensitivity to the tissue motion and their environment. In this study, we propose a necrosis progression-based temperature estimation technique as an added safety feature for avoiding overheating. This model-based method does not require additional sensing hardware. It is designed to work as an independent estimator or a complimentary estimation component with other thermometers for improved robustness. For this objective, the Neural State Space model is used to approximate the ablation therapy, whose theoretical models involve nonlinear partial differential equations. Then, the Extended Kalman Filter is designed based on the model. The simulation study shows the estimation module robustly estimates the tissue temperature under several types of noise. The maximum estimation error observed before terminating ablation was around 1 K, and the desired safety feature was successfully demonstrated. The estimator is expected to be used in a variety of necrosis monitoring modalities to guarantee more precise and safer treatment. More ambitiously, the architecture with the Neural State Space model and Extended Kalman Filter is generalizable to other medical/biological procedures involving nonlinear and patient/environment-specific physics and even to procedures having no reliable theoretical models.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t2_07">
             09:00-10:00, Paper WePI2T2.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1979'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Towards Robotised Palpation for Cancer Detection through Online Tissue Viscoelastic Characterisation with a Collaborative Robotic Arm
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#378278" title="Click to go to the Author Index">
             Beber, Luca
            </a>
           </td>
           <td class="r">
            University of Trento
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#231998" title="Click to go to the Author Index">
             Lamon, Edoardo
            </a>
           </td>
           <td class="r">
            University of Trento
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#226152" title="Click to go to the Author Index">
             Moretti, Giacomo
            </a>
           </td>
           <td class="r">
            University of Trento
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#112613" title="Click to go to the Author Index">
             Fontanelli, Daniele
            </a>
           </td>
           <td class="r">
            University of Trento
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#154562" title="Click to go to the Author Index">
             Saveriano, Matteo
            </a>
           </td>
           <td class="r">
            University of Trento
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#115820" title="Click to go to the Author Index">
             Palopoli, Luigi
            </a>
           </td>
           <td class="r">
            University of Trento
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1979" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#compliance_and_impedance_control" title="Click to go to the Keyword Index">
               Compliance and Impedance Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper introduces a new method for online estimating the penetration of the end-effector and the viscoelastic properties of a soft body, by means of palpation exams using a collaborative robotic arm. The estimator is based on the dimensionality reduction method that simplifies the nonlinear Hunt-Crossley model. In addition, in our algorithm, the model parameters can be found without a force sensor, leveraging only the robotic arm controller data. To achieve online estimation, an extended Kalman filter is employed, which embeds the dynamic contact model. The algorithm is tested with various types of silicone, a material that resembles biological tissues, including samples with hard intrusions to simulate cancerous cells within a softer tissue. The results indicate that this technique can accurately determine the model parameters and estimate the penetration of the end-effector into the soft body. These promising preliminary results demonstrate the potential for robots to serve as an effective tool for early-stage cancer diagnostics.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t2_08">
             09:00-10:00, Paper WePI2T2.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1987'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Wirelessly Actuated Rotation-Free Magnetic Motor
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392377" title="Click to go to the Author Index">
             Harman, Umur Ulas
            </a>
           </td>
           <td class="r">
            University of Sheffield
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397465" title="Click to go to the Author Index">
             Hafez, Ahmed
            </a>
           </td>
           <td class="r">
            University of Sheffield
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#296346" title="Click to go to the Author Index">
             Duffield, Cameron
            </a>
           </td>
           <td class="r">
            The University of Sheffield
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#378568" title="Click to go to the Author Index">
             Zhao, Zihan
            </a>
           </td>
           <td class="r">
            The University of Sheffield
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395761" title="Click to go to the Author Index">
             Dixon, Luke
            </a>
           </td>
           <td class="r">
            University of Sheffield
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101388" title="Click to go to the Author Index">
             Rus, Daniela
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#113599" title="Click to go to the Author Index">
             Miyashita, Shuhei
            </a>
           </td>
           <td class="r">
            University of Sheffield
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1987" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#micro_nano_robots" title="Click to go to the Keyword Index">
               Micro/Nano Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper addresses the challenge of actuating millimetre-sized motors, which are wirelessly driven by external magnetic fields. Traditional approaches, relying on rotating magnetic fields, often inadvertently cause the entire robot – especially if it’s small and lightweight – to rotate, instead of a specified shaft in the motor. To overcome this issue, our study introduces a novel mechanism that leverages symmetrically configured magnetic motors to cancel out the torques, thus preventing unwanted rotation of the robot. This is achieved by utilizing a magnetic field along a single axis to induce rotational movement. The design features two millimetre-sized rotating magnets that interact to achieve a 90 degrees rotation, complemented by an external magnetic field that accomplishes the remaining 270 degrees, thus completing a full rotation. Furthermore, we demonstrate that applying a perpendicularly oriented magnetic field can inversely affect the motor’s rotation direction. A proof-of-concept experiment employing this mechanism successfully actuated a gripper in a water tank while it is free-floating, showcasing its potential for enhancing robotic applications at the sub-centimeter scale, where the small net torque of a miniature motor is essential.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t2_09">
             09:00-10:00, Paper WePI2T2.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2081'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Development of Five-Finger Hand-Type Robotic Forceps for Laparoscopic Gastrointestinal Surgery
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396235" title="Click to go to the Author Index">
             Wakamatsu, Hiroyuki
            </a>
           </td>
           <td class="r">
            Yokohama National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394899" title="Click to go to the Author Index">
             Kobayashi, Ibuki
            </a>
           </td>
           <td class="r">
            Yokohama National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396246" title="Click to go to the Author Index">
             Nagase, Yuya
            </a>
           </td>
           <td class="r">
            Yokohama National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#121763" title="Click to go to the Author Index">
             Kato, Ryu
            </a>
           </td>
           <td class="r">
            Yokohama National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#236666" title="Click to go to the Author Index">
             Mukai, Masaya
            </a>
           </td>
           <td class="r">
            Tokai University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2081" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#surgical_robotics__laparoscopy" title="Click to go to the Keyword Index">
               Surgical Robotics: Laparoscopy
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Compared to open surgery, in laparoscopic surgery, with its smaller incisions, is superior in terms of less invasiveness, appearance, and postoperative hospital stay. However, the forceps used in laparoscopic surgery have small end effectors, making it difficult to manipulate large organs with just one forceps and resulting in low surgical efficiency. In addressing these issues, research is being conducted to robotic hands referencing Hand-Assisted Laparoscopic Surgery (HALS). In previous research, the posture when using proposed instrument put great physical strain on the surgeon. Therefore, in this study, we aim to develop a surgical instrument that minimizes the physical strain on the operating surgeon, allowing insertion through small incisions and handling large organs. We propose the instrument with five-fingered robotic hand and gun grip-type input device. First, the five-fingered robotic hand achieve three actions, pinch, grasp, and exclusion, and is insertable through an incision of less than 20-mm with folding. Second, the surgeon holds the input device by grasping the grip part with the ring finger and little finger and operating the robotic hand with the thumb, index finger, and middle finger. In addition, the surgeon uses his arm to manipulate the wrist part by changing the angle of the joint of the input device. Because of using the angle of the surgeon’s fingers for control input the surgeon can intuitively manipulate. We conducted a comparative experiment between the proposed robotic forceps and conventional forceps for sigmoidectomy, a typical surgery targeting the digestive organ. In this experiment, we verified whether the method with the proposed robotic forceps would shorten the surgical time and investigated the degree of burden on the posture when using the proposed robotic forceps. The results of an experiment simulating sigmoidectomy showed that the proposed instrument could shorten the surgical time. The reduced working time is likely because there is no longer a need to give instructions to the assistant or cooperate with the assistant. Moreover, the task completion time for moving the instrument and grasping was also reduced. When grasping and pulling the large intestine and applying tension to the membrane tissue, it must be grasped with contact at multiple points. However, since conventional forceps can only grasp one point, it is necessary to use two forceps, and the movement of the instrument and the grasping action must be performed twice. On the other hand, since the proposed robotic forceps has a large surface and multiple fingers, achieving multi-point contact with a single movement is possible, and may have reduced the task completion time. In addition, we confirmed that the physical burden while using the robotic forceps was comparable to that of conventional forceps. This demonstrated the potential of robotic forceps to improve operative efficiency with a little physical strain.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t2_10">
             09:00-10:00, Paper WePI2T2.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2529'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Novel Approach for Precise Tissue Tracking in Breast Lumpectomy
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398299" title="Click to go to the Author Index">
             Aliyari, Yeganeh
            </a>
           </td>
           <td class="r">
            University of Alberta
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#268416" title="Click to go to the Author Index">
             Afshar, Mehrnoosh
            </a>
           </td>
           <td class="r">
            University of Alberta
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398308" title="Click to go to the Author Index">
             Wiebe, Ericka
            </a>
           </td>
           <td class="r">
            University of Alberta
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398313" title="Click to go to the Author Index">
             Peiris, Lashan
            </a>
           </td>
           <td class="r">
            University of Alberta
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104138" title="Click to go to the Author Index">
             Tavakoli, Mahdi
            </a>
           </td>
           <td class="r">
            University of Alberta
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2529" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#simulation_and_animation" title="Click to go to the Keyword Index">
               Simulation and Animation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Breast cancer is one of the most common cancers in the female population and can be treated surgically in the early stages with a lumpectomy technique. In the context of breast lumpectomy procedures, accurately tracking tumours presents a critical challenge worsened by various sources of anatomical deformations, including breathing, tissue cutting, and ultrasound probe pressure. To address this, we explore how a realistic tissue deformation simulator can enhance the precision of locating internal targets by accurately assessing the deformation applied to a preoperative model of the breast, considering the distinct mechanical properties of both the breast tissue and the tumour within it. Our method uses advanced artificial intelligence techniques by combining a generative variation autoencoder (GNN-VAE) and an updating method called ensemble smoother with multiple data assimilation (ES-MDA), creating a dynamic model based exclusively on surface node data to update all nodes within the tissue. By leveraging a realistic tissue deformation simulator, our approach uses breast surface tracking to infer full tissue deformations. This makes the method compatible with various simulation tools and suitable for tissues with complex properties. The results demonstrate that the accuracy of the trained network on training data is 0.014 cm, and on testing data is 0.026 cm which shows precision in tumour localization, significantly improving upon current methods. This innovation has the potential to enhance patient outcomes by making breast cancer surgery safer, less invasive, and more efficient.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t2_11">
             09:00-10:00, Paper WePI2T2.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2599'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Portable Robot for Needle Insertion Assistance to Femoral Artery
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#167501" title="Click to go to the Author Index">
             Cheng, Zhuoqi
            </a>
           </td>
           <td class="r">
            University of Southern Denmark
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398397" title="Click to go to the Author Index">
             Mány, Bence
            </a>
           </td>
           <td class="r">
            Neurescue ApS
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398400" title="Click to go to the Author Index">
             Jørgensen, Kasper Balsby
            </a>
           </td>
           <td class="r">
            University of Southern Denmark
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#346097" title="Click to go to the Author Index">
             An, Siheon
            </a>
           </td>
           <td class="r">
            University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398403" title="Click to go to the Author Index">
             Jensen, Marcus Leander
            </a>
           </td>
           <td class="r">
            Neurescue ApS
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398421" title="Click to go to the Author Index">
             Thulstrup, Richard
            </a>
           </td>
           <td class="r">
            Neurescue ApS
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398414" title="Click to go to the Author Index">
             Frost, Habib
            </a>
           </td>
           <td class="r">
            Neurescue ApS
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#141998" title="Click to go to the Author Index">
             Savarimuthu, Thiusius Rajeeth
            </a>
           </td>
           <td class="r">
            University of Southern Denmark
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398426" title="Click to go to the Author Index">
             Huldt, Olof
            </a>
           </td>
           <td class="r">
            Neurescue ApS
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2599" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#robotics_and_automation_in_life_sciences" title="Click to go to the Keyword Index">
               Robotics and Automation in Life Sciences
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_based_control" title="Click to go to the Keyword Index">
               Sensor-based Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Femoral artery access is a common and critical procedure for various cardiovascular interventions. Although it is a time critical operation, accessing the Common Femoral Artery (CFA) typically requires expertise found in specialized medical settings. The necessity for specialized personnel or transport to equipped facilities can lead to delays, potentially exacerbating patient outcomes. To address this challenge, a portable and cost-effective robotic device that autonomously localizes a CFA and precisely positions a needle guide is developed. Through the needle guide, needle can be quickly and accurately inserted into the artery even by non-specialist physicians. Different from the conventional B-mode ultrasound guided procedure, the proposed robotic solution utilizes a Doppler transducer for detecting the arterial location and employs a single M-mode transducer for depth measurement. A series of experiments are designed and conducted to validate the system's feasibility, achieving high accuracy within 2mm, rapid processing within 1.5min, and a 100% success rate, thus proving the system's efficacy. These results convince us for further refinement of the system and support its evaluation in animal studies.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t2_12">
             09:00-10:00, Paper WePI2T2.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2629'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              The Design of a Sensorized Laryngoscope Training System for Pediatric Intubation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#360357" title="Click to go to the Author Index">
             Hou, Ningzhe
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#250684" title="Click to go to the Author Index">
             He, Liang
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#204668" title="Click to go to the Author Index">
             Albini, Alessandro
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#338041" title="Click to go to the Author Index">
             Halamek, Louis
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#140995" title="Click to go to the Author Index">
             Maiolino, Perla
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2629" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#health_care_management" title="Click to go to the Keyword Index">
               Health Care Management
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Intubation is essential for ventilating critically ill patients and involves precise maneuvering of a laryngoscope to place an endotracheal tube (ETT). However, training for this procedure is fraught with challenges. Traditional methods, relying on manikins or training with a single sensing modality, fail to adequately convey important interaction information. Such challenge is heightened in pediatric intubation due to anatomical differences that demand greater precision. Furthermore, integrating multiple sensing modalities into a laryngoscope without changing its size presents a significant design challenge, critical for maintaining realistic training scenarios. To overcome these obstacles, we developed a sensorized laryngoscope system equipped with a force-torque sensor, a 9-axis inertial measurement unit (IMU), and tactile sensors. This system, validated in a preliminary user study, provides online feedback on angles, forces, and grip strength through an online feedback GUI. Adopting a learning-by-demonstration approach with both experts and novices, the initial validation confirmed the system's potential, paving the way for expanded trials with more participants.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t2_13">
             09:00-10:00, Paper WePI2T2.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2805'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Enhancing Surgical Precision in Autonomous Robotic Incisions Via Physics-Based Tissue Cutting Simulation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#240309" title="Click to go to the Author Index">
             Ge, Jiawei
            </a>
           </td>
           <td class="r">
            Johns Hopkins University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396856" title="Click to go to the Author Index">
             Kilmer, Ethan
            </a>
           </td>
           <td class="r">
            Johns Hopkins University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#363550" title="Click to go to the Author Index">
             Mady, Leila
            </a>
           </td>
           <td class="r">
            Johns Hopkins University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#286570" title="Click to go to the Author Index">
             Opfermann, Justin
            </a>
           </td>
           <td class="r">
            Johns Hopkins University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#119227" title="Click to go to the Author Index">
             Krieger, Axel
            </a>
           </td>
           <td class="r">
            Johns Hopkins University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2805" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#simulation_and_animation" title="Click to go to the Keyword Index">
               Simulation and Animation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#surgical_robotics__planning" title="Click to go to the Keyword Index">
               Surgical Robotics: Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In soft tissue surgeries, such as tumor resections, achieving precision is of utmost importance. Surgeons conventionally achieve this precision through intraoperative adjustments to the cutting plan, responding to deformations from tool-tissue interactions. This study examines the integration of physics-based tissue cutting simulations into autonomous robotic surgery to preoperatively predict and compensate for such deformations, aiming to improve surgical precision and reduce the necessity for dynamic adjustments during autonomous surgeries. This study adapts a real-to-sim-to-real workflow. Initially, the Autonomous System for Tumor Resection (ASTR) was employed to evaluate its accuracy in performing preoperatively intended incisions along the irregular contours of porcine tongue pseudotumors. Following this, a finite element analysis-based simulation, utilizing the Simulation Open Framework Architecture (SOFA), was developed and tuned to accurately mimic these tissue and incision interactions. Insights gained from this simulation were applied to refine the robot’s path planning, ensuring a closer alignment of actual incisions with the initially intended surgical plan. The efficacy of this approach was validated by comparing surface incision precision on ex vivo porcine tongues, with the average absolute error reducing from 1.73mm to 1.46mm after applying simulation-driven path adjustments (p&lt;0.001). Additionally, our method not only demonstrated improvements in maintaining the intended cutting shapes and locations, with shape matching scores using Hu moments enhancing from 0.10 to 0.06 and centroid shifts decreasing from 2.09mm to 1.33mm, but it also potentially reduced the likelihood of adverse oncologic outcomes by preventing clinically suggested excessively close margins of 2.2mm. This feasibility study suggests that merging physics-based cutting simulations with autonomous robotic surgery could potentially lead to more accurate incisions.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t2_14">
             09:00-10:00, Paper WePI2T2.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2918'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Head-Mounted Hydraulic Needle Driver for Targeted Interventions in Neurosurger
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376801" title="Click to go to the Author Index">
             Fang, Zhiwei
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#345733" title="Click to go to the Author Index">
             Xu, Chao
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#286380" title="Click to go to the Author Index">
             Gao, Huxin
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#191303" title="Click to go to the Author Index">
             Chan, Tat-Ming
            </a>
           </td>
           <td class="r">
            Prince of Wales Hospital
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#345751" title="Click to go to the Author Index">
             Yuan, Wu
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106795" title="Click to go to the Author Index">
             Ren, Hongliang
            </a>
           </td>
           <td class="r">
            Chinese Univ Hong Kong (CUHK) &amp; National Univ Singapore(NUS)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2918" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#surgical_robotics__steerable_catheters_needles" title="Click to go to the Keyword Index">
               Surgical Robotics: Steerable Catheters/Needles
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Needle interventions are crucial in neurosurgery, requiring high precision and stability. This paper presents a 5-DoF head-mounted hydraulic needle robot designed for accurate and targeted needle insertion and neuroimaging in the deep brain. The robot is compact and lightweight by utilizing a hydraulic pipe transmission to connect the needle driver and actuator. The syringe pistons serve as the actuator and executor, enabling synchronized motion, minimal hysteresis, and high-accuracy insertion. The hydraulic transmission system exhibits hysteresis of less than 0.8 mm, with bidirectional insertion accuracy of approximately 0.05 mm. The resulting needle driver features a compact structure measuring 48 mm × 25 mm ×9mm, accompanied by a 70-mm-long needle guide. The needle driver is mainly 3D printed, while the hydraulic transmission ensures full compatibility with magnetic resonance imaging (MRI) by isolating all electromagnetic parts from the executor. This compact and lightweight robot-assisted needle intervention system significantly enhances the safety, accuracy, and effectiveness of deep-brain neuroimaging. The feasibility of precise positioning and insertion is further demonstrated by deploying an optical coherence tomography (OCT) microneedle in a rat brain.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t2_15">
             09:00-10:00, Paper WePI2T2.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2970'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              CathFlow: Self-Supervised Segmentation of Catheters in Interventional Ultrasound Using Optical Flow and Transformers
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#306432" title="Click to go to the Author Index">
             Ranne, Alex
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398694" title="Click to go to the Author Index">
             Kuang, Liming
            </a>
           </td>
           <td class="r">
            Techinical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#334510" title="Click to go to the Author Index">
             Velikova, Yordanka
            </a>
           </td>
           <td class="r">
            TU Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#107647" title="Click to go to the Author Index">
             Navab, Nassir
            </a>
           </td>
           <td class="r">
            TU Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#108147" title="Click to go to the Author Index">
             Rodriguez y Baena, Ferdinando
            </a>
           </td>
           <td class="r">
            Imperial College, London, UK
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2970" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In minimally invasive endovascular procedures, contrast-enhanced angiography remains the most robust imag- ing technique. However, it is at the expense of the patient and clinician’s health due to prolonged radiation exposure. As an alternative, interventional ultrasound has notable benefits such as being radiation-free, fast to deploy, and having a small footprint in the operating room. Yet, ultrasound is hard to interpret, and highly prone to artifacts and noise. Additionally, interventional radiologists must undergo extensive training before they become qualified to diagnose and treat patients effectively, leading to a shortage of staff, and a lack of open-source datasets. In this work, we seek to address both problems by introducing a self-supervised deep learning architecture to segment catheters in longitudinal ultrasound images, without demanding any labeled data. The network architecture builds upon AiAReSeg, a segmentation transformer built with the Attention in Attention mechanism, and is capable of learning feature changes across time and space. To facilitate training, we used synthetic ultrasound data based on physics-driven catheter insertion simulations, and translated the data into a unique CT-Ultrasound common domain, CACTUSS, to improve the segmentation performance. We generated ground truth segmentation masks by computing the optical flow between adjacent frames using FlowNet2, and performed thresholding to obtain a binary map estimate. Finally, we validated our model on a test dataset, consisting of unseen synthetic data and images collected from silicon aorta phantoms, thus demonstrating its potential for applications to clinical data in the future.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t2_16">
             09:00-10:00, Paper WePI2T2.16
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2907'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Seven Benefits of Using Series Elastic Actuators in the Design of an Affordable, Simple Controlled, and Functional Prosthetic Hand
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397344" title="Click to go to the Author Index">
             Koochakzadeh, Erfan
            </a>
           </td>
           <td class="r">
            University of Tehran
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396819" title="Click to go to the Author Index">
             Kargar, Alireza
            </a>
           </td>
           <td class="r">
            University of Tehran
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396320" title="Click to go to the Author Index">
             Sattari, Parsa
            </a>
           </td>
           <td class="r">
            University of Tehran
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396318" title="Click to go to the Author Index">
             Ravanshid, Diba
            </a>
           </td>
           <td class="r">
            University of Tehran
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#169608" title="Click to go to the Author Index">
             Nasiri, Rezvan
            </a>
           </td>
           <td class="r">
            University of Tehran
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2907" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#prosthetics_and_exoskeletons" title="Click to go to the Keyword Index">
               Prosthetics and Exoskeletons
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#compliant_joints_and_mechanisms" title="Click to go to the Keyword Index">
               Compliant Joints and Mechanisms
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper highlights the benefits of using series elastic actuators (SEA) in designing a cost-efficient, easily controlled, and functional prosthetic hand. The designed 3D-printed hand uses only two motors in an antagonistic configuration, transferring power to the fingers via pulleys, cables, and springs; i.e., the motors are in an SEA configuration with the load/fingers. In the designed underactuated prosthetic hand, the thumb is adjustable for various tasks, and the optimization of pulley diameters ensures synchronized finger movement during hand flexion and extension. Thanks to the SEA configuration of the motors and fingers, simple position control of the motor enables features like hand position control, morphological grasp, force control, impedance control, slippage detection, safe interaction, and efficient grasp. An extensive set of experiments has been conducted to evaluate the designed prosthetic hand's performance. The experiments confirm the hand's satisfactory performance while also highlighting the importance of improving the proposed design in different aspects. To attain better position control and morphological grasp, minimizing the cable-body and joint friction is recommended. A higher resolution of the current/torque sensor is needed for the precise force control and slippage detection. Finally, a motor brake system is required to achieve efficient grasping.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wepi2t3">
             <b>
              WePI2T3
             </b>
            </a>
           </td>
           <td class="r">
            Room 3
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wepi2t3" title="Click to go to the Program at a Glance">
             <b>
              Social HRI I
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#103296" title="Click to go to the Author Index">
             Alami, Rachid
            </a>
           </td>
           <td class="r">
            CNRS
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t3_01">
             09:00-10:00, Paper WePI2T3.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('618'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Autonomous Storytelling for Social Robot with Human-Centered Reinforcement Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#342019" title="Click to go to the Author Index">
             Zhang, Lei
            </a>
           </td>
           <td class="r">
            Ocean University of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#341251" title="Click to go to the Author Index">
             Zheng, Chuanxiong
            </a>
           </td>
           <td class="r">
            Ocean University of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#311995" title="Click to go to the Author Index">
             Wang, Hui
            </a>
           </td>
           <td class="r">
            Ocean University of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#116318" title="Click to go to the Author Index">
             Gomez, Randy
            </a>
           </td>
           <td class="r">
            Honda Research Institute Japan Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#289175" title="Click to go to the Author Index">
             Nichols, Eric
            </a>
           </td>
           <td class="r">
            Honda Research Institute Japan
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#175962" title="Click to go to the Author Index">
             Li, Guangliang
            </a>
           </td>
           <td class="r">
            Ocean University of China
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab618" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#human_centered_automation" title="Click to go to the Keyword Index">
               Human-Centered Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_centered_robotics" title="Click to go to the Keyword Index">
               Human-Centered Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#emotional_robotics" title="Click to go to the Keyword Index">
               Emotional Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Social robots are gradually integrating into human's daily lives. Storytelling by social robots could bring a different experience to users through non-verbal and emotional capabilities compared to text-only one. However, as user needs and preferences over storytelling might change over time during long-term interaction with social robots, it is important for social robots to learn from social interactions with human users in real-time. In this paper, we propose to allow our social robot Haru to learn personalized storytelling styles for different human user's emotional states via human-centered reinforcement learning using the reward provided and delivered by directly interaction with the user explicitly. Results of our user study show that Haru can learn to adapt its storytelling style for detected human emotional states in a few number of interactions, and was perceived to have a better storytelling performance, experience and impact than a neutral one.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t3_02">
             09:00-10:00, Paper WePI2T3.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3521'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Understanding Robot Minds: Leveraging Machine Teaching for Transparent Human-Robot Collaboration across Diverse Groups
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#250070" title="Click to go to the Author Index">
             Jayaraman, Suresh Kumaar
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105852" title="Click to go to the Author Index">
             Simmons, Reid
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#115102" title="Click to go to the Author Index">
             Steinfeld, Aaron
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#148680" title="Click to go to the Author Index">
             Admoni, Henny
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3521" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#human_centered_robotics" title="Click to go to the Keyword Index">
               Human-Centered Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_robot_teaming" title="Click to go to the Keyword Index">
               Human-Robot Teaming
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#modeling_and_simulating_humans" title="Click to go to the Keyword Index">
               Modeling and Simulating Humans
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this work, we aim to improve transparency and efficacy in human-robot collaboration by developing machine teaching algorithms suitable for groups with varied learning capabilities. While previous approaches focused on tailored approaches for teaching individuals, our method teaches teams with various compositions of diverse learners using team belief representations. We investigate various group teaching strategies, such as focusing on individual beliefs or the group's collective beliefs, and assess their impact on learning robot policies for different team compositions. Our findings reveal that team belief strategies produce less variation in learning duration and better accommodate diverse teams compared to individual belief strategies, suggesting their suitability in mixed proficiency settings with limited resources. In contrast, individual belief strategies provide a more uniform knowledge level, particularly effective for homogeneously inexperienced groups. Our study indicates that the effectiveness of the teaching strategy is significantly influenced by team composition and learner proficiency, highlighting the importance of real-time assessment of learner proficiency and adapting teaching approaches based on learner proficiency for optimal teaching outcomes.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t3_03">
             09:00-10:00, Paper WePI2T3.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('747'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Emotional Tandem Robots: How Different Robot Behaviors Affect Human Perception While Controlling a Mobile Robot
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391919" title="Click to go to the Author Index">
             Kaduk, Julian
            </a>
           </td>
           <td class="r">
            University of Konstanz
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393608" title="Click to go to the Author Index">
             Weilbeer, Friederike
            </a>
           </td>
           <td class="r">
            Universität Zu Lübeck
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#117790" title="Click to go to the Author Index">
             Hamann, Heiko
            </a>
           </td>
           <td class="r">
            University of Konstanz
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab747" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#human_robot_collaboration" title="Click to go to the Keyword Index">
               Human-Robot Collaboration
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#emotional_robotics" title="Click to go to the Keyword Index">
               Emotional Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In human-robot interaction (HRI), we study how humans interact with robots, but also the effects of robot behavior on human perception and well-being. Especially, the influence on humans by tandem robots with one human-controlled and one autonomous robot or even semi-autonomous multi-robot systems is not yet fully understood. Here, we focus on a leader-follower scenario and study how emotionally expressive motion patterns of a small, mobile follower robot affect the perception of a human operator controlling the leading robot. We examined three distinct emotional behaviors for the follower compared to a neutral condition: angry, happy, and sad. We asked participants to maneuver the leader robot along a set path while experiencing each follower behavior in a randomized order. We identified a significant shift in subjective attention toward the follower with emotionally expressive behaviors compared to the neutral condition. For example, the angry behavior significantly heightened participant stress levels and was considered the least preferred behavior. The happy behavior was the most preferred and associated with increased excitement by the participants. Integrating the proposed behaviors in robots can profoundly influence the human operator's perceived attention, emotional state, and overall experience. These insights are valuable for future HRI tandem robot designs.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t3_04">
             09:00-10:00, Paper WePI2T3.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2155'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Good Things Come in Threes: The Impact of Robot Responsiveness on Workload and Trust in Multi-User Human-Robot Collaboration
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#231446" title="Click to go to the Author Index">
             Semeraro, Francesco
            </a>
           </td>
           <td class="r">
            The University of Manchester
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#266245" title="Click to go to the Author Index">
             Carberry, Jon
            </a>
           </td>
           <td class="r">
            BAE Systems
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397436" title="Click to go to the Author Index">
             Leadbetter, James Hugo
            </a>
           </td>
           <td class="r">
            BAE Systems Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#240194" title="Click to go to the Author Index">
             Cangelosi, Angelo
            </a>
           </td>
           <td class="r">
            University of Manchester
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2155" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#human_robot_collaboration" title="Click to go to the Keyword Index">
               Human-Robot Collaboration
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#acceptability_and_trust" title="Click to go to the Keyword Index">
               Acceptability and Trust
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Human-robot collaboration has the potential of unlocking new manufacturing paradigms thanks to the introduction of a robotic architecture in a production chain that involves human workers. A possible innovative declination of this is the use of collaborative robots to enable two workers to concurrently act on the same manufacturing target without causing mutual disturbances. By doing so, the efficiency of the process would be preserved while reducing the production times. This work designs a physical collaborative task that involves two users and one collaborative robot. The users act in the scenario in a concurrent way on the same target object, while the robot physically intervenes in the scene as a mediator by adjusting the position and orientation of the object to accommodate both users at the same time. Through this experimental setup, 78 apprentices and teachers of the BAE Systems Academy for Skills and Knowledge Centre were recruited to investigate the users' perception of the task workload and trust towards the robotic system. Specifically, they performed the same task under two experimental conditions, in which the robot responded to changes in the interaction in a reactive or timed way, respectively. The statistical analysis showed that a timed response of the robot was associated with lower perceived workload and higher predictability of the system.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t3_05">
             09:00-10:00, Paper WePI2T3.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('325'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              PhotoBot: Reference-Guided Interactive Photography Via Natural Language
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#220207" title="Click to go to the Author Index">
             Limoyo, Oliver
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#140903" title="Click to go to the Author Index">
             Li, Jimmy
            </a>
           </td>
           <td class="r">
            McGill University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#267510" title="Click to go to the Author Index">
             Rivkin, Dmitriy
            </a>
           </td>
           <td class="r">
            None
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106824" title="Click to go to the Author Index">
             Kelly, Jonathan
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102604" title="Click to go to the Author Index">
             Dudek, Gregory
            </a>
           </td>
           <td class="r">
            McGill University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab325" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#natural_dialog_for_hri" title="Click to go to the Keyword Index">
               Natural Dialog for HRI
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_factors_and_human_in_the_loop" title="Click to go to the Keyword Index">
               Human Factors and Human-in-the-Loop
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We introduce PhotoBot, a framework for fully automated photo acquisition based on an interplay between high-level human language guidance and a robot photographer. We propose to communicate photography suggestions to the user via reference images that are selected from a curated gallery. We leverage a visual language model (VLM) and an object detector to characterize the reference images via textual descriptions and then use a large language model (LLM) to retrieve relevant reference images based on a user's language query through text-based reasoning. To correspond the reference image and the observed scene, we exploit pre-trained features from a vision transformer capable of capturing semantic similarity across marked appearance variations. Using these features, we compute suggested pose adjustments for an RGB-D camera by solving a perspective-n-point (PnP) problem. We demonstrate our approach using a manipulator equipped with a wrist camera. Our user studies show that photos taken by PhotoBot are often more aesthetically pleasing than those taken by users themselves, as measured by human feedback. We also show that PhotoBot can generalize to other reference sources such as paintings.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t3_06">
             09:00-10:00, Paper WePI2T3.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2225'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Multimodal Coherent Explanation Generation of Robot Failures
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#230391" title="Click to go to the Author Index">
             Pramanick, Pradip
            </a>
           </td>
           <td class="r">
            University of Naples Federico II
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#128192" title="Click to go to the Author Index">
             Rossi, Silvia
            </a>
           </td>
           <td class="r">
            Universita' Di Napoli Federico II
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2225" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#natural_dialog_for_hri" title="Click to go to the Keyword Index">
               Natural Dialog for HRI
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The explainability of a robot’s actions is crucial to its acceptance in social spaces. Explaining why a robot fails to complete a given task is particularly important for non-expert users to be aware of the robot's capabilities and limitations. So far, research on explaining robot failures has only considered generating textual explanations, even though several studies have shown the benefits of multimodal ones. However, a simple combination of multiple modalities may lead to semantic incoherence between the information across different modalities - a problem that is not well-studied. An incoherent multimodal explanation can be difficult to understand, and it may even become inconsistent with what the robot and the human observe and how they perform reasoning with the observations. Such inconsistencies may lead to wrong conclusions about the robot's capabilities. In this paper, we introduce an approach to generate coherent multimodal explanations by checking the logical coherence of explanations from different modalities, followed by refinements as required. We propose a classification approach for coherence assessment, where we evaluate if an explanation logically follows another. Our experiments suggest that fine-tuning a neural network that was pre-trained to recognize textual entailment, performs well for coherence assessment of multimodal explanations. Code &amp; data: https://pradippramanick.github.io/coherent-explain/.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t3_07">
             09:00-10:00, Paper WePI2T3.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2788'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Where and When Should the Teleoperated Avatar Look: Gaze Instruction Dataset for Enhanced Teleoperated Avatar Communication
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#299115" title="Click to go to the Author Index">
             Hoshimure, Kenya
            </a>
           </td>
           <td class="r">
            Osaka University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#244527" title="Click to go to the Author Index">
             Baba, Jun
            </a>
           </td>
           <td class="r">
            CyberAgent, Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#231165" title="Click to go to the Author Index">
             Nakanishi, Junya
            </a>
           </td>
           <td class="r">
            Osaka Univ
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106455" title="Click to go to the Author Index">
             Yoshikawa, Yuichiro
            </a>
           </td>
           <td class="r">
            Osaka University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101596" title="Click to go to the Author Index">
             Ishiguro, Hiroshi
            </a>
           </td>
           <td class="r">
            Osaka University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2788" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#natural_dialog_for_hri" title="Click to go to the Keyword Index">
               Natural Dialog for HRI
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#social_hri" title="Click to go to the Keyword Index">
               Social HRI
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Effective teleoperated avatar communication requires expressing social behaviors. Gaze behavior is one of the crucial social behaviors and includes reflexive reactions to the avatar's surroundings and intentional responses to the operator's speech and actions. Teleoperated avatars must have their gaze behavior controlled according to situational changes in both the avatar's and operator's contexts. However, it is not clear how to adjust the avatar's gaze in response to changes in both situations. In this paper, we collect a dataset of gazing positions that the avatar is instructed to face, taking into account both avatar and operator situations, and annotation labels that represent both situations in detail. We then exploratorily analyze the ratio of gazing positions per situation through dynamic area-of-interest (AOI) analysis. Our analysis provides insights into determining the gaze behavior of teleoperated avatars.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t3_08">
             09:00-10:00, Paper WePI2T3.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3293'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Empathetic Response Generation System: Enhancing Photo Reminiscence Chatbot with Emotional Context Analysis
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#337435" title="Click to go to the Author Index">
             Herrera Ruiz, Alberto
            </a>
           </td>
           <td class="r">
            National Taiwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#213900" title="Click to go to the Author Index">
             Qian, Xiaobei
            </a>
           </td>
           <td class="r">
            National Taiwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100096" title="Click to go to the Author Index">
             Fu, Li-Chen
            </a>
           </td>
           <td class="r">
            National Taiwan University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3293" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#natural_dialog_for_hri" title="Click to go to the Keyword Index">
               Natural Dialog for HRI
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#robot_companions" title="Click to go to the Keyword Index">
               Robot Companions
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#cognitive_modeling" title="Click to go to the Keyword Index">
               Cognitive Modeling
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Dementia affects 50 million people worldwide, underscoring the urgent need for effective interventions to enhance their well-being. While reminiscence intervention shows promise, its implementation is hindered by limited human resources, making machine-aided systems a viable automated solution for seamless photo-reminiscence sessions. In this paper, we introduce an empathetic response generation system specifically designed to enhance a question-only photo-reminiscence chatbot, with a focus on improving emotional context understanding and enhancing conversation engagement. We leverage Transformers to encode dialogue history, infer emotional states from user responses, and extract named entities. By combining template-based utterances with a retrieval chatbot, our system generates relevant and empathetic responses to user replies. Our system's effectiveness is validated through human evaluations using a Likert-like scale to assess engagement levels. The results demonstrate that our approach surpasses both the question-only system and other models from existing works, including retrieval and generated models. This highlights our system’s potential to enhance interactions and engagement, advancing technology-driven interventions for dementia that improve well-being and quality of life.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t3_09">
             09:00-10:00, Paper WePI2T3.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3348'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              OmniRace: 6D Hand Pose Estimation for Intuitive Guidance of Racing Drone
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#287400" title="Click to go to the Author Index">
             Serpiva, Valerii
            </a>
           </td>
           <td class="r">
            Skolkovo Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#241638" title="Click to go to the Author Index">
             Fedoseev, Aleksey
            </a>
           </td>
           <td class="r">
            Skolkovo Institute of Science AndTechnology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#358267" title="Click to go to the Author Index">
             Karaf, Sausar
            </a>
           </td>
           <td class="r">
            Skolkovo Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398992" title="Click to go to the Author Index">
             Abdulkarim, Ali Alridha
            </a>
           </td>
           <td class="r">
            Skolkovo Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#224191" title="Click to go to the Author Index">
             Dzmitry, Tsetserukou
            </a>
           </td>
           <td class="r">
            Skolkovo Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3348" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#natural_dialog_for_hri" title="Click to go to the Keyword Index">
               Natural Dialog for HRI
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_detection_and_tracking" title="Click to go to the Keyword Index">
               Human Detection and Tracking
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents the OmniRace approach to controlling a racing drone with 6-degree of freedom (DoF) hand pose estimation and gesture recognition. To our knowledge, this is the first technology enabling low-level control of high-speed drones through gestures. OmniRace employs a gesture interface based on computer vision and a deep neural network to estimate 6-DoF hand pose. The advanced machine learning algorithm robustly interprets human gestures, allowing users to control drone motion intuitively. Real-time control tests validate the system's effectiveness and its potential to revolutionize drone racing and other applications. Experimental results conducted in simulation environment revealed that OmniRace allows the users to complite the UAV race track significantly (by 25.1%) faster and to decrease the length of the test drone path (from 102.9 to 83.7 m). Users preferred the gesture interface for attractiveness (1.57 UEQ score), hedonic quality (1.56 UEQ score), and lower perceived temporal demand (32.0 score in NASA-TLX), while noting the high efficiency (0.75 UEQ score) and low physical demand (19.0 score in NASA-TLX) of the baseline remote controller. The deep neural network attains an average accuracy of 99.75% when applied to both normalized datasets and raw datasets. OmniRace can potentially change the way humans interact with and navigate racing drones in dynamic and complex environments. The source code is available at https://github.com/SerValera/OmniRace.git.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t3_10">
             09:00-10:00, Paper WePI2T3.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('529'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Investigating Behavioral and Cognitive Changes Induced by Autonomous Delivery Robots in Incidentally Copresent Persons
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393011" title="Click to go to the Author Index">
             Kim, Nayoung
            </a>
           </td>
           <td class="r">
            KOREA, Korea Institute of Science and Technology (KIST)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#115971" title="Click to go to the Author Index">
             Kwak, Sonya Sona
            </a>
           </td>
           <td class="r">
            Korea Institute of Science and Technology (KIST)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab529" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#social_hri" title="Click to go to the Keyword Index">
               Social HRI
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#physical_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical Human-Robot Interaction
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Autonomous delivery robots (ADRs) encounter incidentally copresent persons (InCoPs) during their delivery journeys. Despite the potential for ADRs' behavior to influence the behavior and cognition of InCoPs, there is limited research on the interaction between ADRs and InCoPs. Therefore, in this study, we conducted a within-participants experiment (N=30) with a 3 (confederate types: humans vs. high anthropomorphism robots vs. low anthropomorphism robots) x 2 (jaywalking status: jaywalking vs. not jaywalking) design to investigate the impact of ADRs on InCoPs’ behavioral and cognitive changes induced by the social influence of ADRs. During the experiment, participants watched a video depicting interactions between ADRs and InCoPs at a crosswalk. Each participant was immersed in the video as an InCoP, instructed to make jaywalking decisions, and subsequently completed questionnaires. Results indicated that, behaviorally, participants displayed similar levels of conformity towards jaywalking behaviors across both the human and robot confederates. Cognitively, there were significant differences in morality based on the confederate types. Additionally, robots that refrained from jaywalking received more positive ratings in terms of morality and intention to use. This study confirms that ADRs have the capacity to induce conformity similar to humans and that the ethical behavior of ADRs can positively influence InCoPs' impressions and intention to use toward ADRs.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t3_11">
             09:00-10:00, Paper WePI2T3.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('899'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Are Large Language Models Aligned with People's Social Intuitions for Human–Robot Interactions?
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#328894" title="Click to go to the Author Index">
             Wachowiak, Lennart
            </a>
           </td>
           <td class="r">
            King's College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#186793" title="Click to go to the Author Index">
             Coles, Andrew
            </a>
           </td>
           <td class="r">
            Kings College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#158663" title="Click to go to the Author Index">
             Celiktutan, Oya
            </a>
           </td>
           <td class="r">
            King's College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#213444" title="Click to go to the Author Index">
             Canal, Gerard
            </a>
           </td>
           <td class="r">
            King's College London
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab899" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#social_hri" title="Click to go to the Keyword Index">
               Social HRI
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_centered_robotics" title="Click to go to the Keyword Index">
               Human-Centered Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Large language models (LLMs) are increasingly used in robotics, especially for high-level action planning. Meanwhile, many robotics applications involve human supervisors or collaborators. Hence, it is crucial for LLMs to generate socially acceptable actions that align with people's preferences and values. In this work, we test whether LLMs capture people's intuitions about behavior judgments and communication preferences in human–robot interaction (HRI) scenarios. For evaluation, we reproduce three HRI user studies, comparing the output of LLMs with that of real participants. We find that GPT-4 strongly outperforms other models, generating answers that correlate strongly with users' answers in two studies — the first study dealing with selecting the most appropriate communicative act for a robot in various situations (r = 0.82), and the second with judging the desirability, intentionality, and surprisingness of behavior (r = 0.83). However, for the last study, testing whether people judge the behavior of robots and humans differently, no model achieves strong correlations. Moreover, we show that vision models fail to capture the essence of video stimuli and that LLMs tend to rate different communicative acts and behavior desirability higher than people.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t3_12">
             09:00-10:00, Paper WePI2T3.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1232'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Belief-Aided Navigation Using Bayesian Reinforcement Learning for Avoiding Humans in Blind Spots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393091" title="Click to go to the Author Index">
             Kim, Jinyeob
            </a>
           </td>
           <td class="r">
            KyungHee University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396055" title="Click to go to the Author Index">
             Daewon, Kwak
            </a>
           </td>
           <td class="r">
            Kyunghee.uni
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395909" title="Click to go to the Author Index">
             Rim, Hyunwoo
            </a>
           </td>
           <td class="r">
            Kyung Hee University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#131348" title="Click to go to the Author Index">
             Kim, Donghan
            </a>
           </td>
           <td class="r">
            Kyung Hee University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1232" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#social_hri" title="Click to go to the Keyword Index">
               Social HRI
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recent research on mobile robot navigation has focused on socially aware navigation in crowded environments. However, existing methods do not adequately account for human–robot interactions and demand accurate location information from omnidirectional sensors, rendering them unsuitable for practical applications. In response to this need, this study introduces a novel algorithm, BNBRL+, predicated on the partially observable Markov decision process framework to assess risks in unobservable areas and formulate movement strategies under uncertainty. BNBRL+ consolidates belief algorithms with Bayesian neural networks to probabilistically infer beliefs based on the positional data of humans. It further integrates the interactions between the robot, humans, and inferred beliefs to determine the navigation paths, thereby facilitating socially aware navigation. Through experiments in various risk-laden scenarios, this study validates the effectiveness of BNBRL+ in navigating crowded environments with blind spots. The model's ability to navigate effectively in spaces with limited visibility and avoid obstacles dynamically can significantly improve the safety and reliability of autonomous vehicles. The complement source code can be accessed here: https://github.com/JinnnK/BNBRLplus.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t3_13">
             09:00-10:00, Paper WePI2T3.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2218'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Service Robot in the Wild: Analysis of Users Intentions, Robot Behaviors, and Their Impact on the Interaction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375348" title="Click to go to the Author Index">
             Arreghini, Simone
            </a>
           </td>
           <td class="r">
            IDSIA USI-SUPSI
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#237877" title="Click to go to the Author Index">
             Abbate, Gabriele
            </a>
           </td>
           <td class="r">
            Istituto Dalle Molle Di Studi sull'Intelligenza Artificiale (IDS
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#155801" title="Click to go to the Author Index">
             Giusti, Alessandro
            </a>
           </td>
           <td class="r">
            IDSIA USI-SUPSI
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#141042" title="Click to go to the Author Index">
             Paolillo, Antonio
            </a>
           </td>
           <td class="r">
            IDSIA USI-SUPSI
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2218" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#social_hri" title="Click to go to the Keyword Index">
               Social HRI
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#intention_recognition" title="Click to go to the Keyword Index">
               Intention Recognition
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We consider a service robot that offers chocolate treats to people passing in its proximity: it has the capability of predicting in advance a person’s intention to interact, and to actuate an “offering” gesture, subtly extending the tray of chocolates towards a given target. We run the system for more than 5 hours across 3 days and two different crowded public locations; the system implements three possible behaviors that are randomly toggled every few minutes: passive (e.g. never performing the offering gesture); or active, triggered by either a naive distance-based rule, or a smart approach that relies on various behavioral cues of the user. We collect a real-world dataset that includes information on 1777 users with several spontaneous human-robot interactions and study the influence of robot actions on people’s behavior. Our comprehensive analysis suggests that users are more prone to engage with the robot when it proactively starts the interaction. We release the dataset and provide insights to make our work reproducible for the community. Also, we report qualitative observations collected during the acquisition campaign and identify future challenges and research directions in the domain of social human-robot interaction.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t3_14">
             09:00-10:00, Paper WePI2T3.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2546'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Context-Aware Conversation Adaptation for Human-Robot Interaction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#277305" title="Click to go to the Author Index">
             Su, Zhidong
            </a>
           </td>
           <td class="r">
            Oklahoma State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100881" title="Click to go to the Author Index">
             Sheng, Weihua
            </a>
           </td>
           <td class="r">
            Oklahoma State University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2546" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#social_hri" title="Click to go to the Keyword Index">
               Social HRI
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#robot_companions" title="Click to go to the Keyword Index">
               Robot Companions
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Existing conversational robots are mostly reactive in that the interactions are usually initiated by the users. With the knowledge of the environmental context such as people's daily activities, robots can be more intelligent and proactive. In this paper, we proposed a context-aware conversation adaptation system (CACAS) for human-robot interaction (HRI). First, a context recognition module and a language processing module are developed to obtain the context information, user intent and slots, which become part of the state. Second, a reinforcement learning algorithm is developed to train an initial policy with a simulated user. User feedback data is collected through HRI using the initial policy. Third, a policy combining the reinforcement learning-based policy with the neural network-based policy is adapted based on the user feedback. We conducted both simulated user tests and real human subject tests to evaluate the proposed system. The results show that CACAS achieved a success rate of 85% in the real human subject test and 87.5% of participants were satisfied with the adaptation results. For the simulation test, CACAS had the highest success rate compared with the baseline methods.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t3_15">
             09:00-10:00, Paper WePI2T3.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2842'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              AEGO: Modeling Attention for HRI in Ego-Sphere Neural Networks
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#225299" title="Click to go to the Author Index">
             Ferreira Chame, Hendry
            </a>
           </td>
           <td class="r">
            University of Lorraine / CNRS
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103296" title="Click to go to the Author Index">
             Alami, Rachid
            </a>
           </td>
           <td class="r">
            CNRS
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2842" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#social_hri" title="Click to go to the Keyword Index">
               Social HRI
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#neurorobotics" title="Click to go to the Keyword Index">
               Neurorobotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#embodied_cognitive_science" title="Click to go to the Keyword Index">
               Embodied Cognitive Science
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Despite important progress in recent years, social robots are still far away from showing advanced behavior for interaction and adaptation in human environments. Thus, we are interested in studying social cognition in human-robot interaction (HRI), notably in improving communication skills relying on joint attention (JA) and knowledge sharing. Since JA involves low-level cognitive processes in humans, we take into account the implications of Moravec's Paradox and focus on the aspect of knowledge representation. Inspired by 4E cognition principles, we study egocentric localization through the concept of sensory ego-sphere. We propose a neural network architecture named AEGO to model attention for each agent in interaction and show how to fuse information in a common representation space. From the perspective of dynamic fields theory, AEGO takes into account the dynamics of bottom-up and top-down modulation processes and the effects of neural excitatory and inhibitory synaptic interaction. In this work we evaluate the model in simulation and experiments with the robot Pepper in JA tasks based on proprioception, vision, rudimentary natural language and Hebbian plasticity. Results show that AEGO is convenient for HRI, allowing the human and the robot to share attention and knowledge about objects in scenarios close to everyday situations. AEGO constitutes a novel brain-inspired architecture to model attention that is suitable for multi-agent applications relying on social cognition skills, having the potential to generalize to several robotics platforms and HRI scenarios.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t3_16">
             09:00-10:00, Paper WePI2T3.16
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3042'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Architectural-Scale Artistic Brush Painting with a Hybrid Cable Robot
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#218263" title="Click to go to the Author Index">
             Chen, Gerry
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398188" title="Click to go to the Author Index">
             Al-Haddad, Tristan
            </a>
           </td>
           <td class="r">
            Formations Studio
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104136" title="Click to go to the Author Index">
             Dellaert, Frank
            </a>
           </td>
           <td class="r">
            Verdant Robotics/Georgia Tech
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101611" title="Click to go to the Author Index">
             Hutchinson, Seth
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3042" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#art_and_entertainment_robotics" title="Click to go to the Keyword Index">
               Art and Entertainment Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#engineering_for_robotic_systems" title="Click to go to the Keyword Index">
               Engineering for Robotic Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#parallel_robots" title="Click to go to the Keyword Index">
               Parallel Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robot art presents an opportunity to both showcase and advance state-of-the-art robotics through the challenging task of creating art. Creating large-scale artworks in particular engages the public in a way that small-scale works cannot, and the distinct qualities of brush strokes contribute to an organic and human-like quality. Combining the large scale of murals with the strokes of the brush medium presents an especially impactful result, but also introduces unique challenges in maintaining precise, dextrous motion control of the brush across such a large workspace. In this work, we present the first robot to our knowledge that can paint architectural-scale murals with a brush.	We create a hybrid robot consisting of a cable-driven parallel robot and 4 degree of freedom (DoF) serial manipulator to paint a 27m by 3.7m mural on windows spanning 2-stories of a building. We discuss our approach to achieving both the scale and accuracy required for brush-painting a mural through a combination of novel mechanical design elements, coordinated planning and control, and on-site calibration algorithms with experimental validations.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wepi2t4">
             <b>
              WePI2T4
             </b>
            </a>
           </td>
           <td class="r">
            Room 4
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wepi2t4" title="Click to go to the Program at a Glance">
             <b>
              Perception I (Detection and Categorization)
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#206428" title="Click to go to the Author Index">
             Xiang, Yu
            </a>
           </td>
           <td class="r">
            University of Texas at Dallas
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#109142" title="Click to go to the Author Index">
             Bensalem, Saddek
            </a>
           </td>
           <td class="r">
            University Grenoble
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t4_01">
             09:00-10:00, Paper WePI2T4.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('135'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Swiss DINO: Efficient and Versatile Vision Framework for On-Device Personal Object Search
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#389592" title="Click to go to the Author Index">
             Paramonov, Kirill
            </a>
           </td>
           <td class="r">
            Samsung Research UK
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#332868" title="Click to go to the Author Index">
             Zhong, Jia-Xing
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#318083" title="Click to go to the Author Index">
             Michieli, Umberto
            </a>
           </td>
           <td class="r">
            Samsung Research
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391356" title="Click to go to the Author Index">
             Moon, Jijoong
            </a>
           </td>
           <td class="r">
            Samsung Research Korea
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#170089" title="Click to go to the Author Index">
             Ozay, Mete
            </a>
           </td>
           <td class="r">
            Samsung Research
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab135" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we address a recent trend in robotic home appliances to include vision systems on personal devices, capable of personalizing the appliances on the fly. In particular, we formulate and address an important technical task of personal object search, which involves localization and identification of personal items of interest on images captured by robotic appliances, with each item referenced only by a few annotated images. The task is crucial for robotic home appliances and mobile systems, which need to process personal visual scenes or to operate with particular personal objects (e.g., for grasping or navigation). In practice, personal object search presents two main technical challenges. First, a robot vision system needs to be able to distinguish between many fine-grained classes, in the presence of occlusions and clutter. Second, the strict resource requirements for the on-device system restrict the usage of most state-of-the-art methods for few-shot learning and often prevent on-device adaptation. In this work, we propose Swiss DINO: a simple yet effective framework for one-shot personal object search based on the recent DINOv2 transformer model, which was shown to have strong zero-shot generalization properties. Swiss DINO handles challenging on-device personalized scene understanding requirements and does not require any adaptation training. We show significant improvement (up to 55%) in segmentation and recognition accuracy compared to the common lightweight solutions, and significant footprint reduction of backbone inference time (up to 100x) and GPU consumption (up to 10x) compared to the heavy transformer-based solutions
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t4_02">
             09:00-10:00, Paper WePI2T4.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('162'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Continuous Rapid Learning by Human Imitation Using Audio Prompts and One-Shot Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#274680" title="Click to go to the Author Index">
             Duque Domingo, Jaime
            </a>
           </td>
           <td class="r">
            University of Valladolid
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#389948" title="Click to go to the Author Index">
             García-Gómez, Miguel
            </a>
           </td>
           <td class="r">
            University of Valladolid
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#113592" title="Click to go to the Author Index">
             Zalama, Eduardo
            </a>
           </td>
           <td class="r">
            Instituo De Las Tecnologías delaProducción(ITAP).Universityof Va
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#113586" title="Click to go to the Author Index">
             Gomez Garcia Bermejo, Jaime
            </a>
           </td>
           <td class="r">
            University of Valladolid
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab162" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In the general field of collaborative robotics, one of the topics of greatest interest to the scientific community is the ability to learn to perform certain actions by imitating humans. If we think about humans, when someone teaches us how to perform a certain action, we often need to be shown just one time how to do it. Likewise, we believe that robotics should follow this line, using models that do not involve the capture of huge data sets or exhaustive training. Furthermore, while general models can typically be pretrained offline, the robot must quickly adapt to new knowledge without requiring an expensive retraining process. In this article we present a flexible neural learning architecture that allows a robot to learn how-to pick-up a given object just by watching how a human does it. Then, the robot will be able to pick up the current object, or other objects previously learned, anywhere in the work field, with a simple audible indication from the user. This is achieved based on continuous incremental learning techniques and generic segmentation networks integrated with Siamese network models according to the recently proposed CP-CVV method. Results are presented for the success rate in grasping a varied set of objects.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t4_03">
             09:00-10:00, Paper WePI2T4.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('510'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              FedRC: A Rapid-Converged Hierarchical Federated Learning Framework in Street Scene Semantic Understanding
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#339729" title="Click to go to the Author Index">
             Kou, Wei-Bin
            </a>
           </td>
           <td class="r">
            The University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392316" title="Click to go to the Author Index">
             Lin, Qingfeng
            </a>
           </td>
           <td class="r">
            The University of HongKong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392509" title="Click to go to the Author Index">
             Tang, Ming
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#288452" title="Click to go to the Author Index">
             Wang, Shuai
            </a>
           </td>
           <td class="r">
            Shenzhen Institute of Advanced Technology, Chinese Academy of Sc
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#339830" title="Click to go to the Author Index">
             Zhu, Guangxu
            </a>
           </td>
           <td class="r">
            Shenzhen Research Institute of Big Data
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#340053" title="Click to go to the Author Index">
             Wu, Yik-Chung
            </a>
           </td>
           <td class="r">
            The University of Hong Kong
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab510" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Street Scene Semantic Understanding (TriSU) is a crucial but complex task for world-wide distributed autonomous driving (AD) vehicles (e.g., Tesla). Its inference model faces poor generalization issue due to inter-city domain-shift. Hierarchical Federated Learning (HFL) offers a potential solution for improving TriSU model generalization, but suffers from slow convergence rate because of vehicles’ surrounding heterogeneity across cities. Going beyond existing HFL works that have deficient capabilities in complex tasks, we propose a rapid-converged heterogeneous HFL framework (FedRC) to address the inter-city data heterogeneity and accelerate HFL model convergence rate. In our proposed FedRC framework, both single RGB image and RGB dataset are modelled as Gaussian distributions. This approach not only differentiates each RGB sample instead of typically equalizing them, but also considers both data volume and statistical properties rather than simply taking data quantity into consideration. Extensive experiments on the TriSU task using across-city datasets demonstrate that FedRC converges faster than the state-of-the-art benchmark by 38.7%, 37.5%, 35.5%, and 40.6% in terms of mIoU, mPrecision, mRecall, and mF1, respectively. Furthermore, qualitative evaluations in the CARLA simulation environment confirm that the proposed FedRC framework delivers top-tier performance.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t4_04">
             09:00-10:00, Paper WePI2T4.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('619'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Model Agnostic Defense against Adversarial Patch Attacks on Object Detection in Unmanned Aerial Vehicles
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#353641" title="Click to go to the Author Index">
             Pathak, Saurabh
            </a>
           </td>
           <td class="r">
            Technology Innovation Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#353622" title="Click to go to the Author Index">
             Shrestha, Samridha
            </a>
           </td>
           <td class="r">
            Technology Innovation Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393354" title="Click to go to the Author Index">
             AlMahmoud, Abdelrahman
            </a>
           </td>
           <td class="r">
            Technology Innovation Institute
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab619" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__perception_and_autonomy" title="Click to go to the Keyword Index">
               Aerial Systems: Perception and Autonomy
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Object detection forms a key component in Unmanned Aerial Vehicles (UAVs) for completing high-level tasks that depend on the awareness of objects on the ground from an aerial perspective. In that scenario, adversarial patch attacks on an onboard object detector can severely impair the performance of upstream tasks. This paper proposes a novel model-agnostic defense mechanism against the threat of adversarial patch attacks in the context of UAV-based object detection. We formulate adversarial patch defense as an occlusion removal task. The proposed defense method can neutralize adversarial patches located on objects of interest, without exposure to adversarial patches during training. Our lightweight single-stage defense approach allows us to maintain a model-agnostic nature, that once deployed does not require to be updated in response to changes in the object detection pipeline. The evaluations in digital and physical domains show the feasibility of our method for deployment in UAV object detection pipelines, by significantly decreasing the Attack Success Ratio without incurring significant processing costs. As a result, the proposed defense solution can improve the reliability of object detection for UAVs.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t4_05">
             09:00-10:00, Paper WePI2T4.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('673'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Proto-CLIP: Vision-Language Prototypical Network for Few-Shot Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#337160" title="Click to go to the Author Index">
             P, Jishnu Jaykumar
            </a>
           </td>
           <td class="r">
            The University of Texas at Dallas
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#385121" title="Click to go to the Author Index">
             Palanisamy, Kamalesh
            </a>
           </td>
           <td class="r">
            University of Texas at Dallas
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#198471" title="Click to go to the Author Index">
             Chao, Yu-Wei
            </a>
           </td>
           <td class="r">
            NVIDIA
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#385123" title="Click to go to the Author Index">
             Du, Xinya
            </a>
           </td>
           <td class="r">
            UT Dallas
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#206428" title="Click to go to the Author Index">
             Xiang, Yu
            </a>
           </td>
           <td class="r">
            University of Texas at Dallas
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab673" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#recognition" title="Click to go to the Keyword Index">
               Recognition
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#representation_learning" title="Click to go to the Keyword Index">
               Representation Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We propose a novel framework for few-shot learning by leveraging large-scale vision-language models such as CLIP. Motivated by unimodal prototypical networks for few-shot learning, we introduce Proto-CLIP which utilizes image prototypes and text prototypes for few-shot learning. Specifically, Proto-CLIP adapts the image and text encoder embeddings from CLIP in a joint fashion using few-shot examples. The embeddings from the two encoders are used to compute the respective prototypes of image classes for classification. During adaptation, we propose aligning the image and text prototypes of the corresponding classes. Such alignment is beneficial for few-shot classification due to the reinforced contributions from both types of prototypes. Proto-CLIP has both training-free and fine-tuned variants. We demonstrate the effectiveness of our method by conducting experiments on benchmark datasets for few-shot learning, as well as in the real world for robot perception. The project page can be found at https://irvlutd.github.io/Proto-CLIP.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t4_06">
             09:00-10:00, Paper WePI2T4.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('925'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SWCF-Net: Similarity-Weighted Convolution and Local-Global Fusion for Efficient Large-Scale Point Cloud Semantic Segmentation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#385649" title="Click to go to the Author Index">
             Lin, Zhenchao
            </a>
           </td>
           <td class="r">
            Guangdong University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#195587" title="Click to go to the Author Index">
             He, Li
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#373982" title="Click to go to the Author Index">
             Yang, Hongqiang
            </a>
           </td>
           <td class="r">
            Meituan Technology Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394494" title="Click to go to the Author Index">
             Xiaoqun, Sun
            </a>
           </td>
           <td class="r">
            Meituan
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394491" title="Click to go to the Author Index">
             Zhang, Guojin
            </a>
           </td>
           <td class="r">
            Meituan
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#199170" title="Click to go to the Author Index">
             Chen, Weinan
            </a>
           </td>
           <td class="r">
            Guangdong University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#116809" title="Click to go to the Author Index">
             Guan, Yisheng
            </a>
           </td>
           <td class="r">
            Guangdong University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#317689" title="Click to go to the Author Index">
             Zhang, Hong
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab925" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Large-scale point cloud consists of a multitude of individual objects, thereby encompassing rich structural and underlying semantic contextual information, resulting in a challenging problem in efficiently segmenting a point cloud. Most existing researches mainly focus on capturing intricate local features without giving due consideration to global ones, thus failing to leverage semantic context. In this paper, we propose a Similarity-Weighted Convolution and local-global Fusion Network, named SWCF-Net, which takes into account both local and global features. We propose a Similarity-Weighted Convolution (SWConv) to effectively extract local features, where similarity weights are incorporated into the convolution operation to enhance the generalization capabilities. Then, we employ a downsampling operation on the K and V channels within the attention module, thereby reducing the quadratic complexity to linear, enabling Transformer to deal with large-scale point cloud. At last, orthogonal components are extracted in the global features and then aggregated with local features, thereby eliminating redundant information between local and global features and consequently promoting efficiency. We evaluate SWCF-Net on large-scale outdoor datasets SemanticKITTI and Toronto3D. Our experimental results demonstrate the effectiveness of the proposed network. Our method achieves a competitive result with less computational cost, and is able to handle large-scale point clouds efficiently. The code is available at https://github.com/Sylva-Lin/SWCF-Net.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t4_07">
             09:00-10:00, Paper WePI2T4.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1290'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              3D Object Detection Via Stereo Pyramid Transformers with Rich Semantic Feature Fusion
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#351422" title="Click to go to the Author Index">
             Gu, Rongqi
            </a>
           </td>
           <td class="r">
            Tongji University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#329778" title="Click to go to the Author Index">
             Yang, Chu
            </a>
           </td>
           <td class="r">
            Tongji University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396183" title="Click to go to the Author Index">
             Lu, Yaohan
            </a>
           </td>
           <td class="r">
            Westwell-Lab
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#303913" title="Click to go to the Author Index">
             Liu, Peigen
            </a>
           </td>
           <td class="r">
            Tongji University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396187" title="Click to go to the Author Index">
             Wu, Fei
            </a>
           </td>
           <td class="r">
            Westwell-Lab
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#157845" title="Click to go to the Author Index">
             Chen, Guang
            </a>
           </td>
           <td class="r">
            Tongji University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1290" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Camera-based 3D object detectors, prized for their broader applicability and cost-effectiveness compared to LiDAR sensors, still grapple with the inherently ill-posed nature of depth extraction from images. In this work, we present a novel approach that employs a transformer-based backbone and a fused geometry volume to bolster feature richness and elevate detection accuracy. Firstly, we propose the Stereo Pyramid Transformer backbone to extract features from stereo images, which can capture global information and establish cross-image semantic connections. Then, to tackle the challenge posed by small baseline binocular cameras, we propose to fuse stereo geometry volumes constructed by Stereo Plane Sweeping Volume (SPSV), Monocular Semantic Volume (MSV), and Lifted Volume (LV) to create finely detailed feature volumes. Through extensive experiments on both the KITTI and our datasets, our approach not only surpasses all existing transformer-based stereo 3D detection methods but also marks a significant milestone by achieving comparable performance with the leading CNN-based 3D detectors for the first time.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t4_08">
             09:00-10:00, Paper WePI2T4.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1886'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              MOSFormer: A Transformer-Based Multi-Modal Fusion Network for Moving Object Segmentation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393630" title="Click to go to the Author Index">
             Cheng, Zike
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#240029" title="Click to go to the Author Index">
             Zhao, Hengwang
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372190" title="Click to go to the Author Index">
             Shen, Qiyuan
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#300932" title="Click to go to the Author Index">
             Yan, Weihao
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#191295" title="Click to go to the Author Index">
             Wang, Chunxiang
            </a>
           </td>
           <td class="r">
            Shanghai Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#146916" title="Click to go to the Author Index">
             Yang, Ming
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1886" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             3D moving object segmentation (MOS) is vital for autonomous systems, providing essential information for downstream tasks like mapping and localization. However, current MOS methods face challenges due to the limitation of existing datasets, which are sparse in moving objects and limited in scene diversity. Meanwhile, the prevalent methods are projection-based, struggling with the challenge of blurred boundaries. To tackle the dataset issue, we introduce a nuScenes-based MOS dataset, which provides richer scenes and more dynamic instances. To alleviate the boundary blurring issue and further improve accuracy and generalizability, we propose a dual-branch multimodal fusion MOS network, MOSFormer. The Transformer structure is incorporated to extract spatio-temporal information better, while image semantic information is utilized to refine the boundaries of moving objects. Finally, experiments on two datasets show that our method achieves state-of-the-art performance, and a mapping experiment with our method confirms its effectiveness in downstream tasks such as mapping and localization.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t4_09">
             09:00-10:00, Paper WePI2T4.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2059'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              CTS: Sim-To-Real Unsupervised Domain Adaptation on 3D Detection
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#301850" title="Click to go to the Author Index">
             Zhang, Meiying
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397027" title="Click to go to the Author Index">
             Peng, Weiyuan
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#312348" title="Click to go to the Author Index">
             Ding, Guangyao
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397039" title="Click to go to the Author Index">
             Lei, Chenyang
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#342912" title="Click to go to the Author Index">
             Ji, Chunlin
            </a>
           </td>
           <td class="r">
            Kuang-Chi Institute of Advanced Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#200472" title="Click to go to the Author Index">
             Hao, Qi
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2059" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#transfer_learning" title="Click to go to the Keyword Index">
               Transfer Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Simulation data can be accurately labeled and have been expected to improve the performance of data-driven algorithms, including object detection. However, due to the various domain inconsistencies from simulation to reality (sim-to-real), cross-domain object detection algorithms usually suffer from dramatic performance drops. While numerous unsupervised domain adaptation (UDA) methods have been developed to address cross-domain tasks between real-world datasets, progress in sim-to-real remains limited. This paper presents a novel Complex-to-Simple (CTS) framework to transfer models from labeled simulation (source) to unlabeled reality (target) domains. Based on a two-stage detector, the novelty of this work is threefold: 1) developing fixed-size anchor heads and RoI augmentation to address size bias and feature diversity between two domains, thereby improving the quality of pseudo-label; 2) developing a novel corner-format representation of aleatoric uncertainty (AU) for the bounding box, to uniformly quantify pseudo-label quality; 3) developing a noise-aware mean teacher domain adaptation method based on AU, as well as object-level and frame-level sampling strategies, to migrate the impact of noisy labels. Experimental results demonstrate that our proposed approach significantly enhances the sim-to-real domain adaptation capability of 3D object detection models, outperforming state-of-the-art cross-domain algorithms, which are usually developed for real-to-real UDA tasks.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t4_10">
             09:00-10:00, Paper WePI2T4.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2191'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              BAM: Box Abstraction Monitors for Real-Time OoD Detection in Object Detection
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392173" title="Click to go to the Author Index">
             Wu, Changshun
            </a>
           </td>
           <td class="r">
            Université Grenoble Alpes
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392545" title="Click to go to the Author Index">
             He, Weicheng
            </a>
           </td>
           <td class="r">
            Université Grenoble Alpes
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#130911" title="Click to go to the Author Index">
             Cheng, Chih-Hong
            </a>
           </td>
           <td class="r">
            Chalmers University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#226960" title="Click to go to the Author Index">
             Huang, Xiaowei
            </a>
           </td>
           <td class="r">
            University of Liverpool
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#109142" title="Click to go to the Author Index">
             Bensalem, Saddek
            </a>
           </td>
           <td class="r">
            University Grenoble
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2191" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Out-of-distribution (OoD) detection techniques for deep neural networks (DNNs) become crucial thanks to their filtering of abnormal inputs, especially when DNNs are used in safety-critical applications and interact with an open and dynamic environment. Nevertheless, integrating OoD detection into state-of-the-art (SOTA) object detection DNNs poses significant challenges, partly due to the complexity introduced by the SOTA OoD construction methods, which require the modification of DNN architecture and the introduction of complex loss functions. This paper proposes a simple, yet surprisingly effective, method that requires neither retraining nor architectural change in object detection DNN, called Box Abstraction-based Monitors (BAM). The novelty of BAM stems from using a finite union of convex box abstractions to capture the learned features of objects for in-distribution (ID) data, and an important observation that features from OoD data are more likely to fall outside of these boxes. The union of convex regions within the feature space allows the formation of non-convex and interpretable decision boundaries, overcoming the limitations of VOS-like detectors without sacrificing real-time performance. Experiments integrating BAM into Faster R-CNN-based object detection DNNs demonstrate a considerably improved performance against SOTA OoD detection techniques, with a reduction in the false detection rate of over 10% in most cases.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t4_11">
             09:00-10:00, Paper WePI2T4.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2310'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Embodied Uncertainty-Aware Object Segmentation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#298963" title="Click to go to the Author Index">
             Fang, Xiaolin
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103153" title="Click to go to the Author Index">
             Kaelbling, Leslie
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106519" title="Click to go to the Author Index">
             Lozano-Perez, Tomas
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2310" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#perception_action_coupling" title="Click to go to the Keyword Index">
               Perception-Action Coupling
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We introduce uncertainty-aware object instance segmentation (UNCOS) and demonstrate its usefulness for embodied interactive segmentation. To deal with uncertainty in robot perception, we propose a method for generating a hypothesis distribution of object segmentation. We obtain a set of region-factored segmentation hypotheses together with confidence estimates by making multiple queries of large pre-trained models. This process can produce segmentation results that achieve state-of-the-art performance on unseen object segmentation problem. The output can also serve as input to a belief-driven process for selecting robot actions to perturb the scene to reduce ambiguity. We demonstrate the effectiveness of this method in real-robot experiments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t4_12">
             09:00-10:00, Paper WePI2T4.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3029'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Unsupervised 3D Part Decomposition Via Leveraged Gaussian Splatting
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#238665" title="Click to go to the Author Index">
             Choy, Jae Goo
            </a>
           </td>
           <td class="r">
            Sequor Robotics
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#216356" title="Click to go to the Author Index">
             Cha, Geonho
            </a>
           </td>
           <td class="r">
            NAVER Corp
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#266254" title="Click to go to the Author Index">
             Kee, Hogun
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#119971" title="Click to go to the Author Index">
             Oh, Songhwai
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3029" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#recognition" title="Click to go to the Keyword Index">
               Recognition
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We propose a novel unsupervised method for motion-based 3D part decomposition of articulated objects using a single monocular video of a dynamic scene. In contrast to existing unsupervised methods relying on optical flow or tracking techniques, our approach addresses this problem without additional information by leveraging Gaussian splatting techniques. We generate a series of Gaussians from a monocular video and analyze their relationships to decompose the dynamic scene into motion-based parts. To decompose dynamic scenes consisting of articulated objects, we design an articulated deformation field suitable for the movement of articulated objects. And to effectively understand the relationships of Gaussians of different shapes, we propose a 3D reconstruction loss using 3D occupied voxel maps generated from the Gaussians. Experimental results demonstrate that our method outperforms existing approaches in terms of 3D part decomposition for articulated objects. More demos and code are available at https://choonsik93.github.io/artnerf/.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t4_13">
             09:00-10:00, Paper WePI2T4.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3352'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Non-Repetitive: A Promising LiDAR Scanning Pattern
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391301" title="Click to go to the Author Index">
             Xie, Angchen
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#205158" title="Click to go to the Author Index">
             Qian, Yeqiang
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#300932" title="Click to go to the Author Index">
             Yan, Weihao
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#191295" title="Click to go to the Author Index">
             Wang, Chunxiang
            </a>
           </td>
           <td class="r">
            Shanghai Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#146916" title="Click to go to the Author Index">
             Yang, Ming
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3352" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             LiDAR is an essential sensor for intelligent vehicles. Recently, LiDARs used in vehicles produced by different companies have significant differences in their scanning patterns. Some vehicles use mechanical and solid-state (repetitive) LiDARs, while others use prism-based (non-repetitive) LiDARs. The scanning pattern of a LiDAR has a profound impact on its scanning performance. To investigate the influence of LiDAR scanning patterns, we created the ``Repetitive-or-not" dataset, which is collected simultaneously by LiDARs with both repetitive and non-repetitive scanning patterns in the CARLA simulation environment. Using this dataset, we conducted a comprehensive statistical analysis of the scanning ability of repetitive and non-repetitive LiDARs. Furthermore, we looked into the effects of these two LiDAR scanning patterns on the performance of various 3D object detection algorithms. Finally, we explored the domain gap in the point cloud data produced by repetitive and non-repetitive LiDARs. Through an in-depth investigation of the ``Repetitive-or-not" dataset, we have discovered that non-repetitive LiDAR shows great promise. This conclusion is primarily supported by its superior object scanning capabilities.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t4_14">
             09:00-10:00, Paper WePI2T4.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3430'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Scale Disparity of Instances in Interactive Point Cloud Segmentation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397290" title="Click to go to the Author Index">
             Han, Chenrui
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#361265" title="Click to go to the Author Index">
             Yu, Xuan
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398486" title="Click to go to the Author Index">
             Xie, Yuxuan
            </a>
           </td>
           <td class="r">
            Tongji University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#361267" title="Click to go to the Author Index">
             Liu, Yili
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#352739" title="Click to go to the Author Index">
             Mao, Sitong
            </a>
           </td>
           <td class="r">
            ShenZhen Huawei Cloud Computing Technologies Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#195314" title="Click to go to the Author Index">
             Zhou, Shunbo
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#113216" title="Click to go to the Author Index">
             Xiong, Rong
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#156231" title="Click to go to the Author Index">
             Wang, Yue
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3430" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Interactive point cloud segmentation has become a pivotal task for understanding 3D scenes, enabling users to guide segmentation models with simple interactions such as clicks, therefore significantly reducing the effort required to tailor models to diverse scenarios and new categories.However, in the realm of interactive segmentation, the meaning of instance diverges from that in instance segmentation, because users might desire to segment instances of both thing and stuff categories that vary greatly in scale. Existing methods have focused on thing categories, neglecting the segmentation of stuff categories and the difficulties arising from scale disparity.To bridge this gap, we propose ClickFormer, an innovative interactive point cloud segmentation model that accurately segments instances of both thing and stuff categories. We propose a query augmentation module to augment click queries by a global query sampling strategy, thus maintaining consistent performance across different instance scales. Additionally, we employ global attention in the query-voxel transformer to mitigate the risk of generating false positives, along with several other network structure improvements to further enhance the model's segmentation performance. Experiments demonstrate that ClickFormer outperforms existing interactive point cloud segmentation methods across both indoor and outdoor datasets,providing more accurate segmentation results with fewer user clicks in an open-world setting.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t4_15">
             09:00-10:00, Paper WePI2T4.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2279'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              MDHA: Multi-Scale Deformable Transformer with Hybrid Anchors for Multi-View 3D Object Detection
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397479" title="Click to go to the Author Index">
             Adeline, Michelle
            </a>
           </td>
           <td class="r">
            Monash University Malaysia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#281937" title="Click to go to the Author Index">
             Loo, Junn Yong
            </a>
           </td>
           <td class="r">
            Monash Malaysia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#284764" title="Click to go to the Author Index">
             Baskaran, Vishnu Monn
            </a>
           </td>
           <td class="r">
            Monash University Malaysia
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2279" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Multi-view 3D object detection is a crucial component of autonomous driving systems. Contemporary query-based methods primarily depend either on dataset-specific initialization of 3D anchors, introducing bias, or utilize dense attention mechanisms, which are computationally inefficient and unscalable. To overcome these issues, we present MDHA, a novel sparse query-based framework, which constructs adaptive 3D output proposals using hybrid anchors from multi-view, multi-scale image input. Fixed 2D anchors are combined with depth predictions to form 2.5D anchors, which are projected to obtain 3D proposals. To ensure high efficiency, our proposed Anchor Encoder performs sparse refinement and selects the top-k anchors and features. Moreover, while existing multi-view attention mechanisms rely on projecting reference points to multiple images, our novel Circular Deformable Attention mechanism only projects to a single image but allows reference points to seamlessly attend to adjacent images, improving efficiency without compromising on performance. On the nuScenes val set, it achieves 46.4% mAP and 55.0% NDS with a ResNet101 backbone. MDHA significantly outperforms the baseline where anchor proposals are modelled as learnable embeddings. Code is available at https://github.com/NaomiEX/MDHA.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t4_16">
             09:00-10:00, Paper WePI2T4.16
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2230'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              R2SNet: Scalable Domain Adaptation for Object Detection in Cloud-Based Robotic Ecosystems Via Proposal Refinement
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#325292" title="Click to go to the Author Index">
             Antonazzi, Michele
            </a>
           </td>
           <td class="r">
            University of Milan
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#180015" title="Click to go to the Author Index">
             Luperto, Matteo
            </a>
           </td>
           <td class="r">
            Università Degli Studi Di Milano
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#115337" title="Click to go to the Author Index">
             Borghese, N. Alberto
            </a>
           </td>
           <td class="r">
            University of Milano
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#120727" title="Click to go to the Author Index">
             Basilico, Nicola
            </a>
           </td>
           <td class="r">
            University of Milan
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2230" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#distributed_robot_systems" title="Click to go to the Keyword Index">
               Distributed Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We introduce a novel approach for scalable domain adaptation in cloud robotics scenarios where robots rely on third-party AI inference services powered by large pre-trained deep neural networks. Our method is based on a downstream proposal-refinement stage running locally on the robots, exploiting a new lightweight DNN architecture, R2SNet. This architecture aims to mitigate performance degradation from domain shifts by adapting the object detection process to the target environment, focusing on relabeling, rescoring, and suppression of bounding-box proposals. Our method allows for local execution on robots, addressing the scalability challenges of domain adaptation without incurring significant computational costs. Real-world results on mobile service robots performing door detection show the effectiveness of the proposed method in achieving scalable domain adaptation.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wepi2t5">
             <b>
              WePI2T5
             </b>
            </a>
           </td>
           <td class="r">
            Room 5
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wepi2t5" title="Click to go to the Program at a Glance">
             <b>
              Deep Learning II
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#299310" title="Click to go to the Author Index">
             Shafique, Muhammad
            </a>
           </td>
           <td class="r">
            New York University Abu Dhabi
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t5_01">
             09:00-10:00, Paper WePI2T5.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2119'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Non-Invasive Device for Skin Cancer Diagnosis: First Clinical Evidence with Spectroscopic Data Enhanced by Machine Learning Algorithms
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#366349" title="Click to go to the Author Index">
             Mainardi, Vanessa
            </a>
           </td>
           <td class="r">
            Scuola Superiore Sant'Anna
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397680" title="Click to go to the Author Index">
             Carletti, Laura
            </a>
           </td>
           <td class="r">
            Scuola Superiore Sant'Anna
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#346557" title="Click to go to the Author Index">
             Tsiakmakis, Dimitrios
            </a>
           </td>
           <td class="r">
            Aristotle University of Thessaloniki
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397819" title="Click to go to the Author Index">
             Dal Canto, Marco
            </a>
           </td>
           <td class="r">
            Scuola Superiore Sant'Anna
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397821" title="Click to go to the Author Index">
             Mellilo, Tommaso
            </a>
           </td>
           <td class="r">
            Scuola Superiore Sant'Anna
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397812" title="Click to go to the Author Index">
             Noferi, Stefano
            </a>
           </td>
           <td class="r">
            Noze Srl
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397822" title="Click to go to the Author Index">
             Bagnoni, Giovanni
            </a>
           </td>
           <td class="r">
            Dermatological Department of Spedali Riuniti
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397826" title="Click to go to the Author Index">
             Rubegni, Pietro
            </a>
           </td>
           <td class="r">
            Dermatological Department of Senese Hospital
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#250675" title="Click to go to the Author Index">
             Ciuti, Gastone
            </a>
           </td>
           <td class="r">
            Scuola Superiore Sant'Anna
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2119" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#health_care_management" title="Click to go to the Keyword Index">
               Health Care Management
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#engineering_for_robotic_systems" title="Click to go to the Keyword Index">
               Engineering for Robotic Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Skin cancer represents a significant global health concern, with melanoma alone accounting for thousands of deaths annually. Early diagnosis is crucial for improving survival rates and reducing healthcare costs. While traditional diagnostic approaches involve visual inspection followed by biopsy, emerging technologies offer less invasive options with improved precision. In this study, a novel non-invasive device was designed, developed, and validated to employ near-infrared reflectance spectroscopy for skin lesion analysis. Furthermore, this work presents a machine learning approach aimed at classifying different types of skin lesions, as well as a new sequential approach to distinguish benign from malignant lesions based on spectral data and exploring the impact of anamnestic features. The device was used in two independent hospitals in Italy to collect data from 69 patients in total, including various types of skin lesions, all of whom followed the standard protocol for screening and diagnosis intervention. The implemented model achieved a recall of 93.8% and an accuracy of 75% for melanoma and benign classification, and a recall of 100% and an accuracy of 98.6% in distinguishing non-melanoma cancer from benign lesions, demonstrating promising results for skin cancer diagnosis utilizing spectral and anamnestic data. In summary, this study contributes to the development of allied non-invasive diagnostic tools and underscores the potential of machine learning in dermatology using spectroscopic data.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t5_02">
             09:00-10:00, Paper WePI2T5.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('193'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Deep Signed Directional Distance Function for Shape Representation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#277390" title="Click to go to the Author Index">
             Zobeidi, Ehsan
            </a>
           </td>
           <td class="r">
            University of California San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#149893" title="Click to go to the Author Index">
             Atanasov, Nikolay
            </a>
           </td>
           <td class="r">
            University of California, San Diego
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab193" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#representation_learning" title="Click to go to the Keyword Index">
               Representation Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Predicting accurate observations efficiently from novel views is a key requirement for several robotics applications. Existing shape and surface representations, however, either require expensive ray-tracing operations, e.g., in the case of meshes or signed distance functions (SDFs), or offer only a coarse view, e.g., in the case of quadrics or point clouds. We develop a new representation that captures viewing direction and enables fast novel view synthesis. Our first contribution is a signed directional distance function (SDDF) that extends the SDF definition by measuring distance in a desired viewing direction rather than to the nearest point. As a result, SDDF removes post-processing steps for view synthesis required by SDF, such as surface extraction via marching cubes or rendering via sphere tracing, and allows ray-tracing through a single function call. SDDF also encodes by construction the property that distance decreases linearly along the viewing direction. We show that this enables dimensionality reduction in the function representation and guarantees the prediction accuracy independent of the distance to the surface. Recent advances demonstrate impressive performance of deep neural networks for shape learning, including IGR for SDF, Occupancy Networks for occupancy, AtlasNet for meshes, and NeRF for density. Our second contribution, DeepSDDF, is a deep neural network model for SDDF shape learning. Similar to IGR, we show that DeepSDDF can model whole object categories and interpolate or complete shapes from partial views.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t5_03">
             09:00-10:00, Paper WePI2T5.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('326'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Best of Both Worlds: Hybrid SNN-ANN Architecture for Event-Based Optical Flow Estimation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#389112" title="Click to go to the Author Index">
             Negi, Shubham
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391369" title="Click to go to the Author Index">
             Sharma, Deepika
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#273795" title="Click to go to the Author Index">
             Kosta, Adarsh Kumar
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#299278" title="Click to go to the Author Index">
             Roy, Kaushik
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab326" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In the field of robotics, event-based cameras are emerging as a promising low-power alternative to traditional frame-based cameras for capturing high-speed motion and high dynamic range scenes. This is due to their sparse and asynchronous event outputs. Spiking Neural Networks (SNNs) with their asynchronous event-driven compute, show great potential for extracting the spatio-temporal features from these event streams. In contrast, the standard Analog Neural Networks (ANNs) fail to process event data effectively. However, training SNNs is difficult due to additional trainable parameters (thresholds and leaks), vanishing spikes at deeper layers, and a non-differentiable binary activation function. Furthermore, an additional data structure, “membrane potential", responsible for keeping track of temporal information, must be fetched and updated at every timestep in SNNs. To overcome these challenges, we propose a novel SNN-ANN hybrid architecture that combines the strengths of both. Specifically, we leverage the asynchronous compute capabilities of SNN layers to effectively extract the input temporal information. Concurrently, the ANN layers facilitate training and efficient hardware deployment on traditional machine learning hardware such as GPUs. We provide extensive experimental analysis for assigning each layer to be spiking or analog, leading to a network configuration optimized for performance and ease of training. We evaluate our hybrid architecture for optical flow estimation on DSEC-flow and Multi-Vehicle Stereo Event-Camera (MVSEC) datasets. On the DSEC-flow dataset, the hybrid SNN-ANN architecture achieves a 40% reduction in average endpoint error (AEE) with 22% lower energy consumption compared to Full-SNN, and 48% lower AEE compared to Full-ANN, while maintaining comparable energy usage.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t5_04">
             09:00-10:00, Paper WePI2T5.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('386'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Just Flip: Flipped Observation Generation and Optimization for Neural Radiance Fields to Cover Unobserved View
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#350110" title="Click to go to the Author Index">
             Lee, Sibaek
            </a>
           </td>
           <td class="r">
            Sungkyunkwan University (SKKU)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#350111" title="Click to go to the Author Index">
             Kang, Kyeongsu
            </a>
           </td>
           <td class="r">
            Ulsan National Institute of Science and Technology (UNIST)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#209868" title="Click to go to the Author Index">
             Yu, Hyeonwoo
            </a>
           </td>
           <td class="r">
            SungKyunKwan University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab386" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             With the advent of Neural Radiance Field (NeRF), representing 3D scenes through multiple observations has shown significant improvements. Since this cutting-edge technique can obtain high-resolution renderings by interpolating dense 3D environments, various approaches have been proposed to apply NeRF for the spatial understanding of robot perception. However, previous works are challenging to represent unobserved scenes or views on the unexplored robot trajectory, as these works do not take into account 3D reconstruction without observation information. To overcome this problem, we propose a method to generate flipped observation in order to cover absent observation for unexplored robot trajectory. To achieve this, we propose a data augmentation method for 3D reconstruction using NeRF by flipping observed images and estimating flipped camera 6DOF poses. Furthermore, to ensure the NeRF model operates robustly in general scenarios, we also propose a training method that adjusts the flipped pose and considers the uncertainty in flipped images accordingly. Our technique does not utilize an additional network, making it simple but fast, thus ensuring its suitability for robotic applications where real-time performance is important.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t5_05">
             09:00-10:00, Paper WePI2T5.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('439'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              RAM-NAS: Resource-Aware Multiobjective Neural Architecture Search Method for Robot Vision Tasks
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#387308" title="Click to go to the Author Index">
             Mao, Shouren
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392564" title="Click to go to the Author Index">
             Qin, MingHao
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100397" title="Click to go to the Author Index">
             Dong, Wei
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#338506" title="Click to go to the Author Index">
             Liu, Huajian
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#177263" title="Click to go to the Author Index">
             Gao, Yongzhuo
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab439" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Neural architecture search (NAS) has shown great promise in automatically designing lightweight models. However, conventional approaches are insufficient in training the supernet and pay little attention to actual robot hardware resources. To meet such challenges, we propose RAM-NAS, a resource-aware multi-objective NAS method that focuses on improving the supernet pretrain and resource-awareness on robot hardware devices. We introduce the concept of subnets mutual distillation, which refers to mutually distilling all subnets sampled by the sandwich rule. Additionally, we utilize the Decoupled Knowledge Distillation (DKD) loss to enhance logits distillation performance. To expedite the search process with consideration for hardware resources, we used data from three types of robotic edge hardware to train Latency Surrogate predictors. These predictors facilitated the estimation of hardware inference latency during the search phase, enabling a unified multi-objective evolutionary search to balance model accuracy and latency trade-offs. Our discovered model family, RAM-NAS models, can achieve top-1 accuracy ranging from 76.7% to 81.4% on ImageNet. In addition, the resource-aware multi-objective NAS we employ significantly reduces the model's inference latency on edge hardware for robots. We conducted experiments on downstream tasks to verify the scalability of our methods. The inference time for detection and segmentation is reduced on all three hardware types compared to MobileNetv3-based methods. Our work fills the gap in NAS for robot hardware resource-aware.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t5_06">
             09:00-10:00, Paper WePI2T5.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('550'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Towards Dynamic and Small Objects Refinement for Unsupervised Domain Adaptative Nighttime Semantic Segmentation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#365271" title="Click to go to the Author Index">
             Pan, Jingyi
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology (Guangzhou)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#313837" title="Click to go to the Author Index">
             Li, Sihang
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#374498" title="Click to go to the Author Index">
             Chen, Yucheng
            </a>
           </td>
           <td class="r">
            Hong Kong University of Technology and Science(Guangzhou)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376696" title="Click to go to the Author Index">
             Zhu, Jinjing
            </a>
           </td>
           <td class="r">
            HKUST(GZ)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#256235" title="Click to go to the Author Index">
             Wang, Lin
            </a>
           </td>
           <td class="r">
            HKUST
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab550" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Nighttime semantic segmentation plays a crucial role in practical applications, such as autonomous driving, where it frequently encounters difficulties caused by inadequate illumination conditions and the absence of well-annotated datasets. Moreover, semantic segmentation models trained on daytime datasets often face difficulties in generalizing effectively to nighttime conditions. Unsupervised domain adaptation (UDA) has shown the potential to address the challenges and achieved remarkable results for nighttime semantic segmentation. However, existing methods still face limitations in 1) their reliance on style transfer or relighting models, which struggle to generalize to complex nighttime environments, and 2) their ignorance of dynamic and small objects like vehicles and poles, which are difficult to be directly learned from other domains. This paper proposes a novel UDA method that refines both label and feature levels for dynamic and small objects for nighttime semantic segmentation. First, we propose a dynamic and small object refinement module to complement the knowledge of dynamic and small objects from the source domain to target the nighttime domain. These dynamic and small objects are normally context-inconsistent in under-exposed conditions. Then, we design a feature prototype alignment module to reduce the domain gap by deploying contrastive learning between features and prototypes of the same class from different domains, while re-weighting the categories of dynamic and small objects. Extensive experiments on three benchmark datasets demonstrate that our method outperforms prior arts by a large margin for nighttime segmentation. Project page: https://rorisis.github.io/DSRNSS/.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t5_07">
             09:00-10:00, Paper WePI2T5.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('594'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Latent Disentanglement for Low Light Image Enhancement
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#390480" title="Click to go to the Author Index">
             Zheng, Zhihao
            </a>
           </td>
           <td class="r">
            Lehigh University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#377301" title="Click to go to the Author Index">
             Chuah, Mooi Choo
            </a>
           </td>
           <td class="r">
            Lehigh University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab594" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Many learning-based low light image enhancement (LLIE) algorithms are based on the Retinex theory. However, the Retinex-based decomposition models introduce corruptions which limit their enhancement performance. In this paper, we propose a Latent Disentangle-based Enhancement Network (LDE-Net) for low light vision tasks. The latent disentanglement module disentangles the input image in latent space such that no corruption remains in the disentangled Content and Illumination components. For LLIE task, we design a Content-Aware Embedding (CAE) module that utilizes Content features to direct the enhancement of the Illumination component. For downstream tasks (e.g. nighttime UAV tracking and low light object detection), we develop an effective light-weight enhancer based on the latent disentanglement framework. Comprehensive quantitative and qualitative experiments demonstrate that our LDE-Net significantly outperforms state-of-the-art methods on various LLIE benchmarks. In addition, the great results obtained by applying our framework on the downstream tasks also demonstrate the usefulness of our latent disentanglement design.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t5_08">
             09:00-10:00, Paper WePI2T5.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('653'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              CaFNet: A Confidence-Driven Framework for Radar Camera Depth Estimation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391381" title="Click to go to the Author Index">
             Sun, Huawei
            </a>
           </td>
           <td class="r">
            Technical University of Munich; Infineon Technologies AG
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392110" title="Click to go to the Author Index">
             Feng, Hao
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392273" title="Click to go to the Author Index">
             Ott, Julius
            </a>
           </td>
           <td class="r">
            Infineon Technologies AG
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391988" title="Click to go to the Author Index">
             Servadei, Lorenzo
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391986" title="Click to go to the Author Index">
             Wille, Robert
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab653" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Depth estimation is critical in autonomous driving for interpreting 3D scenes accurately. Recently, radar-camera depth estimation has become of sufficient interest due to the robustness and low-cost properties of radar. Thus, this paper introduces a two-stage, end-to-end trainable Confidence-aware Fusion Net (CaFNet) for dense depth estimation, combining RGB imagery with sparse and noisy radar point cloud data. The first stage addresses radar-specific challenges, such as ambiguous elevation and noisy measurements, by predicting a radar confidence map and a preliminary coarse depth map. A novel approach is presented for generating the ground truth for the confidence map, which involves associating each radar point with its corresponding object to identify potential projection surfaces. These maps, together with the initial radar input, are processed by a second encoder. For the final depth estimation, we innovate a confidence-aware gated fusion mechanism to integrate radar and image features effectively, thereby enhancing the reliability of the depth map by filtering out radar noise. Our methodology, evaluated on the nuScenes dataset, demonstrates superior performance, improving upon the current leading model by 3.2% in Mean Absolute Error (MAE) and 2.7% in Root Mean Square Error (RMSE). Code: https://github.com/harborsarah/CaFNet
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t5_09">
             09:00-10:00, Paper WePI2T5.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1095'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              VANP: Learning Where to See for Navigation with Self-Supervised Vision-Action Pre-Training
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#349198" title="Click to go to the Author Index">
             Nazeri, Mohammad
            </a>
           </td>
           <td class="r">
            PhD Student at George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391947" title="Click to go to the Author Index">
             Wang, Junzhe
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#350504" title="Click to go to the Author Index">
             Payandeh, Amirreza
            </a>
           </td>
           <td class="r">
            George Mason
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#177144" title="Click to go to the Author Index">
             Xiao, Xuesu
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1095" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#representation_learning" title="Click to go to the Keyword Index">
               Representation Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Humans excel at efficiently navigating through crowds without collision by focusing on specific visual regions relevant to navigation. However, most robotic visual navigation methods rely on deep learning models pre-trained on vision tasks, which prioritize salient objects---not necessarily relevant to navigation and potentially misleading. Alternative approaches train specialized navigation models from scratch, requiring significant computation. On the other hand, self-supervised learning has revolutionized computer vision and natural language processing, but its application to robotic navigation remains underexplored due to the difficulty of defining effective self-supervision signals. Motivated by these observations, in this work, we propose a Self-Supervised Vision-Action Model for Visual Navigation Pre-Training (VANP). Instead of detecting salient objects that are beneficial for tasks such as classification or detection, VANP learns to focus only on specific visual regions that are relevant to the navigation task. To achieve this, VANP uses a history of visual observations, future actions, and a goal image for self-supervision, and embeds them using two small Transformer Encoders. Then, VANP maximizes the information between the embeddings by using a mutual information maximization objective function. We demonstrate that most VANP-extracted features match with human navigation intuition. VANP achieves comparable performance as models learned end-to-end with half the training time and models trained on a large-scale, fully supervised dataset, i.e., ImageNet, with only 0.08% data.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t5_10">
             09:00-10:00, Paper WePI2T5.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1168'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SD-Net: Symmetric-Aware Keypoint Prediction and Domain Adaptation for 6D Pose Estimation in Bin-Picking Scenarios
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#366196" title="Click to go to the Author Index">
             Huang, Dingtao
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376942" title="Click to go to the Author Index">
             Lin, Ente
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#217702" title="Click to go to the Author Index">
             Chen, Lipeng
            </a>
           </td>
           <td class="r">
            Tencent
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376239" title="Click to go to the Author Index">
             Liu, Lifu
            </a>
           </td>
           <td class="r">
            Shenzhen International Graduate School, Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#214687" title="Click to go to the Author Index">
             Zeng, Long
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1168" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_manufacturing" title="Click to go to the Keyword Index">
               Computer Vision for Manufacturing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Despite the success in 6D pose estimation in bin-picking scenarios, existing methods still struggle to produce accurate prediction results for symmetry objects and real world scenarios. The primary bottlenecks include 1) the ambiguity keypoints caused by object symmetries; 2) the domain gap between real and synthetic data. To circumvent these problem, we propose a new 6D pose estimation network with symmetric-aware keypoint prediction and self-training domain adaptation (SD-Net). SD-Net builds on pointwise keypoint regression and deep hough voting to perform reliable detection keypoint under clutter and occlusion. Specifically, at the keypoint prediction stage, we designe a robust 3D keypoints selection strategy considering the symmetry class of objects and equivalent keypoints, which facilitate locating 3D keypoints even in highly occluded scenes. Additionally, we build an effective filtering algorithm on predicted keypoint to dynamically eliminate multiple ambiguity and outlier keypoint candidates. At the domain adaptation stage, we propose the self-training framework using a student-teacher training scheme. To carefully distinguish reliable predictions, we harnesses a tailored heuristics for 3D geometry pseudo labelling based on semi-chamfer distance. On public Sil'eane dataset, SD-Net achieves state-of-the-art results, obtaining an average precision of 96%. Testing learning and generalization abilities on public Parametric datasets, SD-Net is 8% higher than the state-of-the-art method. The code is available at https://github.com/dingthuang/SD-Net.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t5_11">
             09:00-10:00, Paper WePI2T5.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1223'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              MaskingDepth: Masked Consistency Regularization for Semi-Supervised Monocular Depth Estimation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#297232" title="Click to go to the Author Index">
             Baek, Jongbeom
            </a>
           </td>
           <td class="r">
            Korea University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#310264" title="Click to go to the Author Index">
             Kim, Gyeongnyeon
            </a>
           </td>
           <td class="r">
            Korea University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395893" title="Click to go to the Author Index">
             Park, Seonghoon
            </a>
           </td>
           <td class="r">
            Korea University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395891" title="Click to go to the Author Index">
             An, Honggyu
            </a>
           </td>
           <td class="r">
            Korea University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#223499" title="Click to go to the Author Index">
             Poggi, Matteo
            </a>
           </td>
           <td class="r">
            University of Bologna
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#219496" title="Click to go to the Author Index">
             Kim, Seungryong
            </a>
           </td>
           <td class="r">
            Korea University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1223" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We propose MaskingDepth, a semi-supervised learning framework for monocular depth estimation. MaskingDepth is designed to enforce consistency between the depths obtained from strongly-augmented images and the pseudo-depths derived from weakly-augmented images, which enables mitigating the reliance on large ground-truth depth quantities. In this framework, we leverage uncertainty estimation to only retain high-confident depth predictions from the weakly-augmented branch as pseudo-depths. We also present a novel data augmentation, dubbed K-way disjoint masking, that takes advantage of a naive token masking strategy as an augmentation, while avoiding its scale ambiguity problem between depths from weakly- and strongly-augmented branches and risk of missing small-scale objects. Experiments on KITTI and NYU-Depth-v2 datasets demonstrate the effectiveness of each component, its robustness to the use of fewer depth-annotated images, and superior performance compared to other state-of-the-art semi-supervised learning methods for monocular depth estimation.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t5_12">
             09:00-10:00, Paper WePI2T5.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1509'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of Its LEDs
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#374333" title="Click to go to the Author Index">
             Carlotti, Nicholas
            </a>
           </td>
           <td class="r">
            Dalle Molle Institute for Artificial Intelligence (IDSIA)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#235964" title="Click to go to the Author Index">
             Nava, Mirko
            </a>
           </td>
           <td class="r">
            IDSIA
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#155801" title="Click to go to the Author Index">
             Giusti, Alessandro
            </a>
           </td>
           <td class="r">
            IDSIA USI-SUPSI
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1509" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We consider the problem of training a fully convolutional network to estimate the relative 6D pose of a robot given a camera image, when the robot is equipped with independent controllable LEDs placed in different parts of its body. The training data is composed by few (or zero) images labeled with a ground truth relative pose and many images labeled only with the true state (on or off) of each of the peer LEDs. The former data is expensive to acquire, requiring external infrastructure for tracking the two robots; the latter is cheap as it can be acquired by two unsupervised robots moving randomly and toggling their LEDs while sharing the true LED states via radio.
             <p>
              Training with the latter dataset on estimating the LEDs' state of the peer robot (pretext task) promotes learning the relative localization task (end task).
              <p>
               Experiments on real-world data acquired by two autonomous wheeled robots show that a model trained only on the pretext task successfully learns to localize a peer robot on the image plane; fine-tuning such model on the end task with few labeled images yields statistically significant improvements in 6D relative pose estimation with respect to baselines that do not use pretext-task pre-training, and alternative approaches. Estimating the state of multiple independent LEDs promotes learning to estimate relative heading. The approach works even when a large fraction of training images do not include the peer robot and generalizes well to unseen environments.
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t5_13">
             09:00-10:00, Paper WePI2T5.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1521'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Exploring Few-Beam LiDAR Assistance in Self-Supervised Multi-Frame Depth Estimation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#347195" title="Click to go to the Author Index">
             Fan, Rizhao
            </a>
           </td>
           <td class="r">
            University of Bologna
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#223499" title="Click to go to the Author Index">
             Poggi, Matteo
            </a>
           </td>
           <td class="r">
            University of Bologna
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#224965" title="Click to go to the Author Index">
             Mattoccia, Stefano
            </a>
           </td>
           <td class="r">
            University of Bologna
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1521" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Self-supervised multi-frame depth estimation methods only require unlabeled monocular videos for training. However, most existing methods face challenges, including accuracy degradation caused by moving objects in dynamic scenes and scale ambiguity due to the absence of real-world references. In this field, the emergence of low-cost LiDAR sensors highlights the potential to improve the robustness of multi-frame depth estimation by exploiting accurate sparse measurements at the correct scale. Moreover, the LiDAR ranging points often intersect moving objects, providing more precise depth cues for them. This paper explores the impact of few-beam LiDAR data on self-supervised multi-frame depth estimation, proposing a method that fuses multi-frame matching and sparse depth features. It significantly enhances depth estimation robustness, particularly in scenarios involving moving objects and textureless backgrounds. We demonstrate the effectiveness of our approach through comprehensive experiments, showcasing its potential to address the limitations of existing methods and paving the way for more robust and reliable depth estimation based on this paradigm.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t5_14">
             09:00-10:00, Paper WePI2T5.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1577'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              MARVIS: Motion &amp; Geometry Aware Real and Virtual Image Segmentation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#341510" title="Click to go to the Author Index">
             Wu, Jiayi
            </a>
           </td>
           <td class="r">
            University of Maryland, College Park
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#301815" title="Click to go to the Author Index">
             Lin, Xiaomin
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106421" title="Click to go to the Author Index">
             Negahdaripour, Shahriar
            </a>
           </td>
           <td class="r">
            University of Miami
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#136632" title="Click to go to the Author Index">
             Fermuller, Cornelia
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#118557" title="Click to go to the Author Index">
             Aloimonos, Yiannis
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1577" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#marine_robotics" title="Click to go to the Keyword Index">
               Marine Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Tasks such as autonomous navigation, 3D reconstruction, and object recognition near the water surfaces are crucial in marine robotics applications. However, challenges arise due to dynamic disturbances, e.g., light reflections and refraction from the random air-water interface, irregular liquid flow, and similar factors, which can lead to potential failures in perception and navigation systems. Traditional computer vision algorithms struggle to differentiate between real and virtual image regions, significantly complicating tasks. A virtual image region is an apparent representation formed by the redirection of light rays, typically through reflection or refraction, creating the illusion of an object's presence without its actual physical location. This work proposes a novel approach for segmentation on real and virtual image regions, exploiting synthetic images combined with domain-invariant information, a Motion Entropy Kernel, and Epipolar Geometric Consistency. Our segmentation network does not need to be re-trained if the domain changes. We show this by deploying the same segmentation network in two different domains: simulation and the real world. By creating realistic synthetic images that mimic the complexities of the water surface, we provide fine-grained training data for our network (MARVIS) to discern between real and virtual images effectively. By motion &amp; geometry-aware design choices and through comprehensive experimental analysis, we achieve state-of-the-art real-virtual image segmentation performance in unseen real world domain, achieving an IoU over 78% and a F1-Score over 86% while ensuring a small computational footprint. MARVIS offers over 43 FPS (8 FPS) inference rates on a single GPU (CPU core). Our code and dataset are available here https://github.com/jiayi-wu-umd/MARVIS.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t5_15">
             09:00-10:00, Paper WePI2T5.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1859'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SSAP: A Shape-Sensitive Adversarial Patch for Comprehensive Disruption of Monocular Depth Estimation in Autonomous Navigation Applications
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#355308" title="Click to go to the Author Index">
             Guesmi, Amira
            </a>
           </td>
           <td class="r">
            NYU Abu Dhabi
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#325136" title="Click to go to the Author Index">
             Hanif, Muhammad Abdullah
            </a>
           </td>
           <td class="r">
            New York University Abu Dhabi (NYUAD)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#355336" title="Click to go to the Author Index">
             Alouani, Ihsen
            </a>
           </td>
           <td class="r">
            Queen's University Belfast
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397408" title="Click to go to the Author Index">
             Ouni, Bassem
            </a>
           </td>
           <td class="r">
            Technology Innovation Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#299310" title="Click to go to the Author Index">
             Shafique, Muhammad
            </a>
           </td>
           <td class="r">
            New York University Abu Dhabi
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1859" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Monocular depth estimation (MDE) has advanced significantly, primarily through the integration of convolutional neural networks (CNNs) and more recently, Transformers. However, concerns about their susceptibility to adversarial attacks have emerged, especially in safety-critical domains like autonomous driving and robotic navigation. Existing approaches for assessing CNN-based depth prediction methods have fallen short in inducing comprehensive disruptions to the vision system, often limited to specific local areas. In this paper, we introduce SSAP (Shape-Sensitive Adversarial Patch), a novel approach designed to comprehensively disrupt monocular depth estimation (MDE) in autonomous navigation applications. Our patch is crafted to selectively undermine MDE in two distinct ways: by distorting estimated distances or by creating the illusion of an object disappearing from the system's perspective. Notably, our patch is shape-sensitive, meaning it considers the specific shape and scale of the target object, thereby extending its influence beyond immediate proximity. Furthermore, our patch is trained to effectively address different scales and distances from the camera. Experimental results demonstrate that our approach induces a mean depth estimation error surpassing 0.5, impacting up to 99% of the targeted region for CNN-based MDE models. Additionally, we investigate the vulnerability of Transformer-based MDE models to patch-based attacks, revealing that SSAP yields a significant error of 0.59 and exerts substantial influence over 99% of the target region on these models.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t5_16">
             09:00-10:00, Paper WePI2T5.16
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('905'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Conditional Variational Autoencoders for Probabilistic Pose Regression
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#340625" title="Click to go to the Author Index">
             Zangeneh, Fereidoon
            </a>
           </td>
           <td class="r">
            KTH Royal Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#256125" title="Click to go to the Author Index">
             Bruns, Leonard
            </a>
           </td>
           <td class="r">
            KTH Royal Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#340656" title="Click to go to the Author Index">
             Dekel, Amit
            </a>
           </td>
           <td class="r">
            Univrses AB
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#158896" title="Click to go to the Author Index">
             Pieropan, Alessandro
            </a>
           </td>
           <td class="r">
            KTH
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101846" title="Click to go to the Author Index">
             Jensfelt, Patric
            </a>
           </td>
           <td class="r">
            KTH - Royal Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab905" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robots rely on visual relocalization to estimate their pose from camera images when they lose track. One of the challenges in visual relocalization is repetitive structures in the operation environment of the robot. This calls for probabilistic methods that support multiple hypotheses for robot's pose. We propose such a probabilistic method to predict the posterior distribution of camera poses given an observed image. Our proposed training strategy results in a generative model of camera poses given an image, which can be used to draw samples from the pose posterior distribution. Our method is streamlined and well-founded in theory and outperforms existing methods on localization in presence of ambiguities.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wepi2t6">
             <b>
              WePI2T6
             </b>
            </a>
           </td>
           <td class="r">
            Room 6
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wepi2t6" title="Click to go to the Program at a Glance">
             <b>
              Learning I
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#180884" title="Click to go to the Author Index">
             Sartoretti, Guillaume Adrien
            </a>
           </td>
           <td class="r">
            National University of Singapore (NUS)
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t6_01">
             09:00-10:00, Paper WePI2T6.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('992'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Bayesian Optimization for Sample-Efficient Policy Improvement in Robotic Manipulation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#236637" title="Click to go to the Author Index">
             Röfer, Adrian
            </a>
           </td>
           <td class="r">
            University of Freiburg
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#236721" title="Click to go to the Author Index">
             Nematollahi, Iman
            </a>
           </td>
           <td class="r">
            University of Freiburg
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#177085" title="Click to go to the Author Index">
             Welschehold, Tim
            </a>
           </td>
           <td class="r">
            Albert-Ludwigs-Universität Freiburg
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101785" title="Click to go to the Author Index">
             Burgard, Wolfram
            </a>
           </td>
           <td class="r">
            University of Technology Nuremberg
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#160427" title="Click to go to the Author Index">
             Valada, Abhinav
            </a>
           </td>
           <td class="r">
            University of Freiburg
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab992" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#learning_from_experience" title="Click to go to the Keyword Index">
               Learning from Experience
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Sample efficient learning of manipulation skills poses a major challenge in robotics. While recent approaches demonstrate impressive advances in the type of task that can be addressed and the sensing modalities that can be incorporated, they still require large amounts of training data. Especially with regard to learning actions on robots in the real world, this poses a major problem due to the high costs associated with both demonstrations and real-world robot interactions. To address this challenge, we introduce BOpt-GMM, a hybrid approach that combines imitation learning with own experience collection. We first learn a skill model as a dynamical system encoded in a Gaussian Mixture Model from a few demonstrations. We then improve this model with Bayesian optimization building on a small number of autonomous skill executions in a sparse reward setting. We demonstrate the sample efficiency of our approach on multiple complex manipulation skills in both simulations and real-world experiments. We make the video, code, and pre-trained models publicly available at http://bopt-gmm.cs.uni-freiburg.de.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t6_02">
             09:00-10:00, Paper WePI2T6.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1441'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              DecAP : Decaying Action Priors for Accelerated Imitation Learning of Torque-Based Legged Locomotion Policies
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#340519" title="Click to go to the Author Index">
             Sood, Shivam
            </a>
           </td>
           <td class="r">
            Indian Institute of Technology Kharagpur
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#293824" title="Click to go to the Author Index">
             Sun, Ge
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#379074" title="Click to go to the Author Index">
             Li, Peizhuo
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#180884" title="Click to go to the Author Index">
             Sartoretti, Guillaume Adrien
            </a>
           </td>
           <td class="r">
            National University of Singapore (NUS)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1441" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Optimal Control for legged robots has gone through a paradigm shift from position-based to torque-based control, owing to the latter's compliant and robust nature. In parallel to this shift, the community has also turned to Deep Reinforcement Learning (DRL) as a promising approach to directly learn locomotion policies for complex real-life tasks. However, most end-to-end DRL approaches still operate in position space, mainly because learning in torque space is often sample-inefficient and does not consistently converge to natural gaits. To address these challenges, we propose a two-stage framework. In the first stage, we generate our own imitation data by training a position-based policy, eliminating the need for expert knowledge to design optimal controllers. The second stage incorporates decaying action priors, a novel method to enhance the exploration of torque-based policies aided by imitation rewards. We show that our approach consistently outperforms imitation learning alone and is robust to scaling these rewards from 0.1x to 10x. We further validate the benefits of torque control by comparing the robustness of a position-based policy to a position-assisted torque-based policy on a quadruped (Unitree Go1) without any domain randomization in the form of external disturbances during training.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t6_03">
             09:00-10:00, Paper WePI2T6.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1587'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Efficient Trajectory Forecasting and Generation with Conditional Flow Matching
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#251252" title="Click to go to the Author Index">
             Ye, Sean
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#160727" title="Click to go to the Author Index">
             Gombolay, Matthew
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1587" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Trajectory prediction and generation are crucial for autonomous robots in dynamic environments. While prior research has typically focused on either prediction or generation, our approach unifies these tasks to provide a versatile framework and achieve state-of-the-art performance. While diffusion models excel in trajectory generation, their iterative sampling process is computationally intensive, hindering robotic systems' dynamic capabilities. We introduce Trajectory Conditional Flow Matching (T-CFM), a novel approach using flow matching techniques to learn a solver time-varying vector field for efficient, fast trajectory generation. T-CFM demonstrates effectiveness in adversarial tracking, real-world aircraft trajectory forecasting, and long-horizon planning, outperforming state-of-the-art baselines with 35% higher predictive accuracy and 142% improved planning performance. Crucially, T-CFM achieves up to 100x speed-up compared to diffusion models without sacrificing accuracy, enabling real-time decision making in robotics. Codebase: https://github.com/CORE-Robotics-Lab/TCFM
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t6_04">
             09:00-10:00, Paper WePI2T6.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1899'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Driving from Vision through Differentiable Optimal Control
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396569" title="Click to go to the Author Index">
             Acerbo, Flavia Sofia
            </a>
           </td>
           <td class="r">
            Siemens Digital Industries Software
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#114656" title="Click to go to the Author Index">
             Swevers, Jan
            </a>
           </td>
           <td class="r">
            KU Leuven
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#129626" title="Click to go to the Author Index">
             Tuytelaars, Tinne
            </a>
           </td>
           <td class="r">
            KU Leuven
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397338" title="Click to go to the Author Index">
             Tong, Son
            </a>
           </td>
           <td class="r">
            Siemens Digital Industries Software
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1899" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper proposes DriViDOC: a framework for Driving from Vision through Differentiable Optimal Control, and its application to learn autonomous driving controllers from human demonstrations. DriViDOC combines the automatic inference of relevant features from camera frames with the properties of nonlinear model predictive control (NMPC), such as constraint satisfaction. Our approach leverages the differentiability of parametric NMPC, allowing for end-to-end learning of the driving model from images to control. The model is trained on an offline dataset comprising various human demonstrations collected on a motion-base driving simulator. During online testing, the model demonstrates successful imitation of different driving styles, and the interpreted NMPC parameters provide insights into the achievement of specific driving behaviors. Our experimental results show that DriViDOC outperforms other methods involving NMPC and neural networks, exhibiting an average improvement of 20% in imitation scores.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t6_05">
             09:00-10:00, Paper WePI2T6.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2374'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning Multi-Reference Frame Skills from Demonstration with Task-Parameterized Gaussian Processes
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#340254" title="Click to go to the Author Index">
             Ramirez Montero, Mariano
            </a>
           </td>
           <td class="r">
            Delft University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#269151" title="Click to go to the Author Index">
             Franzese, Giovanni
            </a>
           </td>
           <td class="r">
            TU Delft
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#117613" title="Click to go to the Author Index">
             Kober, Jens
            </a>
           </td>
           <td class="r">
            TU Delft
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#179240" title="Click to go to the Author Index">
             Della Santina, Cosimo
            </a>
           </td>
           <td class="r">
            TU Delft
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2374" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#probabilistic_inference" title="Click to go to the Keyword Index">
               Probabilistic Inference
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#probability_and_statistical_methods" title="Click to go to the Keyword Index">
               Probability and Statistical Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             A central challenge in Learning from Demonstration is to generate representations that are adaptable and can generalize to unseen situations. This work proposes to learn such a representation without using task-specific heuristics within the context of multi-reference frame skill learning by superimposing local skills in the global frame. Local policies are first learned by fitting the relative skills with respect to each frame using Gaussian Processes (GPs). Then, another GP, which determines the relevance of each frame for every time step, is trained in a self-supervised manner from a different batch of demonstrations. The uncertainty quantification capability of GPs is exploited to stabilize the local policies and to train the frame relevance in a fully Bayesian way. We validate the method through a dataset of multi-frame tasks generated in simulation and on real-world experiments with a robotic manipulation pick-and-place re-shelving task.
             <p>
              We evaluate the performance of our method with two metrics: how close the generated trajectories get to each of the task goals and the deviation between these trajectories and test expert trajectories. According to both of these metrics, the proposed method consistently outperforms the state-of-the-art baseline, Task-Parameterised Gaussian Mixture Model (TPGMM).
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t6_06">
             09:00-10:00, Paper WePI2T6.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2512'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              IntervenGen: Interventional Data Generation for Robust and Data-Efficient Robot Imitation Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#267585" title="Click to go to the Author Index">
             Hoque, Ryan
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#210582" title="Click to go to the Author Index">
             Mandlekar, Ajay Uday
            </a>
           </td>
           <td class="r">
            NVIDIA
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#183173" title="Click to go to the Author Index">
             Garrett, Caelan
            </a>
           </td>
           <td class="r">
            NVIDIA
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#107102" title="Click to go to the Author Index">
             Goldberg, Ken
            </a>
           </td>
           <td class="r">
            UC Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104592" title="Click to go to the Author Index">
             Fox, Dieter
            </a>
           </td>
           <td class="r">
            University of Washington
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2512" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robot_learning" title="Click to go to the Keyword Index">
               Data Sets for Robot Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Imitation learning is a promising paradigm for training robot control policies, but these policies can suffer from distribution shift, where the conditions at evaluation time differ from those in the training data. A popular approach for increasing policy robustness to distribution shift is interactive imitation learning (i.e., DAgger and variants), where a human operator provides corrective interventions during policy rollouts. However, collecting a sufficient amount of interventions to cover the distribution of policy mistakes can be burdensome for human operators. We propose IntervenGen (I-Gen), a novel data augmentation system for robot control that autonomously produces a large set of corrective interventions with rich coverage of the state space from a small number of human interventions. We apply I-Gen to 4 simulated environments and 1 physical environment with object pose estimation error and show that it can increase policy robustness by up to 39x with only 10 human interventions. Videos and more results are available at https://sites.google.com/view/intervengen2024.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t6_07">
             09:00-10:00, Paper WePI2T6.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2583'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning Generalizable Tool-Use Skills through Trajectory Generation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#318744" title="Click to go to the Author Index">
             Qi, Carl
            </a>
           </td>
           <td class="r">
            University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#269428" title="Click to go to the Author Index">
             Wu, Yilin
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398398" title="Click to go to the Author Index">
             Yu, Lifan
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#339538" title="Click to go to the Author Index">
             Liu, Haoyue
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#291310" title="Click to go to the Author Index">
             Jiang, Bowen
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#234074" title="Click to go to the Author Index">
             Lin, Xingyu
            </a>
           </td>
           <td class="r">
            UC Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#150386" title="Click to go to the Author Index">
             Held, David
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2583" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Autonomous systems that efficiently utilize tools can assist humans in completing many common tasks such as cooking and cleaning. However, current systems fall short of matching human-level of intelligence in terms of adapting to novel tools. Prior works based on affordance often make strong assumptions about the environments and cannot scale to more complex, contact-rich tasks. In this work, we tackle this challenge and explore how agents can learn to use previously unseen tools to manipulate deformable objects. We propose to learn a generative model of the tool-use trajectories as a sequence of point clouds, which generalizes to different tool shapes. Given any novel tool, we first generate a tool-use trajectory and then optimize the sequence of tool poses to align with the generated trajectory. We train a textit{single model} for four different challenging deformable object manipulation tasks. Our model is trained with demonstration data from just a textit{single tool} for each task and is able to generalize to various novel tools, significantly outperforming baselines. We also test our trained policy in the real world with unseen tools and it achieves the performance similar to human oracle.Additional materials can be found on our project website.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t6_08">
             09:00-10:00, Paper WePI2T6.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2784'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              ARCADE: Scalable Demonstration Collection and Generation Via Augmented Reality for Imitation Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398610" title="Click to go to the Author Index">
             Yang, Yue
            </a>
           </td>
           <td class="r">
            The University of North Carolina at Chapel Hill
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#314831" title="Click to go to the Author Index">
             Ikeda, Bryce
            </a>
           </td>
           <td class="r">
            University of North Carolina Chapel Hill
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#220790" title="Click to go to the Author Index">
             Bertasius, Gedas
            </a>
           </td>
           <td class="r">
            UNC Chapel Hill
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#184155" title="Click to go to the Author Index">
             Szafir, Daniel J.
            </a>
           </td>
           <td class="r">
            University of North Carolina at Chapel Hill
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2784" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#physical_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical Human-Robot Interaction
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robot Imitation Learning (IL) is a crucial technique in robot learning, where agents learn by mimicking human demonstrations. However, IL encounters scalability challenges stemming from both non-user-friendly demonstration collection methods and the extensive time required to amass a sufficient number of demonstrations for effective training. In response, we introduce the Augmented Reality for Collection and genertextitAtion of DEmonstrations (ARCADE) framework, designed to scale up demonstration collection for robot manipulation tasks. Our framework combines two key capabilities: 1) it leverages AR to make demonstration collection as simple as users performing daily tasks using their hands, and 2) it enables the automatic generation of additional synthetic demonstrations from a single human-derived demonstration, significantly reducing user effort and time. We assess ARCADE's performance on a real Fetch robot across three robotics tasks: 3-Waypoints-Reach, Push, and Pick-And-Place. Using our framework, we were able to rapidly train a policy using vanilla Behavioral Cloning (BC), a classic IL algorithm, which excelled across these three tasks. We also deploy ARCADE on a real household task, Pouring-Water, achieving an 80% success rate.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t6_09">
             09:00-10:00, Paper WePI2T6.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3014'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Self Supervised Detection of Incorrect Human Demonstrations: A Path Toward Safe Imitation Learning by Robots in the Wild
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#355218" title="Click to go to the Author Index">
             Sojib, Noushad
            </a>
           </td>
           <td class="r">
            University of New Hampshire
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#114366" title="Click to go to the Author Index">
             Begum, Momotaz
            </a>
           </td>
           <td class="r">
            University of New Hampshire
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3014" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robot_learning" title="Click to go to the Keyword Index">
               Data Sets for Robot Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             A major appeal of learning from demonstrations or imitation learning (IL) in robotics is that it learns a policy directly from lay users. However, Lay users may inadvertently provide erroneous demonstrations that lead to learning of policies that are inaccurate and hence, unsafe for humans and/or robot. This paper makes two contributions in the endeavour of recognizing human errors in demonstrations and thereby helping to learn a safe IL policy. First, we created a dataset – Layman V1.0 – with 15 lay users who provided a total of 1200 demonstrations for three simulated tasks – Lift, Can and Square in the simulated Robosuite environment – and two real robot tasks with a Sawyer robot, using a custom designed Android app for tele-operation. Second, we propose a framework named Behavior Cloning for Error Detection (BED) to autonomously detect and discard erroneous demonstrations from a demonstration pool. Our method uses a Behavior Cloning method as self-supervised technique and assigns binary weight to each demonstration based on its inconsistencies with the rest of the demonstrations. We show the effectiveness of this framework in detecting incorrect demonstrations in the Layman V1.0 dataset. We further show that state-of-the- art (SOTA) policy learners learns a better policy when bad demonstrations, identified through the proposed framework, are removed from the training pool. Dataset and Codes are available in https://github.com/AssistiveRoboticsUNH/bed
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t6_10">
             09:00-10:00, Paper WePI2T6.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Learning Force-Based Control Policies Via Differentiable Virtual Coupling (Diff-VC)
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#269025" title="Click to go to the Author Index">
             Galvan, Aldo
            </a>
           </td>
           <td class="r">
            University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#132936" title="Click to go to the Author Index">
             Majewicz Fey, Ann
            </a>
           </td>
           <td class="r">
            University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398887" title="Click to go to the Author Index">
             Patel, Ravi
            </a>
           </td>
           <td class="r">
            University of Texas at Austin
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t6_11">
             09:00-10:00, Paper WePI2T6.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3252'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              RISE: 3D Perception Makes Real-World Robot Imitation Simple and Effective
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#269964" title="Click to go to the Author Index">
             Wang, Chenxi
            </a>
           </td>
           <td class="r">
            Shanghai Noematrix Intelligence Technology Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#300234" title="Click to go to the Author Index">
             Fang, Hongjie
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#288067" title="Click to go to the Author Index">
             Fang, Hao-Shu
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#224610" title="Click to go to the Author Index">
             Lu, Cewu
            </a>
           </td>
           <td class="r">
            ShangHai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3252" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Precise robot manipulations require rich spatial information in imitation learning. Image-based policies model object positions from fixed cameras, which are sensitive to camera view changes. Policies utilizing 3D point clouds usually predict keyframes rather than continuous actions, posing difficulty in frequently changing scenarios. To utilize 3D perception efficiently, we present RISE, an end-to-end baseline for real-world imitation learning, which predicts continuous actions directly from single-view point clouds. It compresses the point cloud to tokens with a sparse 3D encoder. After adding sparse positional encoding, the tokens are then featurized using a transformer. Finally, the features are decoded into robot actions by a diffusion head. Trained with 50 demonstrations for each real-world task, RISE surpasses currently representative 2D and 3D policies by a large margin, showcasing significant advantages in both accuracy and efficiency. Experiments also demonstrate that RISE is more general and robust to environmental change compared with previous baselines. Project website: rise-policy.github.io.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t6_12">
             09:00-10:00, Paper WePI2T6.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3397'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              TinyLidarNet: 2D Lidar-Based End-To-End Deep Learning Model for F1TENTH Autonomous Racing
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393268" title="Click to go to the Author Index">
             Zarrar, Mohammed Misbah
            </a>
           </td>
           <td class="r">
            University of Kansas
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398876" title="Click to go to the Author Index">
             Weng, QiTao
            </a>
           </td>
           <td class="r">
            University of Kansas
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398592" title="Click to go to the Author Index">
             Yerjan, Bakhbyergyen
            </a>
           </td>
           <td class="r">
            University of Kansas
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398811" title="Click to go to the Author Index">
             Soyyigit, Ahmet
            </a>
           </td>
           <td class="r">
            University of Kansas
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#399059" title="Click to go to the Author Index">
             Yun, Heechul
            </a>
           </td>
           <td class="r">
            University of Kansas
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3397" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#embedded_systems_for_robotic_and_automation" title="Click to go to the Keyword Index">
               Embedded Systems for Robotic and Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Prior research has demonstrated the effectiveness of end-to-end deep learning for robotic navigation, where the control signals are directly derived from raw sensory data. However, the majority of existing end-to-end navigation solutions are predominantly camera-based. In this paper, we introduce TinyLidarNet, a lightweight 2D LiDAR-based end-to-end deep learning model for autonomous racing. An F1TENTH vehicle using TinyLidarNet won 3rd place in the 12th F1TENTH Autonomous Grand Prix competition, demonstrating its competitive performance. We systematically analyze its performance on untrained tracks and computing requirements for real-time processing. We find that TinyLidarNet's 1D Convolutional Neural Network (CNN) based architecture significantly outperforms widely used Multi-Layer Perceptron (MLP) based architecture. In addition, we show that it can be processed in real-time on low-end micro-controller units (MCUs).
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t6_13">
             09:00-10:00, Paper WePI2T6.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('198'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robust Imitation Learning for Mobile Manipulator Focusing on Task-Related Viewpoints and Regions
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#323924" title="Click to go to the Author Index">
             Ishida, Yutaro
            </a>
           </td>
           <td class="r">
            Toyota Motor Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#390595" title="Click to go to the Author Index">
             Noguchi, Yuki
            </a>
           </td>
           <td class="r">
            Toyota Motor Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#276161" title="Click to go to the Author Index">
             Kanai, Takayuki
            </a>
           </td>
           <td class="r">
            Toyota Motor Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#374936" title="Click to go to the Author Index">
             Shintani, Kazuhiro
            </a>
           </td>
           <td class="r">
            Toyota Motor Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#323899" title="Click to go to the Author Index">
             Bito, Hiroshi
            </a>
           </td>
           <td class="r">
            Toyota Motor Corporation
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab198" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mobile_manipulation" title="Click to go to the Keyword Index">
               Mobile Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We study how to generalize the visuomotor policy of a mobile manipulator from the perspective of visual observations. The mobile manipulator is prone to occlusion owing to its own body when only a single viewpoint is employed and a significant domain shift when deployed in diverse situations. However, to the best of the authors’ knowledge, no study has been able to solve occlusion and domain shift simultaneously and propose a robust policy. In this paper, we propose a robust imitation learning method for mobile manipulators that focuses on task-related viewpoints and their spatial regions when observing multiple viewpoints. The multiple viewpoint policy includes attention mechanism, which is learned with an augmented dataset, and brings optimal viewpoints and robust visual embedding against occlusion and domain shift. Comparison of our results for different tasks and environments with those of previous studies revealed that our proposed method improves the success rate by up to 29.3 points. We also conduct ablation studies using our proposed method. Learning task-related viewpoints from the multiple viewpoints dataset increases robustness to occlusion than using a uniquely defined viewpoint. Focusing on task-related regions contributes to up to a 33.3-point improvement in the success rate against domain shift.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t6_14">
             09:00-10:00, Paper WePI2T6.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1868'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Safe CoR: A Dual-Expert Approach to Integrating Imitation Learning and Safe Reinforcement Learning Using Constraint Rewards
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396916" title="Click to go to the Author Index">
             Kwon, Hyeokjin
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#246764" title="Click to go to the Author Index">
             Lee, Gunmin
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#340305" title="Click to go to the Author Index">
             Lee, Junseo
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#119971" title="Click to go to the Author Index">
             Oh, Songhwai
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1868" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In the realm of autonomous agents, ensuring safety and reliability in complex and dynamic environments remains a paramount challenge. Safe reinforcement learning addresses these concerns by introducing safety constraints, but still faces challenges in navigating intricate environments such as complex driving situations. To overcome these challenges, we present the safe constraint reward (Safe CoR) framework, a novel method that utilizes two types of expert demonstrations—reward expert demonstrations focusing on performance optimization and safe expert demonstrations prioritizing safety. By exploiting a constraint reward (CoR), our framework guides the agent to balance performance goals of reward sum with safety constraints. We test the proposed framework in diverse environments, including the safety gym, metadrive, and the real-world Jackal platform. Our proposed framework improves algorithm performance by 39% and reduces constraint violations by 88% on the real-world Jackal platform, highlighting its effectiveness. Through this innovative approach, we expect significant advancements in real-world performance, leading to transformative effects in the realm of safe and reliable autonomous agents.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t6_15">
             09:00-10:00, Paper WePI2T6.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2887'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Imitation Learning for Sim-To-Real Adaptation of Robotic Cutting Policies Based on Residual Gaussian Process Disturbance Force Model
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#313132" title="Click to go to the Author Index">
             Hathaway, Jamie
            </a>
           </td>
           <td class="r">
            University of Birmingham, Birmingham, UK
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#198452" title="Click to go to the Author Index">
             Rastegarpanah, Alireza
            </a>
           </td>
           <td class="r">
            University of Birmingham
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104289" title="Click to go to the Author Index">
             Stolkin, Rustam
            </a>
           </td>
           <td class="r">
            University of Birmingham
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2887" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#transfer_learning" title="Click to go to the Keyword Index">
               Transfer Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#model_learning_for_control" title="Click to go to the Keyword Index">
               Model Learning for Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robotic cutting, a crucial task in applications such as disassembly and decommissioning, faces challenges due to uncertainties in real-world environments. This paper presents a novel approach to enhance sim-to-real transfer of robotic cutting policies, leveraging a hybrid method integrating Gaussian process (GP) regression to model disturbance forces encountered during cutting tasks. By learning from a limited number of real-world trials, our method captures residual process dynamics, enabling effective adaptation to diverse materials without the need for fine-tuning on physical robots. Key to our approach is the utilisation of imitation learning, where expert actions in the uncorrected simulation are paired with GP-corrected observations. This pairing aligns action distributions between simulated and real-world domains, facilitating robust policy transfer. We illustrate the efficacy of our method through real world cutting trials in autonomously adapting to diverse material properties; our method surpasses re-training, while providing similar benefits to fine-tuning in real-world cutting scenarios. Notably, policies transferred using our approach exhibit enhanced resilience to noise and disturbances, while maintaining fidelity to expert behaviours from the source domain.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t6_16">
             09:00-10:00, Paper WePI2T6.16
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1729'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              ViSaRL: Visual Reinforcement Learning Guided by Human Saliency
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#378604" title="Click to go to the Author Index">
             Liang, Anthony
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#228363" title="Click to go to the Author Index">
             Thomason, Jesse
            </a>
           </td>
           <td class="r">
            USC Viterbi School of Engineering
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#246919" title="Click to go to the Author Index">
             Bıyık, Erdem
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1729" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#representation_learning" title="Click to go to the Keyword Index">
               Representation Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Training robots to perform complex control tasks from high-dimensional pixel input using reinforcement learning (RL) is sample-inefficient, because image observations are comprised primarily of task-irrelevant information. By contrast, humans are able to visually attend to task-relevant objects and areas. Based on this insight, we introduce Visual Saliency-Guided Reinforcement Learning (ViSaRL). Using ViSaRL to learn visual representations significantly improves the success rate, sample efficiency, and generalization of an RL agent on diverse tasks including DeepMind Control benchmark, robot manipulation in simulation and on a real robot. We present approaches for incorporating saliency into both CNN and Transformer-based encoders. We show that visual representations learned using ViSaRL are robust to various sources of visual perturbations including perceptual noise and scene variations. ViSaRL nearly doubles success rate on the real-robot tasks compared to the baseline which does not use saliency.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wepi2t7">
             <b>
              WePI2T7
             </b>
            </a>
           </td>
           <td class="r">
            Room 7
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wepi2t7" title="Click to go to the Program at a Glance">
             <b>
              Grasping &amp; Manipulation I
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t7_01">
             09:00-10:00, Paper WePI2T7.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('463'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              RTTF: Rapid Tactile Transfer Framework for Contact-Rich Manipulation Tasks
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372300" title="Click to go to the Author Index">
             Wu, Qiwei
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#370870" title="Click to go to the Author Index">
             Peng, Xuanbin
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372311" title="Click to go to the Author Index">
             Zhou, Jiayu
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372314" title="Click to go to the Author Index">
             Sun, Zhuoran
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#249197" title="Click to go to the Author Index">
             Xiong, Xiaogang
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100484" title="Click to go to the Author Index">
             Lou, Yunjiang
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology, Shenzhen
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab463" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#dexterous_manipulation" title="Click to go to the Keyword Index">
               Dexterous Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             An increasing number of robotic manipulation tasks now use optical tactile sensors to provide tactile feedback, making tactile servo control a crucial aspect of robotic operations. This paper presents a rapid tactile transfer framework (RTTF) that achieves optical-tactile image sim2real transfer and robust tactile servo control using limited paired data. The sim2real aspect of RTTF employs a semi-supervised approach, beginning with pretraining the latent space representations of tactile images and subsequently mapping different tactile image domains to a shared latent space within a simulated tactile image domain. This latent space, combined with the proprioceptive information of the robotic arm, is then integrated into a privileged learning framework for policy training, which results in a deployable tactile control policy. Our results demonstrate the robustness of the proposed framework in achieving task objectives across different tactile sensors with varying physical parameters. Furthermore, manipulators equipped with tactile sensors, allow for rapid training and deployment for diverse contact-rich tasks, including object pushing and surface-following.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t7_02">
             09:00-10:00, Paper WePI2T7.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3392'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Seg2Grasp: A Robust Modular Suction Grasping in Bin Picking
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#339622" title="Click to go to the Author Index">
             Yoon, Hye Jung
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#352172" title="Click to go to the Author Index">
             Kim, Juno
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#352260" title="Click to go to the Author Index">
             Park, Yesol
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#373017" title="Click to go to the Author Index">
             Lee, Jun Ki
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#133606" title="Click to go to the Author Index">
             Zhang, Byoung-Tak
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3392" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#logistics" title="Click to go to the Keyword Index">
               Logistics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Current bin picking methods that rely heavily on end-to-end learning often falter when confronted with unfamiliar or complex objects in unstructured environments. To overcome these limitations, we introduce Seg2Grasp, a modular pipeline designed for robust suction grasping in dynamic and cluttered bin scenarios. Seg2Grasp is built on a three-step process: Segmentation, Grasping, and Classification. The Segmentation module employs a Transformer-based model to generate class-agnostic object masks from RGB-D images, ensuring accurate detection across various conditions. The Grasping module uses surface normals and mask proposals to determine the optimal suction points, enhancing grasp success. Finally, the Classification module leverages fine-tuned open-vocabulary Mask-CLIP for precise object identification, enabling versatile handling of diverse objects. Real-world robotic experiments demonstrate that Seg2Grasp outperforms existing methods in success rates and adaptability, establishing it as a powerful tool for automated bin picking in industrial settings.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t7_03">
             09:00-10:00, Paper WePI2T7.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2077'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Beyond the Cascade: Juggling Vanilla Siteswap Patterns
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376468" title="Click to go to the Author Index">
             Gomez Andreu, Mario Alejandro
            </a>
           </td>
           <td class="r">
            Technical University Darmstadt
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#219221" title="Click to go to the Author Index">
             Ploeger, Kai
            </a>
           </td>
           <td class="r">
            Technische Universität Darmstadt
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104326" title="Click to go to the Author Index">
             Peters, Jan
            </a>
           </td>
           <td class="r">
            Technische Universität Darmstadt
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2077" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#art_and_entertainment_robotics" title="Click to go to the Keyword Index">
               Art and Entertainment Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#dexterous_manipulation" title="Click to go to the Keyword Index">
               Dexterous Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Being widespread in human motor behavior, dynamic movements demonstrate higher efficiency and greater capacity to address a broader range of skill domains compared to their quasi-static counterparts. Among the frequently studied dynamic manipulation problems, robotic juggling tasks stand out due to their inherent ability to scale their difficulty levels to arbitrary extents, making them an excellent subject for investigation. In this study, we explore juggling patterns with mixed throw heights, following the vanilla siteswap juggling notation, which jugglers widely adopted to describe toss juggling patterns. This requires extending our previous analysis of the simpler cascade juggling task by a throw-height sequence planner and further constraints on the end effector trajectory. These are not necessary for cascade patterns but are vital to achieving patterns with mixed throw heights. Using a simulated environment, we demonstrate successful juggling of most common 3-9 ball siteswap patterns up to 9 ball height, transitions between these patterns, and random sequences covering all possible vanilla siteswap patterns with throws between 2 and 9 ball height. https://kai-ploeger.com/beyond-cascades
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t7_04">
             09:00-10:00, Paper WePI2T7.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2295'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Insert-One: One-Shot Robust Visual-Force Servoing for Novel Object Insertion with 6-DoF Tracking
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#219127" title="Click to go to the Author Index">
             Chang, Haonan
            </a>
           </td>
           <td class="r">
            Rutgers University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#114191" title="Click to go to the Author Index">
             Boularias, Abdeslam
            </a>
           </td>
           <td class="r">
            Rutgers University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#135389" title="Click to go to the Author Index">
             Jain, Siddarth
            </a>
           </td>
           <td class="r">
            Mitsubishi Electric Research Laboratories (MERL)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2295" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#assembly" title="Click to go to the Keyword Index">
               Assembly
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_servoing" title="Click to go to the Keyword Index">
               Visual Servoing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recent advancements in autonomous robotic assembly have shown promising results, especially in addressing the precision insertion challenge. However, achieving adaptability across diverse object categories and tasks often necessitates a learning phase that requires costly real-world data collection. Moreover, previous research often assumes either the rigid attachment of the inserted object to the robot’s end-effector or relies on precise calibration within structured environments. We propose a one-shot method for high-precision contact-rich manipulation assembly tasks, enabling a robot to perform insertions of new objects from randomly presented orientations using just a single demonstration image. Our method incorporates a hybrid framework that blends 6-DoF visual tracking-based iterative control and impedance control, facilitating high-precision tasks with real-time visual feedback. Importantly, our approach requires no pre-training and demonstrates resilience against uncertainties arising from camera pose calibration errors and disturbances in the object in-hand pose. We validate the effectiveness of the proposed framework through extensive experiments in real-world scenarios, encompassing various high-precision assembly tasks.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t7_05">
             09:00-10:00, Paper WePI2T7.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1600'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Exploring How Non-Prehensile Manipulation Expands Capability in Robots Experiencing Multi-Joint Failure
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#329574" title="Click to go to the Author Index">
             Briscoe-Martinez, Gilberto
            </a>
           </td>
           <td class="r">
            University of Colorado Boulder
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#250297" title="Click to go to the Author Index">
             Pasricha, Anuj
            </a>
           </td>
           <td class="r">
            University of Colorado Boulder
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#355151" title="Click to go to the Author Index">
             Abderezaei, Ava
            </a>
           </td>
           <td class="r">
            University of Colorado Boulder
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392426" title="Click to go to the Author Index">
             Chaganti, Rama Durga Santosh Kumar
            </a>
           </td>
           <td class="r">
            University of Colorado Boulder
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392473" title="Click to go to the Author Index">
             Vajrala, Sarath Chandra
            </a>
           </td>
           <td class="r">
            University of Colorado Boulder
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392502" title="Click to go to the Author Index">
             Popuri, Srikanth
            </a>
           </td>
           <td class="r">
            University of Colorado Boulder
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#168176" title="Click to go to the Author Index">
             Roncone, Alessandro
            </a>
           </td>
           <td class="r">
            University of Colorado Boulder
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1600" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#failure_detection_and_recovery" title="Click to go to the Keyword Index">
               Failure Detection and Recovery
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This work explores non-prehensile manipulation (NPM) and whole-body interaction as strategies for enabling robotic manipulators to conduct manipulation tasks despite experiencing locked multi-joint (LMJ) failures. LMJs are critical system faults where two or more joints become inoperable; they impose constraints on the robot's configuration and control spaces, consequently limiting the capability and reach of a prehensile-only approach. This approach involves three components: i) modeling the failure-constrained workspace of the robot, ii) generating a kinodynamic map of NPM actions within this workspace, and iii) a manipulation action planner that uses a sim-in-the-loop approach to select the best actions to take from the kinodynamic map. The experimental evaluation shows that our approach can increase the failure-constrained reachable area in LMJ cases by 79%. Further, it demonstrates the ability to complete real-world manipulation with up to 88.9% success when the end-effector is unusable and up to 100% success when it is usable.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t7_06">
             09:00-10:00, Paper WePI2T7.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2643'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Multimodal Failure Prediction for Vision-Based Manipulation Tasks with Camera Faults
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#357919" title="Click to go to the Author Index">
             Ma, Yuliang
            </a>
           </td>
           <td class="r">
            University of Stuttgart
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#389578" title="Click to go to the Author Index">
             Liu, Jingyi
            </a>
           </td>
           <td class="r">
            University of Stuttgart
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#292136" title="Click to go to the Author Index">
             Mamaev, Ilshat
            </a>
           </td>
           <td class="r">
            Proximity Robotics &amp; Automation GmbH
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#357830" title="Click to go to the Author Index">
             Morozov, Andrey
            </a>
           </td>
           <td class="r">
            University of Stuttgart
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2643" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#failure_detection_and_recovery" title="Click to go to the Keyword Index">
               Failure Detection and Recovery
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Due to the increasing behavioral and structural complexity of robots, it is challenging to predict the execution outcome after error detection. Anomaly detection methods can help detect errors and prevent potential failures. However, not every fault leads to a failure due to the system's fault tolerance or unintended error masking. In practical applications, a robotic system should have a potential failure evaluation module to estimate the probability of failures when receiving an error alert. Subsequently, a decision-making mechanism should help to take the next action, e.g., terminate, degrade performance, or continue the execution of the task. This paper proposes a multimodal method for failure prediction for vision-based manipulation systems that suffer from potential camera faults. We inject faults into images (e.g., noise and blur) and observe manipulation failure scenarios (e.g., pick failure, place failure, and collision) that can occur during the task. Through extensive fault injection experiments, we created a FAULT-to-FAILURE dataset containing 4000 real-world manipulation samples. The dataset is subsequently used to train the failure predictor. Our approach processes the combination of RGB images, masked images, and planned paths to effectively evaluate whether a certain faulty image could potentially lead to a manipulation failure. Results demonstrate that the proposed method outperforms state-of-the-art models in terms of overall performance, requires fewer sensors, and achieves faster inference speeds. The analytical software prototype and dataset are available at Github: MultimodalFailurePrediction.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t7_07">
             09:00-10:00, Paper WePI2T7.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('174'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Development of a Bendable and Extendable Soft Gripper Driven by Differential Worm Gear Mechanism
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#334801" title="Click to go to the Author Index">
             Selvamuthu, Moses Gladson
            </a>
           </td>
           <td class="r">
            Yamagata University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106440" title="Click to go to the Author Index">
             Tadakuma, Riichiro
            </a>
           </td>
           <td class="r">
            Yamagata University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab174" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             A gripper mechanism using flexible double-rack finger actuated using differential worm gear mechanism that can change its finger length according to the object being grasped was developed. Thermoplastic polyurethane (TPU) based fingers were soft, impact resistant, highly compliant, and were able to conform to the contour of the objects when grasping. The fingers can extend, contract and bend in 2D space when driven by the differential worm gear mechanism. A normal worm and an inner worm gear was used to actuate the flexible double-rack fingers. The relative motions between the two worm gears resulted in different motions of the finger. Multiple fingered configuration of the gripper can be driven from the same mechanism actuated using two actuators. A mathematical model was developed to describe the kinematics of the finger for positioning experiments. Experiments were also conducted to measure the fingertip force for different lengths of the finger. Grasping experiments of two and three-finger gripper were performed to test the grasping performance of the gripper for objects of different size, shape and weight. The gripper successfully grasped objects of different sizes by adjusting the finger length and conforming to the shape of the objects.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t7_08">
             09:00-10:00, Paper WePI2T7.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('291'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Gravity-Aware Grasp Generation with Implicit Grasp Mode Selection for Underactuated Hands
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#177032" title="Click to go to the Author Index">
             Ko, Tianyi
            </a>
           </td>
           <td class="r">
            Woven by Toyota, Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#172403" title="Click to go to the Author Index">
             Ikeda, Takuya
            </a>
           </td>
           <td class="r">
            Woven by Toyota, Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#371904" title="Click to go to the Author Index">
             Stewart, Thomas
            </a>
           </td>
           <td class="r">
            Woven by Toyota
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#238317" title="Click to go to the Author Index">
             Lee, Robert
            </a>
           </td>
           <td class="r">
            Australian Centre for Robotic Vision
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104350" title="Click to go to the Author Index">
             Nishiwaki, Koichi
            </a>
           </td>
           <td class="r">
            Woven by Toyota
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab291" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Learning-based grasp detectors typically assume precision grasp, where each finger only has one contact point, and estimate the grasp probability. In this work, we propose a data generation and learning pipeline that can leverage power grasp, which has more contact points with an enveloping configuration and is robust against both positioning error and force disturbance. To train a grasp detector to prioritize power grasp while still keeping precision grasp as the secondary choice, we propose to train the network against the magnitude of disturbance in the gravity direction a grasp can resist (gravity-rejection score) rather than the binary classification of success. We also provide an efficient data generation pipeline for a dataset with gravity-rejection score annotation. In addition to thorough ablation studies, quantitative evaluation in both simulation and real-robot clarifies the significant improvement in our approach, especially when the objects are heavy.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t7_09">
             09:00-10:00, Paper WePI2T7.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('581'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Multi-Fingered End-Effector Grasp Reflex Modeling for One-Shot Tactile Servoing in Tool Manipulation Tasks
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#269265" title="Click to go to the Author Index">
             Sheetz, Emily
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393222" title="Click to go to the Author Index">
             Savchenko, Misha
            </a>
           </td>
           <td class="r">
            METECS
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393233" title="Click to go to the Author Index">
             Zemler, Emma
            </a>
           </td>
           <td class="r">
            NASA
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393242" title="Click to go to the Author Index">
             Presswala, Abbas
            </a>
           </td>
           <td class="r">
            Aeyon (Jacobs)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393244" title="Click to go to the Author Index">
             Crouch, Andrew
            </a>
           </td>
           <td class="r">
            CACI
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#211225" title="Click to go to the Author Index">
             Azimi, Shaun
            </a>
           </td>
           <td class="r">
            NASA
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#107426" title="Click to go to the Author Index">
             Kuipers, Benjamin
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab581" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#in_hand_manipulation" title="Click to go to the Keyword Index">
               In-Hand Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multifingered_hands" title="Click to go to the Keyword Index">
               Multifingered Hands
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Autonomous tool manipulation tasks are challenging for robots because they must reason over the tool's object affordances, how to grasp the tool so it may be used, how the tool will interact with other objects in the environment, and how to perform the complex tool affordances to complete the manipulation task. Focusing on tool grasping presents further challenges, specifically generalization to novel tools and modeling the problem in an explainable way suitable for safety-critical task domains, such as robots operating autonomously to perform repair tasks in NASA lunar habitats. In this work, we focus on grasping tools in an explainable way that can be generalized to novel tools. We present a logistic regression based grasp reflex model, which maps continuous end-effector sensor data to a set of discrete symbolic states. An adjustment policy uses these symbolic states to compute the appropriate gradient to change the end-effector pose and increase the probability of a secure tool grasp. Once the tool grasp is sufficiently secure, the robot proceeds with the rest of the manipulation task. We test our grasp reflex model on 6 novel tools, and find that the model achieves one-shot generalization by successfully using tactile servoing to secure grasps from one example of a secure grasp state. The robot's ability to learn to grasp tools in an explainable way that achieves one-shot generalization to novel tools demonstrates the power of our grasp reflex model in allowing robots to achieve autonomous tool manipulation tasks.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t7_10">
             09:00-10:00, Paper WePI2T7.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('659'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              MultiGripperGrasp: A Dataset for Robotic Grasping from Parallel Jaw Grippers to Dexterous Hands
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393508" title="Click to go to the Author Index">
             Casas, Luis Felipe
            </a>
           </td>
           <td class="r">
            University of Texas at Dallas
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#327082" title="Click to go to the Author Index">
             Khargonkar, Ninad
            </a>
           </td>
           <td class="r">
            University of Texas at Dallas
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#151866" title="Click to go to the Author Index">
             Prabhakaran, B
            </a>
           </td>
           <td class="r">
            University of Texas at Dallas
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#206428" title="Click to go to the Author Index">
             Xiang, Yu
            </a>
           </td>
           <td class="r">
            University of Texas at Dallas
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab659" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multifingered_hands" title="Click to go to the Keyword Index">
               Multifingered Hands
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#dexterous_manipulation" title="Click to go to the Keyword Index">
               Dexterous Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We introduce a large-scale dataset named MultiGripperGrasp for robotic grasping. Our dataset contains 30.4M grasps from 11 grippers for 345 objects. These grippers range from two-finger grippers to five-finger grippers, including a human hand. All grasps in the dataset are verified in the robot simulator Isaac Sim to classify them as successful and unsuccessful grasps. Additionally, the object fall-off time for each grasp is recorded as a grasp quality measurement. Furthermore, the grippers in our dataset are aligned according to the orientation and position of their palms, allowing us to transfer grasps from one gripper to another. The grasp transfer significantly increases the number of successful grasps for each gripper in the dataset. Our dataset is useful to study generalized grasp planning and grasp transfer across different grippers.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t7_11">
             09:00-10:00, Paper WePI2T7.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('998'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Speeding up 6-DoF Grasp Sampling with Quality-Diversity
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#338725" title="Click to go to the Author Index">
             Huber, Johann
            </a>
           </td>
           <td class="r">
            ISIR, Sorbonne Université
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#266764" title="Click to go to the Author Index">
             Hélénon, François
            </a>
           </td>
           <td class="r">
            Sorbonne Université
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393054" title="Click to go to the Author Index">
             Kappel, Mathilde
            </a>
           </td>
           <td class="r">
            Institut Des Systèmes Intelligents Et De Robotique
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391346" title="Click to go to the Author Index">
             Chelly, Elie
            </a>
           </td>
           <td class="r">
            Sorbonne Université - Institut Des Systèmes Intelligents Et Rob
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#368126" title="Click to go to the Author Index">
             Khoramshahi, Mahdi
            </a>
           </td>
           <td class="r">
            Sorbonne Université
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102570" title="Click to go to the Author Index">
             Ben Amar, Faiz
            </a>
           </td>
           <td class="r">
            Université Pierre Et Marie Curie, Paris 6
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#110325" title="Click to go to the Author Index">
             Doncieux, Stéphane
            </a>
           </td>
           <td class="r">
            Sorbonne University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab998" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robot_learning" title="Click to go to the Keyword Index">
               Data Sets for Robot Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#evolutionary_robotics" title="Click to go to the Keyword Index">
               Evolutionary Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recent advances in AI have led to significant results in robotic learning, including natural language-conditioned planning and efficient optimization of controllers using generative models. However, the interaction data remains the bottleneck for generalization. Getting data for grasping is a critical challenge, as this skill is required to complete many manipulation tasks. Quality-Diversity (QD) algorithms optimize a set of solutions to get diverse, high-performing solutions to a given problem. This paper investigates how QD can be combined with priors to speed up the generation of diverse grasps poses in simulation compared to standard 6-DoF grasp sampling schemes. Experiments conducted on 4 grippers with 2-to-5 fingers on standard objects show that QD outperforms commonly used methods by a large margin. Further experiments show that QD optimization automatically finds some efficient priors that are usually hard coded. The deployment of generated grasps on a 2-finger gripper and an Allegro hand shows that the diversity produced maintains sim-to-real transferability. We believe these results to be a significant step toward the generation of large datasets that can lead to robust and generalizing robotic grasping policies.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t7_12">
             09:00-10:00, Paper WePI2T7.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1085'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Toward an Analytic Theory of Intrinsic Robustness for Dexterous Grasping
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#220442" title="Click to go to the Author Index">
             Li, Albert H.
            </a>
           </td>
           <td class="r">
            California Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#210078" title="Click to go to the Author Index">
             Culbertson, Preston
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#134049" title="Click to go to the Author Index">
             Ames, Aaron
            </a>
           </td>
           <td class="r">
            Caltech
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1085" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#dexterous_manipulation" title="Click to go to the Keyword Index">
               Dexterous Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multifingered_hands" title="Click to go to the Keyword Index">
               Multifingered Hands
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Conventional approaches to grasp planning require perfect knowledge of an object's pose and geometry. Uncertainties in these quantities induce uncertainties in the quality of planned grasps, which can lead to failure. Classically, grasp robustness refers to the ability to resist external disturbances after grasping an object. In contrast, this work studies robustness to intrinsic sources of uncertainty like object pose or geometry affecting grasp planning before execution. To do so, we develop a novel analytic theory of grasping that reasons about this intrinsic robustness by characterizing the effect of friction cone uncertainty on a grasp's force closure status. We apply this result in two ways. First, we analyze the theoretical guarantees on intrinsic robustness of two grasp metrics in the literature, the classical Ferrari-Canny metric and more recent min-weight metric. We validate these results with hardware trials that compare grasps synthesized with and without robustness guarantees, showing a clear improvement in success rates. Second, we use our theory to develop a novel analytic notion of probabilistic force closure, which we show can generate unique, uncertainty-aware grasps in simulation.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t7_13">
             09:00-10:00, Paper WePI2T7.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1482'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              6-DoF Grasp Detection in Clutter with Enhanced Receptive Field and Graspable Balance Sampling
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#390516" title="Click to go to the Author Index">
             Wang, Hanwen
            </a>
           </td>
           <td class="r">
            Beijing University of Posts and Telecommunications
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#367574" title="Click to go to the Author Index">
             Ying, Zhang
            </a>
           </td>
           <td class="r">
            Beijing University of Posts and Telecommunications
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394911" title="Click to go to the Author Index">
             Wang, Yunlong
            </a>
           </td>
           <td class="r">
            Institute of Automation, Chinese Academy of Sciences (CASIA)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#222665" title="Click to go to the Author Index">
             Li, Jian
            </a>
           </td>
           <td class="r">
            Beihang University &amp; National Research Center for Rehabilitation
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1482" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             6-DoF grasp detection of small-scale grasps is crucial for robots to perform specific tasks. This paper focuses on enhancing the recognition capability of small-scale grasping, aiming to improve the overall accuracy of grasping prediction results and the generalization ability of the network. We propose an enhanced receptive field method that includes a multi-radii cylinder grouping module and a passive attention module. This method enhances the receptive field area within the graspable space and strengthens the learning of graspable features. Additionally, we design a graspable balance sampling module based on a segmentation network, which enables the network to focus on features of small objects, thereby improving the recognition capability of small-scale grasping. Our network achieves state-of-the-art performance on the GraspNet-1Billion dataset, with an overall improvement of approximately 10% in average precision@k (AP). Furthermore, We deployed our grasp detection model on the PyBullet grasping platform and in real-world scenarios, validating the effectiveness of our method.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t7_14">
             09:00-10:00, Paper WePI2T7.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1597'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              GripFlexer: Development of Hybrid Gripper with a Novel Shape That Can Perform in Narrow Spaces
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#276897" title="Click to go to the Author Index">
             Kim, Donghyun
            </a>
           </td>
           <td class="r">
            Daegu Gyeongbuk Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#276888" title="Click to go to the Author Index">
             Choi, Sunghyun
            </a>
           </td>
           <td class="r">
            Daegu Gyeongbuk Institute of Science &amp; Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#250260" title="Click to go to the Author Index">
             Song, Bongsub
            </a>
           </td>
           <td class="r">
            Daegu Gyeongbuk Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#236900" title="Click to go to the Author Index">
             Song, Jinhyeok
            </a>
           </td>
           <td class="r">
            DGIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#319056" title="Click to go to the Author Index">
             Yoon, Jingon
            </a>
           </td>
           <td class="r">
            Daegu Gyeongbuk Institute of Science and Technology (DGIST), Dae
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#206601" title="Click to go to the Author Index">
             Yun, Dongwon
            </a>
           </td>
           <td class="r">
            Daegu Gyeongbuk Institute of Science and Technology (DGIST)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1597" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#tendon_wire_mechanism" title="Click to go to the Keyword Index">
               Tendon/Wire Mechanism
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#underactuated_robots" title="Click to go to the Keyword Index">
               Underactuated Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In recent years, the role of robots across industries has become increasingly diverse, and they are now required to perform complex missions beyond simple repetitive tasks. However, robots used in confined spaces that humans cannot reach or in disaster field missions have challenges in performing various tasks due to their small size. In this study, we developed a compact hybrid gripper that fuses a multi-finger gripper and a jamming gripper to perform various tasks in a confined environment. Such a hybrid gripper can have both the strengths of a multi finger gripper that can perform various tasks and a jamming gripper that can effectively handle irregular small objects. In this study, we developed a hybrid gripper "GripFlexer" based on theoretical analysis and confirmed its performance through experiments by taking the task of turning a circular doorknob, which is one of the most difficult tasks in disaster sites, as the final target task. We also confirmed that the two grippers of GripFlexer can interact by showing performance improvement effects when two grippers are operated simultaneously.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t7_15">
             09:00-10:00, Paper WePI2T7.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2735'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Enhancing Object Grasping Efficiency with Deep Learning and Post-Processing for Multi-Finger Robotic Hands
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#275419" title="Click to go to the Author Index">
             Samandi, Pouya
            </a>
           </td>
           <td class="r">
            Simon Fraser University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101859" title="Click to go to the Author Index">
             Gupta, Kamal
            </a>
           </td>
           <td class="r">
            Simon Fraser University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105977" title="Click to go to the Author Index">
             Mehrandezh, Mehran
            </a>
           </td>
           <td class="r">
            University of Regina
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2735" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper builds upon the well-established ML-based grasping technique, known as the Grasp-Rectangle (GR) method. The original GR method made two simplifying assumptions: it was designed exclusively for two-finger grippers, and it assumed that the gripper would approach objects solely from a top-down perspective on a horizontal surface. We have extended the GR method, for a multi-finger hand beyond these assumptions to (1) enable grasping from top and side angles and (2) engage multiple points of contact, enhancing the algorithm’s overall performance. Our approach leverages geometric cues extracted from object images to calculate the optimal grasp pose and contact points, thereby enhancing grasp reliability. Extensive testing was conducted using a 7- DOF robotic arm equipped with a 7-DOF 3-finger gripper. We achieved an accuracy of 98.6% on the Cornell Grasping Dataset with a processing time of 120 milliseconds. Furthermore, when assessing object grasping from both top and side perspectives, our algorithm delivered successful grasps at rates of 95% and 96%, respectively. These findings are rooted in a comprehensive series of tests performed across a diverse array of objects.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t7_16">
             09:00-10:00, Paper WePI2T7.16
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('452'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Task-Oriented Design Method for Monolithic Flexible Hands with Wire Drive Systems
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392635" title="Click to go to the Author Index">
             Kusuhara, Rina
            </a>
           </td>
           <td class="r">
            Osaka University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101838" title="Click to go to the Author Index">
             Higashimori, Mitsuru
            </a>
           </td>
           <td class="r">
            Osaka University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab452" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#tendon_wire_mechanism" title="Click to go to the Keyword Index">
               Tendon/Wire Mechanism
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#flexible_robotics" title="Click to go to the Keyword Index">
               Flexible Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multifingered_hands" title="Click to go to the Keyword Index">
               Multifingered Hands
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper discusses a novel task-oriented design method for wire-driven flexible hands. For a monolithic hand fabricated using 3D printing, an analytical design method is proposed to enable it to perform the given tasks. First, the wiring-synergy equation, which relates the parameters of the hand mechanism, the wire tension, and the generated posture is derived based on an analytical model of a hand with wire drive systems. Next, the posture-synergy equation is derived, using principal component analysis for multiple desired postures given to perform a task. Based on the isomorphism of the mathematical structure in the two synergy equations, a method for designing a hand is developed. By quantitatively evaluating the posture reproducibility with respect to the number of wire drive systems, this method can analytically determine the mechanism parameters and wire tension for the desired postures. Subsequently, the proposed method is validated through case studies. Finally, a hand for an in-hand manipulation task is developed, and the feasibility of the proposed method is validated experimentally. The method potentially contributes to expediting the design procedure, increasing the accuracy of the posture reproduction, and reducing the number of actuators.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t7_17">
             09:00-10:00, Paper WePI2T7.17
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1493'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Novel Geometrical Structure Robot Hand for Linear-Parallel Pinching and Coupled Self-Adaptive Hybrid Grasping
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393463" title="Click to go to the Author Index">
             Chen, Shi
            </a>
           </td>
           <td class="r">
            Nanchang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395403" title="Click to go to the Author Index">
             Zhang, Bihao
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395204" title="Click to go to the Author Index">
             Feng, Kehan
            </a>
           </td>
           <td class="r">
            Nanjing University of Aeronautics and Astronautics
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395231" title="Click to go to the Author Index">
             Wang, Yizhou
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#413965" title="Click to go to the Author Index">
             Li, Jiayun
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106792" title="Click to go to the Author Index">
             Zhang, Wenzeng
            </a>
           </td>
           <td class="r">
            Shenzhen X-Institute
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1493" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#underactuated_robots" title="Click to go to the Keyword Index">
               Underactuated Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Current robot hand grippers capable of self-adaptive or coupled grasping often cannot perform linear-parallel pinching at the physical end of the gripper, which is widely used in industrial applications. For this reason, this paper introduces a gripper with hybrid grasping modes— the LPCSA hand. It can achieve three grasping modes: linear-parallel pinching, coupled, and self-adaptive grasping. The design cleverly couples two kinds of Chebyshev linear mechanisms to enable flat movement at the end of the finger. It also utilizes the deformability of the parallelogram to achieve self-adaptive grasping. Furthermore, the gripper uses an idle stroke and a special component to facilitate the switch between the three modes. The linear-parallel pinching function is suitable for pinching objects of different sizes on the desktop. The self-adaptive grasping mode can adapt to objects of various shapes and sizes. The coupled grasping mode enables fast grasping of irregular objects. This paper also analyzes the kinematics and dynamics of the LPCSA hand. Combined with experiments, it demonstrates that the LPCSA hand has a wide range of grasping space and stable performance.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wepi2t8">
             <b>
              WePI2T8
             </b>
            </a>
           </td>
           <td class="r">
            Room 8
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wepi2t8" title="Click to go to the Program at a Glance">
             <b>
              Robot Motion Planning I
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#120785" title="Click to go to the Author Index">
             Manoonpong, Poramate
            </a>
           </td>
           <td class="r">
            Vidyasirimedhi Institute of Science and Technology (VISTEC)
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t8_01">
             09:00-10:00, Paper WePI2T8.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('336'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Active Information Gathering for Long-Horizon Navigation under Uncertainty by Predicting the Value of Information
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#337458" title="Click to go to the Author Index">
             Arnob, Raihan Islam
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#205862" title="Click to go to the Author Index">
             Stein, Gregory
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab336" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We address the task of long-horizon navigation in partially mapped environments for which active gathering of information about faraway unseen space is essential for good behavior. We present a novel planning strategy that, at training time, affords tractable computation of the value of information associated with revealing potentially informative regions of unseen space, data used to train a graph neural network to predict the goodness of temporally-extended exploratory actions. Our learning-augmented model-based planning approach predicts the expected value of information of revealing unseen space and is capable of using these predictions to actively seek information and so improving long-horizon navigation. Across two simulated office-like environments, our planner outperforms both competitive learned and non-learned baseline navigation strategies, achieving improvements of up to 63.76% and 36.68%, demonstrating its capacity to actively seek performance-critical information.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t8_02">
             09:00-10:00, Paper WePI2T8.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('358'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Time-Optimal Path Parameterization for Cooperative Multi-Arm Robotic Systems with Third-Order Constraints
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#338925" title="Click to go to the Author Index">
             Dio, Maximilian
            </a>
           </td>
           <td class="r">
            Friedrich-Alexander-Universität Erlangen-Nürnberg
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#159313" title="Click to go to the Author Index">
             Graichen, Knut
            </a>
           </td>
           <td class="r">
            Friedrich Alexander University Erlangen-Nürnberg
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#209618" title="Click to go to the Author Index">
             Völz, Andreas
            </a>
           </td>
           <td class="r">
            Friedrich-Alexander-Universität Erlangen-Nürnberg
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab358" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#dual_arm_manipulation" title="Click to go to the Keyword Index">
               Dual Arm Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a time-optimal path parameterization (TOPP) method for cooperative multi-arm robotic systems (MARS) manipulating heavy objects with third-order constraints that include jerk, torque rate and wrench rate limits. The method is based on a problem reformulation as a sequential linear program and provides a unified planning approach that is faster than previous convex optimization techniques. The equivalence to a reachability-based TOPP is shown and simulation results for a cooperative MARS consisting of two 7 degree of freedom (DOF) robots and a tightly grasped object with 6 DOFs are provided.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t8_03">
             09:00-10:00, Paper WePI2T8.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('389'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Neural Trajectory Model: Implicit Neural Trajectory Representation for Trajectories Generation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391417" title="Click to go to the Author Index">
             Yu, Zihan
            </a>
           </td>
           <td class="r">
            The Hongkong University of Science and Technology(Guangzhou)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#193090" title="Click to go to the Author Index">
             Tang, Yuqing
            </a>
           </td>
           <td class="r">
            International Digital Economy Academy (IDEA)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab389" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The multi-agent trajectory planning problem is a difficult problem in robotics due to its computational complexity and real-world environment complexity with uncertainty, non-linearity, and real-time requirements. Many existing solutions are either search-based or optimization-based approaches with simplified assumptions of environment, limited planning speed, and limited scalability in the number of agents. In this work, we first attempt to reformulate single-agent and multi-agent trajectory planning problems as query problems over an implicit neural representation of trajectories. We formulate such implicit representations as Neural Trajectory Models (NTM) which can be queried to generate nearly optimal trajectory in complex environments. We conduct experiments in simulation environments and demonstrate that NTM can solve single-agent and multi-agent trajectory planning problems. In the experiments, NTMs achieve (1) sub-millisecond panning time using GPUs, (2) almost avoiding all environment collision, (3) almost avoiding all inter-agent collision, and (4) generating almost shortest paths. We also demonstrate that the same NTM framework can also be used for trajectory correction and multi-trajectory conflict resolution refining low-quality and conflicting multi-agent trajectories into nearly optimal solutions efficiently. (Open source code is available at https://github.com/ laser2099/neural-trajectory-model)
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t8_04">
             09:00-10:00, Paper WePI2T8.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('883'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Planning for Long-Term Monitoring Missions in Time-Varying Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#268948" title="Click to go to the Author Index">
             Stephens, Alex
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#140866" title="Click to go to the Author Index">
             Lacerda, Bruno
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#116406" title="Click to go to the Author Index">
             Hawes, Nick
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab883" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#planning__scheduling_and_coordination" title="Click to go to the Keyword Index">
               Planning, Scheduling and Coordination
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#environment_monitoring_and_management" title="Click to go to the Keyword Index">
               Environment Monitoring and Management
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recent years have seen autonomous robots deployed in long-term missions across an ever-increasing breadth of domains. We consider robots deployed over a sequence of finite-horizon missions in the same environment, with the objective of maximising the value from observations of some unknown spatiotemporal process. This work is motivated by applications such as ecological monitoring, in which a robot might be repeatedly deployed in the field over weeks or months with the task of modelling processes of scientific interest. We formalise the problem of long-term monitoring over multiple finite-horizon missions as a Markov decision process with a partially unknown state, and present an online planning approach to address it. Our approach uses a spatiotemporal Gaussian process to model the environment and make predictions about unvisited states, integrating this with a belief-based Monte Carlo tree search algorithm which decides where the robot should go next. We empirically demonstrate the strengths of our framework through a series of experiments using synthetic data as well as real acoustic data from monitoring of bioactivity in coral reefs.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t8_05">
             09:00-10:00, Paper WePI2T8.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('473'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Local Path Planning among Pushable Objects Based on Reinforcement Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#297372" title="Click to go to the Author Index">
             Yao, Linghong
            </a>
           </td>
           <td class="r">
            University College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#177063" title="Click to go to the Author Index">
             Modugno, Valerio
            </a>
           </td>
           <td class="r">
            University College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#371005" title="Click to go to the Author Index">
             Delfaki, Andromachi Maria
            </a>
           </td>
           <td class="r">
            University College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#293915" title="Click to go to the Author Index">
             Liu, Yuanchang
            </a>
           </td>
           <td class="r">
            University College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#128031" title="Click to go to the Author Index">
             Stoyanov, Danail
            </a>
           </td>
           <td class="r">
            University College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#147896" title="Click to go to the Author Index">
             Kanoulas, Dimitrios
            </a>
           </td>
           <td class="r">
            University College London
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab473" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we introduce a method to tackle the problem of robot local path planning among pushable objects - an open problem in robotics. In particular, we simultaneously train multiple agents in a physics-based simulation environment, utilizing an Advantage Actor-Critic algorithm coupled with a deep neural network. The developed online policy enables these agents to push obstacles in ways that are not limited to axial alignments, adapt to unforeseen changes in obstacle dynamics instantaneously, and effectively tackle local path planning in confined areas. We tested the method in various simulated environments to prove the adaptation effectiveness to various unseen scenarios in unfamiliar settings. Moreover, we have successfully applied this policy on an actual quadruped robot, confirming its capability to handle the unpredictability and noise associated with real-world sensors and the inherent uncertainties in unexplored object-pushing tasks.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t8_06">
             09:00-10:00, Paper WePI2T8.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('481'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning-Informed Long-Horizon Navigation under Uncertainty for Vehicles with Dynamics
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#267223" title="Click to go to the Author Index">
             Khanal, Abhish
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#278703" title="Click to go to the Author Index">
             Bui, Hoang-Dung
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102421" title="Click to go to the Author Index">
             Plaku, Erion
            </a>
           </td>
           <td class="r">
            U.S. National Science Foundation
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#205862" title="Click to go to the Author Index">
             Stein, Gregory
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab481" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#nonholonomic_motion_planning" title="Click to go to the Keyword Index">
               Nonholonomic Motion Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present a novel approach to learning-augmented, long-horizon navigation under uncertainty in large-scale environments in which considering the robot dynamics is essential for informing good behavior. Our approach tightly integrates high-level planning, in which a dynamics-aware learned model estimates the goodness of actions that enter unseen space, and low-level planning, which provides dynamically feasible trajectories for both informing high-level decision-making and low-level progress towards the unseen goal. Owing to its ability to understand the impacts of the robot’s dynamics on how it should attempt to reach the goal, our approach achieves both higher reliability and improved navigation performance compared to competitive learning-informed and non-learned baselines in simulated office-building-like environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t8_07">
             09:00-10:00, Paper WePI2T8.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('623'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Enhancing Safety Via Deep Reinforcement Learning in Trajectory Planning for Agile Flights within Unknown Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#277830" title="Click to go to the Author Index">
             Rocha, Lidia
            </a>
           </td>
           <td class="r">
            UFSCar
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#255680" title="Click to go to the Author Index">
             Bidinotto, Jorge
            </a>
           </td>
           <td class="r">
            University of Sao Paulo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#128150" title="Click to go to the Author Index">
             Heintz, Fredrik
            </a>
           </td>
           <td class="r">
            Linköping University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#180334" title="Click to go to the Author Index">
             Tiger, Mattias
            </a>
           </td>
           <td class="r">
            AI and Integrated Computer Systems (AIICS), Linköping University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#139494" title="Click to go to the Author Index">
             Vivaldini, Kelen Cristiane Teixeira
            </a>
           </td>
           <td class="r">
            FEL-CTU / DC - UFSCar
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab623" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Unmanned aerial vehicles (UAVs), known for their agile flight capabilities, require safe trajectory planning to achieve high-speed flights. This is necessary to swiftly evade obstacles and adapt trajectories under hard real-time constraints. These adjustments are essential to generate viable paths that prevent collisions while maintaining high speeds with minimal tracking errors. This paper addresses the challenge of enhancing the safety of agile trajectory planning. The proposed method combines a supervised learning approach, as teacher policy, with deep reinforcement learning (DRL), as student policy. Initially, we train the teacher policy using a path planning algorithm that prioritizes safety while minimizing jerk and flight time. Then, we use this policy to guide the learning of the student policy in various unknown environments. Testing in simulation demonstrates noteworthy advancements, including an 80% reduction in tracking error, a 31% decrease in flight time, a 19% increase in high-speed duration, and a success rate improvement from 50% to 100%, as compared to baseline methods.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t8_08">
             09:00-10:00, Paper WePI2T8.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('664'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Generic Trajectory Planning Method for Constrained All-Wheel-Steering Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#320444" title="Click to go to the Author Index">
             Xin, Ren
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#319031" title="Click to go to the Author Index">
             Liu, Hongji
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#279609" title="Click to go to the Author Index">
             Chen, Yingbing
            </a>
           </td>
           <td class="r">
            The Hongkokng University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#279604" title="Click to go to the Author Index">
             Cheng, Jie
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#323660" title="Click to go to the Author Index">
             Wang, Sheng
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#182083" title="Click to go to the Author Index">
             Ma, Jun
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#125556" title="Click to go to the Author Index">
             Liu, Ming
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology (Guangzhou)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab664" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#nonholonomic_motion_planning" title="Click to go to the Keyword Index">
               Nonholonomic Motion Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a generic trajectory planning method for wheeled robots with fixed steering axes while the steering angle of each wheel is constrained. In the existing literatures, All-Wheel-Steering (AWS) robots, incorporating modes such as rotation-free translation maneuvers, in-situ rotational maneuvers, and proportional steering, exhibit inefficient performance due to time-consuming mode switches. This inefficiency arises from wheel rotation constraints and inter-wheel cooperation requirements. The direct application of a holonomic moving strategy can lead to significant slip angles or even structural failure. Additionally, the limited steering range of AWS wheeled robots exacerbates non-linearity characteristics, thereby complicating control processes. To address these challenges, we developed a novel planning method termed Constrained AWS (C-AWS), which integrates second-order discrete search with predictive control techniques. Experimental results demonstrate that our method adeptly generates feasible and smooth trajectories for C-AWS while adhering to steering angle constraints.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t8_09">
             09:00-10:00, Paper WePI2T8.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1251'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Safe and Efficient Timed-Elastic-Band Planner for Unstructured Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396093" title="Click to go to the Author Index">
             Xi, Haoyu
            </a>
           </td>
           <td class="r">
            University of Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#284456" title="Click to go to the Author Index">
             Li, Wei
            </a>
           </td>
           <td class="r">
            Institute of Computing Technology, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#216058" title="Click to go to the Author Index">
             Zhao, Fangzhou
            </a>
           </td>
           <td class="r">
            Institute of Computing Technology, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395603" title="Click to go to the Author Index">
             Chen, Liang
            </a>
           </td>
           <td class="r">
            Institute of Computing Technology: Beijing, CN
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#207125" title="Click to go to the Author Index">
             Hu, Yu
            </a>
           </td>
           <td class="r">
            Institute of Computing Technology Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1251" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In unstructured environments with complex obstacles and obscure road boundaries, the local planner faces more severe challenges in terms of safety and real-time performance. In order to fulfill these emerging requirements, we propose a novel Timed- Elastic-Band approach for unstructured environments, abbreviated as TEB-U. This approach incorporates a free space extraction optimization module for 2D occupancy grid maps, which efficiently transforms irregular free space boundaries into polygons and restrains robots within the boundaries. Moreover, a dynamic global point adjustment module is designed to adaptively correct the trajectory points obtained from the global planner, thereby enabling robots to travel along the centerline of free space and providing a better initial trajectory for subsequent modules. To reduce the computational cost, we replace the obstacle constraint of TEB with the boundary constraint in hyper-graph optimization. We evaluate our planner in three distinct scenarios, and the results show that TEB-U improves the average success rate by 21% and reduces the planning time by 23% compared to TEB in unstructured road, which demonstrates its safety and efficiency.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t8_10">
             09:00-10:00, Paper WePI2T8.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1263'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              An Optimization-Based Planner with B-Spline Parameterized Continuous-Time Reference Signals
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#383471" title="Click to go to the Author Index">
             Tao, Chuyuan
            </a>
           </td>
           <td class="r">
            University of Illinois, Urbana and Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#231782" title="Click to go to the Author Index">
             Cheng, Sheng
            </a>
           </td>
           <td class="r">
            University of Illinois Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391594" title="Click to go to the Author Index">
             Zhao, Yang
            </a>
           </td>
           <td class="r">
            University of Illinois Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#225315" title="Click to go to the Author Index">
             Wang, Fanxin
            </a>
           </td>
           <td class="r">
            University of Illinois at Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#151876" title="Click to go to the Author Index">
             Hovakimyan, Naira
            </a>
           </td>
           <td class="r">
            University of Illinois at Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1263" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             For the cascaded planning and control modules implemented for robot navigation, the frequency gap between the planner and controller has received limited attention. In this study, we introduce a novel B-spline parameterized optimization-based planner (BSPOP) designed to address the frequency gap challenge with limited onboard computational power in robots. The proposed planner generates continuous-time control inputs for low-level controllers running at arbitrary frequencies to track. Furthermore, when considering the convex control action sets, BSPOP uses the convex hull property to automatically constrain the continuous-time control inputs within the convex set. Consequently, compared with the discrete-time optimization-based planners, BSPOP reduces the number of decision variables and inequality constraints, which improves computational efficiency as a byproduct. Simulation results demonstrate that our approach can achieve a comparable planning performance to the high-frequency baseline optimization-based planners while demanding less computational power. Both simulation and experiment results show that the proposed method performs better in planning compared with baseline planners in the same frequency.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t8_11">
             09:00-10:00, Paper WePI2T8.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1301'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Sequential Convex Programming for Time-Optimal Quadrotor Waypoint Flight
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392363" title="Click to go to the Author Index">
             Shen, Zhipeng
            </a>
           </td>
           <td class="r">
            The Hong Kong Polytechnic University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396230" title="Click to go to the Author Index">
             Zhou, Guanzhong
            </a>
           </td>
           <td class="r">
            The Hong Kong Polytechnic University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#343246" title="Click to go to the Author Index">
             Huang, Hailong
            </a>
           </td>
           <td class="r">
            The Hong Kong Polytechnic University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1301" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Agile flight is significant for target tracking, search and rescue, and delivery applications. To achieve agile flight, we can exploit the actuator's potential by utilizing the full dynamics of the quadrotor. However, the 6-degrees-of-freedom dynamics render the optimization problem non-convex, and thus computationally intractable. To tackle this issue, we convert the original non-convex optimal control problem (OCP) into a convex subproblem and use the sequential convex programming (SCP) algorithm to iteratively solve the subproblems. Moreover, the state-triggered constraints are proposed to simultaneously optimize the time allocation of the waypoint and the trajectory itself. The numerical and physical experiment results show that the SCP algorithm can significantly reduce the computing time while ensuring a satisfactory solution.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t8_12">
             09:00-10:00, Paper WePI2T8.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1333'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Energy-Optimized Planning in Non-Uniform Wind Fields with Fixed-Wing Aerial Vehicles
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395364" title="Click to go to the Author Index">
             Duan, Yufei
            </a>
           </td>
           <td class="r">
            KTH Royal Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#236361" title="Click to go to the Author Index">
             Achermann, Florian
            </a>
           </td>
           <td class="r">
            ETH Zurich, ASL
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#193069" title="Click to go to the Author Index">
             Lim, Jaeyoung
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100088" title="Click to go to the Author Index">
             Siegwart, Roland
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1333" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#nonholonomic_motion_planning" title="Click to go to the Keyword Index">
               Nonholonomic Motion Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__perception_and_autonomy" title="Click to go to the Keyword Index">
               Aerial Systems: Perception and Autonomy
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Fixed-wing small uncrewed aerial vehicles (sUAVs) possess the capability to remain airborne for extended durations and traverse vast distances. However, their operation is susceptible to wind conditions, particularly in regions of complex terrain where high wind speeds may push the aircraft beyond its operational limits, potentially raising safety concerns. Moreover, wind impacts the energy required to follow a path, especially in locations where the wind direction and speed are not favorable. Incorporating wind information into mission planning is essential to ensure both safety and energy efficiency. In this paper, we propose a sampling-based planner using the kinematic Dubins aircraft paths with respect to the ground, to plan energy-efficient paths in non-uniform wind fields. We study the characteristics of the planner with synthetic and real-world wind data and compare its performance against baseline cost and path formulations. We demonstrate that the energy-optimized planner effectively utilizes updrafts to minimize energy consumption, albeit at the expense of increased travel time. The ground-relative path formulation facilitates the generation of safe trajectories onboard sUAVs within reasonable computational timeframes.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t8_13">
             09:00-10:00, Paper WePI2T8.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1392'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Efficient Path Planning for Modular Reconfigurable Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#276567" title="Click to go to the Author Index">
             Mayer, Matthias
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391432" title="Click to go to the Author Index">
             Li, Zihao
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#114506" title="Click to go to the Author Index">
             Althoff, Matthias
            </a>
           </td>
           <td class="r">
            Technische Universität München
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1392" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#cellular_and_modular_robots" title="Click to go to the Keyword Index">
               Cellular and Modular Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#industrial_robots" title="Click to go to the Keyword Index">
               Industrial Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Industrial robots are essential for modern production but often struggle to adapt to new tasks. Modular (reconfigurable) robots can overcome this challenge by eliminating the need to replace the whole robot. However, finding the optimal assembly for a task remains difficult because a valid path has to be computed for each generated assembly - consuming a significant fraction of the computation time. Similar to online path planning, where previous approaches adapt known paths to a changing environment, we show that transferring paths from previously considered module assemblies accelerates path planning for the next assemblies. On average, our method reduces the planning time for single-goal tasks by 50%. The usefulness of our method is evaluated by integrating it in a genetic algorithm (GA) for optimizing assemblies and evaluating it on our benchmark suite CoBRA. Within the optimization loop for modular robots, the time used to check a single assembly is shortened by up to 50%.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t8_14">
             09:00-10:00, Paper WePI2T8.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1534'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robust Precision Landing of a Quadrotor with Online Temporal Scaling Adaptation of Dynamic Movement Primitives
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#288715" title="Click to go to the Author Index">
             Rothomphiwat, Kongkiat
            </a>
           </td>
           <td class="r">
            VidyasirimedhiInstitute of Science and Technology (VISTEC)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#415061" title="Click to go to the Author Index">
             Jaroonsorn, Prakarn
            </a>
           </td>
           <td class="r">
            AI and Robotics Ventures Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#185038" title="Click to go to the Author Index">
             Kriengkomol, Pakpoom
            </a>
           </td>
           <td class="r">
            AI and Robotics Ventures
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#120785" title="Click to go to the Author Index">
             Manoonpong, Poramate
            </a>
           </td>
           <td class="r">
            Vidyasirimedhi Institute of Science and Technology (VISTEC)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1534" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#robust_adaptive_control" title="Click to go to the Keyword Index">
               Robust/Adaptive Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this work, we address the challenges of robust precision landing maneuvers for a quadrotor on both stationary and moving ground targets in the presence of disturbances that can cause the quadrotor to deviate from its desired trajectory, leading to maneuver failure. To overcome this, we propose a novel online adaptive trajectory planning approach based on the online temporal scaling adaptation of dynamic movement primitives (DMPs). This adaptation enables the desired trajectory to be dynamically adjusted in response to tracking errors and the goal’s state. Consequently, our proposed approach enhances accuracy, precision, and safety during landing maneuvers. The effectiveness of the approach is evaluated through comprehensive experiments conducted in both physical simulations and real-world environments, covering various disturbance scenarios.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t8_15">
             09:00-10:00, Paper WePI2T8.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1544'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Sampling-Based Motion Planning for Optimal Probability of Collision under Environment Uncertainty
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393313" title="Click to go to the Author Index">
             Lu, Hao
            </a>
           </td>
           <td class="r">
            Australian National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102676" title="Click to go to the Author Index">
             Kurniawati, Hanna
            </a>
           </td>
           <td class="r">
            Australian National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#176739" title="Click to go to the Author Index">
             Shome, Rahul
            </a>
           </td>
           <td class="r">
            The Australian National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1544" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Motion planning is a fundamental capability in robotics applications. Real-world scenarios can introduce un- certainty to the motion planning problem. In this work we study environment uncertainty in general high-dimensional problems wherein the choice of appropriate metrics and formulations are shown to have significant effect on the probability of collision of the solution path. Several practically motivated cost functions have been proposed in literature to model and solve the problem but are shown in this work to suffer from higher probabilities of collision. The current work presents a theoretically sound formulation that was first mentioned in previous work on minimum constraint removal. In this work, approximating the optimal problem is shown to be better in achieving lower probability of collision. To demonstrate the formulation in a sampling-based setting, a mixed integer linear program seeded by greedy search over a roadmap with sampled environments is used to report paths with low probability of collision. Compared against minimizing the sum and minimizing max probability cost functions on a seven degree-of-freedom robotic arm in uncertain environments, we show clear benefits and promise towards motion planning for optimal probability of collision.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t8_16">
             09:00-10:00, Paper WePI2T8.16
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('398'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Flexible Informed Trees (FIT*): Adaptive Batch-Size Approach in Informed Sampling-Based Path Planning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#370306" title="Click to go to the Author Index">
             Zhang, Liding
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#195330" title="Click to go to the Author Index">
             Bing, Zhenshan
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#338585" title="Click to go to the Author Index">
             Chen, Kejia
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#296908" title="Click to go to the Author Index">
             Chen, Lingyun
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#266688" title="Click to go to the Author Index">
             Cai, Kuanqi
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372916" title="Click to go to the Author Index">
             Zhang, Yu
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#212176" title="Click to go to the Author Index">
             Wu, Fan
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#382159" title="Click to go to the Author Index">
             Krumbholz, Peter
            </a>
           </td>
           <td class="r">
            KION Group
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#382151" title="Click to go to the Author Index">
             Yuan, Zhilin
            </a>
           </td>
           <td class="r">
            KION Group
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#108317" title="Click to go to the Author Index">
             Haddadin, Sami
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105608" title="Click to go to the Author Index">
             Knoll, Alois
            </a>
           </td>
           <td class="r">
            Tech. Univ. Muenchen TUM
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab398" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In path planning, anytime almost-surely asymptotically optimal planners dominate the benchmark of sampling-based planners. A notable example is Batch Informed Trees (BIT*), where planners iteratively determine paths to batches of vertices within the exploration area. However, utilizing a consistent batch size is inefficient for initial pathfinding and optimal performance, it relies on effective task allocation. This paper introduces Flexible Informed Trees (FIT*), a sampling-based planner that integrates an adaptive batch-size method to enhance the initial path convergence rate. FIT* employs a flexible approach in adjusting batch sizes dynamically based on the inherent dimension of the configuration spaces and the hypervolume of the n-dimensional hyperellipsoid. By applying dense and sparse sampling strategy, FIT* improves convergence rate while finding successful solutions faster with lower initial solution cost. This method enhances the planner's ability to handle confined, narrow spaces in the initial finding phase and increases batch vertices sampling frequency in the optimization phase. FIT* outperforms existing single-query, sampling-based planners on the tested problems in R^2 to R^8, and was demonstrated on a real-world mobile manipulation task.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wepi2t9">
             <b>
              WePI2T9
             </b>
            </a>
           </td>
           <td class="r">
            Room 9
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wepi2t9" title="Click to go to the Program at a Glance">
             <b>
              Navigation I
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#327946" title="Click to go to the Author Index">
             Moustakas, Konstantinos
            </a>
           </td>
           <td class="r">
            University of Patras
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t9_01">
             09:00-10:00, Paper WePI2T9.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3512'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              DriVLMe: Enhancing LLM-Based Autonomous Driving Agents with Embodied and Social Experiences
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#399243" title="Click to go to the Author Index">
             Huang, Yidong
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#399325" title="Click to go to the Author Index">
             Sansom, Jacob
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#399256" title="Click to go to the Author Index">
             Ma, Ziqiao
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#279545" title="Click to go to the Author Index">
             Gervits, Felix
            </a>
           </td>
           <td class="r">
            DEVCOM Army Research Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#169794" title="Click to go to the Author Index">
             Chai, Joyce
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3512" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#natural_dialog_for_hri" title="Click to go to the Keyword Index">
               Natural Dialog for HRI
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_modal_perception_for_hri" title="Click to go to the Keyword Index">
               Multi-Modal Perception for HRI
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recent advancements in foundation models (FMs) have unlocked new prospects in autonomous driving, yet the experimental settings of these studies are preliminary, over-simplified, and fail to capture the complexity of real-world driving scenarios in human environments. It remains under-explored whether FM agents can handle long-horizon navigation tasks with free-from dialogue and deal with unexpected situations caused by environmental dynamics or task changes. To explore the capabilities and boundaries of FMs faced with the challenges above, we introduce DriVLMe, a video-language-model-based agent to facilitate natural and effective communication between humans and autonomous vehicles that perceive the environment and navigate. We develop DriVLMe from both embodied experiences in a simulated environment and social experiences from real human dialogue. While DriVLMe demonstrates competitive performance in both open-loop benchmarks and closed-loop human studies, we reveal several limitations and challenges, including unacceptable inference time, imbalanced training data, limited visual understanding, challenges with multi-turn interactions, simplified language generation from robotic experiences, and difficulties in handling on-the-fly unexpected situations like environmental dynamics and task changes. Nevertheless, DriVLMe offers a promising new direction for autonomous driving agents that need to navigate not just complex environments but also complex social interactions.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t9_02">
             09:00-10:00, Paper WePI2T9.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('226'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Perception for Connected Autonomous Vehicles under Adverse Weather Conditions
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391042" title="Click to go to the Author Index">
             Tsakmakopoulou, Dimitra
            </a>
           </td>
           <td class="r">
            University of Patras
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#327946" title="Click to go to the Author Index">
             Moustakas, Konstantinos
            </a>
           </td>
           <td class="r">
            University of Patras
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab226" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Autonomous Vehicles (AVs) have recently attracted considerable attention due to their potential to significantly reduce road accidents and improve people’s lives. However, they rely solely on the data collected by their mounted sensors to make predictions, which can lead to inaccurate results if a sensor becomes occluded or damaged. This issue can be addressed by employing Vehicle-to-Vehicle communication, which allows a Connected Autonomous Vehicle (CAV) to interact with other CAVs within its field of view and exchange information about their surrounding objects. Existing research on cooperative perception has primarily focused on clear weather scenarios, with limited exploration into adverse weather conditions. This paper demonstrates the necessity of Vehicle-to-Vehicle communication by showcasing its benefits in maintaining high accuracy under adverse weather conditions. A collaborative perception system is introduced and its performance in foggy weather scenarios is assessed to further improve adverse weather perception. The pipeline of the network combines state-of-the-art methods for accurate object detection. Specifically, with PointPillars as the backbone, the Spatial-wise Adaptive Feature Fusion method is used to aggregate information from different vehicles. The model is trained on the large-scale dataset OPV2V and evaluated on modified data to simulate fog. The experiments show that cooperative perception can maintain high detection accuracy even in challenging weather conditions. Finally, a comparative analysis of LiDAR detectors for cooperative perception in bad weather conditions is presented.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t9_03">
             09:00-10:00, Paper WePI2T9.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1088'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Reward-Field Guided Motion Planner for Navigation with Limited Sensing Range
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#218032" title="Click to go to the Author Index">
             Bayer, Jan
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#130305" title="Click to go to the Author Index">
             Faigl, Jan
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1088" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we focus on improving planning efficiency for ground vehicles in navigation and exploration tasks where the environment is unknown or partially known, leading to frequent updates of the navigational goal as new sensory information is acquired. Asymptotically optimal motion planners like RRT* or FMT* can be used to plan the sequence of actions the robot can follow to achieve its current goal. Frequent replanning of the whole action sequence becomes computationally demanding when actions are not executed precisely because of limited information about the foreground terrain. The decoupled approach can decrease the computational burden with separated path planning and path following; however, it might lead to suboptimal solutions. Therefore, we propose a novel approach based on generating a reusable reward function that guides a fast sampling-based motion planner. The proposed method provides improved results in navigation scenarios compared to the former approaches, and it led to about 7% faster autonomous exploration than the decoupled approach. The present results support the suitability of the proposed method in navigation tasks with continuously updated navigation goals.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t9_04">
             09:00-10:00, Paper WePI2T9.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1241'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Real-Time Path Generation and Alignment Control for Autonomous Curb Following
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#240150" title="Click to go to the Author Index">
             Wang, Yuanzhe
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#301092" title="Click to go to the Author Index">
             Dai, Yunxiang
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100565" title="Click to go to the Author Index">
             Wang, Danwei
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1241" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#perception_action_coupling" title="Click to go to the Keyword Index">
               Perception-Action Coupling
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Curb following is a key technology for autonomous road sweeping vehicles. Currently, existing implementations primarily involve pre-recording waypoints during human driving and subsequently retracing them autonomously. Moreover, existing research related to this topic predominately focuses on curb detection for driver assistance, yet the resultant curb detection outcomes remain underutilized in the development of autonomous curb following systems. To fill this gap, this paper proposes a real-time path generation and alignment control approach to facilitate autonomous curb following. Firstly, a segmented path generation algorithm is introduced that progressively generates reference path segments while ensuring the overall continuity of the reference path. Secondly, a parameterized alignment control algorithm is developed to accurately navigate the vehicle along the planned reference path with proved stability. Real public road experiments have been conducted to validate the proposed approach. The experimental results demonstrate the efficacy of the proposed methodologies across various curb following scenarios, including common concave, convex, and straight-concave curbs, thereby showcasing the practical viability of our methods in real-world applications.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t9_05">
             09:00-10:00, Paper WePI2T9.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1283'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Real-Time Hazard Prediction in Connected Autonomous Vehicles: A Digital Twin Approach
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#328532" title="Click to go to the Author Index">
             Barroso Ramírez, Sergio
            </a>
           </td>
           <td class="r">
            Universidad De Extremadura
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#357997" title="Click to go to the Author Index">
             Zapata Cornejo, Noé José
            </a>
           </td>
           <td class="r">
            Universidad De Extremadura
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#356399" title="Click to go to the Author Index">
             Pérez González, Gerardo
            </a>
           </td>
           <td class="r">
            Universidad De Extremadura
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#123041" title="Click to go to the Author Index">
             Bustos, Pablo
            </a>
           </td>
           <td class="r">
            Universidad De Extremadura
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#136981" title="Click to go to the Author Index">
             Núñez, Pedro
            </a>
           </td>
           <td class="r">
            University of Extremadura
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1283" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The growing interest in connected autonomous vehicles (CAVs) has intensified the focus on technologies and algorithms that enhance behavior, comfort, and safety. Among these, the concept of Digital Twins (DT) represents an emerging field of research that is now beginning to be applied to autonomous systems. Traditional Advanced Driver-Assistance Systems (ADAS) can prevent real-time collisions using sensor data. However, we propose that employing a DT can enable the accounting for complex, simulated decisions before they occur in reality. This paper introduces an initial model of a Digital Twin, founded on an internal simulator aligned with vehicle control architecture, for real-time hazard prediction and effective decision-making. Our DT synchronizes with the vehicle's state to simulate various hazardous scenarios in advance, allowing for preemptive actions. To support our hypothesis, we introduce an algorithm for the early detection of potential collisions between CAVs and pedestrians through the unsupervised simulation of diverse traffic scenarios. This solution integrates the CORTEX cognitive architecture with CARLA for internal simulation, leveraging probabilistic models to select optimal scenarios. Employing data from external pedestrian cameras, a particle filter predicts the most probable pedestrian trajectories via DT simulations, thereby informing safe maneuvers. Although the algorithm itself is established, the novelty of our approach lies in incorporating a simulator within the digital twin. This simulator, informed by real-time data on the vehicle's and environment's state, facilitates appropriate responses to unpredictable behaviors. We have conducted extensive tests with an actual autonomous electric vehicle on a university campus to validate the system's predictive and adaptive functions.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t9_06">
             09:00-10:00, Paper WePI2T9.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1349'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Domain Adaptation in Visual Reinforcement Learning Via Self-Expert Imitation with Purifying Latent Feature
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#327791" title="Click to go to the Author Index">
             Chen, Lin
            </a>
           </td>
           <td class="r">
            Hu Nan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395818" title="Click to go to the Author Index">
             Huang, Jianan
            </a>
           </td>
           <td class="r">
            Hunan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#359630" title="Click to go to the Author Index">
             Zhou, Zhen
            </a>
           </td>
           <td class="r">
            Hunan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#157693" title="Click to go to the Author Index">
             Wang, Yaonan
            </a>
           </td>
           <td class="r">
            Hunan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#171335" title="Click to go to the Author Index">
             Mo, Yang
            </a>
           </td>
           <td class="r">
            Hunan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#157684" title="Click to go to the Author Index">
             Miao, Zhiqiang
            </a>
           </td>
           <td class="r">
            Hunan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#331268" title="Click to go to the Author Index">
             Zeng, Kai
            </a>
           </td>
           <td class="r">
            Hunan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#322278" title="Click to go to the Author Index">
             Feng, Mingtao
            </a>
           </td>
           <td class="r">
            Xidian University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100565" title="Click to go to the Author Index">
             Wang, Danwei
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1349" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Generalizing visual reinforcement learning is fundamental to robot visual navigation, involving the acquisition of a policy from interactions with source environments to facilitate adaptation to analogous, yet unfamiliar target environments. Recent advancements capitalize on data augmentation techniques, self-supervised learning methods, and the generative adversarial network framework to train policy neural networks with enhanced generalizability. However, current methods, upon extracting domain-general latent features, further utilize these features to train the reinforcement learning policy, resulting in a decline in the performance of the learned policy guiding the agent to accomplish tasks. To tackle these challenges, a framework of self-expert imitation with purifying latent features was devised, empowering the policy to achieve robust and stable zero-shot generalization performance in visually similar domains previously unseen, without diminishing the performance of guiding the agent to accomplish tasks. The extraction method of domain-general latent features is proposed to enhance their quality based on the variational autoencoder. Extensive experiments have shown that our policy, compared with state-of-the-art counterparts, does not diminish the performance of the policy guiding the agent to accomplish tasks after generalization.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t9_07">
             09:00-10:00, Paper WePI2T9.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1757'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Switching Sampling Space of Model Predictive Path-Integral Controller to Balance Efficiency and Safety in 4WIDS Vehicle Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#373979" title="Click to go to the Author Index">
             Aoki, Mizuho
            </a>
           </td>
           <td class="r">
            Nagoya University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#329446" title="Click to go to the Author Index">
             Honda, Kohei
            </a>
           </td>
           <td class="r">
            Nagoya University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102797" title="Click to go to the Author Index">
             Okuda, Hiroyuki
            </a>
           </td>
           <td class="r">
            Nagoya University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104615" title="Click to go to the Author Index">
             Suzuki, Tatsuya
            </a>
           </td>
           <td class="r">
            Nagoya University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1757" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#redundant_robots" title="Click to go to the Keyword Index">
               Redundant Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Four-wheel independent drive and steering vehicle (4WIDS Vehicle, Swerve Drive Robot) has the ability to move in any direction by its eight degrees of freedom (DoF) control inputs. Although the high maneuverability enables efficient navigation in narrow spaces, obtaining the optimal command is challenging due to the high dimension of the solution space. This paper presents a navigation architecture using the Model Predictive Path Integral (MPPI) control algorithm to avoid collisions with obstacles of any shape and reach a goal point. The key idea to make the problem easier is to explore the optimal control input in a reasonably reduced dimension that is adequate for navigation. Through evaluation in simulation, we found that selecting the sampling space of MPPI greatly affects navigation performance. In addition, our proposed controller which switches multiple sampling spaces according to the real-time situation can achieve balanced behavior between efficiency and safety. Source code is available at https://github.com/MizuhoAOKI/mppi_swerve_drive_ros
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t9_08">
             09:00-10:00, Paper WePI2T9.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1785'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Visual Perception System for Autonomous Driving
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#348551" title="Click to go to the Author Index">
             Zhang, Qi
            </a>
           </td>
           <td class="r">
            University of Bath
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#312257" title="Click to go to the Author Index">
             Gou, Siyuan
            </a>
           </td>
           <td class="r">
            University of Bath
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#195093" title="Click to go to the Author Index">
             Li, Wenbin
            </a>
           </td>
           <td class="r">
            University of Bath
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1785" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The recent surge in interest in autonomous driving is fueled by its rapidly developing capacity to enhance safety, efficiency, and convenience. A key component of autonomous driving technology lies in its perceptual systems, where advancements have led to more precise algorithms applicable to autonomous driving, such as vision-based Simultaneous Localization and Mapping (SLAM), object detection, and tracking algorithms. This work introduces a visual-based perception system for autonomous driving that integrates trajectory tracking and prediction of moving objects to prevent collisions, while addressing the localization and mapping needs of autonomous driving. The system leverages motion cues from pedestrians to monitor and forecast their movements while simultaneously mapping the environment. This integrated approach resolves camera localization and tracks other moving objects in the scene, ultimately generating a sparse map to facilitate vehicle navigation. The performance, efficiency, and resilience of this approach are demonstrated through comprehensive evaluations of both simulated and real-world datasets.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t9_09">
             09:00-10:00, Paper WePI2T9.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2079'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Rain-Reaper: Unmasking LiDAR-Based Detector Vulnerabilities in Rain
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392053" title="Click to go to the Author Index">
             Capraru, Richard
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396380" title="Click to go to the Author Index">
             Lupu, Emil Constantin
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392373" title="Click to go to the Author Index">
             Demetriou, Soteris
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#167914" title="Click to go to the Author Index">
             Wang, Jian-Gang
            </a>
           </td>
           <td class="r">
            Institute for Infocomm Research
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#126127" title="Click to go to the Author Index">
             Soong, Boon Hee
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2079" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             LIDAR-based 3D object detection aims to enhance the situational awareness of autonomous vehicles. Despite recent advancements in this technology, there has been evidence that the susceptibility of 3D object detectors to signal spoofing is high, leading to the erroneous detection of 'ghost objects' or the failure to detect genuine ones. While prior work has investigated the design of these new attacks and new defenses, the effect of weather conditions, which is a hot topic in autonomous vehicle research, on both attacks and defenses has never been studied. Inspired by this observation, in this paper, we present a novel genetic algorithm-based attack, entitled Rain-Reaper, that leverages on the effect of rain and identifies critical detection points used by 3D detectors. We show that adverse weather conditions not only diminish detection distance and accuracy but also expose the limitations of existing defenses. We have found that the unique characteristics of wet roads lead to under-performing defenses, thus, leading to a false sense of confidence in them. The effectiveness and efficiency of the attack and the robustness of the defenses have been evaluated with both simulated and real data. Our Rain-Reaper demonstrates a high attack success rate while successfully evading existing defenses with an adversarial point budget of up to 8.8 times smaller than previously demonstrated state-of-the-art attacks.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t9_10">
             09:00-10:00, Paper WePI2T9.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2830'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              An Observability Constrained Downward-Facing Optical-Flow-Aided Visual-Inertial Odometry
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397673" title="Click to go to the Author Index">
             Liu, Dandi
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#388363" title="Click to go to the Author Index">
             Mei, Jiahao
            </a>
           </td>
           <td class="r">
            Zhejiang University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#354528" title="Click to go to the Author Index">
             Zhou, Jin
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#230382" title="Click to go to the Author Index">
             Li, Shuo
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2830" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Visual-Inertial Odometry (VIO) has been widely used by autonomous drones as an onboard navigation method. However, it suffers from drifts especially in scenarios where the environments have few texture features such as an empty room with solid color walls. Optical flow sensors are another type of onboard sensor used by drones that face downward and measure the velocity by detecting changes in pixels between consecutive images, which don't introduce accumulative error. In this work, we present an efficient tight-coupled estimator to improve the accuracy of VIO by fusing the measurements of a downward-facing optical flow sensor into the VIO framework consistently. We further analyze the observability of the estimators and prove that there are four unobservable directions in the ideal case and then we utilize OC-EKF to maintain the consistency of the estimator. Furthermore, we extend an adaptive weighting algorithm to the proposed method, which can better adapt to the scenes where feature tracking is less accurate. Finally, both simulation and real-world experiments demonstrate the feasibility of the proposed method.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t9_11">
             09:00-10:00, Paper WePI2T9.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2955'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning Autonomous Driving from Aerial Imagery
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#189452" title="Click to go to the Author Index">
             Murali, Varun
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#173551" title="Click to go to the Author Index">
             Rosman, Guy
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#124153" title="Click to go to the Author Index">
             Karaman, Sertac
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101388" title="Click to go to the Author Index">
             Rus, Daniela
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2955" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this work, we consider the problem of learning end to end perception to control for ground vehicles solely from aerial imagery. Photogrammetric simulators allow the synthesis of novel views through the transformation of pre-generated assets into novel views. However, they have a large setup cost, require careful collection of data and often human effort to create usable simulators. We use a Neural Radiance Field (NeRF) as an intermediate representation to synthesize novel views from the point of view of a ground vehicle. These novel viewpoints can then be used for several downstream autonomous navigation applications. In this work, we demonstrate the utility of novel view synthesis though the application of training a policy for end to end learning from images and depth data. In a traditional real to sim to real framework, the collected data would be transformed into a visual simulator which could then be used to generate novel views. In contrast, using a NeRF allows a compact representation and the ability to optimize over the parameters of the visual simulator as more data is gathered in the environment. We demonstrate the efficacy of our method in a custom built mini-city environment through the deployment of imitation policies on robotic cars. We additionally consider the task of place localization and demonstrate that our method is able to relocalize the car in the real world.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t9_12">
             09:00-10:00, Paper WePI2T9.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2960'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Magnetic Field Aided Vehicle Localization with Acceleration Correction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398613" title="Click to go to the Author Index">
             Deshpande, Mrunmayee
            </a>
           </td>
           <td class="r">
            Texas A&amp;M University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#209551" title="Click to go to the Author Index">
             Majji, Manoranjan
            </a>
           </td>
           <td class="r">
            Texas A&amp;M University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#298969" title="Click to go to the Author Index">
             Ramos, J Humberto
            </a>
           </td>
           <td class="r">
            University of Florida
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2960" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a novel approach for vehicle localization by leveraging the ambient magnetic field within a given environment. Our approach involves introducing a global mathematical function for magnetic field mapping, combined with Euclidean distance-based matching technique for accurately estimating vehicle position in suburban settings. The mathematical function based map structure ensures efficiency and scalability of the magnetic field map, while the batch processing based localization provides continuity in pose estimation. Additionally, we establish a bias estimation pipeline for an onboard accelerometer by utilizing the updated poses obtained through magnetic field matching. Our work aims to showcase the potential utility of magnetic fields as supplementary aids to existing localization methods, particularly beneficial in scenarios where Global Positioning System (GPS) signal is restricted or where cost-effective navigation systems are required.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t9_13">
             09:00-10:00, Paper WePI2T9.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3016'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Neuro-Explorer: Efficient and Scalable Exploration Planning Via Learned Frontier Regions
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#114740" title="Click to go to the Author Index">
             Han, Kyung Min
            </a>
           </td>
           <td class="r">
            Ewha Womans Univeristy
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104431" title="Click to go to the Author Index">
             Kim, Young J.
            </a>
           </td>
           <td class="r">
            Ewha Womans University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3016" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present an efficient and scalable learning-based autonomous exploration system for mobile robots navigating unknown indoor environments. Our system incorporates three network models trained to identify the frontier region (FR), to evaluate the detected FR regions based on their proximity to the robot (A*-Net), and to measure the coverage reward at the FR regions (Viz-Net). Our method employs an active window of the map that moves along with the robot, offering scalable exploration capabilities while maintaining a high rate of exploration coverage owing to the two exploratory measures utilized by A*-Net (proximity) and Viz-Net (coverage). Consequently, Our system completes over 99% coverage in a large-scale benchmarking world, scaling up to 135m×80m. In contrast, other state-of-the-art approaches completed only less than 40% of the same world with a 30% slower exploration speed than ours.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t9_14">
             09:00-10:00, Paper WePI2T9.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3212'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Skill Q-Network: Learning Adaptive Skill Ensemble for Mapless Navigation in Unknown Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#277516" title="Click to go to the Author Index">
             Seong, Hyunki
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104593" title="Click to go to the Author Index">
             Shim, David Hyunchul
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3212" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper focuses on the acquisition of mapless navigation skills within unknown environments. We introduce the Skill Q-Network (SQN), a novel reinforcement learning method featuring an adaptive skill ensemble mechanism. Unlike existing methods, our model concurrently learns a high-level skill decision process alongside multiple low-level navigation skills, all without the need for prior knowledge. Leveraging a tailored reward function for mapless navigation, the SQN is capable of learning adaptive maneuvers that incorporate both exploration and goal-directed skills, enabling effective navigation in new environments. Our experiments demonstrate that our SQN can effectively navigate complex environments, exhibiting a 40% higher performance compared to baseline models. Without explicit guidance, SQN discovers how to combine low-level skill policies, showcasing both goal-directed navigations to reach destinations and exploration maneuvers to escape from local minimum regions in challenging scenarios. Remarkably, our adaptive skill ensemble method enables zero-shot transfer to out-of-distribution domains, characterized by unseen observations from non-convex obstacles or uneven, subterranean-like environments. The project page is available at https://sites.google.com/view/skill-q-net.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t9_15">
             09:00-10:00, Paper WePI2T9.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3228'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Look before You Leap: Socially Acceptable High-Speed Ground Robot Navigation in Crowded Hallways
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#341395" title="Click to go to the Author Index">
             Sharma, Lakshay
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#418784" title="Click to go to the Author Index">
             Buono, Nicolaniello
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#415040" title="Click to go to the Author Index">
             Flather, Ashton
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#250199" title="Click to go to the Author Index">
             Cai, Xiaoyi
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104610" title="Click to go to the Author Index">
             How, Jonathan
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3228" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#social_hri" title="Click to go to the Keyword Index">
               Social HRI
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             To operate safely and efficiently, autonomous warehouse/delivery robots must be able to accomplish tasks while navigating in dynamic environments and handling the large uncertainties associated with the motions/behaviors of other robots and/or humans. A key scenario in such environments is the hallway problem, where robots must operate in the same narrow corridor as human traffic going in one or both directions. Traditionally, robot planners have tended to focus on socially acceptable behavior in the hallway scenario at the expense of performance. This paper proposes a planner that aims to address the consequent "robot freezing problem" in hallways by allowing for "peek-and-pass" maneuvers. We then go on to demonstrate in simulation how this planner improves robot time to goal without violating social norms. Finally, we show initial hardware demonstrations of this planner in the real world, along with a novel STAR (Socially Trained Agile Robot) platform designed with human comfort in mind.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t9_16">
             09:00-10:00, Paper WePI2T9.16
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3249'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning Sampling Distribution and Safety Filter for Autonomous Driving with VQ-VAE and Differentiable Optimization
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#354183" title="Click to go to the Author Index">
             Idoko, Simon
            </a>
           </td>
           <td class="r">
            University of Tartu
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#354686" title="Click to go to the Author Index">
             Sharma, Basant
            </a>
           </td>
           <td class="r">
            University of Tartu
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#123110" title="Click to go to the Author Index">
             Singh, Arun Kumar
            </a>
           </td>
           <td class="r">
            University of Tartu
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3249" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Sampling trajectories from a distribution followed by ranking them based on a specified cost function is a common approach in autonomous driving. Typically, the sampling distribution is hand-crafted (e.g a Gaussian, or a grid).
             <p>
              Recently, there have been efforts towards learning the sampling distribution through generative models such as Conditional Variational Autoencoder (CVAE). However, these approaches fail to capture the multi-modality of the driving behaviour due to the Gaussian latent prior of the CVAE. Thus, in this paper, we re-imagine the distribution learning through vector quantized variational autoencoder (VQ-VAE), whose discrete latent-space is well equipped to capture multi-modal sampling distribution. The VQ-VAE is trained with demonstration data of optimal trajectories. We further propose a differentiable optimization based safety filter to minimally correct the VQVAE sampled trajectories to ensure collision avoidance. We use backpropagation through the optimization layers in a selfsupervised learning set-up to learn good initialization and optimal parameters of the safety filter. We perform extensive comparisons with state-of-the-art CVAE-based baseline in dense and aggressive traffic scenarios and show a reduction of up to 12 times in collision-rate while being competitive in driving speeds.
             </p>
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wepi2t10">
             <b>
              WePI2T10
             </b>
            </a>
           </td>
           <td class="r">
            Room 10
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wepi2t10" title="Click to go to the Program at a Glance">
             <b>
              Simultaneous Localization and Mapping (SLAM) II
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#119108" title="Click to go to the Author Index">
             La, Hung
            </a>
           </td>
           <td class="r">
            University of Nevada at Reno
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#106848" title="Click to go to the Author Index">
             Milford, Michael J
            </a>
           </td>
           <td class="r">
            Queensland University of Technology
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t10_01">
             09:00-10:00, Paper WePI2T10.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('101'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              CBGL: Fast Monte Carlo Passive Global Localisation of 2D LIDAR Sensor
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#272438" title="Click to go to the Author Index">
             Filotheou, Alexandros
            </a>
           </td>
           <td class="r">
            Aristotle University of Thessaloniki
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab101" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#range_sensing" title="Click to go to the Keyword Index">
               Range Sensing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Navigation of a mobile robot is conditioned on the knowledge of its pose. In observer-based localisation configurations its initial pose may not be knowable in advance, leading to the need of its estimation. Solutions to the problem of global localisation are either robust against noise and environment arbitrariness but require motion and time, which may (need to) be economised on, or require minimal estimation time but assume environmental structure, may be sensitive to noise, and demand preprocessing and tuning. This article proposes a method that retains the strengths and avoids the weaknesses of the two approaches. The method leverages properties of the Cumulative Absolute Error per Ray (CAER) metric with respect to the errors of pose estimates of a 2D LIDAR sensor, and utilises scan--to--map-scan matching for fine(r) pose estimations. A large number of tests, in real and simulated conditions, involving disparate environments and sensor properties, illustrate that the proposed method outperforms state-of-the-art methods of both classes of solutions in terms of pose discovery rate and execution time. The source code is available for download.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t10_02">
             09:00-10:00, Paper WePI2T10.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('289'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SGNet: Salient Geometric Network for Point Cloud Registration
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#308275" title="Click to go to the Author Index">
             Wu, Qianliang
            </a>
           </td>
           <td class="r">
            Nanjing University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#236225" title="Click to go to the Author Index">
             Ding, Yaqing
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#339479" title="Click to go to the Author Index">
             Luo, Lei
            </a>
           </td>
           <td class="r">
            Nanjing University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#320836" title="Click to go to the Author Index">
             Jiang, Haobo
            </a>
           </td>
           <td class="r">
            Nanjing University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#227080" title="Click to go to the Author Index">
             Gu, Shuo
            </a>
           </td>
           <td class="r">
            Nanjing University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#364327" title="Click to go to the Author Index">
             Zhou, Chuanwei
            </a>
           </td>
           <td class="r">
            Nanjing University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#276206" title="Click to go to the Author Index">
             Xie, Jin
            </a>
           </td>
           <td class="r">
            Nanjing University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#203342" title="Click to go to the Author Index">
             Yang, Jian
            </a>
           </td>
           <td class="r">
            Nanjing University of Science &amp; Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab289" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Point Cloud Registration (PCR) is a critical and challenging task in computer vision and robotics. One of the primary difficulties in PCR is identifying salient and meaningful points that exhibit consistent semantic and geometric properties across different scans. Previous methods have encountered challenges with ambiguous matching due to the similarity among patch blocks throughout the entire point cloud and the lack of consideration for efficient global geometric consistency. To address these issues, we propose a new framework that includes several novel techniques. Firstly, we introduce a semantic-aware geometric encoder that combines object-level and patch-level semantic information. This encoder significantly improves registration recall by reducing ambiguity in patch-level superpoint matching. Additionally, we incorporate a prior knowledge approach that utilizes an intrinsic shape signature to identify salient points. This enables us to extract the most salient super points and meaningful dense points in the scene. Secondly, we introduce an innovative transformer that encodes High-Order (HO) geometric features. These features are crucial for identifying salient points within initial overlap regions while considering global high-order geometric consistency. We introduce an anchor node selection strategy to optimize this high-order transformer further. By encoding inter-frame triangle or polyhedron consistency features based on these anchor nodes, we can effectively learn high-order geometric features of salient super points. These high-order features are then propagated to dense points and utilized by a Sinkhorn matching module to identify critical correspondences for successful registration. The experiments conducted on the 3DMatch/3DLoMatch and KITTI datasets demonstrate the effectiveness of our method.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t10_03">
             09:00-10:00, Paper WePI2T10.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('313'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Resource-Aware Collaborative Monte Carlo Localization with Distribution Compression
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#320527" title="Click to go to the Author Index">
             Zimmerman, Nicky
            </a>
           </td>
           <td class="r">
            University of Lugano
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#155801" title="Click to go to the Author Index">
             Giusti, Alessandro
            </a>
           </td>
           <td class="r">
            IDSIA USI-SUPSI
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#152187" title="Click to go to the Author Index">
             Guzzi, Jerome
            </a>
           </td>
           <td class="r">
            IDSIA, USI-SUPSI
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab313" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Global localization is essential in enabling robot autonomy, and collaborative localization is key for multi-robot systems, allowing for more efficient planning and execution of tasks. In this paper, we address the task of collaborative global localization under computational and communication constraints. We propose a method which reduces the amount of information exchanged and the computational cost. We also analyze, implement and open-source seminal approaches, which we believe to be a valuable contribution to the community. We exploit techniques for distribution compression in near-linear time, with error guarantees. We evaluate our approach and the implemented baselines on multiple challenging scenarios, simulated and real-world. Our approach can run online on an onboard computer. We release an open-source C++/ROS2 implementation of our approach, as well as the baselines.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t10_04">
             09:00-10:00, Paper WePI2T10.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('528'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Neighborhood Consensus Guided Matching Based Place Recognition with Spatial-Channel Embedding
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#340034" title="Click to go to the Author Index">
             Li, Kunmo
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#219010" title="Click to go to the Author Index">
             Zhang, Yunzhou
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#339810" title="Click to go to the Author Index">
             Ning, Jian
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#338569" title="Click to go to the Author Index">
             Zhao, Xinge
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395137" title="Click to go to the Author Index">
             Wang, Guiyuan
            </a>
           </td>
           <td class="r">
            Jiangsu Shuguang Optoelectronics Co., Ltd., Yangzhou, China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395142" title="Click to go to the Author Index">
             Liu, Wei
            </a>
           </td>
           <td class="r">
            Jiangsu Shuguang Optoelectronics Co., Ltd., Yangzhou, China
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab528" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             As a crucial part of mobile robotics and autonomous driving, Visual Place Recognition (VPR) is usually addressed by recognizing its similar reference images from a pre-obtained database. However, VPR always suffers from environmental changes, such as weather, illumination, perceptualaliasing and so on. To address this, we firstly introduce a robust and discriminative global descriptor aggregation technique that normalizes the spatial and channel dimensions of features. A Spatial-Channel Embedding (SCE) module is proposed to learn the spatial and scale information of features which make global features more discriminative. Meanwhile, the traditional re-ranking methods (e.g. RANSAC) for geometric consistency verification are time-consuming. Here we propose a Neighborhood Consensus Guided Matching (NCGM) module, which uses Neighborhood Consensus to filter the features from patch-level matching to achieve more accurate matching while reduces the time consumption. Through extensive experiments on multiple benchmarks, we demonstrate that our method outperforms several state-of-the-art methods while maintaining lower time consumption and storage requirements.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t10_05">
             09:00-10:00, Paper WePI2T10.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('582'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Optimal Robot Formations: Balancing Range-Based Observability and User-Defined Configurations
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375951" title="Click to go to the Author Index">
             Ahmed, Syed Shabbir
            </a>
           </td>
           <td class="r">
            McGill University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#285179" title="Click to go to the Author Index">
             Shalaby, Mohammed Ayman
            </a>
           </td>
           <td class="r">
            McGill University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#120607" title="Click to go to the Author Index">
             Le Ny, Jerome
            </a>
           </td>
           <td class="r">
            Polytechnique Montreal
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#140525" title="Click to go to the Author Index">
             Forbes, James Richard
            </a>
           </td>
           <td class="r">
            McGill University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab582" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper introduces a set of customizable and novel cost functions that enable the user to easily specify desirable robot formations, such as a ``high-coverage'' infrastructure-inspection formation, while maintaining high relative pose estimation accuracy. The overall cost function balances the need for the robots to be close together for good ranging-based relative localization accuracy and the need for the robots to achieve specific tasks, such as minimizing the time taken to inspect a given area. The formations found by minimizing the aggregated cost function are evaluated in a coverage path planning task in simulation and experiment, where the robots localize themselves and unknown landmarks using a simultaneous localization and mapping algorithm based on the extended Kalman filter. Compared to an optimal formation that maximizes ranging-based relative localization accuracy, these formations significantly reduce the time to cover a given area with minimal impact on relative pose estimation accuracy.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t10_06">
             09:00-10:00, Paper WePI2T10.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('640'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Augmenting Vision with Radar for All-Weather Geo-Localization without a Prior HD Map
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393432" title="Click to go to the Author Index">
             Dong, Can
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#236090" title="Click to go to the Author Index">
             Hong, Ziyang
            </a>
           </td>
           <td class="r">
            Heriot-Watt University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393428" title="Click to go to the Author Index">
             Li, Siru
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#280111" title="Click to go to the Author Index">
             Hu, Liang
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#170269" title="Click to go to the Author Index">
             Gao, Huijun
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab640" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Accurate and robust geo-localization in all-weather conditions is essential for enabling autonomous vehicles and delivery robots to offer uninterrupted mobility services in the real world. In this paper, we propose the first camera and radar fusion based geo-localisation method that is robust to all-weather conditions. The core of the proposed method is to leverage the rich semantics information in images and sensing consistency in radars across all-weather. Our proposed method surpasses the state of the art camera-based and LiDAR-camera based methods in inclement weather conditions, shown by extensive comparative experiments. Notably, our approach requires only an open-accessible map, eliminating the need for high-definition maps and offering a cost-effective solution for geo-localizing or globally localizing autonomous vehicles in any weather condition. Our code and trained model will be released publicly.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t10_07">
             09:00-10:00, Paper WePI2T10.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('648'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              High-Accuracy 2-D AoA Estimation Using Lightweight UWB Arrays
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#386576" title="Click to go to the Author Index">
             Li, Yi
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#387221" title="Click to go to the Author Index">
             Zhao, Hanying
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392304" title="Click to go to the Author Index">
             Liu, Yiman
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392323" title="Click to go to the Author Index">
             Wang, Tianyu
            </a>
           </td>
           <td class="r">
            QiYuan Lab
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#243258" title="Click to go to the Author Index">
             Jincheng, Yu
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#198388" title="Click to go to the Author Index">
             Shen, Yuan
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab648" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_networks" title="Click to go to the Keyword Index">
               Sensor Networks
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             UWB systems are gaining popularity for multi-robot localization benefiting from their high-accuracy ranging capabilities. However, current UWB systems fall short in determining orientations and realizing pair-wise localization for neglecting bearing information. Given the importance of bearing capabilities, especially when vision-based methods fail, this paper proposes a high-accuracy 2-D bearing estimation method using stereo UWB arrays. We propose a novel phase error calibration method that effectively mitigates various phase imperfections. This array is designed with antenna spacing larger than half the wavelength to diminish antenna coupling and enhance bearing accuracy. As regards the phase ambiguity issue arising from large antenna spacing, a distributed range-assisted phase ambiguity determination method is developed. Our bearing estimation method exhibits low complexity and is well-suited for the deployment on mobile robots with limited computational resources. The performance of the proposed method is validated on the practical platforms under dynamic scenarios, yielding RMSEs less than 4^circ and 3^circ for azimuth and elevation angle estimation, respectively.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t10_08">
             09:00-10:00, Paper WePI2T10.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('840'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Explicit Interaction for Fusion-Based Place Recognition
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#370250" title="Click to go to the Author Index">
             Xu, Jingyi
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#303651" title="Click to go to the Author Index">
             Ma, Junyi
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#338263" title="Click to go to the Author Index">
             Wu, Qi
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#347636" title="Click to go to the Author Index">
             Zhou, Zijie
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#156231" title="Click to go to the Author Index">
             Wang, Yue
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#215437" title="Click to go to the Author Index">
             Chen, Xieyuanli
            </a>
           </td>
           <td class="r">
            National University of Defense Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#216334" title="Click to go to the Author Index">
             Yu, Wenxian
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#204900" title="Click to go to the Author Index">
             Pei, Ling
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab840" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Fusion-based place recognition is an emerging technique jointly utilizing multi-modal perception data, to recognize previously visited places in GPS-denied scenarios for robots and autonomous vehicles. Recent fusion-based place recognition methods combine multi-modal features in implicit manners. While achieving remarkable results, they do not explicitly consider what the individual modality affords in the fusion system. Therefore, the benefit of multi-modal feature fusion may not be fully explored. In this paper, we propose a novel fusion-based network, dubbed EINet, to achieve explicit interaction of the two modalities. EINet uses LiDAR ranges to supervise more robust vision features for long time spans, and simultaneously uses camera RGB data to improve the discrimination of LiDAR point clouds. In addition, we develop a new benchmark for the place recognition task based on the nuScenes dataset. To establish this benchmark for future research with comprehensive comparisons, we introduce both supervised and self-supervised training schemes alongside evaluation protocols. We conduct extensive experiments on the proposed benchmark, and the experimental results show that our EINet exhibits better recognition performance as well as solid generalization ability compared to the state-of-the-art fusion-based place recognition approaches. Our open-source code and benchmark are released at: https://github.com/BIT-XJY/EINet.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t10_09">
             09:00-10:00, Paper WePI2T10.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1049'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              ModaLink: Unifying Modalities for Efficient Image-To-PointCloud Place Recognition
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#383709" title="Click to go to the Author Index">
             Xie, Weidong
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#287493" title="Click to go to the Author Index">
             Luo, Lun
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394841" title="Click to go to the Author Index">
             Ye, Nanfei
            </a>
           </td>
           <td class="r">
            Haomo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394940" title="Click to go to the Author Index">
             Ren, Yi
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#116929" title="Click to go to the Author Index">
             Du, Shaoyi
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#270611" title="Click to go to the Author Index">
             Wang, Minhang
            </a>
           </td>
           <td class="r">
            HAOMO.AI Technology Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#320204" title="Click to go to the Author Index">
             Xu, Jintao
            </a>
           </td>
           <td class="r">
            HAOMO.AI Technology Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#320203" title="Click to go to the Author Index">
             Ai, Rui
            </a>
           </td>
           <td class="r">
            HAOMO.AI Technology Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#320202" title="Click to go to the Author Index">
             Gu, Weihao
            </a>
           </td>
           <td class="r">
            HAOMO.AI Technology Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#215437" title="Click to go to the Author Index">
             Chen, Xieyuanli
            </a>
           </td>
           <td class="r">
            National University of Defense Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1049" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Place recognition is an important task for robots and autonomous cars to localize themselves and close loops in pre-built maps. While single-modal sensor-based methods have shown satisfactory performance, cross-modal place recognition that retrieving images from a point-cloud database remains a challenging problem. Current cross-modal methods transform images into 3D points using depth estimation for modality conversion, which are usually computationally intensive and need expensive labeled data for depth supervision. In this work, we introduce a fast and lightweight framework to encode images and point clouds into place-distinctive descriptors. We propose an effective Field of View (FoV) transformation module to convert point clouds into an analogous modality as images. This module eliminates the necessity for depth estimation and helps subsequent modules achieve real-time performance. We further design a non-negative factorization-based encoder to extract mutually consistent semantic features between point clouds and images. This encoder yields more distinctive global descriptors for retrieval. Experimental results on the KITTI dataset show that our proposed methods achieve state-of-the-art performance while running in real time. Additional evaluation on the HAOMO dataset covering a 17 km trajectory further shows the practical generalization capabilities. We have released the implementation of our methods as open source at: url{https://github.com/SpadyDong/ModaLink.git}.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t10_10">
             09:00-10:00, Paper WePI2T10.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1227'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Multi-Model Fusion of LiDAR-Inertial Odometry Via Localization and Mapping
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#379325" title="Click to go to the Author Index">
             Nguyen, An
            </a>
           </td>
           <td class="r">
            University of Nevada, Reno
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#256016" title="Click to go to the Author Index">
             Le, Chuong
            </a>
           </td>
           <td class="r">
            University of Nevada, Reno
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396022" title="Click to go to the Author Index">
             Walunj, Pratik
            </a>
           </td>
           <td class="r">
            University of Nevada Reno
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#240086" title="Click to go to the Author Index">
             Do, Thanh Nho
            </a>
           </td>
           <td class="r">
            UNSW
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#363381" title="Click to go to the Author Index">
             Netchaev, Anton
            </a>
           </td>
           <td class="r">
            USACE ERDC
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#119108" title="Click to go to the Author Index">
             La, Hung
            </a>
           </td>
           <td class="r">
            University of Nevada at Reno
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1227" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#range_sensing" title="Click to go to the Keyword Index">
               Range Sensing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This work presents a comprehensive LiDAR-inertial odometry framework featuring robust smoothing and mapping capabilities, effectively correcting LiDAR feature point skewness using an inertial measurement unit (IMU). While the Extended Kalman Filter (EKF) is a common choice for nonlinear motion estimation, its complexity grows when handling maneuvering targets. To overcome this challenge, a new framework that incorporates the Iterated Interactive Multiple Models of Kalman Filter (IMMKF) is given, providing a solution for reliable navigation in dynamic motion and noisy conditions. To ensure map consistency, an ikd-tree that facilitates continuous updates and adaptive rebalance is employed, preserving the map's integrity. To guarantee the robustness of our approach, it undergoes extensive testing across diverse scales of indoor and outdoor environments. This testing scenario simulates absolute GPS denial. In terms of estimated motion, the new algorithm demonstrates superior accuracy compared to existing approaches. The implementation is openly accessible on GitHub^4 for further exploration.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t10_11">
             09:00-10:00, Paper WePI2T10.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1242'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Dynamically Modulating Visual Place Recognition Sequence Length for Minimum Acceptable Performance Scenarios
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#286893" title="Click to go to the Author Index">
             Malone, Connor
            </a>
           </td>
           <td class="r">
            Queensland University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#276808" title="Click to go to the Author Index">
             Vora, Ankit
            </a>
           </td>
           <td class="r">
            Ford Motor Company
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#115708" title="Click to go to the Author Index">
             Peynot, Thierry
            </a>
           </td>
           <td class="r">
            Queensland University of Technology (QUT)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106848" title="Click to go to the Author Index">
             Milford, Michael J
            </a>
           </td>
           <td class="r">
            Queensland University of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1242" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Mobile robots and autonomous vehicles are often required to function in environments where critical position estimates from sensors such as GPS become uncertain or unreliable. Single image visual place recognition (VPR) provides an alternative for localization but often requires techniques such as sequence matching to improve robustness, which incurs additional computation and latency costs. Even then, the sequence length required to localize at an acceptable performance level varies widely; and simply setting overly long fixed sequence lengths creates unnecessary latency, computational overhead, and can even degrade performance. In these scenarios it is often more desirable to meet or exceed a set target performance at minimal expense. In this paper we present an approach which uses a calibration set of data to fit a model that modulates sequence length for VPR as needed to exceed a target localization performance. We make use of a coarse position prior, which could be provided by any other localization system, and capture the variation in appearance across this region. We use the correlation between appearance variation and sequence length to curate VPR features and fit a Multi-Layer Perceptron (MLP) for selecting the optimal length. We demonstrate that this method is effective at modulating sequence length to maximize the number of sections in a dataset which meet or exceed a target performance whilst minimizing the median length used. We show applicability across several datasets and reveal key phenomena like generalization capabilities, the benefits of curating features and the utility of non-state-of-the-art feature extractors with nuanced properties.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t10_12">
             09:00-10:00, Paper WePI2T10.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1243'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              JointLoc: A Real-Time Visual Localization Framework for Planetary UAVs Based on Joint Relative and Absolute Pose Estimation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#363782" title="Click to go to the Author Index">
             Luo, Xubo
            </a>
           </td>
           <td class="r">
            University of Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#244562" title="Click to go to the Author Index">
             Wan, Xue
            </a>
           </td>
           <td class="r">
            Technology and Engineering Center for Space Utilization, Chinese
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#184298" title="Click to go to the Author Index">
             Gao, Yixing
            </a>
           </td>
           <td class="r">
            Jilin University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376041" title="Click to go to the Author Index">
             Tian, Yaolin
            </a>
           </td>
           <td class="r">
            University of Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376129" title="Click to go to the Author Index">
             Zhang, Wei
            </a>
           </td>
           <td class="r">
            Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376039" title="Click to go to the Author Index">
             Shu, Leizheng
            </a>
           </td>
           <td class="r">
            Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1243" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Unmanned aerial vehicles (UAVs) visual localization in planetary aims to estimate the absolute pose of the UAV in the world coordinate system through satellite maps and images captured by on-board cameras. However, since planetary scenes often lack significant landmarks and there are modal differences between satellite maps and UAV images, the accuracy and real-time performance of UAV positioning will be reduced. In order to accurately determine the position of the UAV in a planetary scene in the absence of the global navigation satellite system (GNSS), this paper proposes JointLoc, which estimates the real-time UAV position in the world coordinate system by adaptively fusing the absolute 2-degree-of-freedom (2-DoF) pose and the relative 6-degree-of-freedom (6-DoF) pose. Extensive comparative experiments were conducted on a proposed planetary UAV image cross-modal localization dataset, which contains three types of typical Martian topography generated via a simulation engine as well as real Martian UAV images from the Ingenuity helicopter. JointLoc achieved a root-mean-square error of 0.237m in the trajectories of up to 1,000m, compared to 0.594m and 0.557m for ORB-SLAM2 and ORB-SLAM3 respectively. The source code will be available at https://github.com/LuoXubo/JointLoc.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t10_13">
             09:00-10:00, Paper WePI2T10.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1287'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Enhancing Visual Place Recognition Via Fast and Slow Adaptive Biasing in Event Cameras
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#277238" title="Click to go to the Author Index">
             B Nair, Gokul
            </a>
           </td>
           <td class="r">
            QUT Centre for Robotics, Brisbane, Australia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106848" title="Click to go to the Author Index">
             Milford, Michael J
            </a>
           </td>
           <td class="r">
            Queensland University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#191075" title="Click to go to the Author Index">
             Fischer, Tobias
            </a>
           </td>
           <td class="r">
            Queensland University of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1287" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Event cameras are increasingly popular in robotics due to beneficial features such as low latency, energy efficiency, and high dynamic range. Nevertheless, their downstream task performance is greatly influenced by the optimization of bias parameters. These parameters, for instance, regulate the necessary change in light intensity to trigger an event, which in turn depends on factors such as the environment lighting and camera motion. This paper introduces feedback control algorithms that automatically tune the bias parameters through two interacting methods: 1) An immediate, on-the-fly fast adaptation of the refractory period, which sets the minimum interval between consecutive events, and 2) if the event rate exceeds the specified bounds even after changing the refractory period repeatedly, the controller adapts the pixel bandwidth and event thresholds, which stabilizes after a short period of noise events across all pixels (slow adaptation). Our evaluation focuses on the visual place recognition task, where incoming query images are compared to a given reference database. We conducted comprehensive evaluations of our algorithms’ adaptive feedback control in real-time. To do so, we collected the QCR-Fast-and-Slow dataset that contains DAVIS346 event camera streams from 366 repeated traversals of a Scout Mini robot navigating through a 100 meter long indoor lab setting (totaling over 35km distance traveled) in varying brightness conditions with ground truth location information. Our proposed feedback controllers result in superior performance when compared to the standard bias settings and prior feedback control methods. Our findings also detail the impact of bias adjustments on task performance and feature ablation studies on the fast and slow adaptation mechanisms.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t10_14">
             09:00-10:00, Paper WePI2T10.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1343'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Tightly-Coupled Factor Graph Formulation for Radar-Inertial Odometry
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#312897" title="Click to go to the Author Index">
             Michalczyk, Jan
            </a>
           </td>
           <td class="r">
            University of Klagenfurt
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393815" title="Click to go to the Author Index">
             Quell, Julius Karsten Oskar
            </a>
           </td>
           <td class="r">
            Institute of Robotics and Mechatronics - German Aerospace Center
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#154951" title="Click to go to the Author Index">
             Steidle, Florian
            </a>
           </td>
           <td class="r">
            German Aerospace Center
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#219814" title="Click to go to the Author Index">
             Müller, Marcus Gerhard
            </a>
           </td>
           <td class="r">
            German Aerospace Center
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#132320" title="Click to go to the Author Index">
             Weiss, Stephan
            </a>
           </td>
           <td class="r">
            Universität Klagenfurt
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1343" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we present a Radar-Inertial Odometry (RIO) method based on the nonlinear optimization of factor graphs in a sliding window fashion. Our method makes use of a light-weight, low-power, inexpensive and commonly available hardware enabling easy deployment on small Unmanned Aerial Vehicles (UAV)s. We keep the state estimation problem bounded by employing partial marginalization of the oldest states, rendering the method real-time capable. We compare the implemented approach to the state-of-the-art multi-state Extended Kalman Filter (EKF)-based method in a one-to-one fashion. That is, we implemented in a single custom C++ RIO framework both estimation back-ends with all other parts shared and thus identical for a fair direct comparison. In the real-world flight experiments, we compare the two methods and show that both perform similarly in terms of accuracy when the linearization point is not far from the true state. Upon wrong initialization, the factor graph approach heavily outperforms the EKF approach. We also acknowledge that the influence of undetected outliers can overwhelm the inherent benefits of the nonlinear optimization approach leading to the insight that the estimator front-end has an important (and often underestimated) role in the overall performance.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t10_15">
             09:00-10:00, Paper WePI2T10.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1351'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Three-Dimensional Vehicle Dynamics State Estimation for High-Speed Race Cars under Varying Signal Quality
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392364" title="Click to go to the Author Index">
             Goblirsch, Sven
            </a>
           </td>
           <td class="r">
            Technical University Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394982" title="Click to go to the Author Index">
             Weinmann, Marcel
            </a>
           </td>
           <td class="r">
            Technical University Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#268360" title="Click to go to the Author Index">
             Betz, Johannes
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1351" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This work aims to present a three-dimensional vehicle dynamics state estimation under varying signal quality. Few researchers have investigated the impact of three-dimensional road geometries on the state estimation and, thus, neglect road inclination and banking. Especially considering high velocities and accelerations, the literature does not address these effects. Therefore, we compare two- and three-dimensional state estimation schemes to outline the impact of road geometries. We use an Extended Kalman Filter with a point-mass motion model and extend it by an additional formulation of reference angles. Furthermore, virtual velocity measurements significantly improve the estimation of road angles and the vehicle’s side slip angle. We highlight the importance of steady estimations for vehicle motion control algorithms and demonstrate the challenges of degraded signal quality and Global Navigation Satellite System dropouts. The proposed adaptive covariance facilitates a smooth estimation and enables stable controller behavior. The developed state estimation has been deployed on a high-speed autonomous race car at various racetracks. Our findings indicate that our approach outperforms state-of-the-art vehicle dynamics state estimators and an industry-grade Inertial Navigation System. Further studies are needed to investigate the performance under varying track conditions and on other vehicle types.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t10_16">
             09:00-10:00, Paper WePI2T10.16
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1634'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              LiDAR-Based HD Map Localization Using Semantic Generalized ICP with Road Marking Detection
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392568" title="Click to go to the Author Index">
             Gong, Yansong
            </a>
           </td>
           <td class="r">
            UISEE Technology Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392970" title="Click to go to the Author Index">
             Zhang, Xinglian
            </a>
           </td>
           <td class="r">
            UISEE (Shanghai) Automotive Technologies Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392594" title="Click to go to the Author Index">
             Feng, Jingyi
            </a>
           </td>
           <td class="r">
            UISEE Technology Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#370918" title="Click to go to the Author Index">
             He, Xiao
            </a>
           </td>
           <td class="r">
            UISEE Technology (Beijing) Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#332244" title="Click to go to the Author Index">
             Zhang, Dan
            </a>
           </td>
           <td class="r">
            Uisee Technology (Beijing) Co., Ltd
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1634" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In GPS-denied scenarios, a robust environmental perception and localization system becomes crucial for au- tonomous driving. In this paper, a LiDAR-based online localiza- tion system is developed, incorporating road marking detection and registration on a high-definition (HD) map. Within our system, a road marking detection approach is proposed with real- time performance, in which an adaptive segmentation technique is first introduced to isolate high-reflectance points correlated with road markings, enhancing real-time efficiency. Then, a spatio-temporal probabilistic local map is formed by aggregating historical LiDAR scans, providing a dense point cloud. Finally, a LiDAR bird’s-eye view (LiBEV) image is generated, and an instance segmentation network is applied to accurately label the road markings. For road marking registration, a semantic generalized iterative closest point (SG-ICP) algorithm is designed. Linear road markings are modeled as 1-manifolds embedded in 2D space, mitigating the influence of constraints along the linear direction, addressing the under-constrained problem and achieving a lower localization errors on HD maps than ICP. Extensive experiments are conducted in real-world scenarios, demonstrating the effectiveness and robustness of our system.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wepi2t11">
             <b>
              WePI2T11
             </b>
            </a>
           </td>
           <td class="r">
            Room 11
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wepi2t11" title="Click to go to the Program at a Glance">
             <b>
              Multi-Robot Systems and Swarms I
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#152911" title="Click to go to the Author Index">
             Parasuraman, Ramviyas
            </a>
           </td>
           <td class="r">
            University of Georgia
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#118822" title="Click to go to the Author Index">
             Simonin, Olivier
            </a>
           </td>
           <td class="r">
            INSA De Lyon
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t11_01">
             09:00-10:00, Paper WePI2T11.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('77'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              HGP-RL: Distributed Hierarchical Gaussian Processes for Wi-Fi-Based Relative Localization in Multi-Robot Systems
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#332036" title="Click to go to the Author Index">
             Latif, Ehsan
            </a>
           </td>
           <td class="r">
            University of Georgia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#152911" title="Click to go to the Author Index">
             Parasuraman, Ramviyas
            </a>
           </td>
           <td class="r">
            University of Georgia
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab77" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#networked_robots" title="Click to go to the Keyword Index">
               Networked Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Relative localization is crucial for multi-robot systems to perform cooperative tasks, especially in GPS-denied environments. Current techniques for multi-robot relative localization rely on expensive or short-range sensors such as cameras and LIDARs. As a result, these algorithms face challenges such as high computational complexity (e.g., map merging), dependencies on well-structured environments, etc. To remedy this gap, we propose a new distributed approach to perform relative localization (RL) using a common Access Point (AP). To achieve this efficiently, we propose a novel Hierarchical Gaussian Processes (HGP) mapping of the Radio Signal Strength Indicator (RSSI) values from a Wi-Fi AP to which the robots are connected. We termed this approach as HGP-RL (Hierarchical Gaussian Process for Relative Localization). Each robot performs hierarchical inference using the HGP map to locate the AP in its reference frame, and the robots obtain relative locations of the neighboring robots leveraging AP-oriented algebraic transformations. The approach readily applies to resource-constrained devices and relies only on the ubiquitously-available WiFi RSSI measurement. We extensively validate the performance of the proposed HGP-RL in Robotarium simulations against several state-of-the-art methods. The results indicate superior performance of HGP-RL regarding localization accuracy, computation, and communication overheads. Finally, we showcase the utility of HGP-RL through a multi-robot cooperative experiment to achieve a rendezvous task in a team of three mobile robots.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t11_02">
             09:00-10:00, Paper WePI2T11.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('278'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Anchor-Oriented Localized Voronoi Partitioning for GPS-Denied Multi-Robot Coverage
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#313179" title="Click to go to the Author Index">
             Munir, Aiman
            </a>
           </td>
           <td class="r">
            University of Georgia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#332036" title="Click to go to the Author Index">
             Latif, Ehsan
            </a>
           </td>
           <td class="r">
            University of Georgia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#152911" title="Click to go to the Author Index">
             Parasuraman, Ramviyas
            </a>
           </td>
           <td class="r">
            University of Georgia
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab278" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#distributed_robot_systems" title="Click to go to the Keyword Index">
               Distributed Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_networks" title="Click to go to the Keyword Index">
               Sensor Networks
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Multi-robot coverage is crucial in numerous applications, including environmental monitoring, search and rescue operations, and precision agriculture. In modern applications, a multi-robot team must collaboratively explore unknown spatial fields in GPS-denied and extreme environments where global localization is unavailable. Coverage algorithms typically assume that the robot positions and the coverage environment are defined in a global reference frame. However, coordinating robot motion and ensuring coverage of the shared convex workspace without global localization is challenging. This paper proposes a novel anchor-oriented coverage (AOC) approach to generate dynamic localized Voronoi partitions based around a common anchor position. We further propose a consensus-based coordination algorithm that achieves agreement on the coverage workspace around the anchor in the robots' relative frames of reference. Through extensive simulations and real-world experiments, we demonstrate that the proposed anchor-oriented approach using localized Voronoi partitioning performs as well as the state-of-the-art coverage controller using GPS.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t11_03">
             09:00-10:00, Paper WePI2T11.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('319'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Deep Ad-Hoc Sub-Team Partition Learning for Multi-Agent Air Combat Cooperation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391864" title="Click to go to the Author Index">
             Fan, Songyuan
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#297585" title="Click to go to the Author Index">
             Piao, Haiyin
            </a>
           </td>
           <td class="r">
            Northwestern Polytechnical University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391186" title="Click to go to the Author Index">
             Hu, Yi
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#281991" title="Click to go to the Author Index">
             Jiang, Feng
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395600" title="Click to go to the Author Index">
             Yang, Roushu
            </a>
           </td>
           <td class="r">
            SAIL
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab319" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In the future, unmanned autonomous air combat will encounter large-scale confrontation scenarios, where agents must consider complex time-varying relationships among aircraft when making decisions. Previous works have already introduced Multi-Agent Reinforcement Learning (MARL) into air combat and succeeded in surpassing the human expert level. However, they mainly focus on small-scale air combat with low relationship complexity, e.g., 1-vs-1 or 2-vs-2. As more agents join the confrontation, existing algorithms tend to suffer significant performance degradation due to the increase in problem dimensions. In view of this, this paper proposes Deep Ad-hoc Sub-Team Partition Learning(DASPL) to address large-scale air combat problems. DASPL models multi-agent air combat as a graph to handle the complex relations and introduces an automatic partitioning mechanism to generate dynamic sub-teams, which converts the existing large-scale multi-agent air combat cooperation problem into multiple small-scale equivalence problems. Additionally, DASPL incorporates an efficient message passing method among the participating sub-teams. Extensive experiments demonstrate that DASPL outperforms state-of-the-art algorithms with at least about 28.3% in large-scale air combat environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t11_04">
             09:00-10:00, Paper WePI2T11.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('320'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robustness Study of Optimal Geometries for Cooperative Multi-Robot Localization
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391912" title="Click to go to the Author Index">
             Theunissen, Mathilde
            </a>
           </td>
           <td class="r">
            LS2N, CNRS
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104116" title="Click to go to the Author Index">
             Fantoni, Isabelle
            </a>
           </td>
           <td class="r">
            CNRS
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106118" title="Click to go to the Author Index">
             Malis, Ezio
            </a>
           </td>
           <td class="r">
            Inria
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101740" title="Click to go to the Author Index">
             Martinet, Philippe
            </a>
           </td>
           <td class="r">
            INRIA
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab320" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This work focuses on localizing a single target robot with multi-robot formations in 2D space. The cooperative robots employ inter-robot range measurements to assess the target position. In the presence of noisy measurements, the choice of formation geometries significantly impacts the accuracy of the target robot's pose estimation. While an infinite number of geometries exists to optimize localization accuracy, the current practice is to choose the final formation geometry based on convenience criteria such as simplicity or proximity to the initial position of the robots. The former leads to the selection of regular polygon-shaped formations, while the latter results in behaviour-based formations. Different from existing works, we conduct a complete robustness study of formation geometries in the presence of deviations from the desired formation and range measurement errors. In 2D scenarios, we establish necessary and sufficient conditions for formation geometries to be robust against robot positioning errors. This result substantiates the extensive use of regular polygon formations. However, our analysis reveals the lack of robustness of the commonly used square formation geometry, which stands as an exception. Simulation results illustrate the advantages of these robust geometries in enhancing target localization accuracy.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t11_05">
             09:00-10:00, Paper WePI2T11.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('651'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Decentralized Communication-Maintained Coordination for Multi-Robot Exploration: Achieving Connectivity and Adaptability
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#209453" title="Click to go to the Author Index">
             Tang, Wei
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#319174" title="Click to go to the Author Index">
             Li, Chao
            </a>
           </td>
           <td class="r">
            Hangzhou Deeprobotics Co.Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#343116" title="Click to go to the Author Index">
             Wu, Jun
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#232612" title="Click to go to the Author Index">
             Zhu, Qiuguo
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab651" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#planning__scheduling_and_coordination" title="Click to go to the Keyword Index">
               Planning, Scheduling and Coordination
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The realm of multi-robot autonomous exploration tasks underscores the critical role of communication in coordinating group activities. This paper introduces an innovative decentralized multi-robot exploration algorithm, meticulously crafted to ensure unbroken communication within robotic groups, a crucial element for effective coordination. The motivation for our work is two-fold: Firstly, seamless communication is vital for coordinating multi-robot autonomous exploration tasks. Secondly, in applications such as disaster rescue operations or military maneuvers, there are numerous scenarios where spatial congregation of multiple robots is imperative for joint task accomplishment. Our approach addresses these challenges through a stringent communication constraint, ensuring that each robot remains in constant communicative contact with the rest of the group. This is realized by employing a decentralized policy that integrates Graph Neural Network (GNN) layers with self-attention mechanism. Such policy network design allows adaptation to different numbers of robots and varied environments. After an initial imitation learning phase, the policy is refined through learning from experiences generated via a tree-search-based lookahead technique. Our experimental analysis validates that the algorithm not only maintains consistent communication links among all group members but also improve the exploration efficiency under the communication constraints. These results highlight the potential of our method in enhancing the effectiveness of robotic group explorations while ensuring robust communication connection.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t11_06">
             09:00-10:00, Paper WePI2T11.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('795'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Collaborative Object Manipulation on the Water Surface by a UAV-USV Team Using Tethers
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#366314" title="Click to go to the Author Index">
             Novák, Filip
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#192414" title="Click to go to the Author Index">
             Baca, Tomas
            </a>
           </td>
           <td class="r">
            Ceske Vysoke Uceni Technicke V Praze, FEL
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#113384" title="Click to go to the Author Index">
             Saska, Martin
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab795" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper introduces an innovative methodology for object manipulation on the surface of water through the collaboration of an Unmanned Aerial Vehicle (UAV) and an Unmanned Surface Vehicle (USV) connected to the object by tethers. We propose a novel mathematical model of a robotic system that combines the UAV, USV, and the tethered floating object. A novel Model Predictive Control (MPC) framework is designed for using this model to achieve precise control and guidance for this collaborative robotic system. Extensive simulations in the realistic robotic simulator Gazebo demonstrate the system’s readiness for real-world deployment, highlighting its versatility and effectiveness. Our multi-robot system overcomes the state-of-the-art single-robot approach, exhibiting smaller control errors during the tracking of the floating object’s reference. Additionally, our multi-robot system demonstrates a shorter recovery time from a disturbance compared to the single-robot approach.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t11_07">
             09:00-10:00, Paper WePI2T11.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('952'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Multi-Robot Path Planning with Boolean Specification Tasks under Motion Uncertainties
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#390761" title="Click to go to the Author Index">
             Zhang, Zhe
            </a>
           </td>
           <td class="r">
            Shaanxi University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#174319" title="Click to go to the Author Index">
             He, Zhou
            </a>
           </td>
           <td class="r">
            Shaanxi University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#363016" title="Click to go to the Author Index">
             Ran, Ning
            </a>
           </td>
           <td class="r">
            Hebei University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#248304" title="Click to go to the Author Index">
             Reniers, Michel
            </a>
           </td>
           <td class="r">
            Eindhoven University of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab952" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#planning__scheduling_and_coordination" title="Click to go to the Keyword Index">
               Planning, Scheduling and Coordination
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper studies the path planning problem of multi-robot systems under motion uncertainties with high-level tasks that are expressed as Boolean specifications. The specification imposes logical constraints on robot trajectories and final states. First, a global Markov decision process model of the multi-robot system is constructed to provide its current state. In order to tackle the state explosion problem, at each stage, we construct a local Markov decision process for every individual agent in sequence to compute the local optimal movement strategy and update the global Markov decision process accordingly (i.e., compute locally and update globally). Next, we propose a heuristic reward function design method that provides different rewards for visiting different task points by introducing the estimated distance to complete the global task. Finally, a series of numerical experiments are conducted to demonstrate the computational efficiency and scalability of our developed approach.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t11_08">
             09:00-10:00, Paper WePI2T11.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1774'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Coalition Formation Game Approach for Task Allocation in Heterogeneous Multi-Robot Systems under Resource Constraints
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#373086" title="Click to go to the Author Index">
             Zhang, Liwang
            </a>
           </td>
           <td class="r">
            National University of Defense Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394903" title="Click to go to the Author Index">
             Liang, Dong
            </a>
           </td>
           <td class="r">
            College of Sciences, National University of Defense Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#269415" title="Click to go to the Author Index">
             Li, Minglong
            </a>
           </td>
           <td class="r">
            National University of Defense Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#226679" title="Click to go to the Author Index">
             Yang, Wenjing
            </a>
           </td>
           <td class="r">
            State Key Laboratory of High Performance Computing (HPCL), Schoo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#122474" title="Click to go to the Author Index">
             Yang, Shaowu
            </a>
           </td>
           <td class="r">
            National University of Defense Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1774" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#distributed_robot_systems" title="Click to go to the Keyword Index">
               Distributed Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper studies a case of the multi-robot task allocation (MRTA) problem, where each unmanned aerial vehicle (UAV) is endowed with multiple but limited resources. Completing each task necessitates UAVs to combine different resources through coalition formation, which will incur various costs including flight cost, execution cost, and cooperation cost. To minimize the total cost while maximizing both task completion rate and resource utilization rate, we model the MRTA problem of the UAVs as a leader-follower coalition formation game. In this game, leader UAVs coordinate follower UAVs to fulfill task resource requisites. Meanwhile, follower UAVs select suitable coalitions to join based on the altruistic preference. Theoretical analysis confirms the existence of a Nash stable partition in the coalition formation game. To achieve this stable partition, we propose a coalition formation algorithm. Simulation experiments validate that the proposed algorithm outperforms existing methods for the MRTA problem under resource constraints in terms of both task completion rate and resource utilization rate.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t11_09">
             09:00-10:00, Paper WePI2T11.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1804'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Design of a Multi-Robot Coordination System Based on Functional Expressions Using Large Language Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#371123" title="Click to go to the Author Index">
             Kato, Yuki
            </a>
           </td>
           <td class="r">
            Osaka University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#390578" title="Click to go to the Author Index">
             Yoshida, Takahiro
            </a>
           </td>
           <td class="r">
            Osaka University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#141486" title="Click to go to the Author Index">
             Sueoka, Yuichiro
            </a>
           </td>
           <td class="r">
            Osaka Univ
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#10031" title="Click to go to the Author Index">
             Osuka, Koichi
            </a>
           </td>
           <td class="r">
            Osaka University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#216060" title="Click to go to the Author Index">
             Yajima, Ryosuke
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103438" title="Click to go to the Author Index">
             Nagatani, Keiji
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106691" title="Click to go to the Author Index">
             Asama, Hajime
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1804" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#distributed_robot_systems" title="Click to go to the Keyword Index">
               Distributed Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#swarm_robotics" title="Click to go to the Keyword Index">
               Swarm Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             A system is expected to facilitate coordination among multiple construction machines or robots, enabling them to adaptively perform various tasks in disaster sites and unknown environments. Prior research generally adopts a model-based approach to designing cooperative behavior. However, it is difficult to adapt to environments and scenarios that cannot be predicted by the model. In recent years, it has been reported that a robot equipped with foundation models can adapt to unknown (open) environments and unpredictable situations. However, there has been little discussion on foundation models for multiple robot systems; a flow that cooperatively handles unexpected events does not exist. In this paper, we propose the system flow that enables multiple robots to adaptively coordinate to unforeseen scenarios based on the functional expressions of each other and environment understanding utilizing GPT-4 and GPT-4V. Through experimentation, we verify that the proposed flow is able to adapt to an unforeseen environment, particularly path obstruction via robot experiments. Furthermore, we examine the validity of the proposed flow by varying the robots' functional expressions and sensor information for the environment.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t11_10">
             09:00-10:00, Paper WePI2T11.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1823'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              CGA: Corridor Generating Algorithm for Multi-Agent Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397153" title="Click to go to the Author Index">
             Pertzovsky, Arseniy
            </a>
           </td>
           <td class="r">
            Ben-Gurion University of the Negev
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#305571" title="Click to go to the Author Index">
             Stern, Roni
            </a>
           </td>
           <td class="r">
            Ben Gurion University of the Negev, Palo Alto Research Center (P
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397187" title="Click to go to the Author Index">
             Zivan, Roie
            </a>
           </td>
           <td class="r">
            Ben Gurion University of the Negev
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1823" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#planning__scheduling_and_coordination" title="Click to go to the Keyword Index">
               Planning, Scheduling and Coordination
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this work, we consider path planning for a team of mobile agents where one agent must reach a given target as soon as possible and the others must accommodate to avoid collisions. We call this practical problem the Single-Agent Corridor Generating (SACG) problem and explore several algorithms for solving it. We propose two baseline algorithms based on existing Multi-Agent Path Finding (MAPF) algorithms and outline their limitations. Then, we present the Corridor Generating Algorithm (CGA), a fast and complete algorithm for solving SACG. CGA performs well compared to the baseline approaches. In addition, we show how CGA can be generalized to address the lifelong version of MAPF, where new goals appear over time.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t11_11">
             09:00-10:00, Paper WePI2T11.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1844'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning to Imitate Spatial Organization in Multi-Robot Systems
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375969" title="Click to go to the Author Index">
             Agunloye, Ayomide Oluwaseyi
            </a>
           </td>
           <td class="r">
            University of Southampton
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#166478" title="Click to go to the Author Index">
             Ramchurn, Sarvapali
            </a>
           </td>
           <td class="r">
            University of Southampton
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#196426" title="Click to go to the Author Index">
             Soorati, Mohammad D.
            </a>
           </td>
           <td class="r">
            University of Southampton
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1844" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#swarm_robotics" title="Click to go to the Keyword Index">
               Swarm Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Understanding collective behavior and how it evolves is important to ensure that robot swarms can be trusted in a shared environment. One way to understand the behavior of the swarm is through collective behavior reconstruction using prior demonstrations. Existing approaches often require access to the swarm controller which may not be available. We reconstruct collective behaviors in distinct swarm scenarios involving shared environments without using swarm controller information. We achieve this by transforming prior demonstrations into features that describe multi-agent interactions before behavior reconstruction with multi-agent generative adversarial imitation learning (MA-GAIL). We show that our approach outperforms existing algorithms in spatial organization, and can be used to observe and reconstruct a swarm's behavior for further analysis and testing, which might be impractical or undesirable on the original robot swarm.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t11_12">
             09:00-10:00, Paper WePI2T11.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1884'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              D-MARL: A Dynamic Communication-Based Action Space Enhancement for Multi Agent Reinforcement Learning Exploration of Large Scale Unknown Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396308" title="Click to go to the Author Index">
             Calzolari, Gabriele
            </a>
           </td>
           <td class="r">
            Luleå Tekniska Universitet
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#243487" title="Click to go to the Author Index">
             Sumathy, Vidya
            </a>
           </td>
           <td class="r">
            Luleå University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#199367" title="Click to go to the Author Index">
             Kanellakis, Christoforos
            </a>
           </td>
           <td class="r">
            LTU
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105882" title="Click to go to the Author Index">
             Nikolakopoulos, George
            </a>
           </td>
           <td class="r">
            Luleå University of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1884" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#cooperating_robots" title="Click to go to the Keyword Index">
               Cooperating Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this article, we propose a novel communication-based action space enhancement for the D-MARL exploration algorithm to improve the efficiency of mapping an unknown environment, represented by an occupancy grid map. In general, communication between autonomous systems is crucial when exploring large and unstructured environments. In such real-world scenarios, data transmission is limited and relies heavily on inter-agent proximity and the attributes of the autonomous platforms. In the proposed approach, each agent's policy is optimized by utilizing the heterogeneous-agent proximal policy optimization algorithm to autonomously choose whether to communicate or explore the environment. To accomplish this, multiple novel reward functions are formulated by integrating inter-agent communication and exploration. The investigated approach aims to increase efficiency and robustness in the mapping process, minimize exploration overlap, and prevent agent collisions. The D-MARL policies trained on different reward functions have been compared to understand the effect of different reward terms on the collaborative attitude of the homogeneous agents. Finally, multiple simulation results are provided to prove the efficacy of the proposed scheme.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t11_13">
             09:00-10:00, Paper WePI2T11.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2443'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Opinion-Based Strategy for Distributed Multi-Robot Task Allocation in Swarms of Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#348386" title="Click to go to the Author Index">
             Zhang, Ziqiao
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#233982" title="Click to go to the Author Index">
             Chen, Shengkang
            </a>
           </td>
           <td class="r">
            Georgia Tech
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398256" title="Click to go to the Author Index">
             Mayberry, Scott
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#107391" title="Click to go to the Author Index">
             Zhang, Fumin
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2443" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#task_planning" title="Click to go to the Keyword Index">
               Task Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#swarm_robotics" title="Click to go to the Keyword Index">
               Swarm Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Opinions of individuals in large groups evolve through interactions with neighbors and the environment, which can be modeled with opinion dynamics. In this paper, we propose a distributed opinion-based strategy for large-scale multi-robot task allocation utilizing the convergence behaviors of opinion dynamics. The strategy relies on the specialized opinion dynamics on the unit sphere for robot task selection. We investigate the convergence behaviors of opinion dynamics in the context of regions of attraction. Simulation results with a swarm of 200 homogeneous robots validate the effectiveness of our proposed strategy.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t11_14">
             09:00-10:00, Paper WePI2T11.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2448'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robust and Safe Task-Driven Planning and Navigation for Heterogeneous Multi-Robot Teams with Uncertain Dynamics
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#237914" title="Click to go to the Author Index">
             Pan, Tianyang
            </a>
           </td>
           <td class="r">
            Rice University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#164014" title="Click to go to the Author Index">
             Verginis, Christos
            </a>
           </td>
           <td class="r">
            Uppsala University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102678" title="Click to go to the Author Index">
             Kavraki, Lydia
            </a>
           </td>
           <td class="r">
            Rice University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2448" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#robust_adaptive_control" title="Click to go to the Keyword Index">
               Robust/Adaptive Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Task and motion planning (TAMP) can enhance intelligent multi-robot coordination. TAMP becomes significantly more complicated in obstacle-cluttered environments and in the presence of robot dynamic uncertainties. We propose a control framework that solves the motion-planning problem for multi-robot teams with uncertain dynamics, addressing a key component of the TAMP pipeline. The principal part of the proposed algorithm constitutes a decentralized feedback control policy for tracking of reference paths by the robots while avoiding collision and adapting in real time to the underlying dynamic uncertainties. The proposed framework further leverages sampling-based motion planners to free the robots from local-minimum configurations. Extensive experimental results in complex, realistic environments illustrate the superior efficiency of the proposed approach, in terms of planning time and amount of encountered local minima, with respect to state-of-the-art baseline methods.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t11_15">
             09:00-10:00, Paper WePI2T11.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2828'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Communication-Constrained Multi-Robot Exploration with Intermittent Rendezvous
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#344103" title="Click to go to the Author Index">
             Ribeiro da Silva, Alysson
            </a>
           </td>
           <td class="r">
            Universidade Federal De Minas Gerais
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106550" title="Click to go to the Author Index">
             Chaimowicz, Luiz
            </a>
           </td>
           <td class="r">
            Federal University of Minas Gerais
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#327645" title="Click to go to the Author Index">
             Costa Silva, Thales
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106150" title="Click to go to the Author Index">
             Hsieh, M. Ani
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2828" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#distributed_robot_systems" title="Click to go to the Keyword Index">
               Distributed Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#cooperating_robots" title="Click to go to the Keyword Index">
               Cooperating Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Communication constraints can significantly impact robots' ability to share information, coordinate their movements, and synchronize their actions, thus limiting coordination in Multi-Robot Exploration (MRE) applications. In this work, we address these challenges by modeling the MRE application as a DEC-POMDP and designing a joint policy that follows a rendezvous plan. This policy allows robots to explore unknown environments while intermittently sharing maps opportunistically or at rendezvous locations without being constrained by joint path optimizations. To generate the rendezvous plan, robots represent the MRE task as an instance of the Job Shop Scheduling Problem (JSSP) and minimize JSSP metrics. They aim to reduce waiting times and increase connectivity, which correlates to the DEC-POMDP rewards and time to complete the task. Our simulation results suggest that our method is more efficient than using relays or maintaining intermittent communication with a base station, being a suitable approach for Multi-Robot Exploration. We developed a proof-of-concept using the Robot Operating System (ROS) that is available at: https://github.com/multirobotplayground/ROS-Noetic-Multi-robot-Sandbox.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t11_16">
             09:00-10:00, Paper WePI2T11.16
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2853'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Tree-Based Reconfiguration of Metamorphic Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#338857" title="Click to go to the Author Index">
             Ondika, Patrick
            </a>
           </td>
           <td class="r">
            Faculty of Informatics Masaryk University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#243618" title="Click to go to the Author Index">
             Mrázek, Jan
            </a>
           </td>
           <td class="r">
            Masaryk University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#244616" title="Click to go to the Author Index">
             Barnat, Jiri
            </a>
           </td>
           <td class="r">
            Faculty of Informatics Masaryk University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2853" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#cellular_and_modular_robots" title="Click to go to the Keyword Index">
               Cellular and Modular Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#cooperating_robots" title="Click to go to the Keyword Index">
               Cooperating Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Metamorphic robots have gained traction since the start of the 21st century due to their ability to change shape and adapt to various tasks. In order to build versatile and robust metamorphic systems, we need to be able to find a reconfiguration plan efficiently. This paper presents a new approach to the reconfiguration problem of chain-type metamorphic robots. Our algorithm relies on forming tentacles and searching through a lower-dimensional space by solving smaller planning instances. As a result, we obtain a solution that is more scalable than optimal planners, while producing higher quality plans than previously introduced fast solutions.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t11_17">
             09:00-10:00, Paper WePI2T11.17
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1134'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Multi-Robot Navigation among Movable Obstacles: Implicit Coordination to Deal with Conflicts and Deadlocks
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#277929" title="Click to go to the Author Index">
             Renault, Benoit
            </a>
           </td>
           <td class="r">
            INSA Lyon
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#173409" title="Click to go to the Author Index">
             Saraydaryan, Jacques
            </a>
           </td>
           <td class="r">
            Cpe Lyon
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394753" title="Click to go to the Author Index">
             Brown, David
            </a>
           </td>
           <td class="r">
            Inria
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#118822" title="Click to go to the Author Index">
             Simonin, Olivier
            </a>
           </td>
           <td class="r">
            INSA De Lyon
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1134" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#planning__scheduling_and_coordination" title="Click to go to the Keyword Index">
               Planning, Scheduling and Coordination
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             How to find efficient paths for multiple robots in modifiable cluttered environments? This question leads us to the formulation of the new problem of Multi-Robot Navigation Among Movable Obstacles (MR-NAMO). In MR-NAMO, robots must not only plan for the possibility of displacing obstacles as needed to facilitate their navigation, but also solve conflicts that may arise when trying to simultaneously access a location or obstacle. As a first approach to this new problem, we introduce and compare variants of an implicit coordination strategy allowing the use of existing NAMO Algorithms in a Multi-Robot context. We also show how our previously introduced social occupation cost model can improve the efficiency of multi-robot plans with better obstacle placement choices, and how it can be applied in a novel way to find relevant robot placement choices in deadlock situations.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wepi2t12">
             <b>
              WePI2T12
             </b>
            </a>
           </td>
           <td class="r">
            Room 12
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wepi2t12" title="Click to go to the Program at a Glance">
             <b>
              Mechanisms and Actuation
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#105255" title="Click to go to the Author Index">
             Ikemoto, Shuhei
            </a>
           </td>
           <td class="r">
            Kyushu Institute of Technology
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t12_01">
             09:00-10:00, Paper WePI2T12.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1988'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Active Learning for Forward/Inverse Kinematics of Redundantly-Driven Flexible Tensegrity Manipulator
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#324270" title="Click to go to the Author Index">
             Yoshimitsu, Yuhei
            </a>
           </td>
           <td class="r">
            Kyushu Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#113483" title="Click to go to the Author Index">
             Osa, Takayuki
            </a>
           </td>
           <td class="r">
            University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#130054" title="Click to go to the Author Index">
             Ben Amor, Heni
            </a>
           </td>
           <td class="r">
            Arizona State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105255" title="Click to go to the Author Index">
             Ikemoto, Shuhei
            </a>
           </td>
           <td class="r">
            Kyushu Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1988" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#flexible_robotics" title="Click to go to the Keyword Index">
               Flexible Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#redundant_robots" title="Click to go to the Keyword Index">
               Redundant Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#modeling__control__and_learning_for_soft_robots" title="Click to go to the Keyword Index">
               Modeling, Control, and Learning for Soft Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In flexible redundantly-driven multi-DOF systems, like living beings, the representation of redundant kinematics including the diversity of solutions, is crucial for leveraging its distinctive characteristics. This paper proposes an active learning framework for forward and inverse modeling of complex kinematics that improves expressions of control space, task space, and null space. It consists of a VAE-type network that internally holds expressions of control space, task space, and null space, and an algorithm for selecting new data using the cross-entropy method. The validity of the proposed system was verified using a tensegrity manipulator driven by 40 pneumatic cylinders. As a result, it was confirmed that active learning contributed to achieving the entire range of motion covered and a well-organized representation of the null space.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t12_02">
             09:00-10:00, Paper WePI2T12.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2938'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Design of a Variable Wheel-Propeller Integrated Mechanism for Amphibious Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#379422" title="Click to go to the Author Index">
             Lu, Liang
            </a>
           </td>
           <td class="r">
            Huazhong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#379380" title="Click to go to the Author Index">
             Gao, Xiangquan
            </a>
           </td>
           <td class="r">
            Huazhong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#379353" title="Click to go to the Author Index">
             Xiang, Ming
            </a>
           </td>
           <td class="r">
            Huazhong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#231922" title="Click to go to the Author Index">
             Yan, Zefeng
            </a>
           </td>
           <td class="r">
            Huazhong University of Science &amp; Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#137104" title="Click to go to the Author Index">
             Han, Bin
            </a>
           </td>
           <td class="r">
            Huazhong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2938" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#wheeled_robots" title="Click to go to the Keyword Index">
               Wheeled Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In order to address the high complexity and low efficiency of amphibious propulsion systems, this paper proposes a novel variable wheel-propeller integrated mechanism for amphibious robots. By adjusting the blade pitch angle, it enables multiple motion modes, including rapid and stable movement on flat ground, obstacle crossing, and omnidirectional movement on water surface. This study establishes a kinematic model for the propeller blades and conducts multi-objective optimization of the structural parameters by considering both the land obstacle-crossing performance and underwater propulsion performance. Based on the optimized structural parameters, a virtual simulation prototype is constructed. Simulation results indicate that when water surface movement, with a driving torque of 3N.m, robot achieves a maximum linear velocity of 1.25m/s and a maximum angular self-rotation velocity of 3.5rad/s. Moreover, varying the blade pitch angle can alter the thrust direction, enabling omnidirectional mobility on water surface. During land movement, with a rotation speed of 60rpm, the highest obstacle-crossing height is 184mm. This wheel-propeller integrated mechanism exhibits robust comprehensive motion performance and environmental adaptability, with convenient motion modes switching.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t12_03">
             09:00-10:00, Paper WePI2T12.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('551'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Static Modeling of the Stiffness and Contact Forces of Rolling Element Eccentric Drives for Use in Robotic Drive Systems
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392747" title="Click to go to the Author Index">
             Fritsch, Simon
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#346963" title="Click to go to the Author Index">
             Landler, Stefan
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#350877" title="Click to go to the Author Index">
             Otto, Michael
            </a>
           </td>
           <td class="r">
            Technical University of Munich, Chair of Machine Elements, Gear
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#143931" title="Click to go to the Author Index">
             Vogel-Heuser, Birgit
            </a>
           </td>
           <td class="r">
            Technical University Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#243677" title="Click to go to the Author Index">
             Zimmermann, Markus
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#349500" title="Click to go to the Author Index">
             Stahl, Karsten
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab551" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#actuation_and_joint_mechanisms" title="Click to go to the Keyword Index">
               Actuation and Joint Mechanisms
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#methods_and_tools_for_robot_system_design" title="Click to go to the Keyword Index">
               Methods and Tools for Robot System Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Rolling element eccentric drives promise to be an easy-to-manufacture and performant gear system for robotic actuators. They share characteristics with other eccentric drives, such as strain wave and cycloidal drives, but use rolling elements instead of an eccentric gear. They offer reduced manufacturing complexity and costs by using readily available standard parts. Little research into rolling element eccentric drives is available, and their characteristics are still underexplored. This work uses a contact-based model to investigate the previously unknown stiffness of rolling element eccentric drives. Such calculation methods are well established for structurally similar components, such as cycloidal drives and roller bearings, and provide a high-level and computationally efficient model. Good stiffness models are critical for accurately predicting robotic actuator behavior and enabling better control of robotic systems. Additionally, the proposed model is used to calculate the contact forces under load occurring in rolling element eccentric drives. Contact forces are critical to calculating a drive’s load capacity, lifetime, and efficiency and serve as the foundation for further research. The mathematical description of the proposed model is derived, and the stiffness of a representative rolling element eccentric drive is calculated. Different manufacturing techniques, characterized by tolerance levels and material choices, are compared. Irrespective of manufacturing precision, similar stiffness curves result for drives made of steel, but higher contact forces result from less precise manufacturing. The stiffness of drives made from 3D printed plastic is considerably lower than that of drives made from steel. Additionally, the stiffness of rolling element eccentric drives is compared to similar eccentric drives, and a comparable twist-over-torque curve is shown.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t12_04">
             09:00-10:00, Paper WePI2T12.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1657'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Energy Minimization Using Custom-Designed Magnetic-Spring Actuators
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397003" title="Click to go to the Author Index">
             Fu, Yue Yang
            </a>
           </td>
           <td class="r">
            Vanderbilt University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#338214" title="Click to go to the Author Index">
             Kilic, Ali Umut
            </a>
           </td>
           <td class="r">
            Vanderbilt University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#114628" title="Click to go to the Author Index">
             Braun, David
            </a>
           </td>
           <td class="r">
            Vanderbilt University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1657" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#actuation_and_joint_mechanisms" title="Click to go to the Keyword Index">
               Actuation and Joint Mechanisms
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#compliant_joints_and_mechanisms" title="Click to go to the Keyword Index">
               Compliant Joints and Mechanisms
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This study introduces an innovative actuator that resembles a motor with a non-uniform permanent magnetic field. We have developed a prototype of the actuator by combining a standard motor, characterized by a uniform magnetic field, with a custom rotary magnetic spring exhibiting a non-uniform magnetic field. We have also presented a systematic computational approach to customize the magnetic field to minimize the energy consumption of the actuator when used for a user-defined oscillatory task. Experiments demonstrate that this optimized actuator significantly lowers energy consumption in a typical oscillatory task, such as pick-and-place or oscillatory limb motion during locomotion, compared to conventional motors. Our findings imply that incorporating task-optimized non-uniform permanent magnetic fields into conventional motors and direct-drive actuators could enhance the energy efficiency of robotic systems.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t12_05">
             09:00-10:00, Paper WePI2T12.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1734'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Novel Multiport Output Twisted String Actuator with Self-Differential Mechanism: Hand Glove Application
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#217280" title="Click to go to the Author Index">
             Wei, Dunwen
            </a>
           </td>
           <td class="r">
            University of Electronic Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397083" title="Click to go to the Author Index">
             Cui, Chenguang
            </a>
           </td>
           <td class="r">
            University of Electronic Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397090" title="Click to go to the Author Index">
             Yu, Haitao
            </a>
           </td>
           <td class="r">
            University of Electronic Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#256707" title="Click to go to the Author Index">
             Gao, Tao
            </a>
           </td>
           <td class="r">
            University of Electronic Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#416133" title="Click to go to the Author Index">
             Li, Chao
            </a>
           </td>
           <td class="r">
            Sichuan Cancer Center
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#368248" title="Click to go to the Author Index">
             Hussain, Sajjad
            </a>
           </td>
           <td class="r">
            University of Naples Federico II
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#137686" title="Click to go to the Author Index">
             Ficuciello, Fanny
            </a>
           </td>
           <td class="r">
            Università Di Napoli Federico II
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1734" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#actuation_and_joint_mechanisms" title="Click to go to the Keyword Index">
               Actuation and Joint Mechanisms
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#tendon_wire_mechanism" title="Click to go to the Keyword Index">
               Tendon/Wire Mechanism
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#prosthetics_and_exoskeletons" title="Click to go to the Keyword Index">
               Prosthetics and Exoskeletons
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The differential mechanism can reduce the number of actuators and efficiently distribute force or power. We proposed a novel multiport output twisted string actuator (MO-TSA) with self-differential mechanism that employs a single actuator to achieve multiport outputs. The differential MO-TSA is adaptively controlled in accordance with the force differences at each output port, thus replacing the traditional differential gears and whiffletree mechanisms. Inspired by the hand muscles, we designed one hand glove using the MO-TSA, aiming to enhance the range of achievable grasp configurations. The hand glove is capable of performing various grasps with a single actuator, resulting in a lighter and simpler hand design and revolutionizing the field of twisted string actuators (TSAs) by offering a streamlined solution for achieving versatile actuation.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t12_06">
             09:00-10:00, Paper WePI2T12.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3405'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Torque Ripple Reduction in Quasi-Direct Drive Motors through Angle-Based Repetitive Learning Observer and Model Predictive Torque Controller
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393189" title="Click to go to the Author Index">
             Zhang, Hefei
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#387319" title="Click to go to the Author Index">
             Zhang, Xiaohu
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#377300" title="Click to go to the Author Index">
             Cheng, Jinyu
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#377315" title="Click to go to the Author Index">
             Hu, Jiangtao
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#357083" title="Click to go to the Author Index">
             Ji, Chao
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#344022" title="Click to go to the Author Index">
             Wang, Yu
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397594" title="Click to go to the Author Index">
             Jiang, Yutong
            </a>
           </td>
           <td class="r">
            China North Vehicle Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397574" title="Click to go to the Author Index">
             Han, Zhen
            </a>
           </td>
           <td class="r">
            China North Vehicle Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#268163" title="Click to go to the Author Index">
             Gao, Wei
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102646" title="Click to go to the Author Index">
             Zhang, Shiwu
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3405" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#actuation_and_joint_mechanisms" title="Click to go to the Keyword Index">
               Actuation and Joint Mechanisms
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#force_control" title="Click to go to the Keyword Index">
               Force Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Torque ripple reduction in quasi-direct drive (QDD) motors is crucial in their robotic applications for dynamic locomotion and dexterous manipulation. In this paper, we present a novel approach for reducing torque ripples of QDD motors, which integrates an angle-based repetitive learning observer (ARLO) and a model predictive control-based field-oriented controller (MPC-FOC). The proposed method successfully improves the torque loop control bandwidth and surpasses conventional proportional-integral (PI) controllers owing to the integrated physical constraints inside MPC. Additionally, the ARLO portion is able to mitigate ripple caused by the inherent cogging torque in brushless motors and also the periodic friction torque from the planetary gearboxes in QDD systems. The effectiveness of the proposed method is demonstrated through both simulation of a single QDD motor and experiments on a two-degree-of-freedom robotic leg, where the performance improvement can be 72.7% in speed tracking and 58.5% in trajectory tracking. The proposed method shows great potential in facilitating smooth motion and precise force control in future robotic applications.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t12_07">
             09:00-10:00, Paper WePI2T12.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3338'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Development of a Mobile Reconfigurable Mecanum Robot with a Locking Device of Rollers
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#321908" title="Click to go to the Author Index">
             Zakharov, Dmitrii
            </a>
           </td>
           <td class="r">
            ITMO University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398535" title="Click to go to the Author Index">
             Iaremenko, Andrei
            </a>
           </td>
           <td class="r">
            ITMO
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#399085" title="Click to go to the Author Index">
             Kurovskii, Denis
            </a>
           </td>
           <td class="r">
            ITMO University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#399067" title="Click to go to the Author Index">
             Kurovskii, Artem
            </a>
           </td>
           <td class="r">
            ITMO University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#229086" title="Click to go to the Author Index">
             Borisov, Oleg
            </a>
           </td>
           <td class="r">
            ITMO University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#172022" title="Click to go to the Author Index">
             Zhang, Botao
            </a>
           </td>
           <td class="r">
            Hangzhou Dianzi University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3338" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#wheeled_robots" title="Click to go to the Keyword Index">
               Wheeled Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#service_robotics" title="Click to go to the Keyword Index">
               Service Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents the design and analysis of an omnidirectional reconfigurable wheeled robot capable of switching between omnidirectional and conventional wheeled mode. We have developed a new pneumatic locking mechanism of rollers for the mecanum wheel. In the mecanum mode, the robot can perform holonomic movements, and in the wheeled platform mode, it can overcome inclined surfaces and perform more energy-efficient movements. In addition, the locking device allows the robot to brake faster compared to other mecanum robots. Unlike other works describing the reconfigurable structure of the mecanum wheel, this work offers a new design characterized by the simplicity of the mechanism and does not require the location of active reconfiguration elements inside the wheel itself. The paper describes the design concept and presents the mechanism for locking rollers. The study evaluates the use of the developed robot in various scenarios, including movement on an inclined surface, sudden braking on a plane and an inclined surface, and also analyzes the energy efficiency of the resulting solution for some operating scenarios. The experiments carried out confirm that this mobile platform, when switching mode, is able to move on surfaces with a large angle of inclination and perform more effective deceleration on both flat and inclined surfaces.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t12_08">
             09:00-10:00, Paper WePI2T12.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2607'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Parametric Synthesis of Compliant Joints for Impact Robust Shaftless Leg Mechanisms
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398041" title="Click to go to the Author Index">
             Rakshin, Egor
            </a>
           </td>
           <td class="r">
            ITMO University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398073" title="Click to go to the Author Index">
             Ogureckiy, Dmitriy
            </a>
           </td>
           <td class="r">
            ITMO University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#201182" title="Click to go to the Author Index">
             Borisov, Ivan
            </a>
           </td>
           <td class="r">
            ITMO University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#166925" title="Click to go to the Author Index">
             Kolyubin, Sergey
            </a>
           </td>
           <td class="r">
            ITMO University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2607" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#compliant_joints_and_mechanisms" title="Click to go to the Keyword Index">
               Compliant Joints and Mechanisms
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper describes a novel parametric optimization procedure for three flexure cross hinges (TFCH) integrated into multi-link leg mechanisms with closed-loop kinematics. Despite advantages such as compliance, no need for joint lubrication, light weight and cost-efficiency, such shaftless mechanisms have not been widely used, especially in the field of dynamic locomotion, also because their design is challenging and barely studied. Using a morphological computation approach, we have optimized the TFCH geometry to achieve the desired joint stiffness using frequency analysis, ensuring safe and stable hopping under external perturbations. We combined rigid body dynamics with lumped stiffness model and finite element modeling using the SPACAR toolbox to simulate various designs within our optimization pipeline. To illustrate the efficiency of the resulting designs, we built a prototype and conducted a series of full-scale experiments with ramp jumps whose trajectories were recorded by a motion capture system. The experiments showed that TFCH can be effectively integrated into leg mechanisms, providing benefits such as impact robustness, energy recuperation, and the ability to work in extreme conditions.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t12_09">
             09:00-10:00, Paper WePI2T12.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1671'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Trans-Rotor: An Active Omnidirectional Aerial-Ground Vehicle with Differential Gear Joint Transformation Mechanism
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#363277" title="Click to go to the Author Index">
             Wu, Xuankang
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#377444" title="Click to go to the Author Index">
             Sun, Haoxiang
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395758" title="Click to go to the Author Index">
             Xiao, Tong
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395601" title="Click to go to the Author Index">
             Pan, Yanzhang
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#121608" title="Click to go to the Author Index">
             Fang, Zheng
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1671" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Air-ground vehicles have shown great potential in various fields due to their superior mobility and outstanding endurance. However, most of morphing air-ground vehicles consider little about controllability and traversability in ground mode. We present a novel air-ground vehicle called Trans-Rotor. By proposing a differential gear joint, we equip Trans-Rotor with omnidirectional mobility in both air and ground mode. Besides, using a four-wheel-steering model in ground mode provides better traversability and ground flexibility. With mid-mode transformation, Trans-Rotor can provide smooth and rapid mode switching. In this work, we firstly propose a novel design of an air-ground vehicle with a differential gear joint transformation mechanism. Furthermore, to achieve autonomous navigation, we propose the vehicle's decoupled controller considering the four-wheel-steer model. Meanwhile, comprehensive experiments and a benchmark comparison are carried out to validate the system's outstanding performance, where the system shows ground flexibility and saves energy up to more than 95%.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t12_10">
             09:00-10:00, Paper WePI2T12.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2896'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SNU-Avatar Haptic Glove: Novel Modularized Haptic Glove Via Trigonometric Series Elastic Actuators
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#294364" title="Click to go to the Author Index">
             Sung, Eunho
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#302751" title="Click to go to the Author Index">
             You, Seungbin
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398744" title="Click to go to the Author Index">
             Moon, Seongkyeong
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#386409" title="Click to go to the Author Index">
             Kim, Juhyun
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101200" title="Click to go to the Author Index">
             Park, Jaeheung
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2896" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#haptics_and_haptic_interfaces" title="Click to go to the Keyword Index">
               Haptics and Haptic Interfaces
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The avatar robot is a robot capable of realistic remote operation. In remote operation, the controllability of the glove, which can manipulate the hand interacting directly with the environment at the remote site, is an important factor. The glove must be able to accurately estimate the hand posture and provide haptic feedback to convey information about the remote environment and enhance operability. It should minimize user discomfort throughout the process. To achieve this goal, the research proposes providing force feedback to the fingers using Trigonometric Series Elastic Actuators, and devices are attached to the Middle Phalanx to facilitate the easy installation of additional add-ons, ensuring users feel securely fixed when attached. Additionally, by proposing an algorithm to estimate the fingertip position without directly attaching it to the fingertip, we estimate the hand posture and provide appropriate force when necessary. Furthermore, several additional add-ons can be attached to the fingertips to enable roughness and temperature feedback. Finally, we participated in the ANA Avatar XPRIZE using this system and performed eight missions, including not only remote manipulation of objects but also social interactions, demonstrating its effectiveness.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t12_11">
             09:00-10:00, Paper WePI2T12.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3061'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Versatile Variable-Stiffness Scooping End-Effector: Tilting-Scooping-Transfer Mechanism for Objects with Various Properties
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#357141" title="Click to go to the Author Index">
             Takahashi, Yuta
            </a>
           </td>
           <td class="r">
            Tohoku University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102290" title="Click to go to the Author Index">
             Tadakuma, Kenjiro
            </a>
           </td>
           <td class="r">
            Osaka University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#254295" title="Click to go to the Author Index">
             Abe, Kazuki
            </a>
           </td>
           <td class="r">
            Osaka University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#192974" title="Click to go to the Author Index">
             Watanabe, Masahiro
            </a>
           </td>
           <td class="r">
            Osaka University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#357142" title="Click to go to the Author Index">
             Shimizu, Shoya
            </a>
           </td>
           <td class="r">
            Tohoku University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100118" title="Click to go to the Author Index">
             Tadokoro, Satoshi
            </a>
           </td>
           <td class="r">
            Tohoku University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3061" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             To address the setup and changeover time issues in high-mix, low-volume production systems, we developed an endeffector capable of uniformly scooping, holding, and transporting a wide variety of objects, and demonstrated this system with prototype. Our experiments showed that the prototype was successful in scooping up and transporting a wide variety of objects and could be applied to high-mix low-volume production systems. In addition, the load testing of the spatula and modeling of objects that can be tilted backwards provided insight into further improvements of the scooping performance of this mechanism.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t12_12">
             09:00-10:00, Paper WePI2T12.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3079'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Enhanced Omni-Ball: Spherical Omnidirectional Wheel Achieving Passive Rollers with High Load Capacity and Smoothness through an Offset Rotational Axis
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102290" title="Click to go to the Author Index">
             Tadakuma, Kenjiro
            </a>
           </td>
           <td class="r">
            Osaka University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398911" title="Click to go to the Author Index">
             Sakiyama, Seiji
            </a>
           </td>
           <td class="r">
            Tohoku University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#196599" title="Click to go to the Author Index">
             Takane, Eri
            </a>
           </td>
           <td class="r">
            Tohoku University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106440" title="Click to go to the Author Index">
             Tadakuma, Riichiro
            </a>
           </td>
           <td class="r">
            Yamagata University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100118" title="Click to go to the Author Index">
             Tadokoro, Satoshi
            </a>
           </td>
           <td class="r">
            Tohoku University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3079" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#wheeled_robots" title="Click to go to the Keyword Index">
               Wheeled Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper introduces an innovation of the Spherical Omnidirectional Wheel, designed to achieve omnidirectional driving motion. In previous models, the supporting shaft was placed at the center of the mechanism. However, achieving both smoothness and high load-capacity in such designs proved challenging. The mechanism proposed in this study features an offset design, enabling outer support for the wheel. A prototype was developed and its basic motion was experimentally validated.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t12_13">
             09:00-10:00, Paper WePI2T12.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3331'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Design and Control of a Novel Six-Degree-Of-Freedom Hybrid Robotic Arm
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397596" title="Click to go to the Author Index">
             Chen, Yang
            </a>
           </td>
           <td class="r">
            Beijing Academy of Agriculture and Forestry Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#218327" title="Click to go to the Author Index">
             Miao, Zhonghua
            </a>
           </td>
           <td class="r">
            Shanghai University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#223591" title="Click to go to the Author Index">
             Ge, Yuanyue
            </a>
           </td>
           <td class="r">
            Beijing Academy of Agriculture and Forestry Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414384" title="Click to go to the Author Index">
             Lin, Sen
            </a>
           </td>
           <td class="r">
            Intelligent Equipment Research Center, Beijing Academy of Agricu
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#410924" title="Click to go to the Author Index">
             Chen, Liping
            </a>
           </td>
           <td class="r">
            Intelligent Equipment Research Center, Beijing Academy of Agricu
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#219580" title="Click to go to the Author Index">
             Xiong, Ya
            </a>
           </td>
           <td class="r">
            Beijing Academy of Agriculture and Forestry Sciences
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3331" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#robotics_and_automation_in_agriculture_and_forestry" title="Click to go to the Keyword Index">
               Robotics and Automation in Agriculture and Forestry
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#parallel_robots" title="Click to go to the Keyword Index">
               Parallel Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robotic arms are key components in fruit-harvesting robots. In agricultural settings, conventional serial or parallel robotic arms often fall short in meeting the demands for a large workspace, rapid movement, enhanced capability of obstacle avoidance and affordability. This study proposes LingXtend, a novel hybrid six-degree-of-freedom (DoF) robotic arm that combines the advantages of parallel and serial mechanisms. Inspired by yoga, we designed two sliders capable of moving independently along a single rail, acting as two feet. These sliders are interconnected with linkages and a meshed-gear set, allowing the parallel mechanism to lower itself and perform a split to pass under obstacles. This unique feature allows the arm to avoid obstacles such as pipes, tables and beams typically found in greenhouses. Integrated with serially mounted joints, the patented hybrid arm is able to maintain the end's pose even when it moves with a mobile platform, facilitating fruit picking with the optimal pose in dynamic conditions. Moreover, the hybrid arm's workspace is substantially larger, being almost three times the volume of UR3 serial arms and fourteen times that of the ABB IRB parallel arms. Experiments show that the repeatability errors are 0.017 mm, 0.03 mm and 0.109 mm for the two sliders and the arm's end, respectively, providing sufficient precision for agricultural robots.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t12_14">
             09:00-10:00, Paper WePI2T12.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1961'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              DIABLO: A 6-DoF Wheeled Bipedal Robot Composed Entirely of Direct-Drive Joints
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391279" title="Click to go to the Author Index">
             Liu, Dingchuan
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#356208" title="Click to go to the Author Index">
             Fangfang, Yang
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#310801" title="Click to go to the Author Index">
             Liao, Xuanhong
            </a>
           </td>
           <td class="r">
            Direct Drive Technology Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#204460" title="Click to go to the Author Index">
             Lyu, Ximin
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1961" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#wheeled_robots" title="Click to go to the Keyword Index">
               Wheeled Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Wheeled bipedal robots offer the advantages of both wheeled and legged robots, combining the ability to traverse a wide range of terrains and environments with high efficiency. However, the conventional approach in existing wheeled bipedal robots involves motor-driven joints with high-ratio gearboxes. While this approach provides specific benefits, it also presents several challenges, including increased mechanical complexity, efficiency losses, noise, vibrations, and higher maintenance and lubrication requirements.
             <p>
              Addressing the aforementioned concerns, we developed a direct-drive wheeled bipedal robot called DIABLO, which eliminates the use of gearboxes entirely. Our robotic system is simplified as a second-order inverted pendulum, and we have designed an LQR-based balance controller to ensure stability. Additionally, we implemented comprehensive motion controller, including yaw, split-angle, height, and roll controllers. Through simulations and field experiments, we have demonstrated that our platform achieves satisfactory performance.
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t12_15">
             09:00-10:00, Paper WePI2T12.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('894'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Safe Imitation Learning of Nonlinear Model Predictive Control for Flexible Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#286894" title="Click to go to the Author Index">
             Mamedov, Shamil
            </a>
           </td>
           <td class="r">
            KU Leuven
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#325309" title="Click to go to the Author Index">
             Reiter, Rudolf
            </a>
           </td>
           <td class="r">
            University of Freiburg
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#324457" title="Click to go to the Author Index">
             Basiri Azad, Seyed Mahdi
            </a>
           </td>
           <td class="r">
            University of Freiburg
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#287993" title="Click to go to the Author Index">
             Viljoen, Ruan Matthys
            </a>
           </td>
           <td class="r">
            KU Leuven
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#107316" title="Click to go to the Author Index">
             Boedecker, Joschka
            </a>
           </td>
           <td class="r">
            University of Freiburg
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101488" title="Click to go to the Author Index">
             Diehl, Moritz
            </a>
           </td>
           <td class="r">
            Univ. of Heidelberg
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#114656" title="Click to go to the Author Index">
             Swevers, Jan
            </a>
           </td>
           <td class="r">
            KU Leuven
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab894" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#flexible_robotics" title="Click to go to the Keyword Index">
               Flexible Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Flexible robots may overcome some of industry's major challenges, such as enabling intrinsically safe human-robot collaboration and achieving a higher payload-to-mass ratio. However, controlling flexible robots is complicated due to their complex dynamics, which include oscillatory behavior and a high-dimensional state space. Nonlinear model predictive control (NMPC) offers an effective means to control such robots, but its significant computational demand often limits its application in real-time scenarios. To enable fast control of flexible robots, we propose a framework for a safe approximation of NMPC using imitation learning and a predictive safety filter. Our framework significantly reduces computation time while incurring a slight loss in performance. Compared to NMPC, our framework shows more than an eightfold improvement in computation time when controlling a three-dimensional flexible robot arm in simulation, all while guaranteeing safety constraints. Notably, our approach outperforms state-of-the-art reinforcement learning methods. The development of fast and safe approximate NMPC holds the potential to accelerate the adoption of flexible robots in industry.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi2t12_16">
             09:00-10:00, Paper WePI2T12.16
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1701'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Design and Modeling of a Thin-Walled Multi-Segment Continuum Robotic Bronchoscope
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#137161" title="Click to go to the Author Index">
             Bian, Gui-Bin
            </a>
           </td>
           <td class="r">
            Institute of Automation, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376480" title="Click to go to the Author Index">
             Zhang, Ming-Yang
            </a>
           </td>
           <td class="r">
            Institute of Automation, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#374033" title="Click to go to the Author Index">
             Ye, Qiang
            </a>
           </td>
           <td class="r">
            Institute of Automation, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396976" title="Click to go to the Author Index">
             Ren, Han
            </a>
           </td>
           <td class="r">
            Institute of Automation, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396983" title="Click to go to the Author Index">
             Zhai, Yu-Peng
            </a>
           </td>
           <td class="r">
            School of Automation, Beijing Information Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#363811" title="Click to go to the Author Index">
             Ma, Ruichen
            </a>
           </td>
           <td class="r">
            Institute of Automation, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#246607" title="Click to go to the Author Index">
             Li, Zhen
            </a>
           </td>
           <td class="r">
            Institute of Automation, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1701" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#flexible_robotics" title="Click to go to the Keyword Index">
               Flexible Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Cable-driven continuum robots in bronchoscopic procedures hold immense potential to revolutionize the diagnosis and treatment of lung cancer. However, robotic bronchoscopes in current studies are typically large in size and inflexible. Therefore, this article introduces a novel cable-driven continuum robot bronchoscopy system that achieves modular design between the actuation and operation ends. A continuum structure with a dual-segment notched flexible skeleton, featuring a wall thickness of 0.45 mm, has been designed to perform bending movements exceeding 190°. This enhances flexibility and increases the spatial capacity of the working channels. A kinematic model was developed, integrating the actuation force and the mechanical characteristics of the driving cables for error compensation, estimating the correlation between the displacement of the driving cables and the position of the continuum robot's end-effector. The verification showed that the root mean square error (RMSE) of the end-effector position is 2.57 mm, which accounts for 4.8% of the continuum's length. A prototype of the robotic bronchoscopy system was created, and its performance and potential applications in bronchoscopic intervention surgeries were validated through vivo pig intervention experiments.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="weat1">
             <b>
              WeAT1
             </b>
            </a>
           </td>
           <td class="r">
            Room 1
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#weat1" title="Click to go to the Program at a Glance">
             <b>
              Best Safety, Security, and Rescue Robotics Papers (IRSI)
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#105044" title="Click to go to the Author Index">
             Kyrki, Ville
            </a>
           </td>
           <td class="r">
            Aalto University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat1_01">
             10:00-10:15, Paper WeAT1.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1374'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Automating ROS2 Security Policies Extraction through Static Analysis
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396363" title="Click to go to the Author Index">
             Zanatta, Giacomo
            </a>
           </td>
           <td class="r">
            Ca' Foscari University of Venice
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#226616" title="Click to go to the Author Index">
             Caiazza, Gianluca
            </a>
           </td>
           <td class="r">
            Ca Foscari University of Venice
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396412" title="Click to go to the Author Index">
             Ferrara, Pietro
            </a>
           </td>
           <td class="r">
            Ca' Foscari University of Venice
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396365" title="Click to go to the Author Index">
             Negrini, Luca
            </a>
           </td>
           <td class="r">
            Ca' Foscari University of Venice
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#196478" title="Click to go to the Author Index">
             White, Ruffin
            </a>
           </td>
           <td class="r">
            University of California San Diego
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1374" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#formal_methods_in_robotics_and_automation" title="Click to go to the Keyword Index">
               Formal Methods in Robotics and Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#software__middleware_and_programming_environments" title="Click to go to the Keyword Index">
               Software, Middleware and Programming Environments
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Cybersecurity in mission-critical robotic applications is a necessity to scale deployments securely. ROS2 builds upon DDS-Security specs in ROS Client Library (RCL) to implement its security features. Utilizing SROS2, developers have access to a set of utilities to help set up security in a way RCL can use. Through SROS2, security deployment is eased for developers. However, while access control is handled by DDS and consequently based on the SROS2-generated permission artifacts, the necessary authorization policies are manually generated by developers. This requires an entire system exercise to be sampled via live extraction and, per each node, list all the necessary Topics, Services, and Actions, which is a daunting and laborious process. Developers first have to generate tests. Then, they obtain a 'snapshot' of the system for each test. Later, these snapshots must be collected and grouped into a policy by a minimum set of rules. All this procedure is quite error-prone. This paper introduces LiSA4ROS2, a tool for automatically extract the ROS2 computational graph via static analysis to derive a minimal correct configuration for ROS2 security policies. Our approach relies on the abstract interpretation theory to statically overapproximate all possible executions to extract a minimal and complete configuration per node. We evaluate our approach with minimal examples covering all the main communication patterns in ROS2 tutorials and all publicly available real-world ROS2 Python systems extracted from GitHub. The results of the minimal examples show that LiSA4ROS2 precisely supports all the main communication patterns. The extensive evaluation underlines that our prototype implementation of the analysis in LiSA4ROS2 is already able to precisely analyze 66% of existing repositories, automatically producing detailed computational graphs and access policies. All the results of the analysis, as well as a Docker artifact to reproduce them, are publicly available.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat1_02">
             10:15-10:30, Paper WeAT1.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1483'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Jointly Learning Cost and Constraints from Demonstrations for Safe Trajectory Generation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396343" title="Click to go to the Author Index">
             Chaubey, Shivam
            </a>
           </td>
           <td class="r">
            Aalto University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#224374" title="Click to go to the Author Index">
             Verdoja, Francesco
            </a>
           </td>
           <td class="r">
            Aalto University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105044" title="Click to go to the Author Index">
             Kyrki, Ville
            </a>
           </td>
           <td class="r">
            Aalto University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1483" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Learning from Demonstration allows robots to mimic human actions. However, these methods do not model constraints crucial to ensure safety of the learned skill. Moreover, even when explicitly modelling constraints, they rely on the assumption of a known cost function, which limits their practical usability for task with unknown cost. In this work we propose a two-step optimization process that allow to estimate cost and constraints by decoupling the learning of cost functions from the identification of unknown constraints within the demonstrated trajectories. Initially, we identify the cost function by isolating the effect of constraints on parts of the demonstrations. Subsequently, a constraint leaning method is used to identify the unknown constraints. Our approach is validated both on simulated trajectories and a real robotic manipulation task. Our experiments show the impact that incorrect cost estimation has on the learned constraints and illustrate how the proposed method is able to infer unknown constraints, such as obstacles, from demonstrated trajectories without any initial knowledge of the cost.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat1_03">
             10:30-10:45, Paper WeAT1.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2746'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learned Regions of Attraction for Safe Motion Primitive Transitions
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#159499" title="Click to go to the Author Index">
             Ubellacker, Wyatt
            </a>
           </td>
           <td class="r">
            California Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#116276" title="Click to go to the Author Index">
             Ames, Aaron
            </a>
           </td>
           <td class="r">
            California Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2746" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#dynamics" title="Click to go to the Keyword Index">
               Dynamics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Estimating regions of attraction (ROAs) of dynamical systems is critical for understanding the operational bounds within which a system will converge to a desired state. In this paper, we introduce a neural network-based approach to approximating ROAs that leverages labeled data generated by offline sampling and simulation of initial conditions, with labels determined by flow membership in an “explicit region of attraction.” This framework is designed to estimate ROAs with a level of precision suitable for integration into a motion primitive transition framework as conditions to switch between candidate primitive behaviors. To account for gaps between the simulated environment and the real world, online learning is employed; this refines the offline-learned model of the ROA based on observed discrepancies between predicted and actual system behaviors. We validate this methodology on a quadrupedal robot, demonstrating that our ROA estimates can effectively model regions of attraction for a high-dimensional system. We show this for multiple primitive behaviors and in environments different from the training data. The outcomes highlight the usefulness of our method in estimating regions of attraction and informing transition conditions between primitive behaviors.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat1_04">
             10:45-11:00, Paper WeAT1.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('591'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Embodied AI with Two Arms: Zero-Shot Learning, Safety and Modularity
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#184419" title="Click to go to the Author Index">
             Varley, Jacob
            </a>
           </td>
           <td class="r">
            Google
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#180343" title="Click to go to the Author Index">
             Singh, Sumeet
            </a>
           </td>
           <td class="r">
            Google
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#245808" title="Click to go to the Author Index">
             Jain, Deepali
            </a>
           </td>
           <td class="r">
            Robotics at Google
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#219017" title="Click to go to the Author Index">
             Choromanski, Krzysztof
            </a>
           </td>
           <td class="r">
            Google DeepMind Robotics
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#205686" title="Click to go to the Author Index">
             Zeng, Andy
            </a>
           </td>
           <td class="r">
            Google DeepMind
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375770" title="Click to go to the Author Index">
             Basu Roy Chowdhury, Somnath
            </a>
           </td>
           <td class="r">
            UNC Chapel Hill
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#373804" title="Click to go to the Author Index">
             Dubey, Avinava
            </a>
           </td>
           <td class="r">
            Google
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#205788" title="Click to go to the Author Index">
             Sindhwani, Vikas
            </a>
           </td>
           <td class="r">
            Google Brain, NYC
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab591" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#bimanual_manipulation" title="Click to go to the Keyword Index">
               Bimanual Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present an embodied AI system which receives open-ended natural language instructions from a human, and controls two arms to collaboratively accomplish potentially long-horizon tasks over a large workspace. Our system is modular: it deploys state of the art Large Language Models for task planning, Vision-Language models for semantic perception, and Point Cloud transformers for grasping. With semantic and physical safety in mind, these modules are interfaced with a real-time trajectory optimizer and a compliant tracking controller to enable human-robot proximity. We demonstrate performance for the following tasks: bi-arm sorting, bottle opening, and trash disposal tasks. These are done zero-shot where the models used have not been trained with any real world data from this bi-arm robot, scenes or workspace. Composing both learning- and non-learning-based components in a modular fashion with interpretable inputs and outputs allows the user to easily debug points of failures and fragilities. One may also in-place swap modules to improve the robustness of the overall platform, for instance with imitation-learned policies.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="weat2">
             <b>
              WeAT2
             </b>
            </a>
           </td>
           <td class="r">
            Room 2
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#weat2" title="Click to go to the Program at a Glance">
             <b>
              Best Mobile Manipulation Papers (OMRON Sinix X Corp.)
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat2_01">
             10:00-10:15, Paper WeAT2.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('699'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Harmonic Mobile Manipulation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#308775" title="Click to go to the Author Index">
             Yang, Ruihan
            </a>
           </td>
           <td class="r">
            UC San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393531" title="Click to go to the Author Index">
             Kim, Yejin
            </a>
           </td>
           <td class="r">
            Allen Institute for AI
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#219861" title="Click to go to the Author Index">
             Hendrix, Rose
            </a>
           </td>
           <td class="r">
            Allen Institute for AI
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393529" title="Click to go to the Author Index">
             Kembhavi, Aniruddha
            </a>
           </td>
           <td class="r">
            Allen Institute for AI
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#280419" title="Click to go to the Author Index">
             Wang, Xiaolong
            </a>
           </td>
           <td class="r">
            UC San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#353118" title="Click to go to the Author Index">
             Ehsani, Kiana
            </a>
           </td>
           <td class="r">
            Allen Institute for Artificial Intelligence
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab699" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#mobile_manipulation" title="Click to go to the Keyword Index">
               Mobile Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recent advancements in robotics have enabled robots to navigate complex scenes or manipulate diverse objects independently. However, robots are still impotent in many household tasks requiring coordinated behaviors such as opening doors. The factorization of navigation and manipulation, while effective for some tasks, fails in scenarios requiring coordinated actions. To address this challenge, we introduce, HarmonicMM, an end-to-end learning method that optimizes both navigation and manipulation, showing notable improvement over existing techniques in everyday tasks. This approach is validated in simulated and real-world environments and adapts to novel unseen settings without additional tuning. Our contributions include a new benchmark for mobile manipulation and the successful deployment with only RGB visual observation in a real unseen apartment, demonstrating the potential for practical indoor robot deployment in daily life
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat2_02">
             10:15-10:30, Paper WeAT2.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1177'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              BaSeNet: A Learning-Based Mobile Manipulator Base Pose Sequence Planning for Pickup Tasks
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#236330" title="Click to go to the Author Index">
             Naik, Lakshadeep
            </a>
           </td>
           <td class="r">
            University of Southern Denmark (SDU)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103855" title="Click to go to the Author Index">
             Kalkan, Sinan
            </a>
           </td>
           <td class="r">
            Middle East Technical University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#332505" title="Click to go to the Author Index">
             Sørensen, Sune Lundø
            </a>
           </td>
           <td class="r">
            University of Southern Denmark
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#296610" title="Click to go to the Author Index">
             Mikkel, Kjærgaard
            </a>
           </td>
           <td class="r">
            University of Southern Denmark
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#113951" title="Click to go to the Author Index">
             Krüger, Norbert
            </a>
           </td>
           <td class="r">
            University of Southern Denmark
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1177" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#mobile_manipulation" title="Click to go to the Keyword Index">
               Mobile Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In many applications, a mobile manipulator robot is required to grasp a set of objects distributed in space.This may not be feasible from a single base pose and the robot must plan the sequence of base poses for grasping all objects, minimizing the total navigation and grasping time. This is a Combinatorial Optimization problem that can be solved using exact methods, which provide optimal solutions but are computationally expensive, or approximate methods, which offer computationally efficient but sub-optimal solutions. Recent studies have shown that learning-based methods can solve Combinatorial Optimization problems, providing near-optimal and computationally efficient solutions.
             <p>
              In this work, we present BASENET - a learning-based approach to plan the sequence of base poses for the robot to grasp all the objects in the scene. We propose a Reinforcement Learning based solution that learns the base poses for grasping individual objects and the sequence in which the objects should be grasped to minimize the total navigation and grasping costs using Layered Learning. As the problem has a varying number of states and actions, we represent states and actions as a graph and use Graph Neural Networks for learning. We show that the proposed method can produce comparable solutions to exact and approximate methods with significantly less computation time. The code, Reinforcement Learning environments, and pre-trained models will be made available on the project webpage.
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat2_03">
             10:30-10:45, Paper WeAT2.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2339'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              MAkEable: Memory-Centered and Affordance-Based Task Execution Framework for Transferable Mobile Manipulation Skills
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#277637" title="Click to go to the Author Index">
             Pohl, Christoph
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology (KIT)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#292001" title="Click to go to the Author Index">
             Reister, Fabian
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology (KIT)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#232702" title="Click to go to the Author Index">
             Peller-Konrad, Fabian
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology (KIT)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102922" title="Click to go to the Author Index">
             Asfour, Tamim
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology (KIT)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2339" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#mobile_manipulation" title="Click to go to the Keyword Index">
               Mobile Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#cognitive_control_architectures" title="Click to go to the Keyword Index">
               Cognitive Control Architectures
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#software_architecture_for_robotic_and_automation" title="Click to go to the Keyword Index">
               Software Architecture for Robotic and Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             To perform versatile mobile manipulation tasks in human-centered environments, the ability to efficiently transfer learned skills, knowledge, and experiences from one robot to another or across different environments is critical. In this paper, we present MAkEable, a versatile uni- and multi-manual mobile manipulation framework that facilitates the transfer of capabilities and knowledge across different tasks, environments, and robots. Our framework integrates an affordance-based task description into the memory-centric cognitive architecture of the ARMAR humanoid robot family, which supports the sharing of experiences and demonstrations for transferring mobile manipulation skills. By representing mobile manipulation actions through affordances, i.e., interaction possibilities of the robot with its environment, we provide a unifying framework for the autonomous uni- and multi-manual manipulation of known and unknown objects in various environments. We demonstrate MAkEable’s applicability in real-world experiments for multiple robots, tasks, and environments. This includes grasping known and unknown objects, object placing, bimanual object grasping, memory-enabled skill transfer in a drawer opening scenario across two different humanoid robots, and a pouring task learned from human demonstration. Code is available through our project page https://h2t-projects.webarchiv.kit.edu/software/MAkEable.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat2_04">
             10:45-11:00, Paper WeAT2.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3074'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Novel Variable Stiffness Suspension System for Improved Stability and Control of Tactile Mobile Manipulators
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398395" title="Click to go to the Author Index">
             Kuhn, Sebastian
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#188422" title="Click to go to the Author Index">
             Yildirim, Mehmet Can
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#210169" title="Click to go to the Author Index">
             Pozo Fortunić, Edmundo
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#256527" title="Click to go to the Author Index">
             Karacan, Kübra
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#292159" title="Click to go to the Author Index">
             Swikir, Abdalla
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#108317" title="Click to go to the Author Index">
             Haddadin, Sami
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3074" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#compliant_joints_and_mechanisms" title="Click to go to the Keyword Index">
               Compliant Joints and Mechanisms
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#actuation_and_joint_mechanisms" title="Click to go to the Keyword Index">
               Actuation and Joint Mechanisms
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#wheeled_robots" title="Click to go to the Keyword Index">
               Wheeled Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Mobile manipulators (MM) have proven valuable in assisting humans in industrial settings. However, their strict separation from humans in controlled environments limits their effectiveness. Efforts have been made to bridge this gap for physical human-robot interaction (pHRI), leading to the development of collaborative mobile manipulators (CMM). Nonetheless, unpredictable environments continue to present challenges. This paper introduces an innovative suspension design for mobile bases (MBs) to enhance the safety and autonomy of CMMs. We propose an electromechanical approach leveraging variable stiffness and combining passive springs with adaptive transmission mechanisms. Through simulation, physical prototype development, and experimental validation, we demonstrate the effectiveness of our approach in stabilizing the MB against external disturbances. Our findings provide valuable insights for the development of CMMs in dynamic environments.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="weat3">
             <b>
              WeAT3
             </b>
            </a>
           </td>
           <td class="r">
            Room 3
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#weat3" title="Click to go to the Program at a Glance">
             <b>
              Manipulation and Grasping I
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#253643" title="Click to go to the Author Index">
             D'Avella, Salvatore
            </a>
           </td>
           <td class="r">
            Sant'Anna School of Advanced Studies
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#108037" title="Click to go to the Author Index">
             Khorrami, Farshad
            </a>
           </td>
           <td class="r">
            New York University Tandon School of Engineering
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat3_01">
             10:00-10:15, Paper WeAT3.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('21'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Novel Dual-Robot Accurate Calibration Method Using Convex Optimization and Lie Derivative (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#283098" title="Click to go to the Author Index">
             Jiang, Cheng
            </a>
           </td>
           <td class="r">
            Huazhong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#189552" title="Click to go to the Author Index">
             Li, Wen-long
            </a>
           </td>
           <td class="r">
            Huazhong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#346377" title="Click to go to the Author Index">
             Li, Wen-pan
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#343908" title="Click to go to the Author Index">
             Wang, Dongfang
            </a>
           </td>
           <td class="r">
            Huazhong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#152107" title="Click to go to the Author Index">
             Zhu, Lijun
            </a>
           </td>
           <td class="r">
            Huazhong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#308238" title="Click to go to the Author Index">
             Xu, Wei
            </a>
           </td>
           <td class="r">
            Huazhong University of Science &amp; Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#140969" title="Click to go to the Author Index">
             Zhao, Huan
            </a>
           </td>
           <td class="r">
            Huazhong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#195115" title="Click to go to the Author Index">
             Ding, Han
            </a>
           </td>
           <td class="r">
            Huazhong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab21" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#dual_arm_manipulation" title="Click to go to the Keyword Index">
               Dual Arm Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#calibration_and_identification" title="Click to go to the Keyword Index">
               Calibration and Identification
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#convex_optimization_and_lie_derivative" title="Click to go to the Keyword Index">
               Convex Optimization and Lie Derivative
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#industrial_robots" title="Click to go to the Keyword Index">
               Industrial Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Calibrating unknown transformation relationships is an essential task for multi-robot cooperative systems. Traditional linear methods are inadequate to decouple and simultaneously solve the unknown matrices due to their intercoupling. This paper proposes a novel dual-robot accurate calibration method that uses convex optimization and Lie derivative to solve the dual-robot calibration problem simultaneously. The key idea is that a convex optimization model based on dual-robot transformation chain is established using Lie representation of SE(3). The Jacobian matrix of the established optimization model is explicitly derived using the corresponding Lie derivative of SE(3). To balance the influence of the magnitudes of the rotational and translational variables, a weight coefficient is defined. Due to the closure and smoothness of Lie group, the optimization model can be solved simultaneously using Newton-like iterative methods without orthogonalization processing. The performance of the proposed method is verified through simulation and actual calibration experiments. The results show the proposed method outperforms the previous calibration methods in term of accuracy.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat3_02">
             10:15-10:30, Paper WeAT3.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('743'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Grasp Multiple Objects with One Hand
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#337940" title="Click to go to the Author Index">
             Li, Yuyang
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#370835" title="Click to go to the Author Index">
             Liu, Bo
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#319458" title="Click to go to the Author Index">
             Geng, Yiran
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#337939" title="Click to go to the Author Index">
             Li, Puhao
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#323047" title="Click to go to the Author Index">
             Yang, Yaodong
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#194821" title="Click to go to the Author Index">
             Zhu, Yixin
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#223009" title="Click to go to the Author Index">
             Liu, Tengyu
            </a>
           </td>
           <td class="r">
            Beijing Institute for General Artificial Intelligence
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#335817" title="Click to go to the Author Index">
             Huang, Siyuan
            </a>
           </td>
           <td class="r">
            Beijing Institute for General Artificial Intelligence
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab743" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robot_learning" title="Click to go to the Keyword Index">
               Data Sets for Robot Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The intricate kinematics of the human hand enable simultaneous grasping and manipulation of multiple objects, essential for tasks such as object transfer and in-hand manipulation. Despite its significance, the domain of robotic multi-object grasping is relatively unexplored and presents notable challenges in kinematics, dynamics, and object configurations. This paper introduces MultiGrasp, a novel two-stage approach for multi-object grasping using a dexterous multi-fingered robotic hand on a tabletop. The process consists of (i) generating pre-grasp proposals and (ii) executing the grasp and lifting the objects. Our experimental focus is primarily on dual-object grasping, achieving a success rate of 44.13%, highlighting adaptability to new object configurations and tolerance for imprecise grasps. Additionally, the framework demonstrates the potential for grasping more than two objects at the cost of inference speed.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat3_03">
             10:30-10:45, Paper WeAT3.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('53'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              One-Finger Manipulation of 3D Objects by Planning Start-To-Push Points and Pushing Forces
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#233428" title="Click to go to the Author Index">
             Xiao, Mubang
            </a>
           </td>
           <td class="r">
            National University of Defense Technology,
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#141194" title="Click to go to the Author Index">
             Ding, Ye
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#370421" title="Click to go to the Author Index">
             Fan, Shixun
            </a>
           </td>
           <td class="r">
            National University of Defense Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab53" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#dexterous_manipulation" title="Click to go to the Keyword Index">
               Dexterous Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a one-finger nonprehensile manipulation framework for steering a 3D object to the desired pose. The proposed manipulation
             <p>
              framework consists of the periodic searching and pushing modes for the robotic finger. In the searching mode, the optimal start-to-push point on the object is planned based on the defined manipulability indices that comprehensively reflect the continuous pushing distance, the contact force transmissibility, and the pushing demand. In the pushing mode, the pushing force is planned to accelerate the object toward the desired pose. During the pushing process, the equivalent inertia and the pushing force offset at the contact point are estimated online. Both simulation and experimental results show that different 3D objects
              <p>
               on a frictional table can be driven to the desired pose by using a torque-driven robotic finger when the finger's base frame is appropriately selected.
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat3_04">
             10:45-11:00, Paper WeAT3.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3713'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Enabling Grasp Synthesis Approaches to Task-Oriented Grasping Considering the End-State Comfort and Confidence Effects
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#358608" title="Click to go to the Author Index">
             Maranci, Emilio
            </a>
           </td>
           <td class="r">
            Scuola Superiore Sant'Anna
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#253643" title="Click to go to the Author Index">
             D'Avella, Salvatore
            </a>
           </td>
           <td class="r">
            Sant'Anna School of Advanced Studies
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#115945" title="Click to go to the Author Index">
             Tripicchio, Paolo
            </a>
           </td>
           <td class="r">
            Scuola Superiore Sant'Anna
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101830" title="Click to go to the Author Index">
             Avizzano, Carlo Alberto
            </a>
           </td>
           <td class="r">
            Scuola Superiore Sant'Anna
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3713" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Choosing a good grasp is fundamental for accomplishing robotic grasping and manipulation tasks. Typically, the grasp synthesis is addressed separately from the planning phase, which can lead to failures during the execution of the task. In addition, most of the current grasping approaches privilege stability metrics, providing unsuitable grasps for executing subsequent tasks. The proposed work presents a framework for high-level reasoning to select the best-suited grasp depending on the task. The best grasp is chosen among a set of grasp candidates by solving an optimization problem, considering the environmental constraints, and guaranteeing the end-state comfort and the confidence effects for the task, similar to human behavior. The framework leverages Generalized Bender Decomposition to decouple the main non-linear optimization problem into sub-problems, thus presenting a modular structure. The method is validated with an experimental campaign using three different state-of-the-art grasping algorithms and three low-level motion planners in three different types of tasks: pick-and-place in a constrained environment, handover/tool-use, and object re-orientation. The experiments show that the proposed approach is able to find the best grasp, or at least one feasible, among the provided candidates for each task.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="weat4">
             <b>
              WeAT4
             </b>
            </a>
           </td>
           <td class="r">
            Room 4
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#weat4" title="Click to go to the Program at a Glance">
             <b>
              Soft Robot Materials and Design I
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#103313" title="Click to go to the Author Index">
             Wakimoto, Shuichi
            </a>
           </td>
           <td class="r">
            Okayama University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#146365" title="Click to go to the Author Index">
             Cha, Youngsu
            </a>
           </td>
           <td class="r">
            Korea University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat4_01">
             10:00-10:15, Paper WeAT4.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('12'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Electroactive Soft Bistable Actuator with Adjustable Energy Barrier and Stiffness (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#331286" title="Click to go to the Author Index">
             Jiang, Lei
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#217765" title="Click to go to the Author Index">
             Li, Bo
            </a>
           </td>
           <td class="r">
            Xi'an Jiatotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#331288" title="Click to go to the Author Index">
             Ma, Wentao
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong University, School of Mechanical Engineering
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#331287" title="Click to go to the Author Index">
             Wu, Yehui
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#364215" title="Click to go to the Author Index">
             Bai, Ruiyu
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#302031" title="Click to go to the Author Index">
             Sun, Wenjie
            </a>
           </td>
           <td class="r">
            School of Mechanical and Precision Instrument Engineering, Xi' A
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#300396" title="Click to go to the Author Index">
             Wang, Yanjie
            </a>
           </td>
           <td class="r">
            Hohai University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#161774" title="Click to go to the Author Index">
             Chen, Guimin
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab12" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#modeling__control__and_learning_for_soft_robots" title="Click to go to the Keyword Index">
               Modeling, Control, and Learning for Soft Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#electroactive_soft_bistable_actuator" title="Click to go to the Keyword Index">
               Electroactive soft bistable actuator
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             A soft bistable actuator can generate high-speed motion between two prescribed stable positions, which is very useful for boosting the actuation of soft robots. Generally, the stroke of such an actuator is completely determined once the design is finalized, which prohibits its applications in robots that perform multiple tasks. In the current work, a bistable actuator with adjustable characteristics is proposed by exploring its strain energy landscape, in which the energy barrier is manipulatable via electroactive twisted and coiled polymer fibers. As such, the actuator can operate in either bistable or postbistable mode, both of which exhibit adjustable stiffness. A kinetostatic model that combines the chained beam constraint model and the mechanics of electroactive materials is established to characterize the actuator design. Experimental results validate the kinetostatic model and the behaviors of the actuator. As a robotic demonstration, a gripper that is formed by two actuators is prototyped, and it exhibits an adjustable load capacity (up to 6.5 times its weight under a 3 V voltage).
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat4_02">
             10:15-10:30, Paper WeAT4.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('95'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Multi-Modal Soft Amphibious Robots Using Simple Plastic Sheet-Reinforced Thin Pneumatic Actuators (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#273412" title="Click to go to the Author Index">
             Wu, Jiaxi
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#366921" title="Click to go to the Author Index">
             Mingxin, Wu
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#366951" title="Click to go to the Author Index">
             Chen, Wenhui
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#131436" title="Click to go to the Author Index">
             Wang, Chen
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#109735" title="Click to go to the Author Index">
             Xie, Guangming
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab95" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#biologically_inspired_robots" title="Click to go to the Keyword Index">
               Biologically-Inspired Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#hydraulic_pneumatic_actuators" title="Click to go to the Keyword Index">
               Hydraulic/Pneumatic Actuators
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_modal_locomotion" title="Click to go to the Keyword Index">
               Multi-Modal Locomotion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             A large challenge in the field of soft amphibious robotics is achieving high maneuverability and multi-terrain adaptability through multi-modal locomotion. To address this issue, drawing inspiration from fruit-fly larvae and Spanish dancer sea slugs, a novel tethered soft amphibious robot with multi-modal locomotion is proposed in this paper, performing forward, backward, turning, and self-overturn motions both on land and in water. It leverages plastic sheet-reinforced thin pneumatic actuators, which are constructed from thermoplastic membranes and semi-rigid plastic sheets. The robot achieves a forward jumping velocity of 1.77BL/s and a forward swimming velocity of 0.69BL/s, both faster than previously reported soft amphibious robots; connecting two actuator units in parallel, it achieves agile turning with a velocity of 111.8°/s. Our proposed robot demonstrates exceptional multi-terrain adaptability, facile terrestrial-aquatic transition capabilities, and underwater buoyancy adjustment ability. Especially when accidentally overturned, it can recover itself without external assistance, a capability rarely achieved by other soft robots.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat4_03">
             10:30-10:45, Paper WeAT4.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3638'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Design of an Accordion-Fold-Inspired Soft Electrohydraulic Actuator for Angular Motion
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#241125" title="Click to go to the Author Index">
             Kim, Sohyun
            </a>
           </td>
           <td class="r">
            Korea University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#385396" title="Click to go to the Author Index">
             Oh, Yenee
            </a>
           </td>
           <td class="r">
            Korea University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#318872" title="Click to go to the Author Index">
             Kang, Joohyeon
            </a>
           </td>
           <td class="r">
            Korea University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#146365" title="Click to go to the Author Index">
             Cha, Youngsu
            </a>
           </td>
           <td class="r">
            Korea University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3638" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_sensors_and_actuators" title="Click to go to the Keyword Index">
               Soft Sensors and Actuators
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Angular motion of soft actuators is important for utilization in robotic systems. In the robots, the angular motion should enable agile movement and a wide range. This study proposes a novel design of a soft electrohydraulic actuator inspired by an accordion with an improved angular deformation range. The actuator generates instantaneous hydraulic force and achieves a fast response within 0.15 s upon activation. Furthermore, the accordion-fold structure of the actuator induces large rotational deformations of 171 degrees. We conduct a series of experiments to investigate the angular motion characteristics from the geometrical parameters of the actuator. Additionally, based on the experimental results, we demonstrate how to apply electrohydraulic actuators to animate objects.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat4_04">
             10:45-11:00, Paper WeAT4.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3663'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Fabrication Process for Twisting Artificial Muscles by Utilizing Braiding Technology and Water-Soluble Fibers
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#347284" title="Click to go to the Author Index">
             Tian, Weihang
            </a>
           </td>
           <td class="r">
            Okayama University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103313" title="Click to go to the Author Index">
             Wakimoto, Shuichi
            </a>
           </td>
           <td class="r">
            Okayama University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#145651" title="Click to go to the Author Index">
             Yamaguchi, Daisuke
            </a>
           </td>
           <td class="r">
            Okayama University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100826" title="Click to go to the Author Index">
             Kanda, Takefumi
            </a>
           </td>
           <td class="r">
            Okayama Univ
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3663" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#hydraulic_pneumatic_actuators" title="Click to go to the Keyword Index">
               Hydraulic/Pneumatic Actuators
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The McKibben artificial muscle is a pneumatic soft actuator consisting of a rubber tube, with fibers covering it. In this study, we propose a new fabrication process to easily realize twisting artificial muscles by utilizing braiding technology and water-soluble fibers based on the McKibben artificial muscle. In the braiding process, half of the sleeve fibers of the artificial muscle are substituted with water-soluble fibers. However, the water-soluble fibers are removed by placing the muscle in warm water to realize a twisting motion. By changing the direction of the fibers, artificial muscles that twist clockwise or counterclockwise can be produced. We believe that the establishment of such a simple and efficient fabrication process will promote to the practical application of artificial muscles.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="weat5">
             <b>
              WeAT5
             </b>
            </a>
           </td>
           <td class="r">
            Room 5
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#weat5" title="Click to go to the Program at a Glance">
             <b>
              Robot Safety I
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#154562" title="Click to go to the Author Index">
             Saveriano, Matteo
            </a>
           </td>
           <td class="r">
            University of Trento
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat5_01">
             10:00-10:15, Paper WeAT5.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3715'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Safe-VLN: Collision Avoidance for Vision-And-Language Navigation of Autonomous Robots Operating in Continuous Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#382203" title="Click to go to the Author Index">
             Yue, Lu
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#382115" title="Click to go to the Author Index">
             Zhou, Dongliang
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#344481" title="Click to go to the Author Index">
             Xie, Liang
            </a>
           </td>
           <td class="r">
            Unmanned Systems Research Center, National Institute of Defense
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#148116" title="Click to go to the Author Index">
             Zhang, Feitian
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#344607" title="Click to go to the Author Index">
             Yan, Ye
            </a>
           </td>
           <td class="r">
            Academy of Military Sciences China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#344610" title="Click to go to the Author Index">
             Yin, Erwei
            </a>
           </td>
           <td class="r">
            Harbin Engineering University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3715" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#embodied_cognitive_science" title="Click to go to the Keyword Index">
               Embodied Cognitive Science
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The task of vision-and-language navigation in continuous environments (VLN-CE) aims at training an autonomous agent to perform low-level actions to navigate through 3D continuous surroundings using visual observations and language instructions. The significant potential of VLN-CE for mobile robots has been demonstrated across a large number of studies. However, most existing works in VLN-CE focus primarily on transferring the standard discrete vision-and-language navigation (VLN) methods to continuous environments, overlooking the problem of collisions. Such oversight often results in the agent deviating from the planned path or, in severe instances, the agent being trapped in obstacle areas and failing the navigational task. To address the above-mentioned issues, this paper investigates various collision scenarios within VLN-CE and proposes a classification method to predicate the underlying causes of collisions. Furthermore, a new VLN-CE algorithm, named Safe-VLN, is proposed to bolster collision avoidance capabilities including two key components, i.e., a waypoint predictor and a navigator. In particular, the waypoint predictor leverages a simulated 2D LiDAR occupancy mask to prevent the predicted waypoints from being situated in obstacle-ridden areas. The navigator, on the other hand, employs the strategy of 're-selection after collision' to prevent the robot agent from becoming ensnared in a cycle of perpetual collisions. The proposed Safe-VLN is evaluated on the R2R-CE, the results of which demonstrate an enhanced navigational performance and a statistically significant reduction in collision incidences.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat5_02">
             10:15-10:30, Paper WeAT5.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3698'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Safe Control for Navigation in Cluttered Space Using Multiple Lyapunov-Based Control Barrier Functions
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#257191" title="Click to go to the Author Index">
             Jang, Inkyu
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103663" title="Click to go to the Author Index">
             Kim, H. Jin
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3698" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Control barrier functions (CBFs) are powerful tools for ensuring safety in controlled systems, commonly employed through the construction of a safety filter using quadratic programming (QP), known as CBF-QP. However, synthesizing a CBF specifically for the navigation tasks of mobile robots, where safety is crucial, poses challenges due to the complexity of the operating environments. In addition to that, the CBF synthesis should be repeated for every new environment, further escalating the computational burden. In this paper, we introduce Lyapunov-based CBFs, which is a CBF built solely from a control Lyapunov function (CLF). By utilizing multiple Lyapunov-based CBFs as building blocks to create a large control invariant set, we formulate a CBF-QP-like safety filter to ensure safety in cluttered environments. The proposed safety filter inherits the favorable characteristics of CBF-QP such as fast computation and safety guarantee, and can adapt to diverse environments without the need for burdensome resynthesis of a new environment-specific CBF. We demonstrate the effectiveness of the proposed approach through multiple simulation and real-world experiments, whose results show that the proposed safety filter was successful in providing safety for the robot even in complex workspaces with many obstacles.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat5_03">
             10:30-10:45, Paper WeAT5.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3709'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Novel Safety-Aware Energy Tank Formulation Based on Control Barrier Functions
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#179527" title="Click to go to the Author Index">
             Michel, Youssef
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#154562" title="Click to go to the Author Index">
             Saveriano, Matteo
            </a>
           </td>
           <td class="r">
            University of Trento
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104647" title="Click to go to the Author Index">
             Lee, Dongheui
            </a>
           </td>
           <td class="r">
            Technische Universität Wien (TU Wien)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3709" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#compliance_and_impedance_control" title="Click to go to the Keyword Index">
               Compliance and Impedance Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#force_control" title="Click to go to the Keyword Index">
               Force Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this work, we propose a novel formulation for energy tanks based on Control Barrier Functions (CBF). Our approach is able to handle simultaneously energy constraints to ensure passivity, as well as enforce power limits in the system to enhance safety. Furthermore, our approach overcomes the discrete switching nature of classical energy tanks, ensuring smooth control commands. To achieve our desiderata, we formulate our tank as a second order dynamical system, where we exploit
             <p>
              CBF and Higher-Order CBF to obtain theoretical guarantees on fulfilling
              <p>
               the energy and power constraints in the system. Furthermore, we derive conditions related to our tank design in order to ensure the passivity of the controlled robot. Our proposed approach is tested in a series of
               <p>
                robot experiments where we validate our approach on tasks such variable
                <p>
                 stiffness and force control, and in a scenario where it is desired to constraint the kinetic energy in the system.
                </p>
               </p>
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat5_04">
             10:45-11:00, Paper WeAT5.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3759'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Compliant Robust Control for Robotic Insertion of Soft Bodies
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#276437" title="Click to go to the Author Index">
             Liu, Yi
            </a>
           </td>
           <td class="r">
            University Ghent
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#267872" title="Click to go to the Author Index">
             Verleysen, Andreas
            </a>
           </td>
           <td class="r">
            Ghent University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#131145" title="Click to go to the Author Index">
             Wyffels, Francis
            </a>
           </td>
           <td class="r">
            Ghent University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3759" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper proposes a novel framework for insertion-type tasks with soft bodies, such as cleaning a bottle with a soft brush. First, a multimodal model based on vision and force perception is trained, where we use domain randomization for the soft body’s properties to overcome the simulation-to- reality gap. Second, we propose a dynamic safety lock method based on force perception, which is embedded in the training model to make sure that the tool explores and traverses the hole’s path in a compliant way, this results in a higher success rate without damaging the tools/holes. Finally, we perform experiments in simulation and the real world, and the success rate of our proposed method reaches 85.14% in simulation and 83.45% in the real world. Ablation experiments in the real world demonstrate that our method is effective for complex paths and soft bodies with varying deformation intensities.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="weat6">
             <b>
              WeAT6
             </b>
            </a>
           </td>
           <td class="r">
            Room 6
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#weat6" title="Click to go to the Program at a Glance">
             <b>
              Actuation and Joint Mechanisms
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#321707" title="Click to go to the Author Index">
             Khorasani, Amin
            </a>
           </td>
           <td class="r">
            Vrije Universiteit Brussel
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat6_01">
             10:00-10:15, Paper WeAT6.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3729'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Mitigating Collision Forces and Improving Response Performance in Human-Robot Interaction by Using Dual-Motor Actuators
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#321707" title="Click to go to the Author Index">
             Khorasani, Amin
            </a>
           </td>
           <td class="r">
            Vrije Universiteit Brussel
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#204909" title="Click to go to the Author Index">
             Usman, Muhammad
            </a>
           </td>
           <td class="r">
            Vrije Universiteit Brussel
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#321684" title="Click to go to the Author Index">
             Hubert, Thierry
            </a>
           </td>
           <td class="r">
            Vrije Universiteit Brussel
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#168099" title="Click to go to the Author Index">
             Furnémont, Raphaël
            </a>
           </td>
           <td class="r">
            Vrije Universiteit Brussel
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#139275" title="Click to go to the Author Index">
             Lefeber, Dirk
            </a>
           </td>
           <td class="r">
            Vrije Universiteit Brussel - VUB
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#330934" title="Click to go to the Author Index">
             Vanderborght, Bram
            </a>
           </td>
           <td class="r">
            VUB
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#175591" title="Click to go to the Author Index">
             Verstraten, Tom
            </a>
           </td>
           <td class="r">
            Vrije Universiteit Brussel
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3729" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#actuation_and_joint_mechanisms" title="Click to go to the Keyword Index">
               Actuation and Joint Mechanisms
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#safety_in_hri" title="Click to go to the Keyword Index">
               Safety in HRI
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#compliance_and_impedance_control" title="Click to go to the Keyword Index">
               Compliance and Impedance Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In collaborative robotics, the safety of humans interacting with cobots is crucial. There is a need for cobots that can move quickly while still being safe. This paper introduces the use of a kinematically redundant actuator in impedance control mode to reduce collision forces, aiming to improve both the safety and efficiency of cobots. By distributing power across multiple drive trains, each with unique properties such as reflected inertia, the actuator's behavior during collisions is optimized, which is key for safe interactions. Using theoretical analysis and practical experiments, we evaluate the response performance of the redundant actuator in various collision situations according to ISO/TS 15066, comparing it with that of a standard single-drive actuator. Our experiments show that the redundant actuator significantly lowers collision forces, with a 44% reduction in peak forces and an 81% decrease in transferred impulses during collisions. The paper concludes by offering a design parameter recommendation for designing actuators with reduced reflected inertia.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat6_02">
             10:15-10:30, Paper WeAT6.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3635'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Flexible Shaft As Remote and Elastic Transmission for Robot Arms
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#204909" title="Click to go to the Author Index">
             Usman, Muhammad
            </a>
           </td>
           <td class="r">
            Vrije Universiteit Brussel
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#321684" title="Click to go to the Author Index">
             Hubert, Thierry
            </a>
           </td>
           <td class="r">
            Vrije Universiteit Brussel
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#321707" title="Click to go to the Author Index">
             Khorasani, Amin
            </a>
           </td>
           <td class="r">
            Vrije Universiteit Brussel
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#168099" title="Click to go to the Author Index">
             Furnémont, Raphaël
            </a>
           </td>
           <td class="r">
            Vrije Universiteit Brussel
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101955" title="Click to go to the Author Index">
             Vanderborght, Bram
            </a>
           </td>
           <td class="r">
            Vrije Universiteit Brussel
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#139275" title="Click to go to the Author Index">
             Lefeber, Dirk
            </a>
           </td>
           <td class="r">
            Vrije Universiteit Brussel - VUB
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#171509" title="Click to go to the Author Index">
             Van de Perre, Greet
            </a>
           </td>
           <td class="r">
            Vrije Universiteit Brussel
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#175591" title="Click to go to the Author Index">
             Verstraten, Tom
            </a>
           </td>
           <td class="r">
            Vrije Universiteit Brussel
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3635" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#compliant_joints_and_mechanisms" title="Click to go to the Keyword Index">
               Compliant Joints and Mechanisms
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#actuation_and_joint_mechanisms" title="Click to go to the Keyword Index">
               Actuation and Joint Mechanisms
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Research on human-friendly robots focuses on safety through software and hardware. Hardware-based safety offers a significant advantage over software-based safety if an accurate hardware model is integrated into the solution. The design of elastic and off-joint actuation has established safety by hardware, where the inherent qualities of elastic and lightweight nature make the robot safe for interaction. Combining series elastic actuators with cable/belt pulley-based remote transmission offers inherently safe hardware design, albeit with increased design and modeling complexity. This paper introduces remote and elastic actuation as a single-element solution for robot arm design using a flexible shaft. The test-bench approach studies the remote and elastic effects of a flexible shaft-based transmission for a robot. A set of nine flexible shafts, differing in length and diameter, are used for benchmarking as 3-D surface empirical maps to facilitate their optimal selection for robot design. An example 3 Degree Of Freedom (DOF) robot arm using a flexible shaft as a remote and elastic actuator is designed and modeled. A low-level control based on a flexible shaft is proposed, backed by the experimental results.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat6_03">
             10:30-10:45, Paper WeAT6.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3660'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Universal Actuation Module and Kinematic Model for Heart Valve Interventional Catheter Robotization
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#359959" title="Click to go to the Author Index">
             Wang, Weizhao
            </a>
           </td>
           <td class="r">
            King's College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#256980" title="Click to go to the Author Index">
             Wu, Zicong
            </a>
           </td>
           <td class="r">
            King's College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#345794" title="Click to go to the Author Index">
             Saija, Carlo
            </a>
           </td>
           <td class="r">
            King's College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#338177" title="Click to go to the Author Index">
             Zeidan, Aya Mutaz
            </a>
           </td>
           <td class="r">
            King’s College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#340058" title="Click to go to the Author Index">
             Xu, Zhouyang
            </a>
           </td>
           <td class="r">
            King's College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#383684" title="Click to go to the Author Index">
             Pishkahi, Aryana
            </a>
           </td>
           <td class="r">
            King's College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#383898" title="Click to go to the Author Index">
             Patterson, Tiffany
            </a>
           </td>
           <td class="r">
            Guy’s &amp; St. Thomas’ Hospitals NHS Foundation Trust
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#383899" title="Click to go to the Author Index">
             Redwood, Simon
            </a>
           </td>
           <td class="r">
            King’s College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#194523" title="Click to go to the Author Index">
             Wang, Shuangyi
            </a>
           </td>
           <td class="r">
            Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#178727" title="Click to go to the Author Index">
             Rhode, Kawal
            </a>
           </td>
           <td class="r">
            King's College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#193114" title="Click to go to the Author Index">
             Housden, Richard James
            </a>
           </td>
           <td class="r">
            King's College London
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3660" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#kinematics" title="Click to go to the Keyword Index">
               Kinematics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#actuation_and_joint_mechanisms" title="Click to go to the Keyword Index">
               Actuation and Joint Mechanisms
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#modeling__control__and_learning_for_soft_robots" title="Click to go to the Keyword Index">
               Modeling, Control, and Learning for Soft Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Catheters have been widely used to deal with heart valve diseases. However, the diversity in handle structures and bending curvatures imposes significant complexities in safe delivery and positioning. In this letter, we designed a module for single knob actuation assembled coaxially on the catheter handle, composed of a chuck for universal clamping of diameters from 15 to 45 mm and a position-adjustable shaft to accommodate various spacing between knobs. In addition, we proposed a two-curvature with pseudo joints (TC-PJ) model for bending control of bendable sections (BSs) in catheters. The verification was decoupled into two steps based on the other three deformation patterns. Firstly, comparing the two-curvature (TC) model with pseudo-rigid-body (PRB), constant curvature (CC), and Euler spiral (ES) models to simulate planar bending and elongation, the results showed a more accurate shape representation. Then, five distinct catheters were employed to test the clamping universality of the module and tip positioning precision of the TC-PJ model which took torsion and shear strain into consideration. The root-mean-square error (RMSE) and the standard deviation (SD) of tip position and direction were analysed. Results indicated the module’s suitability for clamping these catheters, with the large guide sheath exhibiting minimal position RMSE (SD) of around 0.10 (0.051) mm and 0.049 (2.15) degrees, while the puncture catheter demonstrated the highest position and direction RMSE (SD) extending to about 1.16 (0.53) mm and 0.70 (31.33) degrees, primarily attributed to the coupling of two sequential bendable components. Overall, the proposed actuation module and kinematic model showed the ability of universal manipulation and an average tip position and direction RMSE of 0.65 mm and 0.23 degrees in free space.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat6_04">
             10:45-11:00, Paper WeAT6.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('32'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Foam-Embedded Soft Robotic Joint with Inverse Kinematic Modeling by Iterative Self-Improving Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#310764" title="Click to go to the Author Index">
             Huang, Anlun
            </a>
           </td>
           <td class="r">
            University of California, San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#370284" title="Click to go to the Author Index">
             Cao, Yongxi
            </a>
           </td>
           <td class="r">
            Delft University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#369003" title="Click to go to the Author Index">
             Guo, Jiajie
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#257457" title="Click to go to the Author Index">
             Fang, Zhonggui
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#232705" title="Click to go to the Author Index">
             Su, Yinyin
            </a>
           </td>
           <td class="r">
            The University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#228443" title="Click to go to the Author Index">
             Liu, Sicong
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#191272" title="Click to go to the Author Index">
             Yi, Juan
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#152964" title="Click to go to the Author Index">
             Wang, Hongqiang
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#107733" title="Click to go to the Author Index">
             Dai, Jian
            </a>
           </td>
           <td class="r">
            School of Natural and Mathematical Sciences, King's College Lond
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#143162" title="Click to go to the Author Index">
             Wang, Zheng
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab32" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#compliant_joints_and_mechanisms" title="Click to go to the Keyword Index">
               Compliant Joints and Mechanisms
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#modeling__control__and_learning_for_soft_robots" title="Click to go to the Keyword Index">
               Modeling, Control, and Learning for Soft Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Soft robotic arms have gained significant attention owing to their flexibility and adaptability. Nonetheless, the instability due to their high-elasticity structure further leads to the difficulty of precise kinematic modeling and control. This work introduces a novel solution employing foam-embedded joint design (Fe-Joint), effectively mitigating oscillations and enhancing motion stability. This innovation is integrated into the new continuum soft robotic arm (Fe-Arm). Through iterative design optimization, the Fe-Arm attains superior mechanical performance and control capabilities, enabling a settling state in 0.4 seconds post external force. Enabled by the quasi-static behavior of Fe-Arm, we propose a long short-term memory network (LSTM) based iterative self-improving learning strategy (ISL) for end-to-end inverse kinematics modeling, tailored to Fe-Arm’s mechanical traits, enhancing modeling performance with limited data. Investigating key control parameters, we achieve target trajectory modeling errors within 9% of the workspace radius. The generalization potential of the ISL method is demonstrated using the pentagonal trajectory and on a different Fe-Arm configuration.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="weat7">
             <b>
              WeAT7
             </b>
            </a>
           </td>
           <td class="r">
            Room 7
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#weat7" title="Click to go to the Program at a Glance">
             <b>
              Rehabilitation Robotics
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#118310" title="Click to go to the Author Index">
             Kyung, Ki-Uk
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science &amp; Technology (KAIST)
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#102881" title="Click to go to the Author Index">
             Campolo, Domenico
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat7_01">
             10:00-10:15, Paper WeAT7.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3751'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Hierarchical Trajectory Deformation Algorithm with Hybrid Controller for Active Lower Limb Rehabilitation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#385913" title="Click to go to the Author Index">
             Yang, Ze
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#162947" title="Click to go to the Author Index">
             Jin, Hu
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#268163" title="Click to go to the Author Index">
             Gao, Wei
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#386073" title="Click to go to the Author Index">
             Wang, Erlong
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#386032" title="Click to go to the Author Index">
             Shu, Yang
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#386120" title="Click to go to the Author Index">
             Wu, Ming
            </a>
           </td>
           <td class="r">
            The First Affiliated Hospital of USTC, Division of Life Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102646" title="Click to go to the Author Index">
             Zhang, Shiwu
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3751" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#physical_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical Human-Robot Interaction
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#rehabilitation_robotics" title="Click to go to the Keyword Index">
               Rehabilitation Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robot-aided active rehabilitation has shown to be an effective treatment approach for hemiplegic patients. This paper presents an active control framework for lower limb rehabilitation, combining an interaction layer with a hierarchical trajectory deformation algorithm (HTDA), and an assist-as-needed (AAN) layer with a hybrid controller. The HTDA uses constrained optimization in both position and velocity domains to continuously generate smooth reference trajectories based on virtual interaction forces during physical human-robot interaction (pHRI). An additional optimization loop is also implemented to achieve adaptive parameter adjustment for HTDA. Meanwhile, the hybrid controller relies on a force field term and a velocity field term to provide AAN feature. The proposed method is validated on a two-degree-of-freedom lower limb rehabilitation robot for walking with variable step height and step length. The experimental results demonstrate that compared to previously developed admittance model (AM) and trajectory deformation algorithm (TDA), under four different evaluation metrics, HTDA can improve dimensionless squared jerk (DSJ) by 73.6% comparing to AM and improve constraint force percentage (CFP) by 20.4% comparing to TDA. This demonstrate the effectiveness of the proposed framework in reducing human-robot confrontation, especially in improving robot actuation compliance and movement smoothness.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat7_02">
             10:15-10:30, Paper WeAT7.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3716'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Optimization-Based Adaptive Assistance for Lower Limb Exoskeleton Robots with a Robotic Walker Via Spatially Quantized Gait (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#225108" title="Click to go to the Author Index">
             Zou, Chaobin
            </a>
           </td>
           <td class="r">
            University of Electronic Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#225127" title="Click to go to the Author Index">
             Peng, Zhinan
            </a>
           </td>
           <td class="r">
            Unversity of Electronic Science and Tehcnology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#322670" title="Click to go to the Author Index">
             Zhang, Long
            </a>
           </td>
           <td class="r">
            University of Electronic Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#296782" title="Click to go to the Author Index">
             Mu, Fengjun
            </a>
           </td>
           <td class="r">
            University of Electronic Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#183121" title="Click to go to the Author Index">
             Huang, Rui
            </a>
           </td>
           <td class="r">
            University of Electronic Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#159479" title="Click to go to the Author Index">
             Cheng, Hong
            </a>
           </td>
           <td class="r">
            University of Electronic Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3716" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#rehabilitation_robotics" title="Click to go to the Keyword Index">
               Rehabilitation Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Gait training with human-like gait patterns can be provided by lower limb exoskeletons (LLEs) for patients with gait impairments. For patients with little effort to keep balance, using a mobile robotic walker to assist gait training with LLEs is an effective way. Since gait patterns are varying with walking speeds, it is a critical issue to coordinated control the robotic walker and the exoskeleton to obtain a natural and human-like walking posture. In this paper, a novel adaptive assistance approach named SQG-OPT is proposed to tackle the problem, which comprises of two parts: the Spatially Quantized Gait (SQG) and the optimization. The SQG generates reference joint angles and reference trajectory of the Center Of Mass (COM) for the human-exoskeleton system in space domain. The optimization part is constructed to convert the reference joint angles from the space domain to the time domain, which is based on the dynamics model of the human-exoskeleton-walker system and adaptive to different walking speeds. The proposed approach has been tested on the robot simulation platform CoppeliaSim, the experimental results indicate that the proposed approach can generate human-like gait patterns for different walking speeds from 0 to 0.8 m/s. Additionally, in comparison with other methods, the proposed approach has a better performance on the movement tracking of the COM for a natural walking posture.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat7_03">
             10:30-10:45, Paper WeAT7.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3682'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Development of a Dual Function Joint Modular Soft Actuator and Its Evaluation Using a Novel Dummy Finger Joint-Soft Actuator Complex Model
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#315583" title="Click to go to the Author Index">
             Tortós, Pablo
            </a>
           </td>
           <td class="r">
            Department of Medical System Engineering, Chiba University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#303737" title="Click to go to the Author Index">
             Kokubu, Shota
            </a>
           </td>
           <td class="r">
            Chiba University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#361500" title="Click to go to the Author Index">
             Matsunaga, Fuko
            </a>
           </td>
           <td class="r">
            Chiba University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#315435" title="Click to go to the Author Index">
             Lu, Yuxi
            </a>
           </td>
           <td class="r">
            Department of Medical System Engineering, Chiba University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#303738" title="Click to go to the Author Index">
             Zhou, Zhongchao
            </a>
           </td>
           <td class="r">
            Graduate School of Science and Engineering, Chiba University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#382667" title="Click to go to the Author Index">
             Gomez-Tames, Jose
            </a>
           </td>
           <td class="r">
            Chiba University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105202" title="Click to go to the Author Index">
             Yu, Wenwei
            </a>
           </td>
           <td class="r">
            Chiba University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3682" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#modeling__control__and_learning_for_soft_robots" title="Click to go to the Keyword Index">
               Modeling, Control, and Learning for Soft Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#rehabilitation_robotics" title="Click to go to the Keyword Index">
               Rehabilitation Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Soft actuators, made from soft materials, offer a safer alternative to rigid robots for use on hand rehabilitation devices. A current challenge is to ensure these actuators comply with human finger morphology. To gain better insights into actuator mechanics when worn on and interacting with human fingers, combining physical experiments with simulation approaches is necessary. However, no simulation has been implemented for finger-actuator interactions. This study proposes a new joint modular soft actuator designed to comply with a dummy finger joint. The new actuator has a dual function design for increasing axial elongation during bending, facilitating compliance with finger morphology. In addition, a novel FEM for the new actuator’s
             <p>
              interaction with the dummy finger joint (dummy joint-soft actuator complex) is developed and used with physical experiments for evaluating
              <p>
               actuator performance. Results show that the new design increases the dummy joint’s bending range while exerting smaller contact forces on the joint. Even when the joint is blocked at specific bending angles, the actuator remains compliant to finger morphology. This research is a
               <p>
                significant advancement in soft actuators design for hand rehabilitation, emphasizing the interaction between human fingers and soft actuators.
               </p>
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat7_04">
             10:45-11:00, Paper WeAT7.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('10'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Origami-Inspired Wearable Robot for Shoulder Abduction Assistance: A Double-Petal Mechanism Utilizing Shape Memory Alloy Actuators
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#315613" title="Click to go to the Author Index">
             Chung, Chongyoung
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology (KAIST)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#244433" title="Click to go to the Author Index">
             Hyeon, Kyujin
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#244471" title="Click to go to the Author Index">
             Jeong, Jaeyeon
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science Ane Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#156028" title="Click to go to the Author Index">
             Lee, Dae-Young
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#118310" title="Click to go to the Author Index">
             Kyung, Ki-Uk
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science &amp; Technology (KAIST)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab10" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#wearable_robotics" title="Click to go to the Keyword Index">
               Wearable Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#rehabilitation_robotics" title="Click to go to the Keyword Index">
               Rehabilitation Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper proposes a novel wearable robot designed to assist with shoulder abduction using a double-petal mechanism based on petal fold origami driven by shape memory alloy (SMA)-based artificial muscle. The proposed double-petal mechanism consists of two petal structures that mimic the scapula and humerus, respectively. It follows the scapulohumeral rhythm to prevent bone collision and reduce the compressive force on the glenohumeral joint. The mechanism is designed to achieve high mechanical advantage and torque output while minimizing the overall weight using lightweight SMA spring actuators and carbon fiber-reinforced plastic-based frames. The proposed robot can assist with shoulder abduction both with (active support) and without energy input (passive support) using bundles of SMA spring actuators. It can generate assistance torque up to 6.36 Nm passively and 12.6 Nm actively at a 90° abduction angle. To verify the assistance performance of the proposed robot, surface electromyography of the lateral deltoid is measured during shoulder abduction with and without the assistance of the robot and the results confirm that the robot effectively assists in shoulder abduction.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="weat8">
             <b>
              WeAT8
             </b>
            </a>
           </td>
           <td class="r">
            Room 8
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#weat8" title="Click to go to the Program at a Glance">
             <b>
              Mapping I
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#104695" title="Click to go to the Author Index">
             Nuechter, Andreas
            </a>
           </td>
           <td class="r">
            University of Würzburg
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat8_01">
             10:00-10:15, Paper WeAT8.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('69'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              An Integrated Hierarchical Approach for Real-Time Mapping with Gaussian Mixture Model
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#362932" title="Click to go to the Author Index">
             Gao, Yuan
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#253549" title="Click to go to the Author Index">
             Dong, Wei
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab69" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#swarm_robotics" title="Click to go to the Keyword Index">
               Swarm Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__perception_and_autonomy" title="Click to go to the Keyword Index">
               Aerial Systems: Perception and Autonomy
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             To achieve effective collaboration of multiple robots, it requires efficient exchanges of map information. As directly exchanging generally used depth map requires high communication bandwidth, it is practical to enhance the efficiency using map compression techniques based on Gaussian mixture models. Currently, parameters of the Gaussian
             <p>
              mixture model are mostly computed using the expectation-maximization algorithm. It is time consuming as it has to iteratively update parameters by traversing all points in a point cloud converted from the
              <p>
               depth map, and it is not suitable for real-time applications. Other methods directly segment the point cloud into grids and then perform a single Gaussian parameter estimation for each grid. They achieve real-time compression but generate parameter sensitive results. To tackle issues above, we improve compression methods with an integrated hierarchical approach. First, the points are clustered hierarchically and efficiently by K-means, generating coarse clusters. Then, each cluster is further hierarchically clustered by expectation-maximization
               <p>
                algorithm for accuracy enhancement. After each clustering process, an evaluation index for ensuring accuracy and preventing over-fitting is calculated to determine whether pruning or retention of newly generated
                <p>
                 clusters is appropriate. At last, parameters of each Gaussian distribution in the model are estimated by points in a corresponding cluster. Experiments conducted in various environments demonstrate that
                 <p>
                  our approach improves computing efficiency by over 79 times compared to
                  <p>
                   the state-of-the-art approach.
                  </p>
                 </p>
                </p>
               </p>
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat8_02">
             10:15-10:30, Paper WeAT8.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('179'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Incremental Triangle Mesh Generation with Mesh Refinement
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#242056" title="Click to go to the Author Index">
             Niedźwiedzki, Jakub
            </a>
           </td>
           <td class="r">
            Lodz University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#303549" title="Click to go to the Author Index">
             Lipinski, Piotr
            </a>
           </td>
           <td class="r">
            Lodz University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#163025" title="Click to go to the Author Index">
             Podsedkowski, Leszek
            </a>
           </td>
           <td class="r">
            Lodz University of Technology, Institute of Machine Tools and Pr
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab179" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#range_sensing" title="Click to go to the Keyword Index">
               Range Sensing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This letter presents an incremental algorithm to generate triangle meshes from Light Detection and Ranging (LiDAR) point clouds with mesh refinement. The algorithm produces triangle mesh directly from LiDAR output without storing a dense point cloud to create a high-quality triangle mesh. In our algorithm, as the number of captured points increases during the LiDAR operation and robot movement, the new scan points from the LiDAR output refine or extend the existing triangle mesh. Such an approach is suitable for computationally-constrained systems like aerial vehicles, mobile robots, and smartphones, as it requires relatively limited resources. Our algorithm can reconstruct the topology of city-sized scenes maintaining a maximum triangle mesh error below 2 cm much faster than state-of-the-art triangle mesh generation algorithms that we demonstrate on publicly available data sets.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat8_03">
             10:30-10:45, Paper WeAT8.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3667'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Uni-Fusion: Universal Continuous Mapping (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#225673" title="Click to go to the Author Index">
             Yuan, Yijun
            </a>
           </td>
           <td class="r">
            University of Wuerzburg
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104695" title="Click to go to the Author Index">
             Nuechter, Andreas
            </a>
           </td>
           <td class="r">
            University of Würzburg
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3667" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#universal_mapping" title="Click to go to the Keyword Index">
               Universal mapping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present Uni-Fusion, a universal continuous mapping framework for surfaces, surface properties (color, infrared, etc.) and more (latent features in CLIP embedding space, etc.). We propose the first universal implicit encoding model that supports encoding of both geometry and different types of properties (RGB, infrared, features, etc.) without requiring any training. Based on this, our framework divides the point cloud into regular grid voxels and generates a latent feature in each voxel to form a Latent Implicit Map (LIM) for geometries and arbitrary properties. Then, by fusing a local LIM frame-wisely into a global LIM, an incremental reconstruction is achieved. Encoded with corresponding types of data, our Latent Implicit Map is capable of generating continuous surfaces, surface property fields, surface feature fields, and all other possible options. To demonstrate the capabilities of our model, we implement three applications: (1) incremental reconstruction for surfaces and color (2) 2D-to-3D transfer of fabricated properties (3) open-vocabulary scene understanding by creating a text CLIP feature
             <p>
              field on surfaces. We evaluate Uni-Fusion by comparing it
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat8_04">
             10:45-11:00, Paper WeAT8.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3779'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              BeautyMap: Binary-Encoded Adaptable Ground Matrix for Dynamic Points Removal in Global Maps
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#382519" title="Click to go to the Author Index">
             Jia, Mingkai
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#293956" title="Click to go to the Author Index">
             Zhang, Qingwen
            </a>
           </td>
           <td class="r">
            KTH Royal Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#289200" title="Click to go to the Author Index">
             Yang, Bowen
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology, Robotics Ins
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#217008" title="Click to go to the Author Index">
             Wu, Jin
            </a>
           </td>
           <td class="r">
            HKUST
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#125556" title="Click to go to the Author Index">
             Liu, Ming
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology (Guangzhou)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101846" title="Click to go to the Author Index">
             Jensfelt, Patric
            </a>
           </td>
           <td class="r">
            KTH - Royal Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3779" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Global point clouds that correctly represent the static environment features can facilitate accurate localization and robust path planning. However, dynamic objects introduce undesired 'ghost' tracks that are mixed up with the static environment. Existing dynamic removal methods normally fail to balance the performance in computational efficiency and accuracy. In response, we present 'BeautyMap' to efficiently remove the dynamic points while retaining static features for high-fidelity global maps. Our approach utilizes a binary-encoded matrix to efficiently extract the environment features. With a bit-wise comparison between matrices of each frame and the corresponding map region, we can extract potential dynamic regions. Then we use coarse to fine hierarchical segmentation of the z-axis to handle terrain variations. The final static restoration module accounts for the range-visibility of each single scan and protects static points out of sight. Comparative experiments underscore BeautyMap's superior performance in both accuracy and efficiency against other dynamic points removal methods. The code is open-sourced at https://github.com/MKJia/BeautyMap.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="weat9">
             <b>
              WeAT9
             </b>
            </a>
           </td>
           <td class="r">
            Room 9
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#weat9" title="Click to go to the Program at a Glance">
             <b>
              Task and Motion Planning I
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#142369" title="Click to go to the Author Index">
             Loianno, Giuseppe
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#217244" title="Click to go to the Author Index">
             Ornik, Melkior
            </a>
           </td>
           <td class="r">
            University of Illinois Urbana-Champaign
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat9_01">
             10:00-10:15, Paper WeAT9.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('87'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              E(2)-Equivariant Graph Planning for Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#330923" title="Click to go to the Author Index">
             Zhao, Linfeng
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#324814" title="Click to go to the Author Index">
             Li, Hongyu
            </a>
           </td>
           <td class="r">
            Brown University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#129456" title="Click to go to the Author Index">
             Padir, Taskin
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#239579" title="Click to go to the Author Index">
             Jiang, Huaizu
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#113403" title="Click to go to the Author Index">
             Wong, Lawson L.S.
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab87" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#integrated_planning_and_learning" title="Click to go to the Keyword Index">
               Integrated Planning and Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Learning for robot navigation presents a critical and challenging task. The scarcity and costliness of real-world datasets necessitate efficient learning approaches. In this letter, we exploit Euclidean symmetry in planning for 2D navigation, which originates from Euclidean transformations between reference frames and enables parameter sharing. To address the challenges of unstructured environments, we formulate the navigation problem as planning on a geometric graph and develop an equivariant message passing network to perform value iteration. Furthermore, to handle multi-camera input, we propose a learnable equivariant layer to lift features to a desired space. We conduct comprehensive evaluations across five diverse tasks encompassing structured and unstructured environments, along with maps of known and unknown, given point goals or semantic goals. Our experiments confirm the substantial benefits of training efficiency, stability, and generalization.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat9_02">
             10:15-10:30, Paper WeAT9.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('195'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Text2Reaction : Enabling Reactive Task Planning Using Large Language Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#371473" title="Click to go to the Author Index">
             Yang, Zejun
            </a>
           </td>
           <td class="r">
            University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#317477" title="Click to go to the Author Index">
             Ning, Li
            </a>
           </td>
           <td class="r">
            University of Chinese Academy of Science
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#277578" title="Click to go to the Author Index">
             Wang, Haitao
            </a>
           </td>
           <td class="r">
            University of Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376293" title="Click to go to the Author Index">
             Jiang, Tianyu
            </a>
           </td>
           <td class="r">
            Institute of Automation, Chinese Academy of Scienses
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#296973" title="Click to go to the Author Index">
             Zhang, Shaolin
            </a>
           </td>
           <td class="r">
            Institute of Automation, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#255090" title="Click to go to the Author Index">
             Cui, Shaowei
            </a>
           </td>
           <td class="r">
            Institute of Automation, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#160132" title="Click to go to the Author Index">
             Jiang, Hao
            </a>
           </td>
           <td class="r">
            Institute of Computing Technology, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#385858" title="Click to go to the Author Index">
             Li, Chunpeng
            </a>
           </td>
           <td class="r">
            University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102451" title="Click to go to the Author Index">
             Wang, Shuo
            </a>
           </td>
           <td class="r">
            Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#149649" title="Click to go to the Author Index">
             Wang, Zhaoqi
            </a>
           </td>
           <td class="r">
            Institute of Computing Technology, the Chinese Academy of Scienc
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab195" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#planning_under_uncertainty" title="Click to go to the Keyword Index">
               Planning under Uncertainty
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             To complete tasks in dynamic environments, robots need to timely update their plans to react to environment changes. Traditional stripe-like or learning-based planners struggle to achieve this due to their high reliance on meticulously predefined planning rules or labeled data. Fortunately, recent works find that Large Language Models (LLMs) can be effectively prompted to solve planning problems. Thus, we investigate the strategies for LLMs to master reactive planning problems without complex definitions and extra training. We propose Text2Reaction, an LLM-based framework enabling robots to continuously reason and update plans according to the latest environment changes. Inspired from human’s step-by-step re-planning process, we present the Re-planning Prompt, which informs LLMs the basic principles of replanning and fosters the gradual development of a current plan to a new one in a three-hop reasoning manner - cause analysis, consequence inference, and plan adjustment. Additionally, Text2Reaction is designed to first generate an initial plan based on the task description before execution, allowing for subsequent iterative updates of this plan. We demonstrate the superior performance of Text2Reaction over prior works in reacting to various environment changes and completing varied tasks. Additionally, we validate the reliability of our re-planning prompt through ablation experiments and its capability when deployed in real-world robots, enabling continuous reasoning in the face of diverse changes until the user instructions are successfully completed.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat9_03">
             10:30-10:45, Paper WeAT9.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('181'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Graph Neural Network for Decentralized Multi-Robot Goal Assignment
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#382693" title="Click to go to the Author Index">
             Goarin, Manohari
            </a>
           </td>
           <td class="r">
            New York University, Tandon School of Engineering
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#142369" title="Click to go to the Author Index">
             Loianno, Giuseppe
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab181" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#integrated_planning_and_learning" title="Click to go to the Keyword Index">
               Integrated Planning and Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The problem of assigning a set of spatial goals to a team of robots plays a crucial role in various multi-robot planning applications including, but not limited to exploration, search and rescue, or surveillance. The Linear Sum Assignment Problem (LSAP) is a common way of formulating and resolving this problem. This optimization problem aims at assigning the tasks to the robots minimizing the sum of costs while respecting a one-to-one matching constraint. However, communication restrictions in real-world scenarios pose significant challenges. Existing decentralized solutions often rely on numerous communication interactions to converge to a conflict-free and optimal solution or assume a prior conflict-free random assignment. In this paper, we propose a novel Decentralized Graph Neural Network approach for multi-robot Goal Assignment (DGNN-GA). We leverage a heterogeneous graph representation to model the inter-robot communication and the assignment relations between goals and robots. We compare in simulation its performance to other decentralized state-of-the-art approaches. Specifically, our method outperforms popular state-of-the art approaches in strictly restricted communication scenarios and does not rely on any initial conflict-free guess compared to two other algorithms. Finally, the DGNN-GA is also deployed and validated in real-world experiments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat9_04">
             10:45-11:00, Paper WeAT9.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3625'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Modular Multi-Level Replanning TAMP Framework for Dynamic Environment
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#370112" title="Click to go to the Author Index">
             Lin, Tao
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#381660" title="Click to go to the Author Index">
             Yue, Chengfei
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#381640" title="Click to go to the Author Index">
             Liu, Ziran
            </a>
           </td>
           <td class="r">
            Research Center of the Satellite Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#381642" title="Click to go to the Author Index">
             Cao, Xibin
            </a>
           </td>
           <td class="r">
            Research Center of the Satellite Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3625" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#task_planning" title="Click to go to the Keyword Index">
               Task Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Task and Motion Planning (TAMP) algorithms can generate plans that combine logic and motion aspects for robots. However, these plans are sensitive to interference and control errors. To make TAMP algorithms more applicable and robust in the real world, we propose the modular multi-level replanning TAMP framework (MMRF), expanded existing TAMP algorithms by combining real-time replanning components. MMRF generates a nominal plan from the initial state and then reconstructs this plan in real-time to reorder manipulations. Following the logic-level adjustment, MMRF attempts to replan a new motion path, ensuring that the updated plan is feasible at the motion level. Finally, we conducted several real-world experiments. The result demonstrated MMRF swiftly completing tasks in scenarios with moving obstacles and varying degrees of interference.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="weat10">
             <b>
              WeAT10
             </b>
            </a>
           </td>
           <td class="r">
            Room 10
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#weat10" title="Click to go to the Program at a Glance">
             <b>
              Vision-Based Navigation I
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#276733" title="Click to go to the Author Index">
             Yang, Tao
            </a>
           </td>
           <td class="r">
            Northwestern Polytechnical University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#138698" title="Click to go to the Author Index">
             Ehsan, Shoaib
            </a>
           </td>
           <td class="r">
            University of Essex
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat10_01">
             10:00-10:15, Paper WeAT10.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3628'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              RMSC-VIO: Robust Multi-Stereoscopic Visual-Inertial Odometry for Local Visually Challenging Scenarios
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#331867" title="Click to go to the Author Index">
             Zhang, Tong
            </a>
           </td>
           <td class="r">
            Northwestern Polytechnical University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#346392" title="Click to go to the Author Index">
             Xu, Jianyu
            </a>
           </td>
           <td class="r">
            Northwestern Polytechnical University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#346519" title="Click to go to the Author Index">
             Shen, Hao
            </a>
           </td>
           <td class="r">
            Northwestern Polytechnical University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#301174" title="Click to go to the Author Index">
             Yang, Rui
            </a>
           </td>
           <td class="r">
            Université De Technologie De Belfort Montbéliard
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#276733" title="Click to go to the Author Index">
             Yang, Tao
            </a>
           </td>
           <td class="r">
            Northwestern Polytechnical University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3628" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present a Multi-Stereoscopic Visual-Inertial Odometry (VIO) system capable of integrating an arbitrary number of stereo cameras, exhibiting excellent robustness in the face of visually challenging scenarios. During system initialization, we introduce multi-view keyframes for simultaneous processing of multiple image inputs and propose an adaptive feature selection method to alleviate the computational burden of multi-camera systems. This method iteratively updates the state information of visual features, filtering out high-quality image feature points and effectively reducing unnecessary redundancy consumption.In the backend phase, we propose an adaptive tightly coupled optimization method, assigning corresponding optimization weights based on the quality of different image feature points, effectively enhancing localization precision.We validate the effectiveness and robustness of our system through a series of datasets, encompassing various visually challenging scenarios and practical flight experiments. Our approach achieves up to a 90% reduction in Absolute Trajectory Error (ATE) compared to state-of-the-art multi-camera VIO methods.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat10_02">
             10:15-10:30, Paper WeAT10.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3742'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              LIVER: A Tightly Coupled LiDAR-Inertial-Visual State Estimator with High Robustness for Underground Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#382872" title="Click to go to the Author Index">
             Wen, Tianci
            </a>
           </td>
           <td class="r">
            Nankai University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#114198" title="Click to go to the Author Index">
             Fang, Yongchun
            </a>
           </td>
           <td class="r">
            Nankai University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#181761" title="Click to go to the Author Index">
             Lu, Biao
            </a>
           </td>
           <td class="r">
            Nankai University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#122338" title="Click to go to the Author Index">
             Zhang, Xuebo
            </a>
           </td>
           <td class="r">
            Nankai University,
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#145045" title="Click to go to the Author Index">
             Tang, Chaoquan
            </a>
           </td>
           <td class="r">
            China University of Mining and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3742" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we propose a tightly coupled LiDAR-inertial-visual (LIV) state estimator termed LIVER, which achieves robust and accurate localization and mapping in underground environments. LIVER starts with an effective strategy for LIV synchronization. A robust initialization process that integrates LiDAR, vision, and IMU is realized. A tightly coupled, nonlinear optimization-based method achieves highly accurate LiDAR-inertial-visual odometry (LIVO) by fusing LiDAR, visual, and IMU information. We consider scenarios in underground environments that are unfriendly to LiDAR and cameras. A visual-IMU-assisted method enables the evaluation and handling of LiDAR degeneracy. A deep neural network is introduced to eliminate the impact of poor lighting conditions on images. We verify the performance of the proposed method by comparing it with the state-of-the-art methods through public datasets and real-world experiments, including underground mines (see our attached video https://youtu.be/0wjXEz3K3ng). In underground mines test, tightly coupled methods without degeneracy handling lead to failure due to self-similar areas (affecting LiDAR) and poor lighting conditions (affecting vision). In these conditions, our degeneracy handling approach successfully eliminates the impact of disturbances on the system.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat10_03">
             10:30-10:45, Paper WeAT10.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('155'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Aggregating Multiple Bio-Inspired Image Region Classifiers for Effective and Lightweight Visual Place Recognition
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#310362" title="Click to go to the Author Index">
             Arcanjo, Bruno
            </a>
           </td>
           <td class="r">
            University of Essex
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#255103" title="Click to go to the Author Index">
             Ferrarini, Bruno
            </a>
           </td>
           <td class="r">
            Universtiy of Essex
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#385222" title="Click to go to the Author Index">
             Fasli, Maria
            </a>
           </td>
           <td class="r">
            University of Essex
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106848" title="Click to go to the Author Index">
             Milford, Michael J
            </a>
           </td>
           <td class="r">
            Queensland University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#159947" title="Click to go to the Author Index">
             McDonald-Maier, Klaus
            </a>
           </td>
           <td class="r">
            University of Essex
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#138698" title="Click to go to the Author Index">
             Ehsan, Shoaib
            </a>
           </td>
           <td class="r">
            University of Essex
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab155" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#bioinspired_robot_learning" title="Click to go to the Keyword Index">
               Bioinspired Robot Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Visual place recognition (VPR) enables autonomous systems to localize themselves within an environment using image information. While VPR techniques built upon a Convolutional Neural Network (CNN) backbone dominate state-of-the-art VPR performance, their high computational requirements make them unsuitable for platforms equipped with low-end hardware. Recently, a lightweight VPR system based on multiple bio-inspired classifiers, dubbed DrosoNets, has been proposed, achieving great computational efficiency at the cost of reduced absolute place retrieval performance. In this work, we propose a novel multi-DrosoNet localization system, dubbed RegionDrosoNet, with significantly improved VPR performance, while preserving a low-computational profile. Our approach relies on specializing distinct groups of DrosoNets on differently sliced partitions of the original images, increasing model differentiation. Furthermore, we introduce a novel voting module to combine the outputs of all DrosoNets into the final place prediction which considers multiple top reference candidates from each DrosoNet. RegionDrosoNet outperforms other lightweight VPR techniques when dealing with both appearance changes and viewpoint variations. Moreover, it competes with computationally expensive methods on some benchmark datasets at a small fraction of their online inference time.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat10_04">
             10:45-11:00, Paper WeAT10.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3664'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Design Space Exploration of Low-Bit Quantized Neural Networks for Visual Place Recognition
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#384586" title="Click to go to the Author Index">
             Grainge, Oliver Edward
            </a>
           </td>
           <td class="r">
            University of Southampton
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106848" title="Click to go to the Author Index">
             Milford, Michael J
            </a>
           </td>
           <td class="r">
            Queensland University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#303010" title="Click to go to the Author Index">
             Bodala, Indu
            </a>
           </td>
           <td class="r">
            University of Southampton
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#166478" title="Click to go to the Author Index">
             Ramchurn, Sarvapali
            </a>
           </td>
           <td class="r">
            University of Southampton
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#138698" title="Click to go to the Author Index">
             Ehsan, Shoaib
            </a>
           </td>
           <td class="r">
            University of Essex
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3664" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#recognition" title="Click to go to the Keyword Index">
               Recognition
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Visual Place Recognition (VPR) is a critical task for performing global re-localization in visual perception systems, requiring the ability to recognize a previously visited location under variations such as illumination, occlusion, appearance and viewpoint. In the case of robotics, the target devices for deployment are usually embedded systems. Therefore whilst the accuracy of VPR systems is important so too is memory consumption and latency. Recently new works have focused on the Recall@1 metric paying limited attention to resource utilization, resulting in methods that use complex models unsuitable for edge deployment. We hypothesize that these methods can be optimized to satisfy the constraints of low powered embedded systems whilst maintaining high recall performance. Our work studies the impact of compact architectural design in combination with full-precision and mixed-precision post-training quantization on VPR performance. Importantly we not only measure performance via the Recall@1 score but also measure memory consumption and latency. We characterize the design implications on memory, latency and recall scores and provide a number of design recommendations for VPR systems under these limitations.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="weat11">
             <b>
              WeAT11
             </b>
            </a>
           </td>
           <td class="r">
            Room 11
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#weat11" title="Click to go to the Program at a Glance">
             <b>
              Path Planning for Multiple Mobile Robots or Agents
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#180884" title="Click to go to the Author Index">
             Sartoretti, Guillaume Adrien
            </a>
           </td>
           <td class="r">
            National University of Singapore (NUS)
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat11_01">
             10:00-10:15, Paper WeAT11.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3744'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Collaborative Planning for Catching and Transporting Objects in Unstructured Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#334052" title="Click to go to the Author Index">
             Pei, Liuao
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#352845" title="Click to go to the Author Index">
             Lin, Junxiao
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#288141" title="Click to go to the Author Index">
             Han, Zhichao
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#283006" title="Click to go to the Author Index">
             Quan, Lun
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#178926" title="Click to go to the Author Index">
             Cao, Yanjun
            </a>
           </td>
           <td class="r">
            Zhejiang University, Huzhou Institute of Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#213352" title="Click to go to the Author Index">
             Xu, Chao
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#200893" title="Click to go to the Author Index">
             Gao, Fei
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3744" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Multi-robot teams have attracted attention from industry and academia for their ability to perform collaborative tasks in unstructured environments, such as wilderness rescue and collaborative transportation. In this paper, we propose a trajectory planning method for a non-holonomic robotic team with collaboration in unstructured environments. For the adaptive state collaboration of a robot team to catch and transport targets to be rescued using a net, we model the process of catching the falling target with a net in a continuous and differentiable form. This enables the robot team to fully exploit the kinematic potential, thereby adaptively catching the target in an appropriate state. Furthermore, the size safety and topological safety of the net, resulting from the collaborative support of the robots, are guaranteed through geometric constraints. We integrate our algorithm on a car-like robot team and test it in simulations and real-world experiments to validate our performance. Our method is compared to state-of-the-art multivehicle trajectory planning methods, demonstrating significant performance in efficiency and trajectory quality.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat11_02">
             10:15-10:30, Paper WeAT11.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A TSP-Based Online Algorithm for Multi-Task Multi-Agent Pickup and Delivery
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#343816" title="Click to go to the Author Index">
             Kudo, Fumiya
            </a>
           </td>
           <td class="r">
            Osaka Metropolitan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#166605" title="Click to go to the Author Index">
             Cai, Kai
            </a>
           </td>
           <td class="r">
            Osaka Metropolitan University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#discrete_event_dynamic_automation_systems" title="Click to go to the Keyword Index">
               Discrete Event Dynamic Automation Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The Multi-Agent Path Finding (MAPF) and its extension, Multi-Agent Pickup and Delivery (MAPD), have received much attention in academia. In industry, on the other hand, automatic control of teams of robots and AGVs on factory floors and logistic warehouses for pickup and delivery operations have also been studied intensively. Currently, MAPD problem formulation does not fully capture important aspects of many real-world industrial applications, e.g., MAPD allocates only one task at a time for each agent, payload capacity for each agent is ignored, and pickup &amp; dropoff operations are assumed to be done immediately. In this paper, we extend MAPD problem to a multi-task setting where each agent is allocated multiple tasks considering payload capacity as well as pickup &amp; dropoff cost. We propose an online multi-task MAPD algorithm which is a combination of MAPF and Traveling Salesman Problem (TSP) algorithm. Comparisons between the proposed and conventional MAPD show that the proposed MAPD is able to achieve 18% − 38% shorter makespan paths in wide range of agent numbers. We also examine the behavior of the proposed online multi-task MAPD by changing payload capacity distribution and pickup &amp; dropoff cost. Simulation results indicate that increase of pickup cost can largely increase the makespan when agent number is small; on the other hand, increase of dropoff cost tend to increase the makespan when agent number is large. Our empirical study also demonstrates that the proposed online multitask MAPD is applicable to large scale environment (e.g., agent number= 300) in an online manner.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat11_03">
             10:30-10:45, Paper WeAT11.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('11'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Motion Planning for Multiple Heterogeneous Magnetic Robots under Global Input (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#346926" title="Click to go to the Author Index">
             Asadi, Farshid
            </a>
           </td>
           <td class="r">
            Southern Methodist University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#151560" title="Click to go to the Author Index">
             Hurmuzlu, Yildirim
            </a>
           </td>
           <td class="r">
            Southern Methodist University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab11" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#underactuated_robots" title="Click to go to the Keyword Index">
               Underactuated Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#magnetic_actuatioin" title="Click to go to the Keyword Index">
               Magnetic Actuatioin
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Magnetism provides an untethered actuation mechanism and an alternative way to actuate robots. Using a magnetic field we can control the motion of robots embedded with magnets. This scales down the size of the robots dramatically such that they can be used in applications like drug delivery, sample collection, micromanipulation, and non-invasive procedures. Despite all advantages and potentials, magnetic actuation has one major drawback. Due to the similar interaction between the magnetic field and the embedded magnets in multi-robot systems, controlling the robots independently is challenging.
             <p>
              Using heterogeneous magnetic robots is one way to overcome the independent control challenge. Here, motion planning for multiple magnetic robots that move in parallel directions at different speeds in response to a global input is addressed in the absence of obstacles in a polygonal workspace. Through controllability analysis, it will be shown that having n linearly independent heterogeneous responses to the global input, called Modes of Motion here, enables independent position control of n robots in the system. Further, a procedure to have a potentially feasible sequen
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat11_04">
             10:45-11:00, Paper WeAT11.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('769'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Leadership Inference for Multi-Agent Interactions
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375850" title="Click to go to the Author Index">
             Khan, Hamzah
            </a>
           </td>
           <td class="r">
            The University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#190197" title="Click to go to the Author Index">
             Fridovich-Keil, David
            </a>
           </td>
           <td class="r">
            The University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab769" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#probabilistic_inference" title="Click to go to the Keyword Index">
               Probabilistic Inference
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Effectively predicting intent and behavior requires inferring leadership in multi-agent interactions. Dynamic games provide an expressive theoretical framework for modeling these interactions. Employing this framework, we propose a novel method to infer the leader in a two-agent game by observing the agents' behavior in complex, long-horizon interactions. We make two contributions. First, we introduce an iterative algorithm that solves dynamic two-agent Stackelberg games with nonlinear dynamics and nonquadratic costs, and demonstrate that it consistently converges in repeated trials. Second, we propose the Stackelberg Leadership Filter (SLF), an online method for identifying the leading agent in interactive scenarios based on observations of the game interactions. We validate the leadership filter's efficacy on simulated driving scenarios to demonstrate that the SLF can draw conclusions about leadership that match right-of-way expectations.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="weat12">
             <b>
              WeAT12
             </b>
            </a>
           </td>
           <td class="r">
            Room 12
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#weat12" title="Click to go to the Program at a Glance">
             <b>
              Reinforcement Learning I
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat12_01">
             10:00-10:15, Paper WeAT12.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('8'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning Whole-Body Manipulation for Quadrupedal Robot
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#296468" title="Click to go to the Author Index">
             Jeon, Seunghun
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#370046" title="Click to go to the Author Index">
             Jung, Moonkyu
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#345307" title="Click to go to the Author Index">
             Choi, Suyoung
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#160363" title="Click to go to the Author Index">
             Kim, Beomjoon
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#172467" title="Click to go to the Author Index">
             Hwangbo, Jemin
            </a>
           </td>
           <td class="r">
            Korean Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab8" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We propose a learning-based system for enabling quadrupedal robots to manipulate large, heavy objects using their whole body. Our system is based on a hierarchical control strategy that uses the deep latent variable embedding which captures manipulation-relevant information from interactions, proprioception, and action history, allowing the robot to implicitly understand object properties. We evaluate our framework in both simulation and real-world scenarios. In the simulation, it achieves a success rate of 93.6 % in accurately re-positioning and re-orienting various objects within a tolerance of 0.03 m and 5 ◦. Real-world experiments demonstrate the successful
             <p>
              manipulation of objects such as a 19.2 kg water-filled drum and a 15.3 kg plastic box filled with heavy objects while the robot weighs 27 kg. Unlike previous works that focus on manipulating small and light objects using prehensile manipulation, our framework illustrates the possibility of using quadrupeds for manipulating large and heavy objects that are ungraspable with the robot’s entire body. Our method does not require explicit object modeling and offers significant computational efficiency compared to optimization-based methods.
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat12_02">
             10:15-10:30, Paper WeAT12.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('58'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              OmniDrones: An Efficient and Flexible Platform for Reinforcement Learning in Drone Control
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372280" title="Click to go to the Author Index">
             Xu, Botian
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#243259" title="Click to go to the Author Index">
             Gao, Feng
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#267884" title="Click to go to the Author Index">
             Yu, Chao
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#380258" title="Click to go to the Author Index">
             Zhang, Ruize
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#239398" title="Click to go to the Author Index">
             Wu, Yi
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#236151" title="Click to go to the Author Index">
             Wang, Yu
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab58" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this work, we introduce OmniDrones, an efficient and flexible platform tailored for reinforcement learning in drone control, built on Nvidia’s Omniverse Isaac Sim. It employs a bottom-up design approach that allows users to easily design and experiment with various application scenarios on top of GPU-parallelized simulations. It also offers a range of benchmark tasks, presenting challenges ranging from single-drone hovering to over-actuated system tracking. In summary, we propose an open-sourced drone simulation platform, equipped with an extensive suite of tools for drone learning. It includes 4 drone models, 5 sensor modalities, 4 control modes, over 10 benchmark tasks, and a selection of widely used RL baselines. To showcase the capabilities of OmniDrones and to support future research, we also provide preliminary results on these benchmark tasks. We hope this platform will encourage further studies on applying RL to practical drone systems. For more resources including documentation and code, please visit: https://omnidrones.readthedocs.io/.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat12_03">
             10:30-10:45, Paper WeAT12.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('178'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Skill-Critic: Refining Learned Skills for Hierarchical Reinforcement Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#373301" title="Click to go to the Author Index">
             Hao, Ce
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#322047" title="Click to go to the Author Index">
             Weaver, Catherine
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#238358" title="Click to go to the Author Index">
             Tang, Chen
            </a>
           </td>
           <td class="r">
            University of California Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#224234" title="Click to go to the Author Index">
             Kawamoto, Kenta
            </a>
           </td>
           <td class="r">
            Sony Research Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100071" title="Click to go to the Author Index">
             Tomizuka, Masayoshi
            </a>
           </td>
           <td class="r">
            University of California
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#170266" title="Click to go to the Author Index">
             Zhan, Wei
            </a>
           </td>
           <td class="r">
            Univeristy of California, Berkeley
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab178" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#transfer_learning" title="Click to go to the Keyword Index">
               Transfer Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Hierarchical reinforcement learning (RL) can accelerate long-horizon decision-making by temporally abstracting a policy into multiple levels. Promising results in sparse reward environments have been seen with skills, i.e. sequences of primitive actions. Typically, a skill latent space and policy are discovered from offline data. However, the resulting low-level policy can be unreliable due to low-coverage demonstrations or distribution shifts. As a solution, we propose the Skill-Critic algorithm to fine-tune the low-level policy in conjunction with high-level skill selection. Our Skill-Critic algorithm optimizes both the low-level and high-level policies; these policies are initialized and regularized by the latent space learned from offline demonstrations to guide the parallel policy optimization. We validate Skill-Critic in multiple sparse-reward RL environments, including a new sparse-reward autonomous racing task in Gran Turismo Sport. The experiments show that Skill-Critic's low-level policy fine-tuning and demonstration-guided regularization are essential for good performance. Code and videos are available at our website: https://sites.google.com/view/skill-critic.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat12_04">
             10:45-11:00, Paper WeAT12.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('252'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Data-Efficient Task Generalization Via Probabilistic Model-Based Meta Reinforcement Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#368207" title="Click to go to the Author Index">
             Bhardwaj, Arjun
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#218792" title="Click to go to the Author Index">
             Rothfuss, Jonas
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#324290" title="Click to go to the Author Index">
             Sukhija, Bhavya
            </a>
           </td>
           <td class="r">
            ETH Zürich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#382376" title="Click to go to the Author Index">
             As, Yarden
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#114045" title="Click to go to the Author Index">
             Hutter, Marco
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#147028" title="Click to go to the Author Index">
             Coros, Stelian
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#115203" title="Click to go to the Author Index">
             Krause, Andreas
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab252" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#model_learning_for_control" title="Click to go to the Keyword Index">
               Model Learning for Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#learning_from_experience" title="Click to go to the Keyword Index">
               Learning from Experience
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We introduce PACOH-RL, a novel model-based Meta-Reinforcement Learning (Meta-RL) algorithm designed to efficiently adapt control policies to changing dynamics. PACOH-RL meta-learns priors for the dynamics model, allowing swift adaptation to new dynamics with minimal interaction data. Existing Meta-RL methods require abundant meta-learning data, limiting their applicability in settings such as robotics, where data is costly to obtain. To address this, PACOH-RL incorporates regularization and epistemic uncertainty quantification in both the meta-learning and task adaptation stages. When facing new dynamics, we use these uncertainty estimates to effectively guide exploration and data collection. Overall, this enables positive transfer, even when access to data from prior tasks or dynamic settings is severely limited. Our experiment results demonstrate that PACOH-RL outperforms model-based RL and model-based Meta-RL baselines in adapting to new dynamic conditions. Finally, on a real robotic car, we showcase the potential for efficient RL policy adaptation in diverse, data-scarce conditions.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="weat13">
             <b>
              WeAT13
             </b>
            </a>
           </td>
           <td class="r">
            Room 13
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#weat13" title="Click to go to the Program at a Glance">
             <b>
              Scientific Exploration
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#145544" title="Click to go to the Author Index">
             Sutoh, Masataku
            </a>
           </td>
           <td class="r">
            Japan Aerospace Exploration Agency
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#177811" title="Click to go to the Author Index">
             Kim, Pyojin
            </a>
           </td>
           <td class="r">
            Gwangju Institute of Science and Technology (GIST)
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat13_01">
             10:00-10:15, Paper WeAT13.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('44'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Transition Gradient from Standing to Traveling Waves for Energy-Efficient Slope Climbing of a Gecko-Inspired Robot
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#295993" title="Click to go to the Author Index">
             Haomachai, Worasuchad
            </a>
           </td>
           <td class="r">
            Nanjing University of Aeronautics and Astronautics
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#136571" title="Click to go to the Author Index">
             Dai, Zhendong
            </a>
           </td>
           <td class="r">
            Nanjing University of Aeronautics and Astronautics
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#120785" title="Click to go to the Author Index">
             Manoonpong, Poramate
            </a>
           </td>
           <td class="r">
            Vidyasirimedhi Institute of Science and Technology (VISTEC)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab44" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#climbing_robots" title="Click to go to the Keyword Index">
               Climbing Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#biomimetics" title="Click to go to the Keyword Index">
               Biomimetics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#biologically_inspired_robots" title="Click to go to the Keyword Index">
               Biologically-Inspired Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Lateral undulation patterns of a flexible spine, including standing waves, traveling waves, and their transitions, enable agile and versatile locomotion in sprawling animals. Inspired by this, we proposed body-wave transition strategies for energy-efficient inclined-surface climbing of a gecko-inspired robot with a bendable body. Using the robot as a scientific tool, we searched a large space of body movements (i.e., percentage of traveling waves and stride frequency) to explore climbing performance at different slope angles. Consequently, we designed a body-wave strategy to smoothly transition from a standing wave at low speeds to a traveling wave at high speeds to achieve energy-efficient climbing for each slope angle. Through a real robot experiment on the steepest slope (30 degrees), we demonstrated that the robot can reduce energy consumption by 7% compared to climbing with a constant-body movement owing to the transition gradient from standing to traveling waves with an optimal speed. To this end, our study can pave the way for the development of climbing robots that utilize multiple body movement patterns with smooth transitions. Moreover, it can make a valuable contribution to biologists by formulating a novel hypothesis concerning the energy efficiency of gecko climbing.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat13_02">
             10:15-10:30, Paper WeAT13.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3699'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Multi-Arm Robotic Platform for Scientific Exploration (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#161029" title="Click to go to the Author Index">
             Marques Marinho, Murilo
            </a>
           </td>
           <td class="r">
            The University of Manchester
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#243468" title="Click to go to the Author Index">
             Quiroz Omana, Juan Jose
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102000" title="Click to go to the Author Index">
             Harada, Kanako
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3699" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#robotics_and_automation_in_life_sciences" title="Click to go to the Keyword Index">
               Robotics and Automation in Life Sciences
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#software_hardware_integration_for_robot_systems" title="Click to go to the Keyword Index">
               Software-Hardware Integration for Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#kinematics" title="Click to go to the Keyword Index">
               Kinematics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             There are a large number of robotic platforms with two or more arms targeting surgical applications. Despite that, very few groups have employed such platforms for scientific exploration. Possible applications of a multi-arm platform in scientific exploration involve the study of the mechanisms of intractable diseases by using organoids (i.e., miniature human organs). The study of organoids requires the preparation of a cranial window which is done by carefully removing an 8 mm patch of the mouse skull. In this work, we present the first prototype of the AI robot science platform for scientific experimentation, its digital twins, and perform validation experiments under teleoperation. The experiments showcase the dexterity of the platform by performing peg transfer, gauze cutting, mock experiments using eggs, and the world's first four-hand teleoperated drilling for a cranial window. The digital twins and related control software are freely available for noncommercial use at https://AISciencePlatform.github.io.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat13_03">
             10:30-10:45, Paper WeAT13.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('131'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Astrobee ISS Free-Flyer Datasets for Space Intra-Vehicular Robot Navigation Research
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#334476" title="Click to go to the Author Index">
             Kang, Suyoung
            </a>
           </td>
           <td class="r">
            Sookmyung Women's University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#233386" title="Click to go to the Author Index">
             Soussan, Ryan
            </a>
           </td>
           <td class="r">
            Aerodyne Industries
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#334461" title="Click to go to the Author Index">
             Lee, Daekyeong
            </a>
           </td>
           <td class="r">
            Sookmyung Women University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#137355" title="Click to go to the Author Index">
             Coltin, Brian
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101835" title="Click to go to the Author Index">
             Mora, Andres
            </a>
           </td>
           <td class="r">
            NASA Ames Research Center
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#250846" title="Click to go to the Author Index">
             Moreira, Marina
            </a>
           </td>
           <td class="r">
            Instituto Superior Técnico, Lisbon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#151236" title="Click to go to the Author Index">
             Browne, Katie
            </a>
           </td>
           <td class="r">
            University of Nevada, Reno
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#354380" title="Click to go to the Author Index">
             Garcia Ruiz, Ruben
            </a>
           </td>
           <td class="r">
            KBR Inc, NASA Ames
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#354388" title="Click to go to the Author Index">
             Bualat, Maria
            </a>
           </td>
           <td class="r">
            NASA Ames Research Center
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106900" title="Click to go to the Author Index">
             Smith, Trey
            </a>
           </td>
           <td class="r">
            NASA Ames Research Center
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#354443" title="Click to go to the Author Index">
             Barlow, Jonathan
            </a>
           </td>
           <td class="r">
            KBR, Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#354387" title="Click to go to the Author Index">
             Benavides, Jose
            </a>
           </td>
           <td class="r">
            NASA
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#314296" title="Click to go to the Author Index">
             Jeong, Eunju
            </a>
           </td>
           <td class="r">
            Sookmyung Women's University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#177811" title="Click to go to the Author Index">
             Kim, Pyojin
            </a>
           </td>
           <td class="r">
            Gwangju Institute of Science and Technology (GIST)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab131" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#space_robotics_and_automation" title="Click to go to the Keyword Index">
               Space Robotics and Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_slam" title="Click to go to the Keyword Index">
               Data Sets for SLAM
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present the first annotated benchmark datasets for evaluating free-flyer visual-inertial localization and mapping algorithms in a zero-g spacecraft interior. The Astrobee free-flying robots that operate inside the International Space Station (ISS) collected the datasets. Space intra-vehicular free-flyers face unique localization challenges: their IMU does not provide a gravity vector, their attitude is fully arbitrary, and they operate in a dynamic, cluttered environment. We extensively evaluate state-of-the-art visual navigation algorithms on these challenging Astrobee datasets, showing superior performance of classical geometry-based methods over recent data-driven approaches. The datasets include monocular images and IMU measurements, with multiple sequences performing a variety of maneuvers and covering four ISS modules. The sensor data is spatio-temporally aligned, and extrinsic/intrinsic calibrations, ground-truth 6-DoF camera poses, and detailed 3D CAD models are included to support evaluation. The datasets are available at: https://astrobee-iss-dataset.github.io/.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat13_04">
             10:45-11:00, Paper WeAT13.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3653'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Transformable Nano Rover for Space Exploration
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#148000" title="Click to go to the Author Index">
             Hirano, Daichi
            </a>
           </td>
           <td class="r">
            Japan Aerospace Exploration Agency
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#256754" title="Click to go to the Author Index">
             Inazawa, Mariko
            </a>
           </td>
           <td class="r">
            Japan Aerospace Exploration Agency
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#145544" title="Click to go to the Author Index">
             Sutoh, Masataku
            </a>
           </td>
           <td class="r">
            Japan Aerospace Exploration Agency
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#143321" title="Click to go to the Author Index">
             Sawada, Hirotaka
            </a>
           </td>
           <td class="r">
            JAXA
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372015" title="Click to go to the Author Index">
             Kawai, Yuta
            </a>
           </td>
           <td class="r">
            Japan Aerospace Exploration Agency
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#370288" title="Click to go to the Author Index">
             Nagata, Masaharu
            </a>
           </td>
           <td class="r">
            Sony Group Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#370290" title="Click to go to the Author Index">
             Sakoda, Gen
            </a>
           </td>
           <td class="r">
            Sony Group Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#370263" title="Click to go to the Author Index">
             Yoneda, Yousuke
            </a>
           </td>
           <td class="r">
            TAKARATOMY
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#370039" title="Click to go to the Author Index">
             Watanabe, Kimitaka
            </a>
           </td>
           <td class="r">
            Doshisha University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3653" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#space_robotics_and_automation" title="Click to go to the Keyword Index">
               Space Robotics and Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#wheeled_robots" title="Click to go to the Keyword Index">
               Wheeled Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This letter introduces a novel nano rover designed to transform its shape for efficient movement on lunar surfaces. The rover, resembling a compact ball, has a diameter of roughly 80 mm and a mass around 250 g. Its transformational mechanism allows for compactness during planetary transportation, with enhanced mobility achieved through the use of extendable wheels, a tail stabilizer, and cameras. To traverse soft terrains efficiently, the rover utilizes an eccentric wheel mechanism, offering two distinct movement modes based on wheel synchronization. This mechanism provides a locomotion velocity of 20 mm/s or more on a flat surface. Moreover, it features onboard image processing to detect spacecraft shielded by Multi-Layer Insulation (MLI) films, facilitating autonomous control and selective image transmission. This rover has been deployed in a real space mission, having been mounted on a lunar lander. This letter presents the design specifics of this transformable rover and results from field tests simulating lunar conditions. These tests affirmed the efficacy of the proposed motion mechanism and onboard image processing.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="weat14">
             <b>
              WeAT14
             </b>
            </a>
           </td>
           <td class="r">
            Room 14
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#weat14" title="Click to go to the Program at a Glance">
             <b>
              Terrestrial Navigation
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#179428" title="Click to go to the Author Index">
             Karki, Hamad
            </a>
           </td>
           <td class="r">
            Khalifa University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat14_01">
             10:00-10:15, Paper WeAT14.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('24'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Horizontal Attention Based Generation Module for Unsupervised Domain Adaptive Stereo Matching
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#341363" title="Click to go to the Author Index">
             Wang, Sungjun
            </a>
           </td>
           <td class="r">
            DGIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#341364" title="Click to go to the Author Index">
             Seo, Junghyun
            </a>
           </td>
           <td class="r">
            DGIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#312114" title="Click to go to the Author Index">
             Jeon, Hyeonjae
            </a>
           </td>
           <td class="r">
            Daegu Gyeongbuk Institute of Science and Technology (DGIST)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#340162" title="Click to go to the Author Index">
             Lim, Sungjin
            </a>
           </td>
           <td class="r">
            Daegu Gyeongbuk Institute of Science and Technology (DGIST)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#210199" title="Click to go to the Author Index">
             Park, Sang Hyun
            </a>
           </td>
           <td class="r">
            DGIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#279782" title="Click to go to the Author Index">
             Lim, Yongseob
            </a>
           </td>
           <td class="r">
            DGIST
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab24" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The emergence of convolutional neural networks (CNNs) has led
             <p>
              to significant advancements in various computer vision tasks. Among them, stereo matching is one of the most important research areas that enables the reconstruction of depth and 3D information, which is difficult to obtain with only a monocular camera. However, CNNs have their limitations, particularly their susceptibility to domain shift. The CNN-based state-of-the-art stereo matching networks suffered from performance degradation under domain changes. Moreover, obtaining a significant amount of real-world ground truth data to address these issues is a laborious and costly task when compared to acquiring synthetic ground truth data. In this paper, we propose an end-to-end framework that utilizes image-to-image translation to overcome the domain gap in stereo matching. Specifically, we suggest a horizontal attentive generation (HAG) module that incorporates the epipolar constraint of contents when generating target-stylized left-right views. By employing a horizontal attention mechanism during generation process, our method can address the issues related to small receptive field by aggregating more information of each view without using the entire feature map. Therefore, our network can maintain consistencies between the left and right views during image generation process, making it more robust for different datasets.
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat14_02">
             10:15-10:30, Paper WeAT14.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3780'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              BeautyMap: Binary-Encoded Adaptable Ground Matrix for Dynamic Points Removal in Global Maps
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#382519" title="Click to go to the Author Index">
             Jia, Mingkai
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#293956" title="Click to go to the Author Index">
             Zhang, Qingwen
            </a>
           </td>
           <td class="r">
            KTH Royal Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#289200" title="Click to go to the Author Index">
             Yang, Bowen
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology, Robotics Ins
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#217008" title="Click to go to the Author Index">
             Wu, Jin
            </a>
           </td>
           <td class="r">
            HKUST
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#125556" title="Click to go to the Author Index">
             Liu, Ming
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology (Guangzhou)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101846" title="Click to go to the Author Index">
             Jensfelt, Patric
            </a>
           </td>
           <td class="r">
            KTH - Royal Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3780" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Global point clouds that correctly represent the static environment features can facilitate accurate localization and robust path planning.
             <p>
              However, dynamic objects introduce undesired `ghost' tracks that are mixed up with the static environment. Existing dynamic removal methods normally fail to balance the performance in computational efficiency and accuracy. In response, we present `BeautyMap' to efficiently remove the dynamic points while retaining static features for high-fidelity global maps. Our approach utilizes a binary-encoded matrix to efficiently extract the environment features. With a bit-wise
              <p>
               comparison between matrices of each frame and the corresponding map region, we can extract potential dynamic regions. Then we use coarse to
               <p>
                fine hierarchical segmentation of the z-axis to handle terrain variations. The final static restoration module accounts for the range-visibility of each single scan and protect static points out of sight. Comparative experiments underscore BeautyMap's superior performance in both accuracy and efficiency against other dynamic points removal methods. The code is open-sourced at https://github.com/HKUSTGZ-IADC/BeautyMap.
               </p>
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat14_03">
             10:30-10:45, Paper WeAT14.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3798'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Under-Canopy Navigation Using Aerial Lidar Maps
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#325276" title="Click to go to the Author Index">
             Carvalho de Lima, Lucas
            </a>
           </td>
           <td class="r">
            The University of Queensland
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#122930" title="Click to go to the Author Index">
             Lawrance, Nicholas
            </a>
           </td>
           <td class="r">
            CSIRO Data61
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#142007" title="Click to go to the Author Index">
             Khosoussi, Kasra
            </a>
           </td>
           <td class="r">
            The Commonwealth Scientific and Industrial Research (CSIRO)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#133626" title="Click to go to the Author Index">
             Borges, Paulo Vinicius Koerich
            </a>
           </td>
           <td class="r">
            CSIRO
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#115437" title="Click to go to the Author Index">
             Bruenig, Michael
            </a>
           </td>
           <td class="r">
            The University of Queensland
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3798" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#robotics_and_automation_in_agriculture_and_forestry" title="Click to go to the Keyword Index">
               Robotics and Automation in Agriculture and Forestry
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Autonomous navigation in unstructured natural environments poses a significant challenge. In goal navigation tasks without prior information, the limited look-ahead of onboard sensors utilised by robots compromises path efficiency. We propose a novel approach that leverages an above-the-canopy aerial map for improved ground robot navigation. Our system utilises aerial lidar scans to create a 3D probabilistic occupancy map, uniquely incorporating the uncertainty in the aerial vehicle’s trajectory for improved accuracy. Novel path planning cost functions are introduced, combining path length with obstruction risk estimated from the probabilistic map. The D* Lite algorithm then calculates an optimal (minimum-cost) path to the goal. This system also allows for dynamic replanning upon encountering unforeseen obstacles on the ground. Extensive experiments and ablation studies in simulated and real forests demonstrate the effectiveness of our system.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="webt1">
             <b>
              WeBT1
             </b>
            </a>
           </td>
           <td class="r">
            Room 1
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#webt1" title="Click to go to the Program at a Glance">
             <b>
              Best Industrial Robotics Research for Application Papers (Mujin Inc.)
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#102634" title="Click to go to the Author Index">
             Nakamura, Taro
            </a>
           </td>
           <td class="r">
            Chuo University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt1_01">
             11:00-11:15, Paper WeBT1.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1041'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Peristaltic Soft Robot for Long-Distance Pipe Inspection with an Endoskeletal Structure for Propulsion and Traction Amplification
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#369928" title="Click to go to the Author Index">
             Okuma, Ryusei
            </a>
           </td>
           <td class="r">
            Chuo University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#346369" title="Click to go to the Author Index">
             Naruse, Yuta
            </a>
           </td>
           <td class="r">
            Chuo University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#243005" title="Click to go to the Author Index">
             Ito, Fumio
            </a>
           </td>
           <td class="r">
            Chuo University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102634" title="Click to go to the Author Index">
             Nakamura, Taro
            </a>
           </td>
           <td class="r">
            Chuo University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1041" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#biologically_inspired_robots" title="Click to go to the Keyword Index">
               Biologically-Inspired Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This study proposed a peristaltic motion-type inspection robot equipped with a “linear antagonistic mechanism using artificial muscles with an endoskeletal structure” to amplify propulsion and traction. We sought to develop an in-pipe inspection robot for long, narrow, and complex pipes requiring large propulsion, traction, and flexibility. In a previous study, we proposed a linear antagonistic mechanism allowing the inspection robot to generate both high propulsion and traction along with flexibility in narrow pipes. The proposed mechanism consisted of two extension actuators and a gripping actuator sandwiched between these extension actuators. The large extension force by the extension actuators is distributed to both propulsion and traction. However, owing to the piston-shaped configuration of the extension actuators, the generated force decreased in a manner dependent on the cross-sectional area within narrow pipelines. Therefore, the in-pipe inspection robot took time to move in longdistance, small-diameter pipes with multiple bends. This paper describes a “linear antagonistic mechanism using artificial muscles with an endoskeletal structure” that amplifies propulsion and traction by inserting a tension spring (skeleton) inside the contraction actuators (artificial muscles) and utilizing the action force generated by the actuator and transmitted by the tension spring. In this study, the developed robot with an endoskeleton exhibited maximum propulsion of 60.2 N, surpassing its nonendoskeleton counterpart by a factor of 1.61. Furthermore, the robot equipped with the endoskeleton passed through an elbow pipe 1.29 times faster than that without the endoskeleton, reducing the time from 741 to 576 s. The function value that compares the propulsion and traction considering the effects of the applied pressure and pipe diameter required for long-distance inspection was more than 1.13 times that of the previous study. In addition, the non-dimensionalized traction was 1.55 times greater than that of any other pipe inspection robot, and the propulsion was large enough to pass through a bending pipe. This result indicates the feasibility of the developed robot for inspecting long, narrow, and complex pipes.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt1_02">
             11:15-11:30, Paper WeBT1.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2128'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Robust and Efficient Robotic Packing Pipeline with Dissipativity-Based Adaptive Impedance-Force Control
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#324234" title="Click to go to the Author Index">
             Zhou, Zhenning
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#310091" title="Click to go to the Author Index">
             Zhou, Lei
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397178" title="Click to go to the Author Index">
             Sun, Shengxin
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100760" title="Click to go to the Author Index">
             Ang Jr, Marcelo H
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2128" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#robust_adaptive_control" title="Click to go to the Keyword Index">
               Robust/Adaptive Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             For humans, dense bin packing heavily relies on force perception. However, current robotic packing studies only focus on the visual input or adopt auxiliary push-to-place actions to eliminate gaps, suffering from high time expenditure and poor robustness. To address such limitations, we first introduce a novel external force estimation method based on the generalized momentum observer, which can avoid the influence of joint acceleration noises and achieve real-time high-precision monitoring. Second, to obtain compliant interaction and fine robustness, an adaptive variable impedance policy is developed to track dynamic motion and desired force, and compensate for uncertainties. Meanwhile, we perform dissipativity analysis and a virtual energy supply function is augmented to the system for optimization, providing a solid foundation for stability. Third, we propose an efficient packing methodology with three subtasks by considering the distinct interaction and constraint states in different areas. Our packing strategies eliminate the need for subsequent auxiliary actions and are proven to enhance efficiency. We perform quantitative evaluations to verify our external force estimation method, conduct comparison studies with current packing methods, and investigate the contribution of our dissipativity-based adaptive controller. The superior results not only prove the robustness and efficiency of our pipeline, but also pave the way for practical applications of packing.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt1_03">
             11:30-11:45, Paper WeBT1.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2274'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Harnessing with Twisting: Single-Arm Deformable Linear Object Manipulation for Industrial Harnessing Task
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#278815" title="Click to go to the Author Index">
             Zhang, Xiang
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#195814" title="Click to go to the Author Index">
             Lin, Hsien-Chung
            </a>
           </td>
           <td class="r">
            FANUC Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#159605" title="Click to go to the Author Index">
             Zhao, Yu
            </a>
           </td>
           <td class="r">
            FANUC America Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100071" title="Click to go to the Author Index">
             Tomizuka, Masayoshi
            </a>
           </td>
           <td class="r">
            University of California
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2274" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#assembly" title="Click to go to the Keyword Index">
               Assembly
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#industrial_robots" title="Click to go to the Keyword Index">
               Industrial Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Wire-harnessing tasks pose great challenges to be automated by the robot due to the complex dynamics and unpredictable behavior of the deformable wire. Traditional methods, often reliant on dual-robot arms or tactile sensing, face limitations in adaptability, cost, and scalability. This paper introduces a novel single-robot wire-harnessing pipeline that leverages a robot's twisting motion to generate necessary wire tension for precise insertion into clamps, using only one robot arm with an integrated force/torque (F/T) sensor. Benefiting from this design, the single robot arm can efficiently apply tension for wire routing and insertion into clamps in a narrow space. Our approach is structured around four principal components: a Model Predictive Control (MPC) based on the Koopman operator for tension tracking and wire following, a motion planner for sequencing harnessing waypoints, a suite of insertion primitives for clamp engagement, and a fix-point switching mechanism for wire constraint updating. Evaluated on an industrial-level wire harnessing task, our method demonstrated superior performance and reliability over conventional approaches, efficiently handling both single and multiple wire configurations with high success rates.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt1_04">
             11:45-12:00, Paper WeBT1.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2822'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Beyond Feasibility: Efficiently Planning Robotic Assembly Sequences That Minimize Assembly Path Lengths
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#238984" title="Click to go to the Author Index">
             Cebulla, Alexander
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology (KIT)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102922" title="Click to go to the Author Index">
             Asfour, Tamim
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology (KIT)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#109688" title="Click to go to the Author Index">
             Kroeger, Torsten
            </a>
           </td>
           <td class="r">
            Intrinsic Innovation LLC
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2822" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#assembly" title="Click to go to the Keyword Index">
               Assembly
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#intelligent_and_flexible_manufacturing" title="Click to go to the Keyword Index">
               Intelligent and Flexible Manufacturing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Advancements in Industry 4.0 demand sophisticated solutions for automatic robotic assembly sequence planning (RASP), capable of handling the diversity and complexity of modern manufacturing tasks. One approach to RASP is Assembly-by-Disassembly (AbD). It first searches for a disassembly sequence that is then inverted to obtain an assembly sequence. One of the challenges of AbD, however, is the exponential number of potential assembly sequences for any given assembly. To mitigate this challenge, we propose to transfer knowledge obtained during previous planning attempts. Specifically, we present an approach that combines Monte Carlo Tree Search (MCTS) with deep Q-learning to optimize the total length of robotic assembly paths. We use a graph-based representation of disassembly states in combination with a graph neural network to learn the Q-function. We further discuss a principled approach to generate 3D~assemblies out of aluminium profiles that a single robot manipulator can assemble. With this approach, we generated two datasets consisting of 14 assemblies with 21 removable parts and 7 assemblies with 30 removable parts. Using leave-one-out cross-validation, we were able to demonstrate how our approach outperformed an unmodified MCTS. Moreover, we successfully transferred knowledge between datasets.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="webt2">
             <b>
              WeBT2
             </b>
            </a>
           </td>
           <td class="r">
            Room 2
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#webt2" title="Click to go to the Program at a Glance">
             <b>
              Best Robot Mechanisms and Design Papers (ROBOTIS)
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt2_01">
             11:00-11:15, Paper WeBT2.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3148'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Novel Vitreoretinal Surgical Robot System to Maximize the Internal Reachable Workspace and Minimize the External Link Motion
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#347142" title="Click to go to the Author Index">
             Jeong, Gowoon
            </a>
           </td>
           <td class="r">
            Chonnam National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#118341" title="Click to go to the Author Index">
             Ko, Seong Young
            </a>
           </td>
           <td class="r">
            Chonnam National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3148" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#surgical_robotics__steerable_catheters_needles" title="Click to go to the Keyword Index">
               Surgical Robotics: Steerable Catheters/Needles
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a novel robotic system designed for efficient minimally invasive eye surgery. The proposed prototype integrates a concentric tube mechanism(CTM) and a belt-driven remote center of motion(RCM) mechanism, aiming to maximize the internal reachable workspace while minimizing external robot movements. The integrated system provides several advantages, including preventing collisions between surgical tools and the lens, minimizing sclera stress, and having efficient robot motion inside and outside the eyeball. It provides sufficient link motions with roll and pitch angles of ±32° and ±85° respectively at the RCM point, allowing access to 89% of the retina. The experiment evaluates the system's performance, with the RCM point accuracy at 0.718mm, CTM position accuracy at 207 µm, and a repeatability error of 246 µm. To reduce hysteresis errors at the RCM point caused by the belt, a lever-based belt tensioner is used for initial calibration while an optical tracking system tracks each joint’s movement. Targeting experiments highlight that the wider workspace was achieved by the CTM+RCM system compared to the traditional RCM mechanism with a straight tool. The results showed the system's compactness, efficiency, and dexterity, confirming its feasibility and potential for the proposed eye surgery robot.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt2_02">
             11:15-11:30, Paper WeBT2.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2814'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Multistable Soft Actuator for Physical Human-Robot Interaction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#319124" title="Click to go to the Author Index">
             Long, Juncai
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#214365" title="Click to go to the Author Index">
             Li, Jituo
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#386378" title="Click to go to the Author Index">
             Diao, Xiaojie
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#319123" title="Click to go to the Author Index">
             Zhou, Chengdi
            </a>
           </td>
           <td class="r">
            ZheJiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#193514" title="Click to go to the Author Index">
             Lu, GuoDong
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#208454" title="Click to go to the Author Index">
             Feng, Yixiong
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2814" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#physical_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical Human-Robot Interaction
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#haptics_and_haptic_interfaces" title="Click to go to the Keyword Index">
               Haptics and Haptic Interfaces
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Collaboration with robots through physical contact offers a more intuitive, natural, and engaging operational experience, showcasing vast potential in the field of human-robot interaction. However, current physical interaction devices, such as collaborative robots and haptic feedback mechanisms, are limited by their singular modes of motion and feedback, hindering enhancements in interaction experiences. Herein, we present a multistable soft actuator capable of driving multimodal shape changes and passively conforming to user touch. This actuator can memorizes and maintains any deformation with zero power consumption. Its structural mechanical properties can be dynamically adjusted to produce a rich haptic feedback for the user, including changes in shape, elasticity, stiffness, and even sensations of rupture and weightlessness. Structurally, the mechanism consists of a network of pneumatic bistable units in series and parallel configurations, which can switch states under air pressure or external force, achieving extension, contraction, and omnidirectional bending. The input of air pressure can either impede or assist deformation, altering structural stiffness and resulting in varied loading curves. With its high safety in physical interactions, robust operability, and rich mechanical tactile feedback, the multistable soft actuator promises new design directions for physical human-robot interaction devices.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt2_03">
             11:30-11:45, Paper WeBT2.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('765'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Development of a Compact Robust Passive Transformable Omni-Ball for Enhanced Step-Climbing and Vibration Reduction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#117997" title="Click to go to the Author Index">
             Hongo, Kazuo
            </a>
           </td>
           <td class="r">
            Sony Group Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#131982" title="Click to go to the Author Index">
             Kito, Takashi
            </a>
           </td>
           <td class="r">
            Sony Group Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#116464" title="Click to go to the Author Index">
             Kamikawa, Yasuhisa
            </a>
           </td>
           <td class="r">
            Sony Group Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#295379" title="Click to go to the Author Index">
             Kinoshita, Masaya
            </a>
           </td>
           <td class="r">
            Sony Group Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#113926" title="Click to go to the Author Index">
             Kawanami, Yasunori
            </a>
           </td>
           <td class="r">
            Sony Group Corporation
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab765" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#wheeled_robots" title="Click to go to the Keyword Index">
               Wheeled Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper introduces the Passive Transformable Omni-Ball (PTOB), an advanced omnidirectional wheel engineered to enhance step-climbing performance, incorporate built-in actuators, diminish vibrations, and fortify structural integrity. By modifying the omni-ball's structure from two to three segments, we have achieved improved in-wheel actuation and a reduction in vibrational feedback. Additionally, we have implemented a sliding mechanism in the follower wheels to boost the wheel's step-climbing abilities. A prototype with a 127 mm diameter PTOB was constructed, which confirmed its functionality for omnidirectional movement and internal actuation. Compared to a traditional omni-wheel, the PTOB demonstrated a comparable level of vibration while offering superior capabilities. Extensive testing in varied settings showed that the PTOB can adeptly handle step obstacles up to 45 mm, equivalent to 35% of the wheel's diameter, in both the forward and lateral directions. The PTOB showcased robust construction and proved to be versatile in navigating through environments with diverse obstacles.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt2_04">
             11:45-12:00, Paper WeBT2.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1250'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              BaRiFlex: A Robotic Gripper with Versatility and Collision Robustness for Robot Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#221444" title="Click to go to the Author Index">
             Jeong, Gu-Cheol
            </a>
           </td>
           <td class="r">
            University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#248809" title="Click to go to the Author Index">
             Bahety, Arpit
            </a>
           </td>
           <td class="r">
            Columbia University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#378273" title="Click to go to the Author Index">
             Pedraza, Gabriel
            </a>
           </td>
           <td class="r">
            The University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106060" title="Click to go to the Author Index">
             Deshpande, Ashish
            </a>
           </td>
           <td class="r">
            The University of Texas
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#142950" title="Click to go to the Author Index">
             Martín-Martín, Roberto
            </a>
           </td>
           <td class="r">
            University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1250" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#compliant_joints_and_mechanisms" title="Click to go to the Keyword Index">
               Compliant Joints and Mechanisms
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present a new approach to robot hand design specifically suited to enable robot learning methods and daily tasks in human environments. We introduce BaRiFlex, an innovative gripper design that alleviates the issues caused by unexpected contact and collisions during robot learning, offering collision mitigation, grasping versatility, task versatility, and simplicity to the learning processes. This achievement is enabled by the incorporation of low-inertia actuators, providing high Back-drivability, and the strategic combination of Rigid and Flexible materials which enhances versatility and the gripper’s resilience against unpredicted collisions. Furthermore, the integration of flexible Fin-Ray and rigid linkages allows the gripper to execute compliant grasping and precise pinching. We conducted rigorous performance tests to characterize the novel gripper’s compliance, durability, grasping and task versatility, and precision. We also integrated the BaRiFlex with a 7 Degree of Freedom (DoF) Franka Emika’s Panda robotic arm to evaluate its capacity to support a trial-and-error (reinforcement learning) training procedure. The results of our experimental study are then compared to those obtained using the original rigid Franka Hand and a reference Fin-Ray soft gripper, demonstrating the superior capabilities and advantages of our developed gripper system. More information and videos at https://robin-lab.cs.utexas.edu/bariflex
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="webt3">
             <b>
              WeBT3
             </b>
            </a>
           </td>
           <td class="r">
            Room 3
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#webt3" title="Click to go to the Program at a Glance">
             <b>
              Manipulation and Grasping II
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#106618" title="Click to go to the Author Index">
             Tzes, Anthony
            </a>
           </td>
           <td class="r">
            New York University Abu Dhabi
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#108037" title="Click to go to the Author Index">
             Khorrami, Farshad
            </a>
           </td>
           <td class="r">
            New York University Tandon School of Engineering
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt3_01">
             11:00-11:15, Paper WeBT3.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3680'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              On the Generality and Application of Mason’s Voting Theorem to Center of Mass Estimation for Pure Translational Motion (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#281206" title="Click to go to the Author Index">
             Gao, Ziyan
            </a>
           </td>
           <td class="r">
            Japan Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103897" title="Click to go to the Author Index">
             Elibol, Armagan
            </a>
           </td>
           <td class="r">
            Forschungszentrum Jülich GmbH
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102527" title="Click to go to the Author Index">
             Chong, Nak Young
            </a>
           </td>
           <td class="r">
            Japan Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3680" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#non_prehensile_manipulation" title="Click to go to the Keyword Index">
               Non-prehensile Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#calibration_and_identification" title="Click to go to the Keyword Index">
               Calibration and Identification
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#foundations_of_automation" title="Click to go to the Keyword Index">
               Foundations of Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Object rearrangement is widely demanded in many of the manipulation tasks performed by industrial and service robots. Rearranging an object through planar pushing is deemed energy efficient and safer compared with the pick-and-place operation. However, due to the unknown physical properties of the object, re-arranging an object toward the target position is difficult to accomplish. Even though robots can benefit from multi-modal sensory data for estimating novel object dynamics, the exact estimation error bound is still unknown. In this work, firstly, we demonstrate a way to obtain an error bound on the center of mass (CoM) estimation for the novel object only using a position-controlled robot arm and a vision sensor. Specifically, we extend Mason's Voting Theorem (MVT) to object CoM estimation in the absence of accurate information on friction and object shape. The probable CoM locations are monotonously narrowed down to a convex region, and the Extended Voting Theorems (EVT's) guarantee that the convex region contains the CoM ground truth in the presence of contact normal estimation error and pushing execution error. For the object translation task, existing methods generally assume that the pusher-object system’s physical properties and full-state feedback are available, or utilize iterative pushing executions, which limits the application of planar pushing to real-world settings. In this work, assuming a nominal friction coefficient between the pusher and object through contact normal error bound analysis, we leverage the estimated convex region and the Zero Moment Two Edge Pushing (ZMTEP) method to select the contact configurations for object pure translation. It is ensured that the selected contact configurations are capable of tolerating the CoM estimation error. The experimental results show that the object can be accurately translated to the target position with only two controlled pushes at most.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt3_02">
             11:15-11:30, Paper WeBT3.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3771'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Probabilistic Closed-Loop Active Grasping
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#331611" title="Click to go to the Author Index">
             Schaub, Henry
            </a>
           </td>
           <td class="r">
            Hochschule Muenchen University of Applied Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#357064" title="Click to go to the Author Index">
             Wolff, Christian
            </a>
           </td>
           <td class="r">
            University of Regensburg
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#331659" title="Click to go to the Author Index">
             Hoh, Maximilian
            </a>
           </td>
           <td class="r">
            University of Applied Sciences Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#331812" title="Click to go to the Author Index">
             Schöttl, Alfred
            </a>
           </td>
           <td class="r">
            University of Applied Sciences Munich, Dept. for Electrical Engi
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3771" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Picking a specific object is an essential task of assistive robotics. While the majority of grasp detection approaches focus on grasp synthesis from a single depth image or point cloud, this approach is often not viable in an unstructured, uncontrolled environment. Due to occlusion, heavy influence of noise or simply because no collision-free grasp is visible from some perspectives, it is beneficial to collect additional information from other views before opting for grasp execution. We present a closed-loop approach that selects and navigates towards the next-best-view by minimizing the entropy of the volume under consideration. We use a local measure of estimation uncertainty of the surface reconstruction, to sample grasps and estimate their success probabilities in an online fashion. Our experiments show that our algorithm achieves better grasp success rates than comparable approaches, when presented with challenging household objects.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt3_03">
             11:30-11:45, Paper WeBT3.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3777'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Pre-Grasp Approaching on Mobile Robots: A Pre-Active Layered Approach
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#236330" title="Click to go to the Author Index">
             Naik, Lakshadeep
            </a>
           </td>
           <td class="r">
            University of Southern Denmark (SDU)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103855" title="Click to go to the Author Index">
             Kalkan, Sinan
            </a>
           </td>
           <td class="r">
            Middle East Technical University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#113951" title="Click to go to the Author Index">
             Krüger, Norbert
            </a>
           </td>
           <td class="r">
            University of Southern Denmark
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3777" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#mobile_manipulation" title="Click to go to the Keyword Index">
               Mobile Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In Mobile Manipulation (MM), navigation and manipulation are generally solved as subsequent disjoint tasks. Combined optimization of navigation and manipulation costs can improve the time efficiency of MM. However, this is challenging as precise object pose estimates, which are necessary for such combined optimization, are often not available until the later stages of MM. Moreover, optimizing navigation and manipulation costs with conventional planning methods using uncertain object pose estimates can lead to failures and hence requires re-planning. Hence, in the presence of object pose uncertainty, pre-active approaches are preferred.
             <p>
              We propose such a pre-active approach for determining the base pose and pre-grasp manipulator configuration to improve the time efficiency of MM. We devise a Reinforcement Learning (RL) based solution that learns suitable base poses for grasping and pre-grasp manipulator configurations using layered learning that guides exploration and enables sample-efficient learning. Further, we accelerate learning of pre-grasp manipulator configurations by providing dense rewards using a predictor network trained on previously learned base poses for grasping. Our experiments validate that in the presence of uncertain object pose estimates, the proposed approach results in reduced execution time. Finally, we show that our policy learned in simulation can be easily transferred to a real robot. The code repository and the supplementary video can be found on the project webpage*.
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt3_04">
             11:45-12:00, Paper WeBT3.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3767'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Smooth Distances for Second Order Kinematic Robot Control (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#132242" title="Click to go to the Author Index">
             Gonçalves, Vinicius Mariano
            </a>
           </td>
           <td class="r">
            New York University Abu Dhabi, United Arab Emirates
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106618" title="Click to go to the Author Index">
             Tzes, Anthony
            </a>
           </td>
           <td class="r">
            New York University Abu Dhabi
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#108037" title="Click to go to the Author Index">
             Khorrami, Farshad
            </a>
           </td>
           <td class="r">
            New York University Tandon School of Engineering
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#111714" title="Click to go to the Author Index">
             Fraisse, Philippe
            </a>
           </td>
           <td class="r">
            LIRMM
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3767" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_control_of_manipulators" title="Click to go to the Keyword Index">
               Motion Control of Manipulators
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#obstacle_avoidance" title="Click to go to the Keyword Index">
               Obstacle Avoidance
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#kinematics" title="Click to go to the Keyword Index">
               Kinematics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we propose an algorithm for computing a smoothed version of the distance between two objects. As opposed to the traditional Euclidean distance between two objects, which may not be differentiable, this smoothed distance is guaranteed to be differentiable. Differentiability is an important property in many applications, in particular in robotics, in which obstacle-avoidance schemes often rely on the derivative/Jacobian of the distance between two objects. We prove mathematical properties of this smoothed distance and of the algorithm for computing it, and show its applicability in robotics by applying it to a second order kinematic control framework, also proposed in this paper. The control framework using smooth distances was successfully implemented on a 7 DOF manipulator.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="webt4">
             <b>
              WeBT4
             </b>
            </a>
           </td>
           <td class="r">
            Room 4
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#webt4" title="Click to go to the Program at a Glance">
             <b>
              Soft Robot Materials and Design II
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#190813" title="Click to go to the Author Index">
             Nabae, Hiroyuki
            </a>
           </td>
           <td class="r">
            Tokyo Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#103313" title="Click to go to the Author Index">
             Wakimoto, Shuichi
            </a>
           </td>
           <td class="r">
            Okayama University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt4_01">
             11:00-11:15, Paper WeBT4.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('96'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Nitinol-Embedded Wearable Soft Robotic Gripper for Deep-Sea Manipulation (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#366382" title="Click to go to the Author Index">
             Zuo, Zonghao
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#366432" title="Click to go to the Author Index">
             He, Xia
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#366431" title="Click to go to the Author Index">
             Wang, Haoxuan
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#284127" title="Click to go to the Author Index">
             Shao, Zhuyin
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#239957" title="Click to go to the Author Index">
             Liu, Jiaqi
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#366606" title="Click to go to the Author Index">
             Zhang, Qiyi
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#271037" title="Click to go to the Author Index">
             Pan, Fei
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#128250" title="Click to go to the Author Index">
             Wen, Li
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab96" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#marine_robotics" title="Click to go to the Keyword Index">
               Marine Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Soft robotic gripper systems that can safely and nondestructively collect deep-sea biological samples, artifact samples and perform deep-sea manipulation tasks are essential for deep-sea science and engineering applications. In this paper, we implemented a soft robotic gripper composed of nitinol-embedded soft fingers and an in-situ wearable mechanism that allows the soft gripper to be put on and removed from the traditional rigid gripper according to the deep-sea tasks. We apply finite element simulation to investigate the influence of nitinol wires’ diameter on the soft finger and then examine the strength and grasping ability. The results indicate that the soft gripper's maximum horizontal and maximum vertical pulling force can reach 75.5N and 135.7N, respectively. We show that the gripper can perform nondestructive sampling tasks, including picking and placing fragile porcelain and operating a precision instrument at a depth range of 1410m to 3600m by a human-crewed deep-sea submersible (Deep Sea Warrior). The results from this study may provide new design insights into the creation of next-generation deep-sea intelligent robotic systems that can perform dexterous manipulation.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt4_02">
             11:15-11:30, Paper WeBT4.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('62'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Novel Hybrid Variable Stiffness Mechanism: Synergistic Integration of Layer Jamming and Shape Memory Polymer
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#316441" title="Click to go to the Author Index">
             Yu, WenKai
            </a>
           </td>
           <td class="r">
            Department of Mechanics and Aerospace Engineering, Southern Univ
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#352045" title="Click to go to the Author Index">
             Liu, Jingyi
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#316440" title="Click to go to the Author Index">
             Li, Xin
            </a>
           </td>
           <td class="r">
            Department of Mechanics and Aerospace Engineering, Southern Univ
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#352702" title="Click to go to the Author Index">
             Yu, Ziyue
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#316433" title="Click to go to the Author Index">
             Yuan, Hongyan
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab62" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Soft robots have garnered considerable attention recently due to their versatility, compliance, and myriad applications. However, the inherent low stiffness of soft robots also limits their stability and force output capability. Hence, variable stiffness technology has emerged as a solution, which enables soft robots to modulate stiffness according to the application scenario. Two primary methods have been developed to regulate stiffness: material phase transition (MPT) based method and geometric reconfiguration (GR) based method. However, these approaches have not achieved miniaturization while maintaining a wide range of stiffness change. This work introduces a novel hybrid variable stiffness (HVS) concept that combines the MPT-based and GR-based variable stiffness methods for the first time. Specially, the HVS structure leverages shape memory polymer (SMP) method and layer jamming (LJ) to get a simultaneous response. Bending tests reveal that the compact bi-layer designed HVS structure can achieve a wide stiffness range (0.31 N/mm ~ 4.86 N/mm, 15.7 times) and load-bearing capacity (1.76 N~ 28.1 N, 16.0 times), which has been simulated by finite element analysis. Response tests show that the jamming response is rapid (~ms) while the maximum heating rate is 2.77 ± 0.16 °C/s, indicating that the HVS structure can achieve a relatively fast response. Furthermore, a soft gripper equipped with the HVS structure is developed to illustrate the enhanced grasping ability. Several performed grasping tests reveal that the variable stiffness soft gripper can grasp various objects with diverse shapes (40.0 mm ~ 190 mm, 4.75 times) and materials while lifting a weight up to 650 g, which provides an effective solution for the complex application requirements of soft robots.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt4_03">
             11:30-11:45, Paper WeBT4.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3657'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Soft Crawling Robot That Can Self-Repair Material Removal and Deep Lengthwise Cuts, Actuated by Thin McKibben Muscles
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#384910" title="Click to go to the Author Index">
             Xie, Mengfei
            </a>
           </td>
           <td class="r">
            Tokyo Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#275132" title="Click to go to the Author Index">
             Feng, Yunhao
            </a>
           </td>
           <td class="r">
            Tokyo Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#190813" title="Click to go to the Author Index">
             Nabae, Hiroyuki
            </a>
           </td>
           <td class="r">
            Tokyo Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100766" title="Click to go to the Author Index">
             Suzumori, Koichi
            </a>
           </td>
           <td class="r">
            Tokyo Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3657" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Soft robots are prone to damage when they come into contact with sharp objects, decreasing their functionality. Self-repairing soft robots have great potential to restore their functionality after the damage has been repaired. However, for some damages where it is difficult to reconnect the cut surfaces, existing self-repairing soft robots often require external intervention to establish contact between the cut surfaces and achieve recovery. This paper proposes a novel self-repairing soft robot composed of thin McKibben muscles and self-healing materials. Experimental validation and mathematical model analysis have demonstrated that this robot can self-repair the damage on hard-to-reconnect cut surfaces, such as material removal and deep lengthwise cuts, by actuating the Thin McKibben muscles in the designed sequence. Furthermore, experimental evidence through bending and crawling confirms that this robot exhibits robust self-repair properties. This recovery process can be achieved without external intervention and shows potential to be extrapolated to other systems.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt4_04">
             11:45-12:00, Paper WeBT4.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3700'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Experimental Validation of a 7-DOF Power Soft Robot Driven by Hydraulic Artificial Muscles
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#275132" title="Click to go to the Author Index">
             Feng, Yunhao
            </a>
           </td>
           <td class="r">
            Tokyo Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#208273" title="Click to go to the Author Index">
             Ide, Tohru
            </a>
           </td>
           <td class="r">
            Tokyo Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#190813" title="Click to go to the Author Index">
             Nabae, Hiroyuki
            </a>
           </td>
           <td class="r">
            Tokyo Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#107755" title="Click to go to the Author Index">
             Endo, Gen
            </a>
           </td>
           <td class="r">
            Tokyo Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#245319" title="Click to go to the Author Index">
             Sakurai, Ryo
            </a>
           </td>
           <td class="r">
            Bridgestone Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#253871" title="Click to go to the Author Index">
             Ohno, Shingo
            </a>
           </td>
           <td class="r">
            Bridgestone Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100766" title="Click to go to the Author Index">
             Suzumori, Koichi
            </a>
           </td>
           <td class="r">
            Tokyo Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3700" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#hydraulic_pneumatic_actuators" title="Click to go to the Keyword Index">
               Hydraulic/Pneumatic Actuators
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Hydraulic artificial muscles offer superior performance compared to most pneumatic artificial muscles, but their suitability in multi-DOF robotics remains unverified. We fabricated a 7-DOF power soft robot spanning over 1.5 m using 29 McKibben hydraulic artificial muscles. We analyzed the proposed robot's workspace, payload capacity, and compliance based on the properties of the hydraulic muscles and conducted several validation experiments. The robot successfully handled a payload of more than 25 kg at a maximum pressure of 5.0 MPa and exhibited passive compliance ranging from 0.5 to 2.0 mm/N with valves fully closed. Furthermore, the robot demonstrated strong impact resistance and successfully performed tasks such as concrete chipping. These results demonstrate the capability of muscle-driven robots to perform diverse tasks in a range of industrial environments.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="webt5">
             <b>
              WeBT5
             </b>
            </a>
           </td>
           <td class="r">
            Room 5
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#webt5" title="Click to go to the Program at a Glance">
             <b>
              Robust and Adaptive Control I
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#198353" title="Click to go to the Author Index">
             Kumar, Shivesh
            </a>
           </td>
           <td class="r">
            DFKI GmbH
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#129946" title="Click to go to the Author Index">
             Monje, Concepción A.
            </a>
           </td>
           <td class="r">
            University Carlos III of Madrid
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt5_01">
             11:00-11:15, Paper WeBT5.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3768'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Hierarchical Incremental MPC for Redundant Robots: A Robust and Singularity-Free Approach (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#280558" title="Click to go to the Author Index">
             Wang, Yongchao
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#319836" title="Click to go to the Author Index">
             Liu, Yang
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#115801" title="Click to go to the Author Index">
             Leibold, Marion
            </a>
           </td>
           <td class="r">
            Technische Universität München
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#10005" title="Click to go to the Author Index">
             Buss, Martin
            </a>
           </td>
           <td class="r">
            Technische Universität München
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#140195" title="Click to go to the Author Index">
             Lee, Jinoh
            </a>
           </td>
           <td class="r">
            German Aerospace Center (DLR)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3768" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#robust_adaptive_control_of_robotic_systems" title="Click to go to the Keyword Index">
               Robust/Adaptive Control of Robotic Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#redundant_robots" title="Click to go to the Keyword Index">
               Redundant Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#model_predictive_control" title="Click to go to the Keyword Index">
               Model Predictive Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a model predictive control (MPC) method for redundant robots controlling multiple hierarchical tasks formulated as multi-layer constrained optimal control problems (OCPs). The proposed method, named hierarchical incremental MPC (HIMPC), is robust to dynamic uncertainties, untethered from kinematic/algorithmic singularities, and capable of handling input and state constraints such as joint torque and position limits. To this end, we first derive robust incremental systems that approximate uncertain system dynamics without computing complex nonlinear functions or identifying model parameters. Then the constrained OCPs are cast as quadratic programming problems which result in linear MPC, where dynamically-consistent task priority is achieved by deploying equality constraints and optimal control is attained under input and state constraints. Moreover, hierarchical feasibility and recursive feasibility are theoretically proven. Since the computational complexity of HIMPC drastically decreases compared with nonlinear MPC-based methods, it is implemented under the sampling frequency of 1 kHz for physical experiments with redundant manipulator setups, where robustness (high tracking accuracy and enhanced dynamic consistency), admissibility of multiple constraints, and singularity-avoidance nature are demonstrated and compared with state-of-the-art task-prioritized controllers.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt5_02">
             11:15-11:30, Paper WeBT5.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3627'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Traversability-Aware Adaptive Optimization for Path Planning and Control in Mountainous Terrain
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#309483" title="Click to go to the Author Index">
             Yoo, Se-Wook
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#361215" title="Click to go to the Author Index">
             Son, E-In
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#205194" title="Click to go to the Author Index">
             Seo, Seung-Woo
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3627" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#robust_adaptive_control" title="Click to go to the Keyword Index">
               Robust/Adaptive Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#integrated_planning_and_learning" title="Click to go to the Keyword Index">
               Integrated Planning and Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Autonomous navigation in extreme mountainous terrains poses challenges due to the presence of mobility-stressing elements and undulating surfaces, making it particularly difficult compared to conventional off-road driving scenarios. In such environments, estimating traversability solely based on exteroceptive sensors often leads to the inability to reach the goal due to a high prevalence of non-traversable areas. In this paper, we consider traversability as a relative value that integrates the robot's internal state, such as speed and torque to exhibit resilient behavior to reach its goal successfully. We separate traversability into apparent traversability and relative traversability, then incorporate these distinctions in the optimization process of sampling-based planning and motion predictive control. Our method enables the robots to execute the desired behaviors more accurately while avoiding hazardous regions and getting stuck. Experiments conducted on simulation with 27 diverse types of mountainous terrain and real-world demonstrate the robustness of the proposed framework, with increasingly better performance observed in more complex environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt5_03">
             11:30-11:45, Paper WeBT5.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3764'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Neural-FxSMC: A Robust Adaptive Neural Fixed-Time Sliding Mode Control for Quadrotors with Unknown Uncertainties
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#251155" title="Click to go to the Author Index">
             Yogi, Subhash Chand
            </a>
           </td>
           <td class="r">
            Indian Institute of Technology - Kanpur
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#121875" title="Click to go to the Author Index">
             Behera, Laxmidhar
            </a>
           </td>
           <td class="r">
            IIT Kanpur
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#195804" title="Click to go to the Author Index">
             Tripathy, Twinkle
            </a>
           </td>
           <td class="r">
            IIT Bombay
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3764" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#robust_adaptive_control" title="Click to go to the Keyword Index">
               Robust/Adaptive Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents Neural-FxSMC, a robust and precise control scheme for quadrotors to counter unknown dynamics, uncertainties, and external disturbances. Neural-FxSMC, (i) addresses fixed-time convergence of the tracking error, control singularity, and chattering issues simultaneously, which is not possible with the existing Fixed time Sliding Mode Control (FxSMC), and (ii) relaxes the a priori bound assumption over the uncertainties that are often considered as a constant or a state-dependent upper bound. The fixed-time convergence of tracking error is guaranteed by establishing fixed-time convergence of the Non-singular Fast Terminal Slid- ing Surface (NFTSS), contrary to the existing works where the NFTSS convergence depends on initial conditions. The Chatter- ing is suppressed via Radial Basis Function Network (RBFN) based uncertainties estimation. Finally, using the Lyapunov theory, we prove the fixed-time convergence and boundedness of Neural-FxSMC weights. We comprehensively evaluate Neural-FxSMC in challenging scenarios such as unknown payload and turbulent wind. Our Neural-FxSMC, apart from handling unknown dynamics and uncertainties, also offers direct gravity compensation without using quadrotor mass and gravity.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt5_04">
             11:45-12:00, Paper WeBT5.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3785'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              An Open Source Dual Purpose Acrobot and Pendubot Platform for Benchmarking Control Algorithms for Underactuated Robotics (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#310508" title="Click to go to the Author Index">
             Wiebe, Felix
            </a>
           </td>
           <td class="r">
            DFKI GmbH Robotics Innovation Center
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#198353" title="Click to go to the Author Index">
             Kumar, Shivesh
            </a>
           </td>
           <td class="r">
            DFKI GmbH
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#311441" title="Click to go to the Author Index">
             Shala, Lasse
            </a>
           </td>
           <td class="r">
            Deutsches Forschungszentrum Für Künstliche Intelligenz
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#311333" title="Click to go to the Author Index">
             Vyas, Shubham
            </a>
           </td>
           <td class="r">
            Robotics Innovation Center, DFKI GmbH
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#325523" title="Click to go to the Author Index">
             Javadi, Mahdi
            </a>
           </td>
           <td class="r">
            German Research Center for Artificial Intelligence Robotics Inn
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#109056" title="Click to go to the Author Index">
             Kirchner, Frank
            </a>
           </td>
           <td class="r">
            University of Bremen
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3785" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#robust_adaptive_control" title="Click to go to the Keyword Index">
               Robust/Adaptive Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#software_tools_for_benchmarking_and_reproducibility" title="Click to go to the Keyword Index">
               Software Tools for Benchmarking and Reproducibility
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents an open-source and low-cost test bench for validating, comparing and benchmarking the per- formance of control algorithms for underactuated robots with strong non-linear dynamics. It introduces a double pendulum platform built using two off-the-shelf quasi-direct drives (QDDs). Due to low friction and high mechanical transparency offered by QDDs, one of the actuators can be kept passive and be used as an encoder, so that the system can be operated as a double pendulum, a pendubot or an acrobot without changing the hardware. Using the proposed platform, trajectory optimization and control algorithms for the swing- up and upright stabilization of the acrobot and pendubot systems are compared and benchmarked. By considering simple variations of the design, the difficulty of the control problem can be varied giving researchers opportunity for showing the robustness of their control algorithms.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="webt6">
             <b>
              WeBT6
             </b>
            </a>
           </td>
           <td class="r">
            Room 6
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#webt6" title="Click to go to the Program at a Glance">
             <b>
              Mechanism Design I
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#101894" title="Click to go to the Author Index">
             Stefanini, Cesare
            </a>
           </td>
           <td class="r">
            Scuola Superiore Sant'Anna
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt6_01">
             11:00-11:15, Paper WeBT6.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('746'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              MTABot: An Efficient Morphable Terrestrial-Aerial Robot with Two Transformable Wheels
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#365076" title="Click to go to the Author Index">
             Shi, Ke
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#164329" title="Click to go to the Author Index">
             Jiang, Zainan
            </a>
           </td>
           <td class="r">
            State Key Laboratory of Robotics and System, Harbin Institute Of
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#380189" title="Click to go to the Author Index">
             Ma, Liyan
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#334016" title="Click to go to the Author Index">
             Qi, Le
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#176648" title="Click to go to the Author Index">
             Jin, Minghe
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab746" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Terrestrial-aerial robots, capable of swift aerial navigation and enduring terrestrial operations, possess significant potential for utilization in exploration and rescue missions. However, achieving their capability to negotiate diverse terrains with a high-power-efficient structure remains a formidable challenge. This paper presents a morphable terrestrial-aerial robot, named MTABot, which achieves three modalities through the deployment of two multifunctional appendages. These include: (1) rolling mode, (2) climbing mode, both achieved with transformable two-wheeled configuration, and (3) flying mode, achieved with a bicopter configuration. Moreover, the radius and sector angle of transformable wheel have been optimized to enhance the obstacle-climbing capability; the position of the robot's body center of gravity has been optimized to balance ground gripping capacity and flight dynamic response speed. Finally, the robot's multi-terrain overcoming capability is validated through obstacle-climbing experiments and continuous terrestrial-aerial transformation experiments, and the high power efficiency of robot is affirmed, demonstrating feasibility of the design.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt6_02">
             11:15-11:30, Paper WeBT6.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3708'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Rail DRAGON: Long-Reach Bendable Modularized Rail Structure for Constant Observation Inside PCV
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#294984" title="Click to go to the Author Index">
             Yokomura, Ryota
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#389625" title="Click to go to the Author Index">
             Goto, Masataka
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#296384" title="Click to go to the Author Index">
             Yoshida, Takehito
            </a>
           </td>
           <td class="r">
            University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103063" title="Click to go to the Author Index">
             Warisawa, Shin'ichi
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#216784" title="Click to go to the Author Index">
             Hanari, Toshihide
            </a>
           </td>
           <td class="r">
            JAEA
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#107330" title="Click to go to the Author Index">
             Kawabata, Kuniaki
            </a>
           </td>
           <td class="r">
            Japan Atomic Energy Agency
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#109217" title="Click to go to the Author Index">
             Fukui, Rui
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3708" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#cellular_and_modular_robots" title="Click to go to the Keyword Index">
               Cellular and Modular Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#environment_monitoring_and_management" title="Click to go to the Keyword Index">
               Environment Monitoring and Management
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             To reduce errors in the remote control of robots during decommissioning, we developed a Rail DRAGON, which enables continuous observation of the work environment. The Rail DRAGON is constructed by assembling and pushing a long rail structure inside the primary containment vessel (PCV), and then repeatedly deploying several monitoring robots on the rails to enable constant observation in a high-radiation environment. In particular, we have developed the following components of Rail DRAGON: bendable rail modules, straight rail modules, a basement unit, and monitoring robots. Concretely, this research proposes and demonstrates a method to realize an ultralong articulated structure with high portability and workability. In addition, it proposes and verifies the feasibility of a method for deploying observation equipment that can be easily deployed and replaced, while considering disposal.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt6_03">
             11:30-11:45, Paper WeBT6.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3776'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Transformable Inspection Robot Design and Implementation for Complex Pipeline Environment
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#369990" title="Click to go to the Author Index">
             Wang, Jianlin
            </a>
           </td>
           <td class="r">
            Chinese University of Hongkong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#384417" title="Click to go to the Author Index">
             Wang, Yixiang
            </a>
           </td>
           <td class="r">
            Rensselaer Polytechnic Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#384418" title="Click to go to the Author Index">
             Peng, Lining
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#384420" title="Click to go to the Author Index">
             Zhang, Haixiang
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#384419" title="Click to go to the Author Index">
             Gao, Hang
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#180353" title="Click to go to the Author Index">
             Wang, Chengjiang
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong, ShenZhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#212292" title="Click to go to the Author Index">
             Gao, Yuan
            </a>
           </td>
           <td class="r">
            Shenzhen Institute of Artificial Intelligence and Robotics for S
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#385673" title="Click to go to the Author Index">
             Luo, Huanliang
            </a>
           </td>
           <td class="r">
            Dapeng Customs of the People's Republic of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#138646" title="Click to go to the Author Index">
             Chen, Yongquan
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong, Shenzhen
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3776" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#engineering_for_robotic_systems" title="Click to go to the Keyword Index">
               Engineering for Robotic Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#surveillance_robotic_systems" title="Click to go to the Keyword Index">
               Surveillance Robotic Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Pipeline inspections are crucial to ensure the reliability of the transmission system. However, with the growing complexity and aging of the pipeline system, traditional pipeline inspection robots struggle to adapt to complex environments with obstacles, cracks, changing cross-section, and other challenges. This paper introduces a novel transformable inspection robot with remarkable adaptability to varying pipeline environment from 163 mm to 312 mm inner diameter. The robot is composed of several motion modules that are arranged along its central axes at a 60-degree angle. The pneumatically powered robot has good active and passive deformation capabilities, enabling it to passively adapt to its surroundings and actively change between different postures. Our robot can also achieve automatic navigation in complex pipeline environments based on a LiDAR camera. Experiments demonstrate the robot adjusting to varying pipeline scenarios, including obstacles, diameter changes, turning up to 90 degrees, climbing up to 45 degrees, and crossing-section changes with a deformation rate up to 191.4%, overcoming the limitations of traditional designs.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt6_04">
             11:45-12:00, Paper WeBT6.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3737'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Enhancing Maximum Stroke of Twisted String Actuators by Adjusting Twisting Ratio
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#385881" title="Click to go to the Author Index">
             Baek, Seungjoon
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#227065" title="Click to go to the Author Index">
             Jang, JaeHyung
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102369" title="Click to go to the Author Index">
             Ryu, Jee-Hwan
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3737" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#tendon_wire_mechanism" title="Click to go to the Keyword Index">
               Tendon/Wire Mechanism
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_sensors_and_actuators" title="Click to go to the Keyword Index">
               Soft Sensors and Actuators
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In robotics, twisted string actuators (TSAs) have attracted considerable attention owing to their high gear ratio, flexibility, and simplicity. However, TSAs face challenges such as control issues, limited lifespan, and limited stroke. Among them, their practical use is hindered by a limited stroke due to overtwisting, leading to hysteresis, efficiency, and lifespan issues. To avoid overtwisting, TSAs are confined to a narrow stroke range, approximately 30% of the original string length. This study introduces an innovative approach to enhance TSA stroke without introducing overtwisting. The key lies in adjusting the ratio of overlap and individual twisting (ROI) to strategically use the string that possesses the capacity of twisting. The method capitalizes on the observation that the maximum strokes of two TSA twisting methods—twisted single string and twisted looped single string (TLS)—are approximately equal. This is attributed to the locking point induced by overlap twisting in TLS. To mathematically model this phenomenon, this study develops a novel kinematic model of TSA accounting for the locking point. Additionally, we propose an optimization process, achieving a maximum stroke of 53.44% of the original string length, significantly surpassing the conventional limitation of 30%. This enhancement is achieved without introducing over-twisting, thereby avoiding hysteresis.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="webt7">
             <b>
              WeBT7
             </b>
            </a>
           </td>
           <td class="r">
            Room 7
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#webt7" title="Click to go to the Program at a Glance">
             <b>
              Wearable Robotics
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#174021" title="Click to go to the Author Index">
             Hussain, Irfan
            </a>
           </td>
           <td class="r">
            Khalifa University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt7_01">
             11:00-11:15, Paper WeBT7.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3654'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Wearable Finger Tremor-Suppression Orthosis Using the PVC Gel Linear Actuator
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#299320" title="Click to go to the Author Index">
             Liu, Chen
            </a>
           </td>
           <td class="r">
            Queen Mary University of London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#139489" title="Click to go to the Author Index">
             Zhang, Ketao
            </a>
           </td>
           <td class="r">
            Queen Mary University of London
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3654" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#wearable_robotics" title="Click to go to the Keyword Index">
               Wearable Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#prosthetics_and_exoskeletons" title="Click to go to the Keyword Index">
               Prosthetics and Exoskeletons
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_sensors_and_actuators" title="Click to go to the Keyword Index">
               Soft Sensors and Actuators
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Tremor is a prevalent neurological disorder that affects individuals of almost all ages and can significantly impede their quality of life and occupational functioning. Wearable medical devices for suppressing tremors, typically low-frequency vibrations ranging between 3 and 12 Hz, are gaining popularity since active vibration absorbers integrated into such devices have demonstrated immediate efficacy and noninvasive nature. However, there are challenges in miniaturizing active absorbers for wearable applications with traditional actuators. To address this problem, here we present a light wearable active finger tremor suppressing orthosis (AFTO) that consists of a stacked polyvinyl chloride (PVC) gel actuator-based absorber, an inertial measurement unit (IMU), and a force sensor. The integrated sensors allow the device to detect tremors and trigger the absorber to suppress vibrations, regardless of whether the fingertip is vibrating in the air or applying tremor force while in contact with an object. A 3D-printed compliant Sarrus-mechanism exoskeleton was used to house the PVC gel stacked actuator, thus minimizing the linear actuator’s swaying while maximizing the effective actuation area. This innovative wearable finger tremor absorption system has the potential for various applications in daily life and occupational contexts, such as stabilizing the finger during grasping, typing, operating surgical instruments, drawing, and other tasks.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt7_02">
             11:15-11:30, Paper WeBT7.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3679'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Novel Lightweight Lower Limb Exoskeleton Design for Single-Motor Sequential Assistance of Knee &amp; Ankle Joints in Real World
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#273533" title="Click to go to the Author Index">
             Wu, Xinyu
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#222113" title="Click to go to the Author Index">
             Zhu, Aibin
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#385734" title="Click to go to the Author Index">
             Li, Xiao
            </a>
           </td>
           <td class="r">
            Rehabilitation Department, Senior Department of Orthopedics, The
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#344530" title="Click to go to the Author Index">
             Bao, Bingsheng
            </a>
           </td>
           <td class="r">
            Institute of Robotics &amp; Intelligent Systems, Shaanxi Key Laborat
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#318050" title="Click to go to the Author Index">
             Zhang, Jing
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375540" title="Click to go to the Author Index">
             Shi, Lei
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375524" title="Click to go to the Author Index">
             Diyang, Dang
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#385735" title="Click to go to the Author Index">
             Xu, Peng
            </a>
           </td>
           <td class="r">
            Honghui Hospital, Xi'an Jiaotong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3679" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#wearable_robotics" title="Click to go to the Keyword Index">
               Wearable Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#prosthetics_and_exoskeletons" title="Click to go to the Keyword Index">
               Prosthetics and Exoskeletons
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we introduce a lightweight lower limb exoskeleton that provides auxiliary torque to both the ankle and knee joints during the stance phase of gait in a real-world environment, using one quasi-direct-drive (QDD) motor . This lightweight exoskeleton incorporates a novel driving mechanism: the Unidirectional Ankle-Knee Gait Clutch(UAKC), which allows for the sequential provision of auxiliary torque to the knee and ankle joints during the stance phase of gait. We trained a lightweight convolutional neural network to determine gait phases from scanned insole pressure data and generate corresponding biological torques. We provide a detailed exposition of the design concept and operation of the lightweight exoskeleton. Through a series of experiments, we evaluated the performance of the lightweight exoskeleton. In real-world conditions, it reduced human energy consumption by 8.9±1.3% compared to walking without the exoskeleton.This study reports on the potential of this rigid-cable coupled underactuated exoskeleton in enhancing human movement.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt7_03">
             11:30-11:45, Paper WeBT7.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3761'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Advanced Enhanced Control of a Novel Wearable Lower-Limb Exoskeleton
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#371231" title="Click to go to the Author Index">
             Qiu, Shuang
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#252592" title="Click to go to the Author Index">
             Pei, Zhongcai
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#285108" title="Click to go to the Author Index">
             Shi, Jia
            </a>
           </td>
           <td class="r">
            BEIHANG UNIVERSITY
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372326" title="Click to go to the Author Index">
             Zhang, Xu
            </a>
           </td>
           <td class="r">
            Beijing Legendary Soaring Technology Company
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372332" title="Click to go to the Author Index">
             Wang, Chen
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#252599" title="Click to go to the Author Index">
             Tang, Zhiyong
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3761" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#wearable_robotics" title="Click to go to the Keyword Index">
               Wearable Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#force_control" title="Click to go to the Keyword Index">
               Force Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#physical_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical Human-Robot Interaction
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, a novel powered lower limb exoskeleton prototype called PTEXO for reducing user burden and enhancing following comfort is presented. The PTEXO is designed with a new control strategy, Enhanced Sensitivity Amplification Control (ESAC), and improves comfort of lower-limb locomotion through three aspects, namely, obtaining high-quality angular acceleration signals, adjusting sensitivities among different model items, and increasing continuity during gait phase transitions. This opens a new option in terms of algorithms for improving the comfort of wearable robotic exoskeletons. In the paper, the mechatronic structure of PTEXO is designed for ESAC, with which dynamic models are established. Finally, wearable experiments validate the proper functioning of the integrated technique, demonstrating the effectiveness of the ESAC strategy in improving PTEXO smoothness. A user survey is included to illustrate the ESAC can effectively and comfortably assists users with lower limb locomotion.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt7_04">
             11:45-12:00, Paper WeBT7.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3734'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Bio-Inspired Cable-Driven Actuation System for Wearable Robotic Devices: Design, Control and Characterization (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#345426" title="Click to go to the Author Index">
             Xu, Ming
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#169480" title="Click to go to the Author Index">
             Zhou, Zhihao
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#345427" title="Click to go to the Author Index">
             Wang, Zezheng
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#276763" title="Click to go to the Author Index">
             Ruan, Lecheng
            </a>
           </td>
           <td class="r">
            University of California Los Angeles
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#109737" title="Click to go to the Author Index">
             Mai, Jingeng
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#109134" title="Click to go to the Author Index">
             Wang, Qining
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3734" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#wearable_robots" title="Click to go to the Keyword Index">
               Wearable Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#prosthetics_and_exoskeletons" title="Click to go to the Keyword Index">
               Prosthetics and Exoskeletons
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_centered_robotics" title="Click to go to the Keyword Index">
               Human-Centered Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Wearable robotic devices interact with human by applying assistive force in parallel with muscle-tendon systems. Designing actuations in mimicking the natural activation patterns of human muscles is a promising way to optimize the performance of wearable robots. In this paper, we propose a bio-inspired cable-driven actuation system capable of providing anisometric contractions (including concentric and eccentric contraction) assistance or nearly acting as a transparent device in an efficient manner. A novel clutch-spring mechanism is employed to accomplish switches between assistive modes and the transparent mode. Corresponding control strategies coordinating with the mechanical design were presented and described in detail. Multiple evaluations were conducted on a test bench to characterize the system performance. The closed-loop bandwidth of the system running concentric assistance control was 18.2 Hz. The R-squared values of linear fitting under eccentric assistance control were above 0.99. The engagement time of the proposed clutch was about 90 ms. Applying the actuation to an ankle exoskeleton, multiple walking experiments with electromyography measurements were performed on five subjects to show its application potential in existing wearable robots. Experimental results revealed that the proposed design could reduce soleus muscle activity by 27.32% compared with normal walking. This study highlights the importance of functional bionic design in human-assistance-related devices and introduces a general actuation system that could be directly applied to existing cable-driven wearable robots.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="webt8">
             <b>
              WeBT8
             </b>
            </a>
           </td>
           <td class="r">
            Room 8
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#webt8" title="Click to go to the Program at a Glance">
             <b>
              Localization I
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#303651" title="Click to go to the Author Index">
             Ma, Junyi
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt8_01">
             11:00-11:15, Paper WeBT8.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('18'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              LCPR: A Multi-Scale Attention-Based LiDAR-Camera Fusion Network for Place Recognition
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#347636" title="Click to go to the Author Index">
             Zhou, Zijie
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#370250" title="Click to go to the Author Index">
             Xu, Jingyi
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102768" title="Click to go to the Author Index">
             Xiong, Guangming
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#303651" title="Click to go to the Author Index">
             Ma, Junyi
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab18" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Place recognition is one of the most crucial modules for autonomous vehicles to identify places that were previously visited in GPS-invalid environments. Sensor fusion is considered an effective method to overcome the weaknesses of individual sensors. In recent years, multimodal place recognition fusing information from multiple sensors has gathered increasing attention. However, most existing multimodal place recognition methods only use limited field-of-view camera images, which leads to an imbalance between features from different modalities and limits the effectiveness of sensor fusion. In this paper, we present a novel neural network named LCPR for robust multimodal place recognition, which fuses LiDAR point clouds with multi-view RGB images to generate discriminative and yaw-rotation invariant representations of the environment. A multi-scale attention-based fusion module is proposed to fully exploit the panoramic views from different modalities of the environment and their correlations. We evaluate our method on the nuScenes dataset, and the experimental results show that our method can effectively utilize multi-view camera and LiDAR data to improve the place recognition performance while maintaining strong robustness to viewpoint changes. Our open-source code and pre-trained models are available at https://github.com/ZhouZijie77/LCPR.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt8_02">
             11:15-11:30, Paper WeBT8.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('91'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robust Cooperative Localization with Failed Communication and Biased Measurements
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#373240" title="Click to go to the Author Index">
             He, Ronghai
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#205818" title="Click to go to the Author Index">
             Shan, Yunxiao
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#193739" title="Click to go to the Author Index">
             Huang, Kai
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab91" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#distributed_robot_systems" title="Click to go to the Keyword Index">
               Distributed Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Cooperative Localization (CL) plays a crucial role in achieving precise localization without relying on localization sensors. However, the performance of CL can be significantly affected by failed communication and biased measurements. This paper presents a robust decentralized CL method that addresses these challenges effectively. To tackle the issue of communication failures, the proposed method adopts a multi-centralized framework that separates the measurement and communication processes. This decoupling allows each robot to utilize measurement information even in the absence of communication. Additionally, an reasonable state estimation method for other robots is proposed by approximating the actual input velocity model of unknown states and then propagating them using the motion model. To handle biased measurements, the method incorporates the M-estimation technique into the measurement update process. This technique weights the received measurements according to their reliability, mitigating the impact of biased measurements on the estimation accuracy. Simulation experiments have been conducted to validate the effectiveness of the proposed method in challenging scenarios. The source code has been made accessible to the public via https://github.com/RonghaiHe/RobustCL.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt8_03">
             11:30-11:45, Paper WeBT8.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('121'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              GeoCluster: Enhancing Visual Place Recognition in Spatial Domain on Aerial Vehicle Platforms
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#373503" title="Click to go to the Author Index">
             Chen, Chao
            </a>
           </td>
           <td class="r">
            Beijing University of Chemical Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#344890" title="Click to go to the Author Index">
             He, Mengfan
            </a>
           </td>
           <td class="r">
            TsinghuaUniversity
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#165282" title="Click to go to the Author Index">
             Wang, Jun
            </a>
           </td>
           <td class="r">
            Beijing University of Chemical Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#161918" title="Click to go to the Author Index">
             Meng, Ziyang
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab121" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#recognition" title="Click to go to the Keyword Index">
               Recognition
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__perception_and_autonomy" title="Click to go to the Keyword Index">
               Aerial Systems: Perception and Autonomy
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Visual Place Recognition (VPR) is a critical technology for achieving robust long-term visual geo-localization. During the past few years, VPR research mainly focused on ground-based platforms in the street-level captured scenes with deep learning methods (e.g. NetVLAD, GeM), but little attention was paid to the VPR task on aerial vehicles. The algorithms and models designed for ground-based platforms are always directly applied to the aerial VPR problem. However, the viewpoint variance on Unmanned Aerial Vehicles (UAV) is much larger than the ground-based platforms. Due to the sparse distribution of aerial image features, when the viewpoint of the camera changes, the features of the query image are largely inconsistent with the descriptors in the database, which results in the failures of image retrieval and visual geo-localization. In this paper, we propose an aerial VPR enhancement module called GeoCluster, which presents a feature aggregation method using spatial clustering information to improve the robustness and consistency of the global descriptors for UAV-captured frames. Moreover, it can be applied to any NetVLAD-based VPR method and boost the pre-trained model without any further training process. By integrating GeoCluster into an existing state-of-the-art localization method, we can achieve about 10% improvement for aerial image retrieval tasks and have more accurate and robust geo-localization results. To foster future research, we make the code and datasets in this work publicly available for any researcher at https://github.com/cbbhuxx/GeoCluster.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="webt9">
             <b>
              WeBT9
             </b>
            </a>
           </td>
           <td class="r">
            Room 9
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#webt9" title="Click to go to the Program at a Glance">
             <b>
              Motion and Path Planning I
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#113220" title="Click to go to the Author Index">
             Bennewitz, Maren
            </a>
           </td>
           <td class="r">
            University of Bonn
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt9_01">
             11:00-11:15, Paper WeBT9.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Safe Navigation Using Density Functions
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#360933" title="Click to go to the Author Index">
             Zheng, Andrew
            </a>
           </td>
           <td class="r">
            Clemson University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#338834" title="Click to go to the Author Index">
             Krishnamoorthy Shankara Narayanan, Sriram Sundar
            </a>
           </td>
           <td class="r">
            Clemson University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#330763" title="Click to go to the Author Index">
             Vaidya, Umesh
            </a>
           </td>
           <td class="r">
            Clemson University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a novel approach for safe control synthesis using the dual formulation of the navigation problem. The main contribution of this paper is in the analytical construction of density functions for almost everywhere navigation with safety constraints. In contrast to the existing approaches, where density functions are used for the analysis of navigation problems, we use density functions for the synthesis of safe controllers. We provide convergence proof using the proposed density functions for navigation with safety. Further, we use these density functions to design feedback controllers capable of navigating in cluttered environments and high-dimensional configuration spaces. The proposed analytical construction of density functions overcomes the problem associated with navigation functions, which are known to exist but challenging to construct, and potential functions, which suffer from local minima. Application of the developed framework is demonstrated on simple integrator dynamics and fully actuated robotic systems. Our project page with implementation is available at url{https://github.com/clemson-dira/density_feedback_control}
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt9_02">
             11:15-11:30, Paper WeBT9.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('6'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              State-Feedback Optimal Motion Planning in the Presence of Obstacles
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#249383" title="Click to go to the Author Index">
             Rousseas, Panagiotis
            </a>
           </td>
           <td class="r">
            National Technical University of Athens
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#122413" title="Click to go to the Author Index">
             Bechlioulis, Charalampos
            </a>
           </td>
           <td class="r">
            University of Patras
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103188" title="Click to go to the Author Index">
             Kyriakopoulos, Kostas
            </a>
           </td>
           <td class="r">
            New York University - Abu Dhabi
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab6" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this work, a solution to the kinematic optimal motion planning problem is presented, where a previous nearly globally optimal approach is extended to workspaces with internal obstacles. The method is inspired by fundamental properties of velocity fields in the presence of obstacles, where topological restrictions inhibit naive approaches. The topological perplexity problem presents itself as a challenging issue for optimal control, even for low-dimensional cases with simple dynamics. Our scheme is formulated such that a locally optimal workspace decomposition enables extracting a close-to-optimal solution. Several synthetic workspace examples are demonstrated, along with comparisons against existing optimal approaches, where our scheme is superior w.r.t. both cost value and execution time.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt9_03">
             11:30-11:45, Paper WeBT9.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('35'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Efficiency Improvement to Neural-Network-Driven Optimal Path Planning Via Region and Guideline Prediction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#346986" title="Click to go to the Author Index">
             Huang, Yuan
            </a>
           </td>
           <td class="r">
            Waseda University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#371060" title="Click to go to the Author Index">
             Tsao, Cheng Tien
            </a>
           </td>
           <td class="r">
            Waseda University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#161285" title="Click to go to the Author Index">
             Lee, Hee-hyol
            </a>
           </td>
           <td class="r">
            Waseda University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab35" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Traditional sampling-based algorithms rely on random samples to explore
             <p>
              a whole configuration space of robots for optimal path planning, while a uniform sampler impedes the exploration with randomly generated samples, leading to a long calculation time, especially in complex environments. Recently, neural-network-driven methods have attracted wide interest in developing non-uniform sampling to improve the sampling efficiency and reduce the calculation time. A region that contains an optimal path is predicted by neural networks and employed subsequently to biasedly generate samples. This work aims at enhancing the sampling efficiency and reducing the calculation time of the optimal path planning by a novel region and guideline prediction (denoted as RGP) model. We innovatively propose the RGP model with a guideline prediction module to estimate the guideline distributions, which are characterized by the central line of the predicted region. The predicted region and guideline are integrated into a sampling-based
              <p>
               algorithm, namely RGP-RRT*, with an adaptively biased sampling strategy
               <p>
                to select a proper domain for sampling. Simulations demonstrate the RGP
                <p>
                 model outperforms other region prediction models in accuracy and robustness. Besides, the RGP-RRT* reliably achieves a 7.2-80.1% reduction in calculation time and a 2.0-58.1% reduction in sample number compared with other neural-network-driven methods. The code is available at https://github.com/RTPWDSDM/RGP-RRTstar.
                </p>
               </p>
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt9_04">
             11:45-12:00, Paper WeBT9.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('468'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Spatiotemporal Attention Enhances Lidar-Based Robot Navigation in Dynamic Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#307784" title="Click to go to the Author Index">
             de Heuvel, Jorge
            </a>
           </td>
           <td class="r">
            University of Bonn
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#311403" title="Click to go to the Author Index">
             Zeng, Xiangyu
            </a>
           </td>
           <td class="r">
            University of Bonn
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#311396" title="Click to go to the Author Index">
             Shi, Weixian
            </a>
           </td>
           <td class="r">
            University of Bonn
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#382786" title="Click to go to the Author Index">
             Sethuraman, Tharun
            </a>
           </td>
           <td class="r">
            Hochschule Bonn-Rhein-Sieg
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#113220" title="Click to go to the Author Index">
             Bennewitz, Maren
            </a>
           </td>
           <td class="r">
            University of Bonn
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab468" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Foresighted robot navigation in dynamic indoor environments with cost-efficient hardware necessitates the use of a lightweight yet dependable controller. So inferring the scene dynamics from sensor readings without explicit object tracking is a pivotal aspect of foresighted navigation among pedestrians. In this paper, we introduce a spatiotemporal attention pipeline for enhanced navigation based on 2D lidar sensor readings. This pipeline is complemented by a novel lidar-state representation that emphasizes dynamic obstacles over static ones. Subsequently, the attention mechanism enables selective scene perception across both space and time, resulting in improved overall navigation performance within dynamic scenarios. We thoroughly evaluated the approach in different scenarios and simulators, finding excellent generalization to unseen environments. The results demonstrate outstanding performance compared to state-of-the-art methods, thereby enabling the seamless deployment of the learned controller on a real robot.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="webt10">
             <b>
              WeBT10
             </b>
            </a>
           </td>
           <td class="r">
            Room 10
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#webt10" title="Click to go to the Program at a Glance">
             <b>
              Data Sets for Robotic Vision I
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#383767" title="Click to go to the Author Index">
             Aguiari, Davide
            </a>
           </td>
           <td class="r">
            TII
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#387267" title="Click to go to the Author Index">
             Meyer, Lukas
            </a>
           </td>
           <td class="r">
            Friedrich-Alexander-Universität Erlangen-Nürnberg
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt10_01">
             11:00-11:15, Paper WeBT10.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('317'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Race against the Machine: A Fully-Annotated, Open-Design Dataset of Autonomous and Piloted High-Speed Flight
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#356636" title="Click to go to the Author Index">
             Bosello, Michael
            </a>
           </td>
           <td class="r">
            Technology Innovation Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#383767" title="Click to go to the Author Index">
             Aguiari, Davide
            </a>
           </td>
           <td class="r">
            TII
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#383768" title="Click to go to the Author Index">
             Keuter, Yvo
            </a>
           </td>
           <td class="r">
            TII
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#383769" title="Click to go to the Author Index">
             Pallotta, Enrico
            </a>
           </td>
           <td class="r">
            TII
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#383770" title="Click to go to the Author Index">
             Kiade, Sara
            </a>
           </td>
           <td class="r">
            TII
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#383771" title="Click to go to the Author Index">
             Caminati, Gyordan
            </a>
           </td>
           <td class="r">
            TII
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#383772" title="Click to go to the Author Index">
             Pinzarrone, Flavio
            </a>
           </td>
           <td class="r">
            TII
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#383773" title="Click to go to the Author Index">
             Halepota, Junaid
            </a>
           </td>
           <td class="r">
            TII
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#218401" title="Click to go to the Author Index">
             Panerati, Jacopo
            </a>
           </td>
           <td class="r">
            Technology Innovation Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#383774" title="Click to go to the Author Index">
             Pau, Giovanni
            </a>
           </td>
           <td class="r">
            TII - Technology Innovation Institute
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab317" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__perception_and_autonomy" title="Click to go to the Keyword Index">
               Aerial Systems: Perception and Autonomy
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#software_tools_for_benchmarking_and_reproducibility" title="Click to go to the Keyword Index">
               Software Tools for Benchmarking and Reproducibility
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Unmanned aerial vehicles, and multi-rotors in particular, can now perform dexterous tasks in impervious environments, from infrastructure monitoring to emergency deliveries. Autonomous drone racing has emerged as an ideal benchmark to develop and evaluate these capabilities. Its challenges include accurate and robust visual-inertial odometry during aggressive maneuvers, complex aerodynamics, and constrained computational resources. As researchers increasingly channel their efforts into it, they also need the tools to timely and equitably compare their results and advances. With this dataset, we want to (i) support the development of new methods and (ii) establish quantitative comparisons for approaches originating from the broader robotics and artificial intelligence communities. We want to provide a one-stop resource that is comprehensive of (i) aggressive autonomous and piloted flight, (ii) high-resolution, high-frequency visual, inertial, and motion capture data, (iii) commands and control inputs, (iv) multiple light settings, and (v) corner-level labeling of drone racing gates. We also release the complete specifications to recreate our flight platform, using commercial off-the-shelf components and the open-source flight controller Betaflight, to democratize drone racing research. Our dataset, open-source scripts, and drone design are available at: https://github.com/tii-racing/drone-racing-dataset
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt10_02">
             11:15-11:30, Paper WeBT10.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3649'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Multi-Class Trajectory Prediction in Urban Traffic Using the View-Of-Delft Prediction Dataset
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#383683" title="Click to go to the Author Index">
             Boekema, Hidde
            </a>
           </td>
           <td class="r">
            TU Delft
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#383688" title="Click to go to the Author Index">
             Martens, Bruno
            </a>
           </td>
           <td class="r">
            TU Delft
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#220905" title="Click to go to the Author Index">
             Kooij, Julian Francisco Pieter
            </a>
           </td>
           <td class="r">
            TU Delft
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#129247" title="Click to go to the Author Index">
             Gavrila, Dariu
            </a>
           </td>
           <td class="r">
            Delft University of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3649" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#datasets_for_human_motion" title="Click to go to the Keyword Index">
               Datasets for Human Motion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robot_learning" title="Click to go to the Keyword Index">
               Data Sets for Robot Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents View-of-Delft Prediction, a new dataset for trajectory prediction, to address the lack of on- board trajectory datasets in urban mixed-traffic environments. View-of-Delft Prediction builds on the recently released urban View-of-Delft (VoD) dataset to make it suitable for trajectory prediction. Unique features of this dataset are the challenging road layouts of Delft, with many narrow roads and bridges, and the close proximity between vehicles and Vulnerable Road Users (VRUs). It contains a large proportion of VRUs, with 569 prediction instances for vehicles, 347 for cyclists, and 934 for pedestrians. We additionally provide high-definition map annotations for the VoD dataset to enable state-of-the-art prediction models to be used. We analyse two state-of-the-art trajectory prediction models, PGP and P2T, which originally were developed for vehicle- dominated traffic scenarios, to assess the strengths and weak- nesses of current modelling approaches in mixed traffic settings with large numbers of VRUs. Our analysis shows that there is a significant domain gap between the vehicle-dominated nuScenes and VRU-dominated VoD Prediction datasets. The dataset is publicly released for non-commercial research purposes.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt10_03">
             11:30-11:45, Paper WeBT10.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('26'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Car-Studio: Learning Car Radiance Fields from Single-View and Unlimited In-The-Wild Images
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#311865" title="Click to go to the Author Index">
             Liu, Tianyu
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#223795" title="Click to go to the Author Index">
             Zhao, Hao
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#220971" title="Click to go to the Author Index">
             Yu, Yang
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology (GUANG ZHOU)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#165639" title="Click to go to the Author Index">
             Zhou, Guyue
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#125556" title="Click to go to the Author Index">
             Liu, Ming
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology (Guangzhou)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab26" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Compositional neural scene graph studies have shown that radiance fields can be an efficient tool in an editable autonomous driving simulator. However, previous studies learned within a sequence of autonomous driving datasets, resulting in unsatisfactory blurring when rotating the car in the simulator. In this letter, we propose a pipeline for learning unconstrained images and building a dataset from processed images. To meet the requirements of the simulator, which demands that the vehicle maintain clarity when the perspective changes and that the contour remains sharp from the background to avoid artifacts when editing, we design a radiation field of the vehicle, a crucial part of the urban scene foreground. Through experiments, we demonstrate that our model achieves competitive performance compared to baselines. Using the datasets built from in-the-wild images, our method gradually presents a controllable appearance editing function. We will release the dataset and code on https://lty2226262.github.io/car-studio/ to facilitate further research in the field.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="webt11">
             <b>
              WeBT11
             </b>
            </a>
           </td>
           <td class="r">
            Room 11
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#webt11" title="Click to go to the Program at a Glance">
             <b>
              Multi-Robot Systems I
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#152911" title="Click to go to the Author Index">
             Parasuraman, Ramviyas
            </a>
           </td>
           <td class="r">
            University of Georgia
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#280460" title="Click to go to the Author Index">
             Sun, Guibin
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt11_01">
             11:00-11:15, Paper WeBT11.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('229'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Spatial Calibration Method for Robust Cooperative Perception
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#335270" title="Click to go to the Author Index">
             Song, Zhiying
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#383743" title="Click to go to the Author Index">
             Xie, Tenghui
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#383741" title="Click to go to the Author Index">
             Zhang, Hailiang
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#383744" title="Click to go to the Author Index">
             Liu, Jiaxin
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#383742" title="Click to go to the Author Index">
             Fuxi, Wen
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#383745" title="Click to go to the Author Index">
             Li, Jun
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab229" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#cooperating_robots" title="Click to go to the Keyword Index">
               Cooperating Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Cooperative perception is a promising technique for intelligent and connected vehicles through vehicle-to-everything (V2X) cooperation, provided that accurate pose information and relative pose transforms are available. Nevertheless, obtaining precise positioning information often entails high costs associated with navigation systems. Hence, it is required to calibrate relative pose information for multi-agent cooperative perception. This paper proposes a simple but effective object association approach named context-based matching (CBM), which identifies inter-agent object correspondences using intra-agent geometrical context. In detail, this method constructs contexts using the relative position of the detected bounding boxes, followed by local context matching and global consensus maximization. The optimal relative pose transform is estimated based on the matched correspondences, followed by cooperative perception fusion. Extensive experiments are conducted on both the simulated and real-world datasets. Even with larger inter-agent localization errors, high object association precision and decimeter-level relative pose calibration accuracy are achieved among the cooperating agents.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt11_02">
             11:15-11:30, Paper WeBT11.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1375'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Mean-Shift Shape Formation of Multi-Robot Systems without Target Assignment
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#371783" title="Click to go to the Author Index">
             Zhang, Yunjie
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#169443" title="Click to go to the Author Index">
             Zhou, Rui
            </a>
           </td>
           <td class="r">
            School of Automation Science and Electrical Engineering, Beihang
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#371676" title="Click to go to the Author Index">
             Li, Xing
            </a>
           </td>
           <td class="r">
            Beihang Univeristy
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#280460" title="Click to go to the Author Index">
             Sun, Guibin
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1375" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#distributed_robot_systems" title="Click to go to the Keyword Index">
               Distributed Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#cooperating_robots" title="Click to go to the Keyword Index">
               Cooperating Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The methods of shape formation in robot swarms are usually classified into two categories by whether assignment is used or not. The first is to use target assignment to assemble precise formation. However, the additional algorithm for re-assignment is required to handle unreasonable situations, which results in lower efficiency. The second, also called assignment-free method, is to use local behaviors to assemble formation, however, existing methods can rarely achieve the precise formation. In this paper, we present a distributed assignment-free algorithm to achieve the precise shape formation based on the mean-shift algorithm. Specifically, each target location in robot's perception range is equally regarded as a point of the mean-shift vector. Then, the weight value of each point is computed according to the density of the target location. Here, each robot obtains the density of the target location according to the distribution of its neighbors. Moreover, this density calculation also considers the states of non-neighboring robots via the hop-count algorithm, thus avoiding conflicts among robots. Subsequently, each robot can regard the calculated mean-shift vector as its control command. Finally, simulation results show that our algorithm can form precise shapes at least 8 times more efficient than the assignment-based approach and physical experiment results confirm that the proposed algorithm exhibits promising potential for practical applications.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt11_03">
             11:30-11:45, Paper WeBT11.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3622'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Distributed Coverage Control for Spatial Processes Estimation with Noisy Observations
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#363355" title="Click to go to the Author Index">
             Mantovani, Mattia
            </a>
           </td>
           <td class="r">
            University of Modena and Reggio Emilia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#250167" title="Click to go to the Author Index">
             Pratissoli, Federico
            </a>
           </td>
           <td class="r">
            Università Degli Studi Di Modena E Reggio Emilia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#122186" title="Click to go to the Author Index">
             Sabattini, Lorenzo
            </a>
           </td>
           <td class="r">
            University of Modena and Reggio Emilia
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3622" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#distributed_robot_systems" title="Click to go to the Keyword Index">
               Distributed Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The present study addresses the challenge of effectively deploying a multi-robot team to optimally cover a domain with unknown density distribution. Specifically, we propose a distribute coverage-based control algorithm that enables a group of autonomous robots to simultaneously learn and estimate a spatial field over the domain. Additionally, we consider a scenario where the robots are deployed in a noisy environment or equipped with noisy sensors. To accomplish this, the control strategy utilizes Gaussian Process Regression (GPR) to construct a model of the monitored spatial process in the environment. Our strategy tackles the computational limits of Gaussian processes (GPs) when dealing with large data sets. The control algorithm filters the set of samples, limiting the GP training data to those that are relevant to improving the process estimate, avoiding excessive computational complexity and managing the noise in the observations. To evaluate the effectiveness of our proposed algorithm, we conducted several simulations and real platform experiments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt11_04">
             11:45-12:00, Paper WeBT11.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3662'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Communication-Efficient Multi-Robot Exploration Using Distributed Coverage-Biased Q-Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#332036" title="Click to go to the Author Index">
             Latif, Ehsan
            </a>
           </td>
           <td class="r">
            University of Georgia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#152911" title="Click to go to the Author Index">
             Parasuraman, Ramviyas
            </a>
           </td>
           <td class="r">
            University of Georgia
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3662" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#networked_robots" title="Click to go to the Keyword Index">
               Networked Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Frontier exploration and reinforcement learning have historically been used to solve the problem of enabling many mobile robots to autonomously and cooperatively explore complex surroundings. These methods need to keep an internal global map for navigation, but they do not consider the high costs of communication and information sharing between robots. This study offers CQLite; a novel distributed Q-learning technique designed to minimize data communication overhead between robots while achieving rapid convergence and thorough coverage in multi-robot exploration. The proposed CQLite method uses ad hoc map merging, and selectively shares updated Q-values at recently identified frontiers to significantly reduce communication costs. The theoretical analysis of CQLite's convergence and efficiency and extensive numerical verification on simulated indoor maps utilizing several robots demonstrate the method's novelty. With over 2x reductions in computation and communication alongside improved mapping performance, CQLite outperformed cutting-edge multi-robot exploration techniques like Rapidly Exploring Random Trees and Deep Reinforcement Learning.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="webt12">
             <b>
              WeBT12
             </b>
            </a>
           </td>
           <td class="r">
            Room 12
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#webt12" title="Click to go to the Program at a Glance">
             <b>
              Reinforcement Learning II
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#205194" title="Click to go to the Author Index">
             Seo, Seung-Woo
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt12_01">
             11:00-11:15, Paper WeBT12.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('834'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Diffusion Policies for Out-Of-Distribution Generalization in Offline Reinforcement Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#269717" title="Click to go to the Author Index">
             Ada, Suzan Ece
            </a>
           </td>
           <td class="r">
            Bogazici University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104664" title="Click to go to the Author Index">
             Oztop, Erhan
            </a>
           </td>
           <td class="r">
            Osaka University / Ozyegin University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106000" title="Click to go to the Author Index">
             Ugur, Emre
            </a>
           </td>
           <td class="r">
            Bogazici University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab834" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Offline Reinforcement Learning (RL) methods leverage previous experiences to learn better policies than the behavior policy used for data collection. However, they face challenges handling distribution shifts due to the lack of online interaction during training. To this end, we propose a novel method named State Reconstruction for Diffusion Policies (SRDP) that incorporates state reconstruction feature learning in the recent class of diffusion policies to address the problem of out-of-distribution (OOD) generalization. Our method promotes learning of generalizable state representation to alleviate the distribution shift caused by OOD states. To illustrate the OOD generalization and faster convergence of SRDP, we design a novel 2D Multimodal Contextual Bandit environment and realize it on a 6-DoF real-world UR10 robot, as well as in simulation, and compare its performance with prior algorithms. In particular, we show the importance of the proposed state reconstruction via ablation studies. In addition, we assess the performance of our model on standard continuous control benchmarks (D4RL), namely the navigation of an 8-DoF ant and forward locomotion of half-cheetah, hopper, and walker2d, achieving state-of-the-art results. Finally, we demonstrate that our method can achieve 167% improvement over the competing baseline on a sparse continuous control navigation task where various regions of the state space are removed from the offline RL dataset, including the region encapsulating the goal.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt12_02">
             11:15-11:30, Paper WeBT12.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('841'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Self-Supervised Curriculum Generation for Autonomous Reinforcement Learning without Task-Specific Knowledge
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#205155" title="Click to go to the Author Index">
             Lee, Sang-Hyun
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#205194" title="Click to go to the Author Index">
             Seo, Seung-Woo
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab841" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             A significant bottleneck in applying current reinforcement learning algorithms to real-world scenarios is the need to reset the environment between every episode. This reset process demands substantial human intervention, making it difficult for the agent to learn continuously and autonomously. Several recent works have introduced autonomous reinforcement learning (ARL) algorithms that generate curricula for jointly training reset and forward policies. While their curricula can reduce the number of required manual resets by taking into account the agent's learning progress, they rely on task-specific knowledge, such as predefined initial states or reset reward functions. In this paper, we propose a novel ARL algorithm that can generate a curriculum adaptive to the agent's learning progress without task-specific knowledge. Our curriculum empowers the agent to autonomously reset to diverse and informative initial states. To achieve this, we introduce a success discriminator that estimates the success probability from each initial state when the agent follows the forward policy. The success discriminator is trained with relabeled transitions in a self-supervised manner. Our experimental results demonstrate that our ARL algorithm can generate an adaptive curriculum and enable the agent to efficiently bootstrap to solve sparse-reward maze navigation and manipulation tasks, outperforming baselines with significantly fewer manual resets.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt12_03">
             11:30-11:45, Paper WeBT12.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3706'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Maneuver-Conditioned Decision Transformer for Tactical In-Flight Decision-Making
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#384643" title="Click to go to the Author Index">
             Jung, Hoseong
            </a>
           </td>
           <td class="r">
            Agency for Defense Development
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105705" title="Click to go to the Author Index">
             Kim, Yong-Duk
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#292052" title="Click to go to the Author Index">
             Kim, Youngjung
            </a>
           </td>
           <td class="r">
            ADD
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3706" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__perception_and_autonomy" title="Click to go to the Keyword Index">
               Aerial Systems: Perception and Autonomy
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Autonomous maneuver decision in air combat is a challenging task with high-dimensional state-action spaces and nonlinear dynamics. Existing approaches are usually based on online learning paradigms, which hinders their application to real-world scenarios where online interactions, i.e., trial-and-error, are impractical or dangerous. In this paper, we explore the offline reinforcement learning framework for tactical air combat. To this end, we first construct a large-scale offline dataset of demonstrations from hand-designed planners, humans, and expert policies using an interactable simulator. A transformer-based architecture with a lightweight maneuver pool is then proposed to store and retrieve information for generating effective tactical maneuvers, while maintaining the sequential modeling ability of the decision transformers. The maneuver pool is structured in a key-value memory space, where key-value pairs are used for addressing and reading the maneuver pool. We also propose pool diversity and centralizing losses to learn our offline policy, boosting the discriminative power of learned features from the offline dataset. Our formulation allows us to learn maneuver-specific feature prototypes, and to explicitly leverage such knowledge during inference. Extensive experimental results and ablation studies demonstrate the effectiveness and flexibility of the proposed method, outperforming other offline baselines.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt12_04">
             11:45-12:00, Paper WeBT12.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('835'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Diffusion Policies for Out-Of-Distribution Generalization in Offline Reinforcement Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#269717" title="Click to go to the Author Index">
             Ada, Suzan Ece
            </a>
           </td>
           <td class="r">
            Bogazici University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104664" title="Click to go to the Author Index">
             Oztop, Erhan
            </a>
           </td>
           <td class="r">
            Osaka University / Ozyegin University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106000" title="Click to go to the Author Index">
             Ugur, Emre
            </a>
           </td>
           <td class="r">
            Bogazici University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab835" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Offline Reinforcement Learning (RL) methods leverage previous experiences to learn better policies than the behavior policy used for data collection. However, they face challenges handling distribution shifts due to the lack of online interaction during training. To this end, we propose a novel method named State Reconstruction for Diffusion Policies (SRDP) that incorporates state reconstruction feature learning in the recent class of diffusion policies to address the problem of out-of-distribution (OOD) generalization. Our method promotes learning of generalizable state representation to alleviate the distribution shift caused by OOD states. To illustrate the OOD generalization and faster convergence of SRDP, we design a novel 2D Multimodal Contextual Bandit environment and realize it on a 6-DoF real-world UR10 robot, as well as in simulation, and compare its performance with prior algorithms. In particular, we show the importance of the proposed state reconstruction via ablation studies. In addition, we assess the performance of our model on standard continuous control benchmarks (D4RL), namely the navigation of an 8-DoF ant and forward locomotion of half-cheetah, hopper, and walker2d, achieving state-of-the-art results. Finally, we demonstrate that our method can achieve 167% improvement over the competing baseline on a sparse continuous control navigation task where various regions of the state space are removed from the offline RL dataset, including the region encapsulating the goal.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="webt13">
             <b>
              WeBT13
             </b>
            </a>
           </td>
           <td class="r">
            Room 13
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#webt13" title="Click to go to the Program at a Glance">
             <b>
              Object Detection, Segmentation and Categorization I
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#196876" title="Click to go to the Author Index">
             Vu, Minh Nhat
            </a>
           </td>
           <td class="r">
            TU Wien, Austria
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#138698" title="Click to go to the Author Index">
             Ehsan, Shoaib
            </a>
           </td>
           <td class="r">
            University of Essex
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt13_01">
             11:00-11:15, Paper WeBT13.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('19'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              VRVP: Valuable Region and Valuable Point Anchor-Free 3D Object Detection
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#359087" title="Click to go to the Author Index">
             Deng, Pengzhen
            </a>
           </td>
           <td class="r">
            University of Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#359248" title="Click to go to the Author Index">
             Zhou, Li
            </a>
           </td>
           <td class="r">
            Institute of Microelectronics of the Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#359247" title="Click to go to the Author Index">
             Chen, Jie
            </a>
           </td>
           <td class="r">
            Institute of Microelectronics of the Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab19" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             3D point cloud object detection is of great significance in autonomous driving, robotics, and related fields. The current algorithms fail to fully consider that positive sample points of a point cloud object exclusively reside on its surface, resulting in decreased accuracy. High-quality classification points are located centrally, while high-quality regression points are predominantly situated at the boundary. We propose an anchor-free object detection algorithm called Valuable Region and Valuable Point (VRVP), aiming to address the inconsistency between the classification and regression tasks. We achieve high-quality object size regression through a classification-based approach and implicitly correlate the regression and classification branches. Furthermore, a valuable region extraction module is introduced to select valuable points and regions and fill in the missing features of the object's center area. We validate the effectiveness of our algorithm on the KITTI dataset and compare it with some state-of-the-art algorithms, demonstrating that the proposed method has strong competitiveness by significantly improving the detection accuracy of small objects such as pedestrians and cyclists while maintaining high detection accuracy for cars.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt13_02">
             11:15-11:30, Paper WeBT13.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('13'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Enhanced Optical Tracking of Weld Beads in Autonomous Inspection of Separator Vessels
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#368485" title="Click to go to the Author Index">
             Terres, Vinicius de Vargas
            </a>
           </td>
           <td class="r">
            Universidade Tecnológica Federal Do Paraná
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#190265" title="Click to go to the Author Index">
             Teixeira, Marco Antonio Simões
            </a>
           </td>
           <td class="r">
            PUCPR - Pontifícia Universidade Católica Do Paraná
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#190377" title="Click to go to the Author Index">
             Neves-Jr, Flávio
            </a>
           </td>
           <td class="r">
            Federal University of Technology - Parana
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#167609" title="Click to go to the Author Index">
             Ramos de Arruda, Lucia Valeria
            </a>
           </td>
           <td class="r">
            UTFPR
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#178542" title="Click to go to the Author Index">
             de Oliveira, Andre Schneider
            </a>
           </td>
           <td class="r">
            Federal University of Technology - Parana
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab13" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Inspection robots have been developed to support the maintenance of separator vessels. One challenge for such robots is to identify and navigate along the weld bead. This paper proposes a new solution to the weld bead recognition problem, including its tracking, which aims to automate weld bead inspection. A reliable weld bead detection method was developed through five steps that process the line profile sensor data. The weld bead was identified based on the estimation of its center. A non-linear controller paired with a module that compensates for uncertainties generated by gravity was designed to ensure the tracking of weld bead. Such a controller can reduce the impact of the variation in the robot's orientation on the weld bead tracking. An algorithm redirects the robot at the end of the weld bead. The experiments were conducted in a laboratory-scale setup, allowing movement along horizontal and diagonal surfaces. The results show that the robot tracked the weld line in all simulated conditions, with a maximum error of 2.86mm.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt13_03">
             11:30-11:45, Paper WeBT13.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3636'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Generalizable Stable Points Segmentation for 3D LiDAR Scan-To-Map Long-Term Localization
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#339258" title="Click to go to the Author Index">
             Hroob, Ibrahim
            </a>
           </td>
           <td class="r">
            University of Lincoln
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#288232" title="Click to go to the Author Index">
             Mersch, Benedikt
            </a>
           </td>
           <td class="r">
            University of Bonn
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101642" title="Click to go to the Author Index">
             Stachniss, Cyrill
            </a>
           </td>
           <td class="r">
            University of Bonn
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104948" title="Click to go to the Author Index">
             Hanheide, Marc
            </a>
           </td>
           <td class="r">
            University of Lincoln
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3636" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Mobile robots increasingly operate in real-world environments that are subject to change over time. Accurate and robust localization is, however, crucial for the effective operation of autonomous mobile systems. In this paper, we tackle the challenge of developing a generalizable learned filter for long-term localization based on scan-to-map matching, using only 3D LiDAR data. Our primary objective is to enhance the reliability of mobile robot localization in dynamic environments. To obtain a strong generalization capability of the learned filter, we exploit the discrepancy between scan and map data. Our approach involves applying sparse 4D convolutions on a joint sparse voxel grid that encompasses both, scan voxels and their corresponding map voxels. This allows us to segment scan points into stable and unstable points based on a predicted long-term stability confidence score for each scan point. Our experimental results demonstrate that utilizing the stable points for localization improves the performance of scan-matching algorithms, especially in environments where changes in appearance are frequent. By exploiting the discrepancy between scan and map voxels, we enhance the segmentation of stable points. As a result, our approach generalizes to new, unseen environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt13_04">
             11:45-12:00, Paper WeBT13.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3760'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Class Semantics Modulation for Open-Set Instance Segmentation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#334096" title="Click to go to the Author Index">
             Yang, Yifei
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#286412" title="Click to go to the Author Index">
             Zhou, Zhongxiang
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#286413" title="Click to go to the Author Index">
             Wu, Jun
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#156231" title="Click to go to the Author Index">
             Wang, Yue
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#113216" title="Click to go to the Author Index">
             Xiong, Rong
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3760" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper addresses the challenge of open-set instance segmentation (OSIS) which segments both known objects and unknown objects not seen in training, thus is essential for enabling robots to safely work in the real world. Existing solutions adopt class-agnostic segmentation where all classes share the same mask output layer leading to inferior performance. Motivated by the superiority of the class-specific mask prediction in close-set instance segmentation, we propose SemSeg with class semantics extraction and mask prediction modulation for conducting class-specific segmentation in OSIS. To extract class semantics for both known and unknown objects in the absence of supervision on unknown objects, we use contrastive learning to construct an embedding space where objects from each known class cluster in an independent territory and the complementary region of known classes can accommodate unknown objects. To modulate the mask prediction, we convert class semantic embedding to convolutional parameters used to predict the mask. Class semantics modulated OSIS allows optimizing the mask output layer for each class independently without competition between each other. And class semantic information is engaged in the segmentation process directly so that can guide and facilitate the segmentation task, which benefits unknown objects with severe generalization challenges particularly. Experiments on the COCO and GraspNet-1Billion datasets demonstrate the merits of our proposed method, especially the strength of instance segmentation for unknown objects.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="webt14">
             <b>
              WeBT14
             </b>
            </a>
           </td>
           <td class="r">
            Room 14
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#webt14" title="Click to go to the Program at a Glance">
             <b>
              Aerial Navigation
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt14_01">
             11:00-11:15, Paper WeBT14.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('30'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Efficient Optimization-Based Cable Force Allocation for Geometric Control of a Multirotor Team Transporting a Payload
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#365857" title="Click to go to the Author Index">
             Wahba, Khaled
            </a>
           </td>
           <td class="r">
            Technical University of Berlin
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#183179" title="Click to go to the Author Index">
             Hoenig, Wolfgang
            </a>
           </td>
           <td class="r">
            TU Berlin
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab30" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#control_architectures_and_programming" title="Click to go to the Keyword Index">
               Control Architectures and Programming
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We consider transporting a heavy payload that is attached to multiple multirotors. The current state-of-the-art controllers either do not avoid inter-robot collision at all, leading to crashes when tasked with
             <p>
              carrying payloads that are small in size compared to the cable lengths,
              <p>
               or use computational demanding nonlinear optimization. We propose an efficient optimization-based cable force allocation for a geometric payload transport controller to effectively avoid such collisions, while retaining the stability properties of the geometric controller. Our approach introduces a cascade of carefully designed quadratic programs that can be solved efficiently on highly constrained embedded flight controllers. We show that our approach exceeds the state-of-the-art controllers in terms of scalability by at least an order of magnitude for up to 10 robots. We demonstrate our method on challenging scenarios with up to three small multirotors with various payloads and cable lengths, where our controller runs in real-time directly on a microcontroller on the robots.
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt14_02">
             11:15-11:30, Paper WeBT14.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('81'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              DIVE: Deep Inertial-Only Velocity Aided Estimation for Quadrotors
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#367540" title="Click to go to the Author Index">
             Bajwa, Angad
            </a>
           </td>
           <td class="r">
            McGill University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#221158" title="Click to go to the Author Index">
             Cossette, Charles Champagne
            </a>
           </td>
           <td class="r">
            McGill University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#285179" title="Click to go to the Author Index">
             Shalaby, Mohammed Ayman
            </a>
           </td>
           <td class="r">
            McGill University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#140525" title="Click to go to the Author Index">
             Forbes, James Richard
            </a>
           </td>
           <td class="r">
            McGill University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab81" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__perception_and_autonomy" title="Click to go to the Keyword Index">
               Aerial Systems: Perception and Autonomy
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a novel deep-learning-based solution to the problem of quadrotor inertial navigation. Visual-inertial odometry (VIO) is often used for quadrotor pose estimation, where an inertial measurement unit (IMU) provides a motion prior. When VIO fails, IMU dead reckoning is often used, which quickly leads to significant pose estimation drift. Learned inertial odometry leverages deep learning and model-based filtering to improve upon dead reckoning. Efforts for quadrotors, however, rely on sensors other than, or in addition to, an IMU, or have only been proven on a specific set of trajectories. The proposed generalizable approach regresses a 3D velocity estimate from only a history of IMU measurements, and the learned outputs are applied as a correction to an on-manifold Extended Kalman Filter. The proposed algorithm is shown to be superior to the state-of-the-art in learned inertial odometry. A 42% improvement in localization accuracy is shown over the state-of-the-art on an in-distribution testing set, and a 22% improvement is shown on an out-of-distribution testing set. Additionally, the proposed algorithm shows a 43% improvement over dead reckoning in VIO failure scenarios. Lastly, this paper is accompanied by an open-source implementation at https://github.com/angadbajwa/DIVE.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt14_03">
             11:30-11:45, Paper WeBT14.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3801'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              RMS: Redundancy-Minimizing Point Cloud Sampling for Real-Time Pose Estimation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#254576" title="Click to go to the Author Index">
             Petracek, Pavel
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#132933" title="Click to go to the Author Index">
             Alexis, Kostas
            </a>
           </td>
           <td class="r">
            NTNU - Norwegian University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#113384" title="Click to go to the Author Index">
             Saska, Martin
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3801" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__perception_and_autonomy" title="Click to go to the Keyword Index">
               Aerial Systems: Perception and Autonomy
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#range_sensing" title="Click to go to the Keyword Index">
               Range Sensing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The typical point cloud sampling methods used in state estimation for mobile robots preserve a high level of point redundancy. This redundancy unnecessarily slows down the estimation pipeline and may cause drift under real-time constraints. Such undue latency becomes a bottleneck for resource-constrained robots (especially UAVs), requiring minimal delay for agile and accurate operation. We propose a novel, deterministic, uninformed, and single-parameter point cloud sampling method named RMS that minimizes redundancy within a 3D point cloud. In contrast to the state of the art, RMS balances the translation-space observability by leveraging the fact that linear and planar surfaces inherently exhibit high redundancy propagated into iterative estimation pipelines. We define the concept of gradient flow, quantifying the local surface underlying a point. We also show that maximizing the entropy of the gradient flow minimizes point redundancy for robot ego-motion estimation. We integrate RMS into the point-based KISS-ICP and feature-based LOAM odometry pipelines and evaluate experimentally on KITTI, Hilti-Oxford, and custom datasets from multirotor UAVs. The experiments demonstrate that RMS outperforms state-of-the-art methods in speed, compression, and accuracy in well-conditioned as well as in geometrically-degenerated settings.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wei2n">
             <b>
              WeI2N
             </b>
            </a>
           </td>
           <td class="r">
            Poster Area
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wei2n" title="Click to go to the Program at a Glance">
             <b>
              Interactive Session 2
             </b>
            </a>
           </td>
           <td class="r">
            Interactive Poster session
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wef2o">
             <b>
              WeF2O
             </b>
            </a>
           </td>
           <td class="r">
            Auditorium
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wef2o" title="Click to go to the Program at a Glance">
             <b>
              Forum 2 - Government Forum: Funding for Robotics Research
             </b>
            </a>
           </td>
           <td class="r">
            Forum
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wef2o_01">
             09:00-12:00, Paper WeF2O.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Government Forum: Funding for Robotics Research
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#110354" title="Click to go to the Author Index">
             Ye, Cang
            </a>
           </td>
           <td class="r">
            Virginia Commonwealth University
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wef3o">
             <b>
              WeF3O
             </b>
            </a>
           </td>
           <td class="r">
            Room 17/18
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wef3o" title="Click to go to the Program at a Glance">
             <b>
              Forum 3 - Europe Regulates Artificial Intelligence: The Challenge for
              <br/>
              Robotics
             </b>
            </a>
           </td>
           <td class="r">
            Forum
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#231557" title="Click to go to the Author Index">
             Bertolini, Andrea
            </a>
           </td>
           <td class="r">
            Scuola Superiore S. Anna
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wef3o_01">
             09:00-12:00, Paper WeF3O.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Europe Regulates Artificial Intelligence: The Challenge for Robotics
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#231557" title="Click to go to the Author Index">
             Bertolini, Andrea
            </a>
           </td>
           <td class="r">
            Scuola Superiore S. Anna
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wep2l">
             <b>
              WeP2L
             </b>
            </a>
           </td>
           <td class="r">
            Auditorium
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wep2l" title="Click to go to the Program at a Glance">
             <b>
              Plenary 2: Building Trust in Autonomous Systems: Security Strategies for
              <br/>
              the Next Generation of Robotics, by Najwa Aaraj
             </b>
            </a>
           </td>
           <td class="r">
            Plenary session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#101631" title="Click to go to the Author Index">
             Dias, Jorge
            </a>
           </td>
           <td class="r">
            Khalifa University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wep2l_01">
             12:00-13:00, Paper WeP2L.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Building Trust in Autonomous Systems: Security Strategies for the Next Generation of Robotics
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#428610" title="Click to go to the Author Index">
             Najwa, Aaraj
            </a>
           </td>
           <td class="r">
            TII
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="welu_br">
             <b>
              WeLU_BR
             </b>
            </a>
           </td>
           <td class="r">
            Poster Area
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#welu_br" title="Click to go to the Program at a Glance">
             <b>
              Lunch (Wed)
             </b>
            </a>
           </td>
           <td class="r">
            Session
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wek2n">
             <b>
              WeK2N
             </b>
            </a>
           </td>
           <td class="r">
            Auditorium
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wek2n" title="Click to go to the Program at a Glance">
             <b>
              Keynote Session 2 - Biorobotics
             </b>
            </a>
           </td>
           <td class="r">
            Keynote session
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wek2n_01">
             14:00-15:30, Paper WeK2N.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Using Robots to Investigate the Neuroscience and Biomechanics of Animal Locomotion
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105018" title="Click to go to the Author Index">
             Ijspeert, Auke
            </a>
           </td>
           <td class="r">
            EPFL
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wek2n_02">
             14:00-15:30, Paper WeK2N.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             A Vision towards Bioinspired Sustainable Robotics
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104024" title="Click to go to the Author Index">
             Mazzolai, Barbara
            </a>
           </td>
           <td class="r">
            Istituto Italiano di Tecnologia
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wek2n_03">
             14:00-15:30, Paper WeK2N.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Building on Nature's Collective Intelligence
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#111035" title="Click to go to the Author Index">
             Werfel, Justin
            </a>
           </td>
           <td class="r">
            Harvard University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wek2n_04">
             14:00-15:30, Paper WeK2N.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Translating Nature: Bio-Inspired Solutions for Robotic Surgery
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101975" title="Click to go to the Author Index">
             Althoefer, Kaspar
            </a>
           </td>
           <td class="r">
            Queen Mary University of London
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wepi3t1">
             <b>
              WePI3T1
             </b>
            </a>
           </td>
           <td class="r">
            Room 1
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wepi3t1" title="Click to go to the Program at a Glance">
             <b>
              Robotics and Automation III
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#244803" title="Click to go to the Author Index">
             Bombieri, Nicola
            </a>
           </td>
           <td class="r">
            University of Verona
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#100151" title="Click to go to the Author Index">
             Sugano, Shigeki
            </a>
           </td>
           <td class="r">
            Waseda University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t1_01">
             15:30-16:30, Paper WePI3T1.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1890'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Exploratory Motion Guided Tactile Learning for Shape-Consistent Robotic Insertion
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#237373" title="Click to go to the Author Index">
             Yan, Gang
            </a>
           </td>
           <td class="r">
            Waseda University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#390877" title="Click to go to the Author Index">
             He, Jinsong
            </a>
           </td>
           <td class="r">
            WASEDA University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#184706" title="Click to go to the Author Index">
             Funabashi, Satoshi
            </a>
           </td>
           <td class="r">
            Waseda University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#108304" title="Click to go to the Author Index">
             Schmitz, Alexander
            </a>
           </td>
           <td class="r">
            Waseda University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100151" title="Click to go to the Author Index">
             Sugano, Shigeki
            </a>
           </td>
           <td class="r">
            Waseda University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1890" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Intelligent robots are expected to do manipulation tasks relying on real-time sensing feedback. Especially, tactile sensing plays a more and more important role in precise manipulation tasks. For example, a 1~mm error while inserting a USB stick, which is hard to perceive visually, will result in a failed insertion or even break the USB stick.	 In this paper, to estimate and compensate residual position uncertainties during robotic insertion tasks, an exploration motion is introduced to acquire environment information by tactile sensing and a state-of-the-art transformer-based neural network is proposed to estimate the error distance from long-duration tactile sensing data. Our system is trained on over 2000 insertion trials with basic geometry shaped 3D printed objects. Without any prior knowledge, we achieve an 85% insertion success rate with average 5 attempts on 4 unseen daily objects relying only on tactile feedback acquired from our proposed exploratory motion. It is noteworthy that our designed exploration motion can provide insightful information about extrinsic contact information and our proposed learning model exceeds previous baselines in extracting useful information regarding the contact interaction between the grasped object and the environment.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t1_02">
             15:30-16:30, Paper WePI3T1.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3333'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              LTL-D*: Incrementally Optimal Replanning for Feasible and Infeasible Tasks in Linear Temporal Logic Specifications
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#354843" title="Click to go to the Author Index">
             Ren, Jiming
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398960" title="Click to go to the Author Index">
             Miller, Haris
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#197904" title="Click to go to the Author Index">
             Feigh, Karen
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#147487" title="Click to go to the Author Index">
             Coogan, Samuel
            </a>
           </td>
           <td class="r">
            Georgia Tech
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#158317" title="Click to go to the Author Index">
             Zhao, Ye
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3333" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#formal_methods_in_robotics_and_automation" title="Click to go to the Keyword Index">
               Formal Methods in Robotics and Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#task_planning" title="Click to go to the Keyword Index">
               Task Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents an incremental replanning algorithm, dubbed LTL-D*, for temporal-logic-based motion planning in a dynamically changing environment. Unexpected changes in the environment may lead to failures in satisfying a task specification in the form of a Linear Temporal Logic (LTL). In this study, the considered failures are categorized into two classes: (i) the desired LTL specification can be satisfied via replanning, and (ii) the desired LTL specification is infeasible to meet strictly and can only be satisfied in a "relaxed" fashion. To address these failures, the proposed algorithm finds an optimal replanning solution that minimally violates desired task specifications. In particular, our approach leverages the D* Lite algorithm and employs a distance metric within the synthesized automaton to quantify the degree of the task violation and then replan incrementally. This ensures plan optimality and reduces planning time, especially when frequent replanning is required. Our approach is implemented in a robot navigation simulation to demonstrate a significant improvement in the computational efficiency for replanning by two orders of magnitude.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t1_03">
             15:30-16:30, Paper WePI3T1.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2264'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Cooperative Modular Manipulation with Numerous Cable-Driven Robots for Assistive Construction and Gap Crossing
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#286672" title="Click to go to the Author Index">
             Murphy, Kevin
            </a>
           </td>
           <td class="r">
            University of Illinois at Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#253766" title="Click to go to the Author Index">
             Soares, João Carlos Virgolino
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#195833" title="Click to go to the Author Index">
             Yim, Justin K.
            </a>
           </td>
           <td class="r">
            University of Illinois Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#333206" title="Click to go to the Author Index">
             Nottage, Dustin
            </a>
           </td>
           <td class="r">
            Construction Engineering Research Lab
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#325306" title="Click to go to the Author Index">
             Soylemezoglu, Ahmet
            </a>
           </td>
           <td class="r">
            US Army Corps of Engineers
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#159651" title="Click to go to the Author Index">
             Ramos, Joao
            </a>
           </td>
           <td class="r">
            University of Illinois at Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2264" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#robotics_and_automation_in_construction" title="Click to go to the Keyword Index">
               Robotics and Automation in Construction
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#tendon_wire_mechanism" title="Click to go to the Keyword Index">
               Tendon/Wire Mechanism
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#parallel_robots" title="Click to go to the Keyword Index">
               Parallel Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Soldiers in the field often need to cross negative obstacles, such as rivers or canyons, to reach goals or safety. Military gap crossing involves on-site temporary bridges construction. However, this procedure is conducted with dangerous, time and labor intensive operations, and specialized machinery. We envision a scalable robotic solution inspired by advancements in force-controlled and Cable Driven Parallel Robots (CDPRs); this solution can address the challenges inherent in this transportation problem, achieving fast, efficient, and safe deployment and field operations. We introduce the embodied vision in Co3MaNDR, a solution to the military gap crossing problem, a distributed robot consisting of several modules simultaneously pulling on a central payload, controlling the cables’ tensions to achieve complex objectives, such as precise trajectory tracking or force amplification. Hardware experiments demonstrate teleoperation of a payload, trajectory following, and the sensing and amplification of operators’ applied physical forces during slow operations. An operator was shown to manipulate a 27.2 kg (60 lb) payload with an average force utilization of 14.5% of its weight. Results indicate that the system can be scaled up to heavier payloads without compromising performance or introducing superfluous complexity. This research lays a foundation to expand CDPR technology to uncoordinated and unstable mobile platforms in unknown environments
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t1_04">
             15:30-16:30, Paper WePI3T1.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('772'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              GDM-Net: Gas Distribution Mapping with a Mobile Robot Using Deep Reinforcement Learning and Gaussian Process Regression
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#378189" title="Click to go to the Author Index">
             Kulbaka, Iliya
            </a>
           </td>
           <td class="r">
            University of North Florida
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#159383" title="Click to go to the Author Index">
             Dutta, Ayan
            </a>
           </td>
           <td class="r">
            University of North Florida
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#237038" title="Click to go to the Author Index">
             Kreidl, Patrick
            </a>
           </td>
           <td class="r">
            University of North Florida
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#138744" title="Click to go to the Author Index">
             Bölöni, Ladislau
            </a>
           </td>
           <td class="r">
            University of Central Florida
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#307184" title="Click to go to the Author Index">
             Roy, Swapnoneel
            </a>
           </td>
           <td class="r">
            University of North Florida
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab772" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#environment_monitoring_and_management" title="Click to go to the Keyword Index">
               Environment Monitoring and Management
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In a gas distribution mapping (GDM) task, the objective of a mobile robot is to map the gas concentrations of an airborne chemical over a region of interest using onboard sensing. Given the limited battery budget available to the robot, covering the entire area to measure gas concentrations at every location might be infeasible. Assuming that the robot only has a budget for b meters of travel, in the rest of the locations, gas concentrations can be inferred using a supervised machine learning technique, namely the Gaussian Process (GP). In this paper, we propose a novel technique that combines deep reinforcement learning and GP regression to find an effective policy for GDM. We have implemented the proposed technique in Python within a 16×16 4-connected plane. We have used six types of Gaussian plumes to validate our presented approach. Compared to two popular baselines, our approach outperforms greedy and random exploration by 62% and 151% in terms of earned rewards, while outperforming them by 47% and 345%, respectively, in terms of the precision of gas distribution modeling in all test cases without obstacles. Our approach also improves the coverage of the exploration while consequently reducing the uncertainty in the prediction.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t1_05">
             15:30-16:30, Paper WePI3T1.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('608'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              GNC Design and Orbital Performance Evaluation of ISS Onboard Autonomous Free-Flying Robot Int-Ball2
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#337864" title="Click to go to the Author Index">
             Nishishita, Taisei
            </a>
           </td>
           <td class="r">
            Japan Aerospace Exploration Agency
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100878" title="Click to go to the Author Index">
             Watanabe, Keisuke
            </a>
           </td>
           <td class="r">
            Japan Aerospace Exploration Agency
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#148000" title="Click to go to the Author Index">
             Hirano, Daichi
            </a>
           </td>
           <td class="r">
            Japan Aerospace Exploration Agency
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#207702" title="Click to go to the Author Index">
             Mitani, Shinji
            </a>
           </td>
           <td class="r">
            JAXA
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab608" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#space_robotics_and_automation" title="Click to go to the Keyword Index">
               Space Robotics and Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#dynamics" title="Click to go to the Keyword Index">
               Dynamics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             A variety of experiments have been conducted on the International Space Station (ISS), and many discoveries have been obtained. In on-orbit experiments, the crew conducts the tests instead of researchers on the ground. Crew resources are limited and precious, and their effective utilization is crucial to maximize the results.
             <p>
              One of the crew tasks that has often been discussed to improve efficiency is the photography task. When performing experiments on the ISS's Japanese Experiment Module (JEM), the crew had to set up cameras around the module to send videos of their work to the ground. However, shooting at an arbitrary location is impossible because the camera must be mounted on the JEM wall. In addition, it is not easy to repeatedly instruct the crew to fine-tune the camera's angle of view, which consumes much valuable crew time. To solve this, Japan Aerospace Exploration Agency (JAXA) developed the Int-Ball, an autonomous mobile camera robot. The robot is designed to receive commands from the ground, fly autonomously inside the JEM, and shooting from an arbitrary location. The introduction of this robot is expected to significantly reduce the crew time for shooting.
              <p>
               The first Int-Ball was launched in 2017 to verify basic functions such as the propeller propulsion system. The next-generation Int-Ball2 was recently developed, incorporating lessons learned from the on-orbit experiments of the first model. Int-Ball2 has unique features compared to other free-flying robots in space, including its small size for use in crowded environments and its high thrust despite its size. In addition, the navigation system uses a visual SLAM algorithm, which does not rely on external markers.
               <p>
                This paper first introduces the design of the guidance, navigation and control (GNC) and the propulsion systems that enable the Int-Ball2's autonomous flight function. This robot has unique features compared to other space free-flying robots, including its small size for use in crowded environments and its high thrust despite its size. The results of orbital performance verification tests for 6-DOF translational and rotational motion are also presented in this paper. The analysis indicated that the proposed method provided sufficient flight performance to conduct the photography. Finally, the results of ground tests simulating the microgravity environment are compared with the results of orbital experiments in order to evaluate the differences in the robot's mobility performance in these tests. The results confirmed that the ground verification method in this paper was valid for achieving stable on-orbit mobility.
               </p>
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t1_06">
             15:30-16:30, Paper WePI3T1.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1969'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Development of a Peristaltic Flexible Transfer System for Transporting Feces under Microgravity: Construction and Validation of Transport Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#369929" title="Click to go to the Author Index">
             Kawano, Masaki
            </a>
           </td>
           <td class="r">
            Chuo University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#322469" title="Click to go to the Author Index">
             Uzawa, Shogo
            </a>
           </td>
           <td class="r">
            Chuo University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#322470" title="Click to go to the Author Index">
             Yamazaki, Chiaki
            </a>
           </td>
           <td class="r">
            Japan Aerospace Exploration Agency
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102634" title="Click to go to the Author Index">
             Nakamura, Taro
            </a>
           </td>
           <td class="r">
            Chuo University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1969" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#space_robotics_and_automation" title="Click to go to the Keyword Index">
               Space Robotics and Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#flexible_robotics" title="Click to go to the Keyword Index">
               Flexible Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#hydraulic_pneumatic_actuators" title="Click to go to the Keyword Index">
               Hydraulic/Pneumatic Actuators
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this study, we propose a peristaltic flexible transfer system for transferring feces in a free piping route. Currently, human feces is incinerated and disposed in space, such as on the International Space Station. As feces contain a large amount of reusable organic matter and water, the ability to recycle feces will improve the performance of manned space technology. However, existing space toilets are not designed to reuse feces, and the transportation of feces from the toilet bowl to the collection area is a technical challenge. A method for transporting intermittent supplies such as feces with less energy and water consumption is required. In a previous study, a peristaltic transfer system was developed based on the peristalsis of the intestinal tract of living organisms. In this method, multiple pump units driven by low air pressure generate peristaltic motion, which enables horizontal, vertical, and curved transfer of simulated feces. However, because the frame of each unit is rigid, the transport path cannot be changed flexibly, and the design must be adapted to the installation location. Therefore, the frame must be flexible. We propose a peristaltic flexible transfer system for transferring feces in a free piping route. First, we construct a simple model of content transfer using the peristaltic flexible transfer system and calculate the transfer rate based on data obtained from basic characteristic experiments of a single unit. Then, we conduct an actual content transfer experiment using the transfer system and compare the results with the simplified model results.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t1_07">
             15:30-16:30, Paper WePI3T1.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2648'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Test-Time Certifiable Self-Supervision to Bridge the Sim2Real Gap in Event-Based Satellite Pose Estimation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#336282" title="Click to go to the Author Index">
             Jawaid, Mohsi
            </a>
           </td>
           <td class="r">
            The University of Adelaide
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#301042" title="Click to go to the Author Index">
             Talak, Rajat
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#155702" title="Click to go to the Author Index">
             Latif, Yasir
            </a>
           </td>
           <td class="r">
            University of Adelaide
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#119426" title="Click to go to the Author Index">
             Carlone, Luca
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#204257" title="Click to go to the Author Index">
             Chin, Tat-Jun
            </a>
           </td>
           <td class="r">
            The University of Adelaide
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2648" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#space_robotics_and_automation" title="Click to go to the Keyword Index">
               Space Robotics and Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Deep learning plays a critical role in vision-based satellite pose estimation. However, the scarcity of real data from the space environment means that deep models need to be trained using synthetic data, which raises the Sim2Real domain gap problem. A major cause of the Sim2Real gap are novel lighting conditions encountered during test time. Event sensors have been shown to provide some robustness against lighting variations in vision-based pose estimation. However, challenging lighting conditions due to strong directional light can still cause undesirable effects in the output of commercial off-the-shelf event sensors, such as noisy/spurious events and inhomogeneous event densities on the object. Such effects are non-trivial to simulate in software, thus leading to Sim2Real gap in the event domain. To close the Sim2Real gap in event-based satellite pose estimation, the paper proposes a test-time self-supervision scheme with a certifier module. Self-supervision is enabled by an optimisation routine that aligns a dense point cloud of the predicted satellite pose with the event data to attempt to rectify the inaccurately estimated pose. The certifier attempts to verify the corrected pose, and only certified test-time inputs are backpropagated via implicit differentiation to refine the predicted landmarks, thus improving the pose estimates and closing the Sim2Real gap. Results show that the our method outperforms established test-time adaptation schemes.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t1_08">
             15:30-16:30, Paper WePI3T1.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3383'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Stability of Tethered Ground Robots on Extreme Terrains
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#378878" title="Click to go to the Author Index">
             Kumar, Rahul
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#271220" title="Click to go to the Author Index">
             Chipade, Vishnu S.
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#166106" title="Click to go to the Author Index">
             Yong, Sze Zheng
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3383" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#space_robotics_and_automation" title="Click to go to the Keyword Index">
               Space Robotics and Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#cooperating_robots" title="Click to go to the Keyword Index">
               Cooperating Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In the absence of a tether attachment mechanism that can provide infinitely large tension to the tethered robots moving on extreme planetary terrains, there is a limit on how much tension can be realistically generated or supported by the tether. In this paper, we consider a team of two robots tethered together moving on extreme terrains. The traction on the wheels of the robot and the friction between the tether and the tether attachment surfaces/objects (e.g., rocks) is the only way to support the tether tension. Given a path for the robots to navigate, we provide a systematic algorithm to check if the robots will be stable along the given path while considering the maximum constraints on the tension generated or supported by the tether. The results are validated via simulation experiments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t1_09">
             15:30-16:30, Paper WePI3T1.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3415'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Satellite-Model-Free Deep Learning Based Pose Estimation of Non-Cooperative Satellite and Tracking Using Navigation Filter
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#235994" title="Click to go to the Author Index">
             Shukla, Shubham
            </a>
           </td>
           <td class="r">
            Tata Consultancy Services
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#296743" title="Click to go to the Author Index">
             Srivastava, Raunak
            </a>
           </td>
           <td class="r">
            TCS Research
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#296744" title="Click to go to the Author Index">
             Lima, Rolif
            </a>
           </td>
           <td class="r">
            TCS Research
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#132781" title="Click to go to the Author Index">
             Bera, Titas
            </a>
           </td>
           <td class="r">
            TCS Innovation Labs
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3415" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#space_robotics_and_automation" title="Click to go to the Keyword Index">
               Space Robotics and Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_tracking" title="Click to go to the Keyword Index">
               Visual Tracking
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             One core component of Active Debris Removal (ADR) and On-Orbit Servicing (OOS) missions in space is to estimate and track the relative pose of a non-cooperative satellite in close proximity. Conventionally, Image Processing methods have been popular in pose estimation by employing manual feature extraction techniques. But the performance of such methods plateaus in the challenging illumination conditions and sensor capability constraints in space, because of which Deep Learning (DL)-based approaches have gained traction. This paper aims to provide an improvement over the existing state-of-the-art direct pose estimation methods from a monocular camera, without relying on any 3D model of the target satellite. The main contribution of this work is to develop a general purpose satellite-invariant pose estimation architecture with improved accuracy and implement an adaptive navigation filter over it to track the pose continuously over a stream of images. The pose estimation module includes a modified DenseNet architecture. In order to test the generalization capability, the proposed pose estimation module is tested on the SPEED, SPEED+, SHIRT and URSO datasets and compared with other existing methods. The advantage of the proposed method is that the same model architecture is able to give accurate pose estimation results for different satellite datasets. To perform continuous tracking of the relative pose, an adaptive EKF (Extended Kalman Filter) is implemented on the initial pose estimates. For performance evaluation of the navigation filter, the accuracy goals required for the relative navigation of Hubble Space Telescope SM4 mission are considered while testing on the SHIRT dataset.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t1_10">
             15:30-16:30, Paper WePI3T1.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('99'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Flight Structure Optimization of Modular Reconfigurable UAVs
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#209690" title="Click to go to the Author Index">
             Su, Yao
            </a>
           </td>
           <td class="r">
            Beijing Institute for General Artificial Intelligence
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#191567" title="Click to go to the Author Index">
             Jiao, Ziyuan
            </a>
           </td>
           <td class="r">
            Beijing Institute for General Artificial Intelligence
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#233455" title="Click to go to the Author Index">
             Zhang, Zeyu
            </a>
           </td>
           <td class="r">
            Beijing Institute for General Artificial Intelligence
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#245248" title="Click to go to the Author Index">
             Zhang, Jingwen
            </a>
           </td>
           <td class="r">
            University of California, Los Angeles
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#351396" title="Click to go to the Author Index">
             Li, Hang
            </a>
           </td>
           <td class="r">
            Beijing Institute for General Artificial Intelligence
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#241349" title="Click to go to the Author Index">
             Wang, Meng
            </a>
           </td>
           <td class="r">
            Beijing Institute for General Artificial Intelligence
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#196468" title="Click to go to the Author Index">
             Liu, Hangxin
            </a>
           </td>
           <td class="r">
            Beijing Institute for General Artificial Intelligence (BIGAI)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab99" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#cellular_and_modular_robots" title="Click to go to the Keyword Index">
               Cellular and Modular Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a Genetic Algorithm (GA) that reconfigures the modular Unmanned Aerial Vehicles (UAVs) to form an over-actuated flight structure with better dynamic properties. Previous research either utilized expert knowledge to design the flight structure for a specific task or relied on enumeration-based algorithms that required extensive computation to find an optimal flight structure. Based on a modular quadcopter MARVEL, which connects to a cubic docking frame through a passive gimbal mechanism and serves as an omni-directional thrust generator in a flight structure, the proposed GA efficiently finds the suboptimal configuration that guarantees over-actuation and consumes minimal control effort. After implementing a hierarchical controller in simulation, we validate that the flight structure generated from the proposed method can (i) accurately track challenging trajectories with decoupled position and attitude commands and (ii) significantly reduce computational cost compared with the traditional enumeration method.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t1_11">
             15:30-16:30, Paper WePI3T1.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('548'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Task-Driven Computational Framework for Simultaneously Optimizing Design and Mounted Pose of Modular Reconfigurable Manipulators
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#275007" title="Click to go to the Author Index">
             Lei, Maolin
            </a>
           </td>
           <td class="r">
            Humanoids and Human Centered Mechatronics (HHCM) Research Line O
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#287615" title="Click to go to the Author Index">
             Romiti, Edoardo
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#208752" title="Click to go to the Author Index">
             Laurenzi, Arturo
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105401" title="Click to go to the Author Index">
             Tsagarakis, Nikos
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab548" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#cellular_and_modular_robots" title="Click to go to the Keyword Index">
               Cellular and Modular Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#robotics_and_automation_in_construction" title="Click to go to the Keyword Index">
               Robotics and Automation in Construction
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Modular reconfigurable manipulators enable quick adaptation and versatility to address different application environments and tailor to the specific requirements of the tasks. Task performance significantly depends on the manipulator's mounted pose and morphology design, therefore posing the need of methodologies for selecting suitable modular robot configurations and mounted pose that can address the specific task requirements and required performance. Morphological changes in modular robots can be derived through a discrete optimization process involving the selective addition or removal of modules. In contrast, the adjustment of the mounted pose operates within a continuous space, allowing for smooth and precise alterations in both orientation and position. This work introduces a computational framework that simultaneously optimizes modular manipulators' mounted pose and morphology. The core of the work is that we design a mapping function that textit{implicitly} captures the morphological state of manipulators in the continuous space. This transformation function unifies the optimization of mounted pose and morphology within a continuous space. Furthermore, our optimization framework incorporates a array of performance metrics, such as minimum joint effort and maximum manipulability, and considerations for trajectory execution error and physical and safety constraints. To highlight our method's benefits, we compare it with previous methods that framed such problem as a combinatorial optimization problem and demonstrate its practicality in selecting the modular robot configuration for executing a drilling task with the CONCERT modular robotic platform.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t1_12">
             15:30-16:30, Paper WePI3T1.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('701'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robot Design Optimization with Rotational and Prismatic Joints Using Black-Box Multi-Objective Optimization
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#206398" title="Click to go to the Author Index">
             Kawaharazuka, Kento
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106350" title="Click to go to the Author Index">
             Okada, Kei
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106348" title="Click to go to the Author Index">
             Inaba, Masayuki
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab701" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#cellular_and_modular_robots" title="Click to go to the Keyword Index">
               Cellular and Modular Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#evolutionary_robotics" title="Click to go to the Keyword Index">
               Evolutionary Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robots generally have a structure that combines rotational joints and links in a serial fashion. On the other hand, various joint mechanisms are being utilized in practice, such as prismatic joints, closed links, and wire-driven systems. Previous research have focused on individual mechanisms, proposing methods to design robots capable of achieving given tasks by optimizing the length of links and the arrangement of the joints. In this study, we propose a method for the design optimization of robots that combine different types of joints, specifically rotational and prismatic joints. The objective is to automatically generate a robot that minimizes the number of joints and link lengths while accomplishing a desired task, by utilizing a black-box multi-objective optimization approach. This enables the simultaneous observation of a diverse range of body designs through the obtained Pareto solutions. Our findings confirm the emergence of practical and known combinations of rotational and prismatic joints, as well as the discovery of novel joint combinations.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t1_13">
             15:30-16:30, Paper WePI3T1.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2917'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              ROS-Lite2: Autonomous-Driving Software Platform for Clustered Many-Core Processor
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398712" title="Click to go to the Author Index">
             Tajima, Yuta
            </a>
           </td>
           <td class="r">
            Saitama University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#399499" title="Click to go to the Author Index">
             Tsunoda, Shuhei
            </a>
           </td>
           <td class="r">
            Saitama University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#218613" title="Click to go to the Author Index">
             Azumi, Takuya
            </a>
           </td>
           <td class="r">
            Saitama University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2917" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#embedded_systems_for_robotic_and_automation" title="Click to go to the Keyword Index">
               Embedded Systems for Robotic and Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#software_architecture_for_robotic_and_automation" title="Click to go to the Keyword Index">
               Software Architecture for Robotic and Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#wheeled_robots" title="Click to go to the Keyword Index">
               Wheeled Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In intelligent robotics, which spans from assistive devices to automation, the development of autonomous systems merges computational and physical capabilities, such as in autonomous wheelchairs. Many-core processors, essential for real-time operations, pose challenges in software adaptability. This paper introduces ROS-lite2, which is a software platform for autonomous vehicles, utilizing a ROS~2 framework based on many-core processors to boost flexibility and simplify deployment. Our method facilitates complex function integration and intuitive operation with less hardware knowledge. Experiments with an autonomous wheelchair demonstrate the platform's effectiveness in improving autonomy and reducing development effort, advancing robotic assistance.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t1_14">
             15:30-16:30, Paper WePI3T1.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3095'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              NeRF-Enabled Analysis-Through-Synthesis for ISAR Imaging of Small Everyday Objects with Sparse and Noisy UWB Radar Data
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#390925" title="Click to go to the Author Index">
             Tasnim Oshim, Md Farhan
            </a>
           </td>
           <td class="r">
            University of Massachusetts Amherst
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391464" title="Click to go to the Author Index">
             Reed, Albert
            </a>
           </td>
           <td class="r">
            Arizona State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#390916" title="Click to go to the Author Index">
             Jayasuriya, Suren
            </a>
           </td>
           <td class="r">
            Arizona State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#289724" title="Click to go to the Author Index">
             Rahman, Tauhidur
            </a>
           </td>
           <td class="r">
            University of California San Diego
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3095" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#sensor_networks" title="Click to go to the Keyword Index">
               Sensor Networks
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#robotics_in_hazardous_fields" title="Click to go to the Keyword Index">
               Robotics in Hazardous Fields
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Inverse Synthetic Aperture Radar (ISAR) imaging presents a formidable challenge when it comes to small everyday objects due to their limited Radar Cross Section (RCS) and the inherent resolution constraints of radar systems. Existing ISAR reconstruction methods including backprojection algorithm often require complex setups and controlled environments, rendering them impractical for many real-world noisy scenarios. In this paper, we propose a novel Analysis-through-Synthesis (ATS) framework enabled by Neural Radiance Fields (NeRF) for high-resolution coherent ISAR imaging of small objects using sparse and noisy Ultra-Wideband (UWB) radar data with an inexpensive and portable setup. Our end-to-end framework integrates ultra-wideband radar wave propagation, reflection characteristics, and scene priors, enabling efficient 2D scene reconstruction without the need for costly anechoic chambers or complex measurement testbeds. With qualitative and quantitative comparisons, we demonstrate that the proposed method outperforms traditional techniques and generates ISAR images of complex scenes with multiple targets and complex structures in Non-Line of Sight (NLOS) and noisy scenarios, particularly with limited number of views and sparse UWB radar scans. This work represents a significant step towards practical, cost-effective, and high-resolution ISAR imaging of small everyday objects, with broad implications for robotics, remote sensing, and surveillance applications.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t1_15">
             15:30-16:30, Paper WePI3T1.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('633'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Optimizing Kubernetes Deployment of Robotic Applications with HEFT-Based Container Orchestration
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#324348" title="Click to go to the Author Index">
             Lumpp, Francesco
            </a>
           </td>
           <td class="r">
            University of Verona
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#324352" title="Click to go to the Author Index">
             Fummi, Franco
            </a>
           </td>
           <td class="r">
            University of Verona
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#244803" title="Click to go to the Author Index">
             Bombieri, Nicola
            </a>
           </td>
           <td class="r">
            University of Verona
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab633" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_architecture_for_robotic_and_automation" title="Click to go to the Keyword Index">
               Computer Architecture for Robotic and Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#software_architecture_for_robotic_and_automation" title="Click to go to the Keyword Index">
               Software Architecture for Robotic and Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#software_hardware_integration_for_robot_systems" title="Click to go to the Keyword Index">
               Software-Hardware Integration for Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This study addresses the challenge of deploying robotic software with Quality of Service (QoS) constraints in Edge-Cloud computing clusters. The paper introduces HEFT4K, an event-driven scheduling method tailored for Kubernetes-managed systems based on the Heterogeneous Early Finish Time (HEFT) algorithm. This algorithm reduces software execution time (makespan) and facilitates re-mapping in case of node failures, involving only essential containers to maintain uninterrupted robot functionality. Experimental results, conducted on a real-world robot and synthetic benchmarks, show a 75% speedup in makespan compared to the standard Kubernetes scheduler, enhancing the efficiency of QoS-focused scheduling for robotic applications in distributed systems.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t1_16">
             15:30-16:30, Paper WePI3T1.16
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1974'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Hardware-Based Time Synchronization for a Multi-Sensor System
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397645" title="Click to go to the Author Index">
             Wang, Yueqi
            </a>
           </td>
           <td class="r">
            University of New South Wales
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#291685" title="Click to go to the Author Index">
             Liu, Tangyou
            </a>
           </td>
           <td class="r">
            The University of New South Wales
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#254231" title="Click to go to the Author Index">
             Feng, Licheng
            </a>
           </td>
           <td class="r">
            University of New South Wales
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#399395" title="Click to go to the Author Index">
             Wang, Jinze
            </a>
           </td>
           <td class="r">
            Swinburne University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397647" title="Click to go to the Author Index">
             Yang, Yang
            </a>
           </td>
           <td class="r">
            University of New South Wales
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#399394" title="Click to go to the Author Index">
             Bao, Jianjun
            </a>
           </td>
           <td class="r">
            China Coal Technology and Engineering Group
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#340668" title="Click to go to the Author Index">
             Li, Binghao
            </a>
           </td>
           <td class="r">
            UNSW
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#149133" title="Click to go to the Author Index">
             Wu, Liao
            </a>
           </td>
           <td class="r">
            University of New South Wales
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1974" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#embedded_systems_for_robotic_and_automation" title="Click to go to the Keyword Index">
               Embedded Systems for Robotic and Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Accurate time synchronization is crucial for multisensor fusion, which is widely used in mobile robotics, autonomous driving, and virtual reality. Despite many advancements, precise multi-sensor synchronization is still challenging due to the sensors’ internal characteristics, data filtering, disjointed clock reference, and transmission delay caused by operation system scheduling. This paper proposes a novel hardware-based synchronization solution to achieve synchronization in microsecond-level precision. By introducing a Sensor Adaptor board that provides a unified clock reference, the proposed hardware architecture enables high-precision synchronization across multiple sensors. Furthermore, we developed a method for visual-inertial time synchronization that actively controls the exposure duration using an ambient light sensor. By managing the IMU clock signal and exposure trigger, we align the camera’s sampling moment with the authentic IMU sampling time and significantly reduce the time discrepancy in the Visual-Inertial system. Experiments are conducted to evaluate the efficiency of the proposed method and system, including comparisons with previous work. The results indicate that our method can achieve precise time synchronization and be successfully implemented in multi-sensor systems.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t1_17">
             15:30-16:30, Paper WePI3T1.17
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('986'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Procedural Generation of Tunnel Networks for Unsupervised Training and Testing in Underground Applications
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#323651" title="Click to go to the Author Index">
             Cano, Lorenzo
            </a>
           </td>
           <td class="r">
            Universidad De Zaragoza
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105200" title="Click to go to the Author Index">
             Mosteo, Alejandro R.
            </a>
           </td>
           <td class="r">
            Centro Universitario De La Defensa De Zaragoza
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#115460" title="Click to go to the Author Index">
             Tardioli, Danilo
            </a>
           </td>
           <td class="r">
            Centro Universitario De La Defensa
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab986" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#software_tools_for_benchmarking_and_reproducibility" title="Click to go to the Keyword Index">
               Software Tools for Benchmarking and Reproducibility
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#simulation_and_animation" title="Click to go to the Keyword Index">
               Simulation and Animation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robot_learning" title="Click to go to the Keyword Index">
               Data Sets for Robot Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Developing a robotic application requires thorough testing of the complete system to ensure its reliability. However, depending on the target environment, real-life testing can be difficult to carry out, which favors simulations. Also, some techniques like those based on machine learning, may require large varieties of sensor data, which can be gathered in simulation with ease, whereas doing the same in real environments can pose a great challenge.
             <p>
              This work presents a flexible approach to the procedural generation of tunnel networks suitable for underground robotics simulations. The method starts with a graph representation of an underground environment, and applies a custom meshing strategy to generate tunnels that follow the graph structure. This mesh can then be imported into the desired simulation software. The ease of use of this method allows for the testing of robotic applications in an arbitrary number of different environments in completely automated workflows.
             </p>
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wepi3t2">
             <b>
              WePI3T2
             </b>
            </a>
           </td>
           <td class="r">
            Room 2
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wepi3t2" title="Click to go to the Program at a Glance">
             <b>
              Robotics in Healthcare II
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#105803" title="Click to go to the Author Index">
             Simaan, Nabil
            </a>
           </td>
           <td class="r">
            Vanderbilt University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#100150" title="Click to go to the Author Index">
             Agrawal, Sunil
            </a>
           </td>
           <td class="r">
            Columbia University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t2_01">
             15:30-16:30, Paper WePI3T2.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3093'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Robotic Mediation Device for Skill Assessment and Training During Colonoscopy
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#354876" title="Click to go to the Author Index">
             Richards, Olivia
            </a>
           </td>
           <td class="r">
            Vanderbilt University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#295494" title="Click to go to the Author Index">
             Ahronovich, Elan
            </a>
           </td>
           <td class="r">
            Vanderbilt ARMA
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#298434" title="Click to go to the Author Index">
             Shihora, Neel
            </a>
           </td>
           <td class="r">
            Vanderbilt University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398825" title="Click to go to the Author Index">
             Yildiz, Ahmet
            </a>
           </td>
           <td class="r">
            Vanderbilt University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398901" title="Click to go to the Author Index">
             Atoum, Jumana
            </a>
           </td>
           <td class="r">
            Vanderbilt University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#225357" title="Click to go to the Author Index">
             Wu, Jie Ying
            </a>
           </td>
           <td class="r">
            Vanderbilt University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#196609" title="Click to go to the Author Index">
             Obstein, Keith
            </a>
           </td>
           <td class="r">
            Vanderbilt University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105803" title="Click to go to the Author Index">
             Simaan, Nabil
            </a>
           </td>
           <td class="r">
            Vanderbilt University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3093" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#haptics_and_haptic_interfaces" title="Click to go to the Keyword Index">
               Haptics and Haptic Interfaces
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Colonoscopy demands multi-finger coordinated motion to achieve safe navigation. As a result, training for colonoscopists is challenging and skill assessment currently relies on subjective scoring by expert proctors. There is a need to provide tools for skill assessment and aid with training new interventionalists. This paper presents a new concept of an in-hand robotic mediation device that can be used for both skill assessment and training. The robotic device can be used to infer the kinematic motion as well as the power input of a user - both of which are proposed to be used for skill assessment and subtask skill classification. Preliminary results collected expert and novice users performing colonoscopy navigation are used to demonstrate this device as a skill assessment tool. A machine-learning model (classification and regression trees) is used for subtask classification of skill and evaluating the most important classification features. A user study demonstrates the effectiveness of this in hand haptic training and assessment tool. We believe that, in the future, this device will enable accelerated skill assessment and training and possible semi-automation of difficult maneuvers.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t2_02">
             15:30-16:30, Paper WePI3T2.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1059'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              X-Ray-Guided Magnetic Fields for Wireless Control of Untethered Magnetic Robots in Cerebral Vascular Phantoms
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#336574" title="Click to go to the Author Index">
             Ligtenberg, Leendert-Jan Wouter
            </a>
           </td>
           <td class="r">
            University of Twente
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393062" title="Click to go to the Author Index">
             de Boer, Marcus Cornelis Johannes
            </a>
           </td>
           <td class="r">
            University of Twente
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#388774" title="Click to go to the Author Index">
             Mulder, Iris
            </a>
           </td>
           <td class="r">
            University of Twente
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#387355" title="Click to go to the Author Index">
             Lomme, Roger MLM
            </a>
           </td>
           <td class="r">
            Radboudumc
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#388492" title="Click to go to the Author Index">
             Wasserberg, Dorothee
            </a>
           </td>
           <td class="r">
            University of Twente
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#388494" title="Click to go to the Author Index">
             Klein Rot, Emily A. M.
            </a>
           </td>
           <td class="r">
            LipoCoat
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#388496" title="Click to go to the Author Index">
             Ben Ami, Doron
            </a>
           </td>
           <td class="r">
            Triticum Medical
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#388497" title="Click to go to the Author Index">
             Sadeh, Udi
            </a>
           </td>
           <td class="r">
            Triticum Medical
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#371799" title="Click to go to the Author Index">
             Liefers, Herman Remco
            </a>
           </td>
           <td class="r">
            University of Twente
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#387300" title="Click to go to the Author Index">
             Shoseyov, Oded
            </a>
           </td>
           <td class="r">
            The Hebrew University Og Jerusalem
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#388499" title="Click to go to the Author Index">
             Jonkheijm, Pascal
            </a>
           </td>
           <td class="r">
            University of Twente
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#352766" title="Click to go to the Author Index">
             Warle, Michiel
            </a>
           </td>
           <td class="r">
            Radboud University Medical Center
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#153284" title="Click to go to the Author Index">
             Khalil, Islam S.M.
            </a>
           </td>
           <td class="r">
            University of Twente
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1059" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#micro_nano_robots" title="Click to go to the Keyword Index">
               Micro/Nano Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#biologically_inspired_robots" title="Click to go to the Keyword Index">
               Biologically-Inspired Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper explores the application of X-ray-guided magnetic fields for the wireless control of untethered magnetic robots (UMRs) within cerebral vascular phantoms. With a focus on addressing challenges associated with strokes and brain aneurysms, the study aims to enhance neurosurgical procedures by improving precision and maneuverability. Experimental findings showcase the feasibility and effectiveness of this innovative approach in navigating UMRs, characterized by a screw-shaped body and a ferromagnetic core, through complex vascular structures. Cone-beam computed tomography is employed to determine the tomography and provide various reference trajectories for the UMR inside the cerebral vascular phantom. Our motion control experiments show that the X-ray-guided magnetic fields enable the UMR to move along any intended path with an average success rate of 89%, allowing the UMR to move between the left and right common carotid artery to the left and right internal and external carotid artery.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t2_03">
             15:30-16:30, Paper WePI3T2.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3523'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Wearable Mechanical Pressure-Electrophysiological Bimodal Sensing System for Rehabilitation Electromechanical Device
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#245178" title="Click to go to the Author Index">
             Wang, Peng
            </a>
           </td>
           <td class="r">
            Hebei University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#236778" title="Click to go to the Author Index">
             Liu, Jixiao
            </a>
           </td>
           <td class="r">
            Hebei University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#399229" title="Click to go to the Author Index">
             Qi, Dianpeng
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#223370" title="Click to go to the Author Index">
             Guo, Shijie
            </a>
           </td>
           <td class="r">
            Hebei University of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3523" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multi_modal_perception_for_hri" title="Click to go to the Keyword Index">
               Multi-Modal Perception for HRI
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#physically_assistive_devices" title="Click to go to the Keyword Index">
               Physically Assistive Devices
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             With the aging of society, there has been an increase in the number of elderly individuals with limb movement disorders. Active rehabilitation training using limb rehabilitation electromechanical devices that incorporate multimodal sensing and monitoring functions can significantly contribute to the recovery of limb motor functions. This report introduces a wearable mechanical pressure-electrophysiological monitoring bimodal sensing system specifically designed for human limb rehabilitation devices. By utilizing just four electrodes (SE, CE/DE, GND, REF), this system enables simultaneous and co-located measurement of sEMG, pressure, and MMG signals. These signals can be utilized to analyze muscle tension, stiffness, and tremor information. At last, the sensing system was tested for muscle contraction force and localized muscle fatigue, and the characteristics of physiological signals in both the time and frequency domains during exercise were thoroughly investigated. The wearable mechanical pressure-electrophysiological bimodal sensing system can provide valuable data references for rehabilitation robots or human limb rehabilitation device, which is of great significance in the diagnosis of muscular diseases and rehabilitation treatment.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t2_04">
             15:30-16:30, Paper WePI3T2.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('638'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Self-Selecting Semi-Supervised Transformer-Attention Convolutional Network for Four Class EEG-Based Motor Imagery Decoding
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393443" title="Click to go to the Author Index">
             Ng, Han Wei
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#279534" title="Click to go to the Author Index">
             Guan, Cuntai
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab638" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#brain_machine_interfaces" title="Click to go to the Keyword Index">
               Brain-Machine Interfaces
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#rehabilitation_robotics" title="Click to go to the Keyword Index">
               Rehabilitation Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#neurorobotics" title="Click to go to the Keyword Index">
               Neurorobotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Brain-computer interfaces (BCI) serve as an important tool in areas such as neurorehabilitation and constructing prostheses. Electroencephalogram (EEG) motor imagery (MI) signal is a common method used to communicate between the human brain and the computer interface. However, differentiating between multiple motor imagery signals may be challenging due to the presence of high noise-to-signal ratio and small dataset sizes. In this study, we propose a variational autoencoder and transformer-attention based convolutional neural network (SSTACNet) for multi-class EEG-based motor imagery classification. The SSTACNet model leverages upon variational autoencoders' ability to measure the contrastive distance between two sets of inputs to perform data self-selection. The model further utilizes multi-head self-attention as well as spatial and temporal convolutional filters to achieve superior extraction of signal features. The model additionally utilizes the variational autoencoder's ability to augment the dataset with feature-informed pseudo-data, achieving stronger classification results. The proposed model outperforms the current state-of-the-art techniques in the BCI Competition IV-2a dataset with an accuracy of 85.52% and 70.56% for the subject-dependent and subject-independent modes, respectively. Codes may be found at: https://github.com/NgHanWei/SSTACNet
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t2_05">
             15:30-16:30, Paper WePI3T2.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1530'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Design Improvements to the Float Upper-Limb Exoskeleton Better Mimics the Glenohumeral Complex Kinematics
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#321561" title="Click to go to the Author Index">
             Bodo, Giulia
            </a>
           </td>
           <td class="r">
            Politecnico Di Torino &amp; Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#273931" title="Click to go to the Author Index">
             Tessari, Federico
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#356932" title="Click to go to the Author Index">
             Capitta, Gianluca
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#356933" title="Click to go to the Author Index">
             De Guglielmo, Luca
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#294653" title="Click to go to the Author Index">
             Buccelli, Stefano
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#123069" title="Click to go to the Author Index">
             Laffranchi, Matteo
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1530" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#kinematics" title="Click to go to the Keyword Index">
               Kinematics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#rehabilitation_robotics" title="Click to go to the Keyword Index">
               Rehabilitation Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_centered_robotics" title="Click to go to the Keyword Index">
               Human-Centered Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The shoulder glenohumeral complex stands out as one of the most complex structures within the human body. Designing a system that can effectively interface with it poses a significant challenge for researchers. In this study, we propose a methodology based on evaluating various metrics to assess the performance of new kinematic solutions for mimicking the glenohumeral complex. The proposed method is demonstrated on an existing design (Float) of an upper-limb exoskeleton. The results show a successful expansion of the reachable workspace and enhancement of the shoulder internal-external rotation. The improvements ensure the necessary range-of-motion for the patient’s natural use of the exoskeleton. Specifically, the existing Eulerian wrist architecture is replaced with a 3-degreeof-freedom RPY wrist to better resemble the glenohumeral shoulder joint complex. This study also explores the trade-offs between these enhancements and the desired system manipulability.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t2_06">
             15:30-16:30, Paper WePI3T2.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('597'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Modular Robot Wear for Walking Rehabilitation Assistance According to Physical Functionality
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#116620" title="Click to go to the Author Index">
             Ogata, Kunihiro
            </a>
           </td>
           <td class="r">
            National Institute of Advanced Industrial Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393310" title="Click to go to the Author Index">
             Futawatari, Toshiki
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#350794" title="Click to go to the Author Index">
             Fujimoto, Masahiro
            </a>
           </td>
           <td class="r">
            National Institute of Advanced Industrial Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#167415" title="Click to go to the Author Index">
             Imamura, Yumeko
            </a>
           </td>
           <td class="r">
            National Inst. of AIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101578" title="Click to go to the Author Index">
             Matsumoto, Yoshio
            </a>
           </td>
           <td class="r">
            AIST
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab597" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#rehabilitation_robotics" title="Click to go to the Keyword Index">
               Rehabilitation Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#wearable_robotics" title="Click to go to the Keyword Index">
               Wearable Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             As people age, walking can become difficult. This difficulty in walking can lead to further physical decline and eventually result in the need for caregiving. To prevent this, wearable robots supporting walking rehabilitation have been developed. In this study, we aim to develop a modular robot wear that can be customized according to the user's needs. The modular robot wear consists of motor modules, sensor modules, and a processor. Motor modules can be attached to any part of the body that requires assistance, enabling support not only in the sagittal plane but also in the frontal plane. By calculating the relative movement of the center of gravity based on the information from the acceleration sensors in the sensor modules, commands to the motor modules are generated. This allows for assistance tailored to the user's walking pattern. Through verification experiments of the robot wear's operation, we confirmed its ability to provide support according to changes in walking patterns. However, while the robot wear can induce changes in walking patterns, there are challenges regarding the output.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t2_07">
             15:30-16:30, Paper WePI3T2.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1027'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Series Variable-Stiffness Joint for Robot-Assisted Resistance Training
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#349715" title="Click to go to the Author Index">
             Hu, Xingyu
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395016" title="Click to go to the Author Index">
             Li, Yuebing
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#349716" title="Click to go to the Author Index">
             Wu, Haoyang
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#231195" title="Click to go to the Author Index">
             Zhang, Wuxiang
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#179147" title="Click to go to the Author Index">
             Feng, Yanggang
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1027" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#rehabilitation_robotics" title="Click to go to the Keyword Index">
               Rehabilitation Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#prosthetics_and_exoskeletons" title="Click to go to the Keyword Index">
               Prosthetics and Exoskeletons
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             As the safe and comfortable human-robot interaction draw more attention, variable stiffness joints are adopted in the rehabilitation robots for the compliant experiences. For patients with joint injury, resistance training has demonstrated its efficacy in concurrently enhancing muscle strength in the rehabilitation process. Here, we introduce a compact passive joint with variable stiffness and damping generation capability for robot-assisted resistance training. The abilities of serial variable stiffness and passive angle tracking were demonstrated by a prototype. The variable stiffness mechanism was mainly formed by 3D-printing, which only weighs 0.1kg with a wide range of stiffness (0.004-11.176Nm/rad). Moreover, the torque-angular displacement characteristics show excellent linearity at high joint stiffness. Finally, the feasibility of being integrated into the wearable rehabilitation robot has been evaluated.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t2_08">
             15:30-16:30, Paper WePI3T2.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1209'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Creating Discomfort Maps Via Hand-Held Human Feedback Interface for Robotic Shoulder Physiotherapy
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395956" title="Click to go to the Author Index">
             Ravenberg, Jevon Gianni
            </a>
           </td>
           <td class="r">
            Delft University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#294324" title="Click to go to the Author Index">
             Belli, Italo
            </a>
           </td>
           <td class="r">
            TU Delft
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#180660" title="Click to go to the Author Index">
             Prendergast, J. Micah
            </a>
           </td>
           <td class="r">
            Delft University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#251343" title="Click to go to the Author Index">
             Seth, Ajay
            </a>
           </td>
           <td class="r">
            Delft University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#156776" title="Click to go to the Author Index">
             Peternel, Luka
            </a>
           </td>
           <td class="r">
            Delft University of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1209" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#rehabilitation_robotics" title="Click to go to the Keyword Index">
               Rehabilitation Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#physical_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical Human-Robot Interaction
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#modeling_and_simulating_humans" title="Click to go to the Keyword Index">
               Modeling and Simulating Humans
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this work, we propose a method of capturing the patient's discomfort during robotic shoulder physiotherapy, creating ``discomfort maps". These maps depict the personalized distribution of discomfort that each patient perceived across their shoulder range of motion, facilitating both robotic devices and human therapists to account for patient-specific characteristics during the therapeutic process. Our system enables a patient to communicate and map discomfort in space and time during movement via a handheld push-button device, while interacting with a robotic physical therapy device capable of moving the patient and estimating their pose. We validated our method through human factors experiments simulating shoulder physiotherapy sessions with 10 healthy participants. To avoid the risk of injury to the participants and to allow for ground truth map information, we emulate perceived discomfort via an auditory signal. Our experimental apparatus enabled participants to reconstruct synthetic discomfort maps, demonstrating the feasibility of automatically capturing and storing patient discomfort during robotic physiotherapy.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t2_09">
             15:30-16:30, Paper WePI3T2.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1560'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Parallel-Actuated Robot with Two End-Effector Degrees-Of-Freedom: Application As a Novel Wearable Head-Neck Traction Brace
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#389235" title="Click to go to the Author Index">
             Zhou, Jingzong
            </a>
           </td>
           <td class="r">
            University of California, Riverside
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#272280" title="Click to go to the Author Index">
             Kulkarni, Priya
            </a>
           </td>
           <td class="r">
            Columbia University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100150" title="Click to go to the Author Index">
             Agrawal, Sunil
            </a>
           </td>
           <td class="r">
            Columbia University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1560" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#rehabilitation_robotics" title="Click to go to the Keyword Index">
               Rehabilitation Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#kinematics" title="Click to go to the Keyword Index">
               Kinematics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper describes a parallel-actuated robotic mechanism designed to provide two degrees-of-freedom (DOF) to the end-effector relative to a fixed base. In a potential application as a head-neck traction brace, these two independent DOFs are the vertical translation of the head with respect to shoulders and a specified orientation of the head in lateral bending. Motivated by recommended clinical methods to apply traction forces on the head, it is designed to provide vertical traction force on the head while tilted in a specific orientation. The design has four chains starting from a base stationed at the shoulders, each chain having 5 DOFs. Each chain imposes a single constraint on the motion of the end-effector. Together, four chains would apply four constraints, allowing only two DOFs of motion to the end-effector. Two out of four component chains are actively driven by linear actuators. Our kinematic studies show that the achievable workspace of this mechanism with a specific stroke length of actuators of ± 50 mm results in 175-222 mm of vertical translation and up to ± 9 deg of lateral bending. The lateral bending is coupled to the flexion/extension angle of the end-effector. A physical prototype was constructed to investigate the functional realization of the design in hardware. Overall, the physical prototype validated the motion of the theoretical model despite potential errors in the fabrication, making the design a candidate for potential head-neck traction application.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t2_10">
             15:30-16:30, Paper WePI3T2.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1651'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Discover2Walk: A Cable-Driven Robotic Platform to Promote Gait in Pediatric Population
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#356872" title="Click to go to the Author Index">
             Romero Sorozabal, Pablo
            </a>
           </td>
           <td class="r">
            CSIC
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#356878" title="Click to go to the Author Index">
             Delgado-Oleas, Gabriel
            </a>
           </td>
           <td class="r">
            CSIC
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396469" title="Click to go to the Author Index">
             Laudanski, Annemarie F
            </a>
           </td>
           <td class="r">
            Dalhousie University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105009" title="Click to go to the Author Index">
             Gutierrez, Alvaro
            </a>
           </td>
           <td class="r">
            Universidad Politécnica De Madrid
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105053" title="Click to go to the Author Index">
             Rocon, Eduardo
            </a>
           </td>
           <td class="r">
            CSIC
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1651" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#rehabilitation_robotics" title="Click to go to the Keyword Index">
               Rehabilitation Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#prosthetics_and_exoskeletons" title="Click to go to the Keyword Index">
               Prosthetics and Exoskeletons
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recent advancements in gait rehabilitation have led to the development of innovative approaches that complement traditional therapeutic methods. These include intense, task-specific exercise strategies, non-invasive treatments, surgical interventions, and advanced robotic technologies. While robotic systems for adult gait rehabilitation are well-established, there is a notable scarcity of such devices for pediatric patients, especially toddlers, due to their unique developmental and biomechanical needs. This work introduces Discover2Walk (D2W), a novel robotic platform designed specifically for pediatric gait rehabilitation in small children. The D2W platform features a multi-module, cable-driven architecture guided by an omnidirectional traction module, addressing the limitations of current rehabilitation devices for younger populations. The platform's modular design consists of three actuated modules—pelvic, ankle, and traction—synchronized by a personalised gait pattern generator. This configuration allows for simultaneous control and monitoring of pelvic and ankle motion using partial body weight support and Assistance As Needed (AAN) approaches. Preliminary evaluations were conducted with pediatric patients with Cerebral Palsy, involving two ambulatory six-year-olds and one non-ambulatory four-year-old, over a series of 10 gait rehabilitation sessions. Data analysis from the ambulatory children showed a decrease in the robotic effort required to assist limb movements along healthy trajectories throughout the sessions, accompanied by an increase in walking speeds. Further work will include expanding the patient cohort to include a broader range of ages, sizes and GMFCS levels to validate the system's effectiveness across a wider spectrum of pediatric gait disabilities and validating the traction effectiveness.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t2_11">
             15:30-16:30, Paper WePI3T2.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1694'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Evaluating Gait Symmetry with a Smart Robotic Walker: A Novel Approach to Mobility Assessment
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#380741" title="Click to go to the Author Index">
             Abdollah Chalaki, Mahdi
            </a>
           </td>
           <td class="r">
            University of Alberta
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#284164" title="Click to go to the Author Index">
             Soleymani, Abed
            </a>
           </td>
           <td class="r">
            University of Alberta
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#296366" title="Click to go to the Author Index">
             Li, Xingyu
            </a>
           </td>
           <td class="r">
            University of Alberta
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#285313" title="Click to go to the Author Index">
             Mushahwar, Vivian K.
            </a>
           </td>
           <td class="r">
            University of Alberta
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104138" title="Click to go to the Author Index">
             Tavakoli, Mahdi
            </a>
           </td>
           <td class="r">
            University of Alberta
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1694" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#rehabilitation_robotics" title="Click to go to the Keyword Index">
               Rehabilitation Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#physically_assistive_devices" title="Click to go to the Keyword Index">
               Physically Assistive Devices
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Gait asymmetry, a consequence of various neurological or physical conditions such as aging and stroke, detrimentally impacts bipedal locomotion, causing biomechanical alterations, increasing the risk of falls and reducing quality of life. Addressing this critical issue, this paper introduces a novel diagnostic method for gait symmetry analysis through the use of an assistive robotic Smart Walker equipped with an innovative asymmetry detection scheme. This method analyzes sensor measurements capturing the interaction torque between user and walker. By applying a seasonal-trend decomposition tool, we isolate gait-specific patterns within these data, allowing for the estimation of stride durations and calculation of a symmetry index. Through experiments involving 5 experimenters, we demonstrate the Smart Walker's capability in detecting and quantifying gait asymmetry by achieving an accuracy of 84.9% in identifying asymmetric cases in a controlled testing environment. Further analysis explores the classification of these asymmetries based on their underlying causes, providing valuable insights for gait assessment. The results underscore the potential of the device as a precise, ready-to-use monitoring tool for personalized rehabilitation, facilitating targeted interventions for enhanced patient outcomes.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t2_12">
             15:30-16:30, Paper WePI3T2.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3358'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Meta-Learning for Fast Adaptation in Intent Inferral on a Robotic Hand Orthosis for Stroke
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#399131" title="Click to go to the Author Index">
             La Rotta, Pedro Leandro
            </a>
           </td>
           <td class="r">
            Columbia University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#266781" title="Click to go to the Author Index">
             Xu, Jingxi
            </a>
           </td>
           <td class="r">
            Columbia University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#289466" title="Click to go to the Author Index">
             Chen, Ava
            </a>
           </td>
           <td class="r">
            Columbia University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#292451" title="Click to go to the Author Index">
             Winterbottom, Lauren
            </a>
           </td>
           <td class="r">
            Columbia University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#399138" title="Click to go to the Author Index">
             Chen, Wenxi
            </a>
           </td>
           <td class="r">
            Columbia University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#207218" title="Click to go to the Author Index">
             Nilsen, Dawn
            </a>
           </td>
           <td class="r">
            Columbia University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#192149" title="Click to go to the Author Index">
             Stein, Joel
            </a>
           </td>
           <td class="r">
            Columbia University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#110328" title="Click to go to the Author Index">
             Ciocarlie, Matei
            </a>
           </td>
           <td class="r">
            Columbia University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3358" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#rehabilitation_robotics" title="Click to go to the Keyword Index">
               Rehabilitation Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#prosthetics_and_exoskeletons" title="Click to go to the Keyword Index">
               Prosthetics and Exoskeletons
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We propose MetaEMG, a meta-learning approach for fast adaptation in intent inferral on a robotic hand orthosis for stroke. One key challenge in machine learning for assistive and rehabilitative robotics with disabled-bodied subjects is the difficulty of collecting labeled training data. Muscle tone and spasticity often vary significantly among stroke subjects, and hand function can even change across different use sessions of the device for the same subject. We investigate the use of meta-learning to mitigate the burden of data collection needed to adapt high-capacity neural networks to a new session or subject. Our experiments on real clinical data collected from five stroke subjects show that MetaEMG can improve the intent inferral accuracy with a small session- or subject-specific dataset and very few fine-tuning epochs. To the best of our knowledge, we are the first to formulate intent inferral on stroke subjects as a meta-learning problem and demonstrate fast adaptation to a new session or subject for controlling a robotic hand orthosis with EMG signals.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t2_13">
             15:30-16:30, Paper WePI3T2.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3414'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Generalized Path Impedance Control
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#252910" title="Click to go to the Author Index">
             Montesino, Ignacio
            </a>
           </td>
           <td class="r">
            Universidad Carlos III De Madrid
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#133796" title="Click to go to the Author Index">
             Victores, Juan G.
            </a>
           </td>
           <td class="r">
            Universidad Carlos III De Madrid
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105670" title="Click to go to the Author Index">
             Balaguer, Carlos
            </a>
           </td>
           <td class="r">
            Universidad Carlos III De Madrid
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104014" title="Click to go to the Author Index">
             Jardon, Alberto
            </a>
           </td>
           <td class="r">
            Universidad Carlos Iii De Madrid
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3414" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#rehabilitation_robotics" title="Click to go to the Keyword Index">
               Rehabilitation Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#compliance_and_impedance_control" title="Click to go to the Keyword Index">
               Compliance and Impedance Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#physical_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical Human-Robot Interaction
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robotic-assisted upper limb rehabilitation has gained significant attention in recent years due to its potential to enhance the recovery process for individuals with motor impairments resulting from neurological conditions and injuries. The main rehabilitation treatments rely on the repetitive execution of a movement of the upper-limb, guided by a therapist to prevent incorrect movements and to provide the necessary support. Many of the exercises performed by therapists can be modeled as a movement in SE(3) space (position and orientation). This movement itself is one-dimensional, as it can be modeled by a one-dimensional curve. To solve a similar problem, some approaches have been proposed in human-robot interaction (HRI) following virtual guides, but are either limited to specific types of curves (e.g. without orientation) or rely on linear control methods with non-intuitive parameters. To address these limitations and enable the use of these methods in physical rehabilitation, this paper extends Cartesian impedance control to splines, which we term path impedance control. It capitalizes on the intrinsic path geometry of end-effector robotic rehabilitation systems. The primary objective of this control algorithm is to emulate the sensation of maneuvering a physical object along a wire, akin to conventional exercise machines; and, in conjunction, provide an intuitive parametrization of rehabilitation exercises. We build on existing virtual guide control strategies using non-linear control and Lie Groups to generalize the control law to any one-parameter SE(3) curve.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t2_14">
             15:30-16:30, Paper WePI3T2.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1136'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Automatic Field of View Adjustment of an RCM Constraint-Free Continuum Laparoscopic Robot
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#388349" title="Click to go to the Author Index">
             Zhang, Jing
            </a>
           </td>
           <td class="r">
            Shenzhen Campus of Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395609" title="Click to go to the Author Index">
             Wang, Baichuan
            </a>
           </td>
           <td class="r">
            Shenzhen Campus of Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395620" title="Click to go to the Author Index">
             Pan, Zhijie
            </a>
           </td>
           <td class="r">
            Shenzhen Campus of Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395611" title="Click to go to the Author Index">
             Li, Weiqi
            </a>
           </td>
           <td class="r">
            Shenzhen Campus of Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395610" title="Click to go to the Author Index">
             Li, Mengtang
            </a>
           </td>
           <td class="r">
            Shenzhen Campus of Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1136" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#surgical_robotics__laparoscopy" title="Click to go to the Keyword Index">
               Surgical Robotics: Laparoscopy
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_medical_robotics" title="Click to go to the Keyword Index">
               Computer Vision for Medical Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Automatic laparoscopic field of view (FOV) adjustment can effectively assist surgeons in minimally invasive surgery (MIS). However, existing work based on rod-shaped laparoscopes is inevitably constrained by the remote center of motion (RCM) during the process of FOV adjustment. The RCM limits laparoscopic movement and makes modeling and control more complex. This paper proposes a novel tendon-driven continuum laparoscope that is not affected by the RCM constraint. Furthermore, an automatic FOV adjustment method is designed for the proposed laparoscope robot, which considers the surgical instrument position and size in the image, as well as eye-hand consistency. Two simulation platforms are developed using MATLAB and Webots to intuitively study and optimize the proposed adjustment method. The convergence time of surgical tool tracking with a complex 3D trajectory is only 1s, the average tracking error after stabilization is about 9.97 pixels, and the maximum eye-hand error is only 0.04°. A first-generation prototype is built to verify the tracking performance of the proposed tendon-driven continuum laparoscope. The experimental results show that the proposed system can perform real-time laparoscopic FOV adjustment without being constrained by the RCM.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wepi3t3">
             <b>
              WePI3T3
             </b>
            </a>
           </td>
           <td class="r">
            Room 3
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wepi3t3" title="Click to go to the Program at a Glance">
             <b>
              Social HRI II
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#100116" title="Click to go to the Author Index">
             Miura, Jun
            </a>
           </td>
           <td class="r">
            Toyohashi University of Technology
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#136950" title="Click to go to the Author Index">
             Lim, Angelica
            </a>
           </td>
           <td class="r">
            Simon Fraser University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t3_01">
             15:30-16:30, Paper WePI3T3.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1357'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Skeleton-Based Human Action Recognition with Noisy Labels
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396356" title="Click to go to the Author Index">
             Xu, Yi
            </a>
           </td>
           <td class="r">
            Kalrsruhe Institute of Technology, IAR
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#319561" title="Click to go to the Author Index">
             Peng, Kunyu
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396358" title="Click to go to the Author Index">
             Wen, Di
            </a>
           </td>
           <td class="r">
            Kalrsruhe Institute of Technology, IAR
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#322797" title="Click to go to the Author Index">
             Liu, Ruiping
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#291270" title="Click to go to the Author Index">
             Zheng, Junwei
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375556" title="Click to go to the Author Index">
             Chen, Yufan
            </a>
           </td>
           <td class="r">
            Karlsruher Institut Für Technologie
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#284099" title="Click to go to the Author Index">
             Zhang, Jiaming
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#297943" title="Click to go to the Author Index">
             Roitberg, Alina
            </a>
           </td>
           <td class="r">
            University of Stuttgart
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#223296" title="Click to go to the Author Index">
             Yang, Kailun
            </a>
           </td>
           <td class="r">
            Hunan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101361" title="Click to go to the Author Index">
             Stiefelhagen, Rainer
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1357" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#gesture__posture_and_facial_expressions" title="Click to go to the Keyword Index">
               Gesture, Posture and Facial Expressions
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_modal_perception_for_hri" title="Click to go to the Keyword Index">
               Multi-Modal Perception for HRI
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#representation_learning" title="Click to go to the Keyword Index">
               Representation Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Understanding human actions from body poses is critical for assistive robots sharing space with humans in order to make informed and safe decisions about the next interaction. However, precise temporal localization and annotation of activity sequences is time-consuming and the resulting labels are often noisy. If not effectively addressed, label noise negatively affects the model's training, resulting in lower recognition quality. Despite its importance, addressing label noise for skeleton-based action recognition has been overlooked so far. In this study, we bridge this gap by implementing a framework that augments well-established skeleton-based human action recognition methods with label-denoising strategies from various research areas to serve as the initial benchmark. Observations reveal that these baselines yield only marginal performance when dealing with sparse skeleton data. Consequently, we introduce a novel methodology, NoiseEraSAR, which integrates global sample selection, co-teaching, and Cross-Modal Mixture-of-Experts (CM-MOE) strategies, aimed at mitigating the adverse impacts of label noise. Our proposed approach demonstrates better performance on the established benchmark, setting new state-of-the-art standards. The source code for this study will be made accessible at https://github.com/xuyizdby/NoiseEraSAR.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t3_02">
             15:30-16:30, Paper WePI3T3.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1872'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Retargeting Human Facial Expression to Human-Like Robotic Face through Neural Network Surrogate-Based Optimization
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#298252" title="Click to go to the Author Index">
             Wu, Bowen
            </a>
           </td>
           <td class="r">
            Osaka University; RIKEN
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#131744" title="Click to go to the Author Index">
             Liu, Chaoran
            </a>
           </td>
           <td class="r">
            Riken
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#109330" title="Click to go to the Author Index">
             Ishi, Carlos Toshinori
            </a>
           </td>
           <td class="r">
            RIKEN
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104030" title="Click to go to the Author Index">
             Minato, Takashi
            </a>
           </td>
           <td class="r">
            RIKEN
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101596" title="Click to go to the Author Index">
             Ishiguro, Hiroshi
            </a>
           </td>
           <td class="r">
            Osaka University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1872" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#gesture__posture_and_facial_expressions" title="Click to go to the Keyword Index">
               Gesture, Posture and Facial Expressions
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#emotional_robotics" title="Click to go to the Keyword Index">
               Emotional Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Facial mimicry is crucial for human-like robots in human-robot interaction. The challenge is that the high diversity of facial expressions proposes difficulties in programming a robotic face to mimic human facial expressions using traditional methods. In this paper, we present a data-driven method to retarget human facial expressions to robotic faces without human effort. Our data collection is fully automatic, where only a robotic face and Apple ARKit are involved to sample actuator commands and record the resulting facial blendshape values. We trained a neural network that predicts blendshape values from commands, which is then used as a surrogate model to optimize command values to resemble given facial expressions. Experiments show that the proposed method has achieved lower error in terms of facial blendshape values than baselines. Moreover, the response time can be reduced to 0.2 seconds via TCP/IP through WiFi, offering great potential for real-time application. Our method is a novel framework for retargeting facial expressions to robotic faces, which can be incorporated into various human-robot interaction systems.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t3_03">
             15:30-16:30, Paper WePI3T3.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2576'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Reducing Cognitive Load in Teleoperating Swarms of Robots through a Data-Driven Shared Control Approach
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#277916" title="Click to go to the Author Index">
             Turco, Enrico
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#384591" title="Click to go to the Author Index">
             Castellani, Chiara
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#277930" title="Click to go to the Author Index">
             Bo, Valerio
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#138065" title="Click to go to the Author Index">
             Pacchierotti, Claudio
            </a>
           </td>
           <td class="r">
            Centre National De La Recherche Scientifique (CNRS)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105260" title="Click to go to the Author Index">
             Prattichizzo, Domenico
            </a>
           </td>
           <td class="r">
            University of Siena
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#186732" title="Click to go to the Author Index">
             Lisini Baldi, Tommaso
            </a>
           </td>
           <td class="r">
            University of Siena
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2576" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#human_factors_and_human_in_the_loop" title="Click to go to the Keyword Index">
               Human Factors and Human-in-the-Loop
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#swarm_robotics" title="Click to go to the Keyword Index">
               Swarm Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Multi-robot systems have gained increasing interest across various fields such as medicine, environmental monitoring, and more. Despite the evident advantages, the coordination of the swarm arises significant challenges for human operators, particularly concerning the cognitive burden needed for efficiently controlling the robots. In this study, we present a novel approach for enabling a human operator to effectively control the motion of multiple robots. Leveraging a shared control data-driven approach, we enable a single user to control the 9 degrees of freedom related to the pose and shape of a swarm. Our methodology was evaluated through an experimental campaign conducted in simulated 3D environments featuring a narrow cylindrical path, which could represent, e.g., blood vessels, industrial pipes. Subjective measures of cognitive load were assessed using a post-experiment questionnaire, comparing different levels of autonomy of the system. Results show substantial reductions in operator cognitive load when compared to conventional teleoperation techniques, accompanied by enhancements in task performance, including reduced completion times and fewer instances of contact with obstacles. This research underscores the efficacy of our approach in enhancing human-robot interaction and improving operational efficiency in multi-robot systems.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t3_04">
             15:30-16:30, Paper WePI3T3.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1457'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              PICaSo: A Collaborative Robotics System for Inpainting on Physical Canvas Using Marker and Eraser
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#359576" title="Click to go to the Author Index">
             Nasrat, Shady
            </a>
           </td>
           <td class="r">
            Pusan National University, Busan, SouthKorea
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#242359" title="Click to go to the Author Index">
             Yi, Jae-Bong
            </a>
           </td>
           <td class="r">
            Pusan National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376048" title="Click to go to the Author Index">
             Jo, Minseong
            </a>
           </td>
           <td class="r">
            Pusan National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#133360" title="Click to go to the Author Index">
             Yi, Seung-Joon
            </a>
           </td>
           <td class="r">
            Pusan National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1457" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#art_and_entertainment_robotics" title="Click to go to the Keyword Index">
               Art and Entertainment Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#social_hri" title="Click to go to the Keyword Index">
               Social HRI
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robotics collaborative drawing involves the interaction between humans and robots to create of visual art using a variety of tools and materials, serving various functions such as communication, narration, and emotional representation. A creative technique within the human natural drawing process is known as inpainting, which involves to reconstructing or editing elements in a drawing. This paper introduces PICaSo (Physical Inpainting on Canvas Solution), a robotic drawing system that enables users to collaboratively create artwork on canvas while integrating the inpainting process. PICaSo harnesses the power of a fine-tuned text-to-image model to interpret natural language prompts into artistic renderings on canvas. Users guide the process by simple descriptive text and specifying desired drawing placement, empowering the robotic arm to autonomously translate these instructions into physical artworks. Our system's innovation lies in its effective translation of digital inpainting processes into physical actions. Leveraging our multi-tool gripper, capable of seamlessly switching between eraser and marker functions, enables to seamlessly execute detailed drawings on canvas while also providing the flexibility to erase and redo sections as required. This paper comprehensively outlines the capabilities of the proposed system, explores potential applications across various domains, and addresses technical challenges encountered during its development.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t3_05">
             15:30-16:30, Paper WePI3T3.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1210'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              React to This! How Humans Challenge Interactive Agents Using Nonverbal Behaviors
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#353290" title="Click to go to the Author Index">
             Zhang, Chuxuan
            </a>
           </td>
           <td class="r">
            Simon Fraser University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395597" title="Click to go to the Author Index">
             Burkanova, Bermet
            </a>
           </td>
           <td class="r">
            Simon Fraser University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#178807" title="Click to go to the Author Index">
             Kim, Lawrence H.
            </a>
           </td>
           <td class="r">
            Simon Fraser University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395120" title="Click to go to the Author Index">
             Yip, Lauren
            </a>
           </td>
           <td class="r">
            SFU
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#177197" title="Click to go to the Author Index">
             Cupcic, Ugo
            </a>
           </td>
           <td class="r">
            Shadow Robot Company
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#136486" title="Click to go to the Author Index">
             Lallée, Stéphane
            </a>
           </td>
           <td class="r">
            NA
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#136950" title="Click to go to the Author Index">
             Lim, Angelica
            </a>
           </td>
           <td class="r">
            Simon Fraser University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1210" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#design_and_human_factors" title="Click to go to the Keyword Index">
               Design and Human Factors
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#gesture__posture_and_facial_expressions" title="Click to go to the Keyword Index">
               Gesture, Posture and Facial Expressions
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#social_hri" title="Click to go to the Keyword Index">
               Social HRI
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             How do people use their faces and bodies to test the interactive abilities of a robot? Making lively, believable agents is often seen as a goal for robots and virtual agents but believability can easily break down. In this Wizard-of-Oz (WoZ) study, we observed 1169 nonverbal interactions between 20 participants and 6 types of agents. We collected the nonverbal behaviors participants used to challenge the characters physically, emotionally, and socially. The participants interacted freely with humanoid and non-humanoid forms: a robot, a human, a penguin, a pufferfish, a banana, and a toilet. We present a human behavior codebook of 188 unique nonverbal behaviors used by humans to test the virtual characters. The insights and design strategies drawn from video observations aim to help build more interaction-aware and believable robots, especially when humans push them to their limits.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t3_06">
             15:30-16:30, Paper WePI3T3.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1911'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Combining Ontological Knowledge and Large Language Model for User-Friendly Service Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397490" title="Click to go to the Author Index">
             Nakajima, Haru
            </a>
           </td>
           <td class="r">
            Toyohashi University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100116" title="Click to go to the Author Index">
             Miura, Jun
            </a>
           </td>
           <td class="r">
            Toyohashi University of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1911" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#domestic_robotics" title="Click to go to the Keyword Index">
               Domestic Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#service_robotics" title="Click to go to the Keyword Index">
               Service Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Lifestyle support through robotics is an increasingly promising field, with expectations for robots to take over or assist with chores like floor cleaning, table setting and clearing, and fetching items. The growth of AI, particularly foundation models, such as large language models (LLMs) and visual language models (VLMs), is significantly shaping this sector. LLMs, by facilitating natural interactions and providing vast general knowledge, are proving invaluable for robotic tasks. This paper focuses on the benefits of LLMs for "bring-me" tasks, where robots fetch specific items for users, often based on ambiguous instructions. Our previous efforts utilized an ontology extended to handle environmental data to resolve such ambiguities, but faced limitations when unresolvable ambiguities required user intervention for clarity. Here, we enhance our approach by integrating LLMs for providing additional commonsense knowledge, pairing it with ontological data to mitigate the issue of hallucinations and reduce the need for user queries, thus improving system usability. We present a system that merges these knowledge bases and assess its efficacy on "bring-me" tasks, aiming to provide a more seamless and efficient robotic assistance experience.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t3_07">
             15:30-16:30, Paper WePI3T3.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2573'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Pilot Study for a Robot-Assisted Timed up and Go Assessment
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#256419" title="Click to go to the Author Index">
             Story, Matthew
            </a>
           </td>
           <td class="r">
            Sheffield Hallam University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#362740" title="Click to go to the Author Index">
             Ait Belaid, Khaoula
            </a>
           </td>
           <td class="r">
            Loughborough University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#410974" title="Click to go to the Author Index">
             Camp, Nicola
            </a>
           </td>
           <td class="r">
            Nottingham Trent University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398369" title="Click to go to the Author Index">
             Vagnetti, Roberto
            </a>
           </td>
           <td class="r">
            Nottingham Trent University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#202646" title="Click to go to the Author Index">
             Magistro, Daniele
            </a>
           </td>
           <td class="r">
            Nottingham Trent University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101889" title="Click to go to the Author Index">
             Zecca, Massimiliano
            </a>
           </td>
           <td class="r">
            Loughborough University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#176120" title="Click to go to the Author Index">
             Di Nuovo, Alessandro
            </a>
           </td>
           <td class="r">
            Sheffield Hallam University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2573" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#domestic_robotics" title="Click to go to the Keyword Index">
               Domestic Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_detection_and_tracking" title="Click to go to the Keyword Index">
               Human Detection and Tracking
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#social_hri" title="Click to go to the Keyword Index">
               Social HRI
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Falls and fall risk management are challenges that are increasing in an aging society, exacerbated by the decreasing availability of care professionals to provide suitable fall management plans. Technology may provide a solution to this, with robotics and vision systems receiving increased attention. A pilot study was conducted using a vision system mounted on a Turtlebot 4, MoveNet, and different machine learning algorithms to assess a Timed Up and Go (TUG) test. The system was evaluated on the performance of a previously trained action classifier and by comparing times for the different phases of the TUG test from the output of the model with the output from the QTUG test acquired by IMU sensors worn by the participants. The results showed the system could determine if the person was sitting, in transition, or standing with high accuracy (97.09%) with higher levels of consistency for participants between tests than the QTUG. This demonstrates that the system is not only advantageous requiring minimal user input but also can match the performance of wearable sensors that are considered the “gold standard” for TUG tests.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t3_08">
             15:30-16:30, Paper WePI3T3.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1014'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Contextual Emotion Recognition Using Large Vision Language Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395103" title="Click to go to the Author Index">
             Etesam, Yasaman
            </a>
           </td>
           <td class="r">
            Simon Fraser University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#381500" title="Click to go to the Author Index">
             Yalcin, Ozge
            </a>
           </td>
           <td class="r">
            Simon Fraser University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#353290" title="Click to go to the Author Index">
             Zhang, Chuxuan
            </a>
           </td>
           <td class="r">
            Simon Fraser University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#136950" title="Click to go to the Author Index">
             Lim, Angelica
            </a>
           </td>
           <td class="r">
            Simon Fraser University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1014" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#emotional_robotics" title="Click to go to the Keyword Index">
               Emotional Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#gesture__posture_and_facial_expressions" title="Click to go to the Keyword Index">
               Gesture, Posture and Facial Expressions
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_modal_perception_for_hri" title="Click to go to the Keyword Index">
               Multi-Modal Perception for HRI
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             "How does the person in the bounding box feel?" Achieving human-level recognition of the apparent emotion of a person in real world situations remains an unsolved task in computer vision. Facial expressions are not enough: body pose, contextual knowledge, and commonsense reasoning all contribute to how humans perform this emotional theory of mind task. In this paper, we examine two major approaches enabled by recent large vision language models: 1) image captioning followed by a language-only LLM, and 2) vision language models, under zero-shot and fine-tuned setups. We evaluate the methods on the Emotions in Context (EMOTIC) dataset and demonstrate that a vision language model, fine-tuned even on a small dataset, can significantly outperform traditional baselines. The results of this work aim to help robots and agents perform emotionally sensitive decision-making and interaction in the future.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t3_09">
             15:30-16:30, Paper WePI3T3.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2567'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              The Subtle Line between Personalization and User Manipulation in a European Regulatory Perspective. a Proposal for a Technology-Assessment Methodology for Artificial Intelligence Systems
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#231557" title="Click to go to the Author Index">
             Bertolini, Andrea
            </a>
           </td>
           <td class="r">
            Scuola Superiore S. Anna
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2567" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#ethics_and_philosophy" title="Click to go to the Keyword Index">
               Ethics and Philosophy
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#acceptability_and_trust" title="Click to go to the Keyword Index">
               Acceptability and Trust
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#social_hri" title="Click to go to the Keyword Index">
               Social HRI
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The paper provides an overview of those elements of HRI research that might have a relevance and give rise to concerns in an ELSE and more specifically regulatory perspective, through a multidisciplinary approach. It then provides a synthetic representation of the emerging regulatory framework in particular the just approved AI Act of the European Commission, the first regulation of AI and robotics at a global level. Based on both such pillars, it advances a proposal for a technology assessment methodology focusing on the aspect of user manipulation. The purpose being that of informing engineers about what regulatory concerns they need to take into account in the design phase, provide a benchmark for describing human-robot interactions, and provide data for policy makers to consider ad-hoc, narrow-tailored regulation that protects human rights without hampering innovation.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t3_10">
             15:30-16:30, Paper WePI3T3.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('227'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Socially Integrated Navigation: A Social Acting Robot with Deep Reinforcement Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391036" title="Click to go to the Author Index">
             Flögel, Daniel
            </a>
           </td>
           <td class="r">
            FZI Research Center for Information Technology, Karlsruhe Instit
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#322037" title="Click to go to the Author Index">
             Fischer, Lars
            </a>
           </td>
           <td class="r">
            FZI Research Center for Information Technology, Karlsruhe Instit
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391038" title="Click to go to the Author Index">
             Rudolf, Thomas
            </a>
           </td>
           <td class="r">
            FZI Research Center for Information Technology, Karlsruhe Instit
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391039" title="Click to go to the Author Index">
             Schürmann, Tobias
            </a>
           </td>
           <td class="r">
            FZI Research Center for Information Technology, Karlsruhe Instit
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#245275" title="Click to go to the Author Index">
             Hohmann, Sören
            </a>
           </td>
           <td class="r">
            Institute of Control Systems, Karlsruhe Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab227" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#human_aware_motion_planning" title="Click to go to the Keyword Index">
               Human-Aware Motion Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#social_hri" title="Click to go to the Keyword Index">
               Social HRI
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Mobile robots are being used on a large scale in various crowded situations and become part of our society. The socially acceptable navigation behavior of a mobile robot with individual human consideration is an essential requirement for scalable applications and human acceptance. Deep Reinforcement Learning (DRL) approaches are recently used to learn a robot’s navigation policy and to model the complex interactions between robots and humans. We propose to divide existing DRL-based navigation approaches based on the robot’s exhibited social behavior and distinguish between social collision avoidance with a lack of social behavior and socially aware approaches with explicit predefined social behavior. In addition, we propose a novel socially integrated navigation approach where the robot’s social behavior is adaptive and emerges from the interaction with humans. The formulation of our approach is derived from a sociological definition, which states that social acting is oriented toward the acting of others. The DRL policy is trained in an environment where other agents interact socially integrated and reward the robot’s behavior individually. The simulation results indicate that the proposed socially integrated navigation approach outperforms a socially aware approach in terms of ego navigation performance while significantly reducing the negative impact on all agents within the environment.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t3_11">
             15:30-16:30, Paper WePI3T3.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1549'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Social Navigation in Crowded Environments with Model Predictive Control and Deep Learning-Based Human Trajectory Prediction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#317406" title="Click to go to the Author Index">
             Le, Viet-Anh
            </a>
           </td>
           <td class="r">
            University of Delaware
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#229717" title="Click to go to the Author Index">
             Chalaki, Behdad
            </a>
           </td>
           <td class="r">
            Honda Research Institute USA, Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#377470" title="Click to go to the Author Index">
             Tadiparthi, Vaishnav
            </a>
           </td>
           <td class="r">
            Honda Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#377800" title="Click to go to the Author Index">
             Nourkhiz Mahjoub, Hossein
            </a>
           </td>
           <td class="r">
            Honda Research Institute US
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#377575" title="Click to go to the Author Index">
             D'sa, Jovin
            </a>
           </td>
           <td class="r">
            Honda Research Institute, USA
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#377793" title="Click to go to the Author Index">
             Moradi-Pari, Ehsan
            </a>
           </td>
           <td class="r">
            Honda Research Institute
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1549" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#human_aware_motion_planning" title="Click to go to the Keyword Index">
               Human-Aware Motion Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#social_hri" title="Click to go to the Keyword Index">
               Social HRI
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Navigating a robot among a crowd has received increasing attention from researchers over the last few decades, resulting in the emergence of numerous approaches aimed at addressing the problem of social navigation to date. Our proposed approach couples agent motion prediction and planning to avoid the freezing robot problem while simultaneously capturing multi-agent social interactions by utilizing a state-of-the-art trajectory prediction model i.e., social long short-term memory model (Social-LSTM). Leveraging the output of Social-LSTM for the prediction of future trajectories of pedestrians at each time-step given the robot's possible future actions, our framework computes the optimal control action using Model Predictive Control (MPC) for the robot to navigate among pedestrians. We demonstrate the effectiveness of our proposed approach in multiple scenarios of simulated social navigation and compare it against several state-of-the-art reinforcement learning-based methods.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t3_12">
             15:30-16:30, Paper WePI3T3.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2242'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Redefining Data Pairing for Motion Retargeting Leveraging a Human Body Prior
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394696" title="Click to go to the Author Index">
             Figuera Michal, Xiyana Veroska
            </a>
           </td>
           <td class="r">
            Ulsan National Institute of Science and Technology (UNIST)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395615" title="Click to go to the Author Index">
             Park, Soogeun
            </a>
           </td>
           <td class="r">
            UNIST (Ulsan National Institute of Science and Technology)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#180472" title="Click to go to the Author Index">
             Ahn, Hyemin
            </a>
           </td>
           <td class="r">
            Ulsan National Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2242" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#human_aware_motion_planning" title="Click to go to the Keyword Index">
               Human-Aware Motion Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_and_humanoid_motion_analysis_and_synthesis" title="Click to go to the Keyword Index">
               Human and Humanoid Motion Analysis and Synthesis
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robot_learning" title="Click to go to the Keyword Index">
               Data Sets for Robot Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We propose MR.HuBo (Motion Retargeting leveraging a HUman BOdy prior), a cost-effective and convenient method to collect high-quality upper body paired
             <robot, human="">
              pose data, which is essential for data-driven motion retargeting methods. Unlike existing approaches which collect
              <robot, human="">
               pose data by converting human MoCap poses into robot poses, our method goes in reverse. We first sample diverse random robot poses, and then convert them into human poses. However, since random robot poses can result in extreme and infeasible human poses, we propose an additional technique to sort out extreme poses by exploiting a human body prior trained from a large amount of human pose data. Our data collection method can be used for any humanoid robots, if one designs or optimizes the system's hyperparameters which include a size scale factor and the joint angle ranges for sampling. In addition to this data collection method, we also present a two-stage motion retargeting neural network that can be trained via supervised learning on a large amount of paired data. Compared to other learning-based methods trained via unsupervised learning, we found that our deep neural network trained with ample high-quality paired data achieved notable performance. Our experiments also show that our data filtering method yields better retargeting results than training the model with raw and noisy data. Our code and video results are available on https://sites.google.com/view/mr-hubo/.
              </robot,>
             </robot,>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t3_13">
             15:30-16:30, Paper WePI3T3.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2336'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SocialNav-FTI: Field-Theory-Inspired Social-Aware Navigation Framework Based on Human Behavior and Social Norms
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#306351" title="Click to go to the Author Index">
             Lu, Siyi
            </a>
           </td>
           <td class="r">
            Central South University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#306349" title="Click to go to the Author Index">
             Zhong, Ping
            </a>
           </td>
           <td class="r">
            Central South University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398126" title="Click to go to the Author Index">
             Ye, Shuqi
            </a>
           </td>
           <td class="r">
            Central South University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#306343" title="Click to go to the Author Index">
             Chen, Bolei
            </a>
           </td>
           <td class="r">
            Central South University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372312" title="Click to go to the Author Index">
             Yu, Sheng
            </a>
           </td>
           <td class="r">
            Central South University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398088" title="Click to go to the Author Index">
             Liu, Run
            </a>
           </td>
           <td class="r">
            University of Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2336" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#human_aware_motion_planning" title="Click to go to the Keyword Index">
               Human-Aware Motion Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Social navigation is a key consideration for integrating robots into human environments. Concurrently, it imposes heightened requisites: tasks must not only be executed succesfully without collisions, but also adhere to principles encompassing comprehensibility, courtesy, social compliance, comprehension, foresight, and scenario compliance. In this paper, we present the incorporation of social norms as a guiding framework for robot navigation within social contexts. We adopt field theory to provide a formal elucidation of the social norms, using Physical-Informed Neural Network (PINN) to predict pedestrian movement under the influence of social norms, respectively, and using Reinforcement Learning (RL) for navigation. We use supervised learning to train the pedestrian velocity field prediction model and reinforcement learning to train the navigation policy. We conduct three parts of experiments: (1) analyzing the spatiotemporal characteristics of the velocity field in the walking pedestrians dataset; (2) evaluating the accuracy of the vector field prediction in the pedestrian dataset; (3) using Gazebo simulation and the PEDSIM library to evaluate the improvement of navigation performance under constraints of social norms. Experiments have confirmed that the pedestrian motion data set indeed satisfies the Gaussian divergence theorem and can be described by the concept of field. The performance of navigation strategies incorporating social rules has been improved to a certain extent.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t3_14">
             15:30-16:30, Paper WePI3T3.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2634'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Adaptive Social Force Window Planner with Reinforcement Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#327849" title="Click to go to the Author Index">
             Martini, Mauro
            </a>
           </td>
           <td class="r">
            Politecnico Di Torino
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#172516" title="Click to go to the Author Index">
             Perez-Higueras, Noe
            </a>
           </td>
           <td class="r">
            University Pablo De Olavide
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391938" title="Click to go to the Author Index">
             Ostuni, Andrea
            </a>
           </td>
           <td class="r">
            Politecnico Di Torino
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#298501" title="Click to go to the Author Index">
             Chiaberge, Marcello
            </a>
           </td>
           <td class="r">
            Politecnico Di Torino
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103508" title="Click to go to the Author Index">
             Caballero, Fernando
            </a>
           </td>
           <td class="r">
            Universidad De Sevilla
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103530" title="Click to go to the Author Index">
             Merino, Luis
            </a>
           </td>
           <td class="r">
            Universidad Pablo De Olavide
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2634" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#human_aware_motion_planning" title="Click to go to the Keyword Index">
               Human-Aware Motion Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#service_robotics" title="Click to go to the Keyword Index">
               Service Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Human-aware navigation is a complex task for mobile robots, requiring an autonomous navigation system capable of achieving efficient path planning together with socially compliant behaviors. Social planners usually add costs or constraints to the objective function, leading to intricate tuning processes or tailoring the solution to the specific social scenario. Machine Learning can enhance planners' versatility and help them learn complex social behaviors from data. This work proposes an adaptive social planner, using a Deep Reinforcement Learning agent to dynamically adjust the weighting parameters of the cost function used to evaluate trajectories. The resulting planner combines the robustness of the classic Dynamic Window Approach, integrated with a social cost based on the Social Force Model, and the flexibility of learning methods to boost the overall performance on social navigation tasks. Our extensive experimentation on different environments demonstrates the general advantage of the proposed method over static cost planners.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t3_15">
             15:30-16:30, Paper WePI3T3.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3177'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Crowd-Aware Robot Navigation with Switching between Learning-Based and Rule-Based Methods Using Normalizing Flows
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#217773" title="Click to go to the Author Index">
             Matsumoto, Kohei
            </a>
           </td>
           <td class="r">
            Kyushu University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#371175" title="Click to go to the Author Index">
             Hyodo, Yuki
            </a>
           </td>
           <td class="r">
            Kyushu University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103231" title="Click to go to the Author Index">
             Kurazume, Ryo
            </a>
           </td>
           <td class="r">
            Kyushu University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3177" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#human_aware_motion_planning" title="Click to go to the Keyword Index">
               Human-Aware Motion Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Mobile robot navigation in crowded environments with pedestrians is a crucial challenge in realizing service robots that can assist people in their daily lives. Navigation methods for mobile robots in environments employing deep reinforcement learning have been extensively studied. However, addressing such unexpected situations is a significant challenge. This study presents an approach that discerns whether a situation has been supposed to utilize a normalizing flow and dynamically switches between learning- and rule-based methods. Specifically, the proposed method achieves a higher success rate than employing only a learning-based approach and reaches the destination faster than employing only a rule-based approach in unexpected situations. Experiments are conducted to validate the performance enhancement achieved with the proposed switching method in both simulated and real-world settings.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t3_16">
             15:30-16:30, Paper WePI3T3.16
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1303'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Transformer-Based Relationship Inference Model for Household Object Organization by Integrating Graph Topology and Ontology
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#386254" title="Click to go to the Author Index">
             Li, Xiaodong
            </a>
           </td>
           <td class="r">
            Shandong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#125757" title="Click to go to the Author Index">
             Tian, Guohui
            </a>
           </td>
           <td class="r">
            Shandong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#386366" title="Click to go to the Author Index">
             Cui, Yongcheng
            </a>
           </td>
           <td class="r">
            Shandong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395267" title="Click to go to the Author Index">
             Gu, Yu
            </a>
           </td>
           <td class="r">
            Shandong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1303" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#service_robotics" title="Click to go to the Keyword Index">
               Service Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#domestic_robotics" title="Click to go to the Keyword Index">
               Domestic Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In domestic environments, the conventional organization of objects by service robots often relies on the inherent properties of each object, such as placing fragile bowls in enclosed cupboards. However, this approach tends to overlook the importance of the orderly arrangement of objects, neglecting the specific placement order of bowls within the cabinet. In practice, effective object organization necessitates consideration of both individual properties and the relationships defined by these properties. In this paper, we have constructed a specialized dataset encompassing the ontological properties of household objects along with their relationships. Furthermore, we have introduced a graph-based model to explicitly represent these relationships and proposed a novel feature extraction technique that integrates the Graph Attention Network (GAT) with the BERT model to predict the relationships among objects. Subsequently, we utilized the Transformer framework to train a model, enabling it to infer relationships between objects. Experimental validation demonstrates the effectiveness of our approach in accurately predicting relationships between household objects, thus facilitating their orderly organization. Our approach significantly augments the object organization capabilities for service robots by accurately predicting the relationships among household objects. Our code is available at: https://github.com/Li-XD-Pro/Household-Object-Organization
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wepi3t4">
             <b>
              WePI3T4
             </b>
            </a>
           </td>
           <td class="r">
            Room 4
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wepi3t4" title="Click to go to the Program at a Glance">
             <b>
              Robot Vision I
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#181302" title="Click to go to the Author Index">
             Pan, Yongping
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t4_01">
             15:30-16:30, Paper WePI3T4.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('547'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Dynamic-Range Focal Sweep: Seamless Continuous Autofocus Based on High-Speed Vision for Magnified Object Tracking
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#294280" title="Click to go to the Author Index">
             Zhang, Tianyi
            </a>
           </td>
           <td class="r">
            Chiba University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#202812" title="Click to go to the Author Index">
             Shimasaki, Kohei
            </a>
           </td>
           <td class="r">
            Hiroshima University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#111980" title="Click to go to the Author Index">
             Ishii, Idaku
            </a>
           </td>
           <td class="r">
            Hiroshima University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103677" title="Click to go to the Author Index">
             Namiki, Akio
            </a>
           </td>
           <td class="r">
            Chiba University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab547" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#visual_servoing" title="Click to go to the Keyword Index">
               Visual Servoing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_tracking" title="Click to go to the Keyword Index">
               Visual Tracking
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents an innovative continuous autofocus (C-AF) approach based on high-speed vision. It consistently provides focused images with stable and sufficiently high frame rates, aiming to improve the ability to track small, fast-moving objects in a highly magnified scene. To achieve this, we propose the concept of a dynamic-range focal sweep enabled by a high-speed camera and a focus-tunable liquid lens with high adjustment capability. The focal sweep consistently covers a small range around the object's focus position, guided by previous depth results obtained through the depth-from-focus (DFF) technique. We conducted verification experiments to thoroughly analyze the capability of the proposed C-AF approach. By integrating a 2-axis Galvano mirror, we built a high-speed C-AF active vision system with rapid focus and pan-tilt adjustments. The comprehensive experiment results highlight the advanced capabilities of our seamless C-AF in tracking magnified objects.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t4_02">
             15:30-16:30, Paper WePI3T4.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1932'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Mathematical Characterization of the Convergence Domain for Direct Visual Servoing
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397146" title="Click to go to the Author Index">
             Naamani, Meriem Belinda
            </a>
           </td>
           <td class="r">
            CNRS-AIST JRL
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#113960" title="Click to go to the Author Index">
             Caron, Guillaume
            </a>
           </td>
           <td class="r">
            CNRS
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102022" title="Click to go to the Author Index">
             Morisawa, Mitsuharu
            </a>
           </td>
           <td class="r">
            National Inst. of AIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#151138" title="Click to go to the Author Index">
             Mouaddib, El Mustapha
            </a>
           </td>
           <td class="r">
            Universite De Picardie Jules Verne
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1932" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#visual_servoing" title="Click to go to the Keyword Index">
               Visual Servoing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Direct Visual Servoing (DVS) is a technique that controls the robot motion by using the pixel intensities captured by a camera. DVS demonstrates high accuracy at convergence, prompting the development of various methods aimed at expanding its convergence domain. In this paper, we propose a mathematical characterization of the DVS convergence domain with closed-form expressions for the controlled degrees of freedom. From these expressions, we concluded that the extent of the convergence domain is related to the presence of isotropic or defocus blur, a phenomenon that had only been observed previously as a trend in empirical experiments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t4_03">
             15:30-16:30, Paper WePI3T4.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2006'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Visual Servo Control of a Conceptual Magnetically Anchored and Guided Flexible Endoscope
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#220958" title="Click to go to the Author Index">
             Li, Weibing
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#339742" title="Click to go to the Author Index">
             Yang, Yang
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#181302" title="Click to go to the Author Index">
             Pan, Yongping
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2006" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#visual_servoing" title="Click to go to the Keyword Index">
               Visual Servoing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#kinematics" title="Click to go to the Keyword Index">
               Kinematics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#flexible_robotics" title="Click to go to the Keyword Index">
               Flexible Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a conceptual magnetically anchored and guided flexible endoscope for minimally invasive surgery (MIS). Leveraging both the magnetic coupling between the external and internal permanent magnets and the bending of a flexible joint, the endoscope offers improved maneuverability and adaptability within confined surgical spaces. The visual servo control allows the endoscope to autonomously track surgical instruments during procedures, thereby reducing the risk of human error and operator fatigue. First, the design and working principles of the endoscope are introduced. Subsequently, the kinematic modeling of the endoscope is derived, and the control scheme is developed based on a quadratic programming (QP) framework by taking into account both magnetically anchoring constraints and physical constraints, where the joint velocities can be resolved given the desired task velocities in a one-step way. Simulative validations are conducted to verify the effectiveness of the visual servo control for the presented endoscope tracking a static/dynamic target with physical constraints considered.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t4_04">
             15:30-16:30, Paper WePI3T4.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2186'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Multi-Spectral Visual Servoing
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#351679" title="Click to go to the Author Index">
             Fiasche, Enrico
            </a>
           </td>
           <td class="r">
            Université Côte D'Azur
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106118" title="Click to go to the Author Index">
             Malis, Ezio
            </a>
           </td>
           <td class="r">
            Inria
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101740" title="Click to go to the Author Index">
             Martinet, Philippe
            </a>
           </td>
           <td class="r">
            INRIA
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2186" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#visual_servoing" title="Click to go to the Keyword Index">
               Visual Servoing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_tracking" title="Click to go to the Keyword Index">
               Visual Tracking
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a novel approach for Visual Servoing (VS) using a multispectral camera, where the number of data are more than three times that of a standard color camera. To meet real-time feasibility, the multispectral data captured by the camera are processed using dimensionality reduction techniques. Instead of relying on traditional approaches that select a subset of bands, our method unlocks the full potential of a multispectral camera by pinpointing individual pixels that hold the richest information across all bands. While sacrificing spectral resolution for enhanced spatial resolution - crucial for precise robotic control in forested environments - this fusion process offers a powerful tool for robust and real-time VS in natural settings. Validated through simulations and real-world experiments, the proposed approach demonstrates its efficacy by leveraging the full spectral information of the camera while preserving spatial details.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t4_05">
             15:30-16:30, Paper WePI3T4.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2762'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Automating Trophectoderm Cells Aspiration and Separation in Embryo Biopsy at the Blastocyst Stage: A Vision-Based Control Approach
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#242287" title="Click to go to the Author Index">
             Abu Ajamieh, Ihab
            </a>
           </td>
           <td class="r">
            Birzeit University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#234351" title="Click to go to the Author Index">
             Al Saaideh, Mohammad
            </a>
           </td>
           <td class="r">
            Memorial University of Newfoundland
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#132899" title="Click to go to the Author Index">
             Al Janaideh, Mohammad
            </a>
           </td>
           <td class="r">
            University of Guelph
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103657" title="Click to go to the Author Index">
             Mills, James K.
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2762" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#visual_servoing" title="Click to go to the Keyword Index">
               Visual Servoing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#micro_nano_robots" title="Click to go to the Keyword Index">
               Micro/Nano Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#additive_manufacturing" title="Click to go to the Keyword Index">
               Additive Manufacturing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Reproductive medicine has recently witnessed significant advancements, particularly in vitro fertilization (IVF). One crucial aspect of IVF involves the extraction of cellular material and its analysis to maximize the chance of successful implantation. This work highlights the development and application of the automated system for Trophectoderm cell (TE) extraction and separation, addressing the need for precision, efficiency, and reduced manual intervention. The presented automated system is equipped with a computer vision algorithm, microliter pump, vacuum system, and micromanipulation tools to consistently and accurately biopsy TE cells. An experimental setup is developed to verify the behavior of the proposed method, in which a holding micropipette is connected to a vacuum system and holds the embryo stationary. Three steps are performed to complete the process and are controlled by a computer vision algorithm. The coordinates of the Zona Pellucida (ZP) perforation (perforated in a previous step) are used as a feedback signal to a simple proportional controller to control the biopsy pipette motion. The computer vision monitors the amount of TE cells aspirated inside the biopsy pipette and controls the microliter pump. The aspirated TE cells were separated away using a laser cutting system. Experimental results demonstrate that the system can relocate the biopsy pipette, TE cell extraction, and separation.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t4_06">
             15:30-16:30, Paper WePI3T4.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2790'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robust Partitioned Visual Servoing for Aerial Manipulation Utilizing Controllable-Space Image Planning and Adaptive Image Representation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#292169" title="Click to go to the Author Index">
             Soltanshah, Mohammad
            </a>
           </td>
           <td class="r">
            Simon Fraser University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#284214" title="Click to go to the Author Index">
             Eskandarpour, Abolfazl
            </a>
           </td>
           <td class="r">
            Simon Fraser University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105977" title="Click to go to the Author Index">
             Mehrandezh, Mehran
            </a>
           </td>
           <td class="r">
            University of Regina
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101859" title="Click to go to the Author Index">
             Gupta, Kamal
            </a>
           </td>
           <td class="r">
            Simon Fraser University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2790" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#visual_servoing" title="Click to go to the Keyword Index">
               Visual Servoing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In the pursuit of object retrieval using an aerial manipulator, developing robust visual servoing techniques in the presence of projection and motion model uncertainties is paramount. This paper proposes a novel approach to conducting image-space planning within the controllable-space of the aerial manipulator. Our new strategy resolves the inherent challenge of adhering to a piecewise linear camera trajectory which is infeasible for an aerial manipulator due to the platform's underactuation and presence of secondary tasks for visual servoing. Through this approach, we introduce center of gravity alignment and camera orientation potential fields without relying on specific degrees of freedom from the arm. Moreover, we introduce a new approach that utilizes an image-resolution scaling technique involving an adaptive virtual camera focal length, leading to a numerically well-conditioned image Jacobian. Our proposed framework maintains robustness to the uncertainty in the intrinsic parameters of the camera. We substantiate the efficacy of our methodology through experiments conducted in a realistic physics-based simulation environment.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t4_07">
             15:30-16:30, Paper WePI3T4.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3395'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Unified Framework of Hybrid Vision-Force Control with Nullspace Compliance for Redundant Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#301088" title="Click to go to the Author Index">
             Li, Zhiwen
            </a>
           </td>
           <td class="r">
            Sun Yat-Set University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#220958" title="Click to go to the Author Index">
             Li, Weibing
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#184438" title="Click to go to the Author Index">
             Chen, Yanjie
            </a>
           </td>
           <td class="r">
            Fuzhou University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#181302" title="Click to go to the Author Index">
             Pan, Yongping
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3395" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#visual_servoing" title="Click to go to the Keyword Index">
               Visual Servoing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#force_control" title="Click to go to the Keyword Index">
               Force Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#physical_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical Human-Robot Interaction
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The ability to handle contact makes robots qualified for many complicated tasks, such as welding, hammering, and wiping. Robot cameras facilitate position planning and control without the geometric knowledge of contact surfaces since they can project contact surfaces onto a 2-dimensional image plane. However, existing hybrid vision-force control (HVFC) methods still rely on this knowledge to project the force on the constraint subspace and do not adequately leverage the redundant degrees of freedom (DoFs) for redundant robots with contact tasks. This paper proposes an enhanced HVFC solution for redundant robots equipped with an eye-to-hand camera to unify HVFC in the Cartesian space and impedance control in the joint nullspace into one closed-loop dynamics with rigorous stability guarantees. Any geometric knowledge of contact surfaces is not required by projecting the force into the redundant space of the visual task rather than the surface's normal space. Experiments on a seven-DoF collaborative robot have verified that the proposed method is qualified for simultaneous contact tasks in the Cartesian space and compliant interaction in the joint nullspace.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t4_08">
             15:30-16:30, Paper WePI3T4.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('94'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Multi-Target Tracking with Occlusion Resistance for Mobile Robots in Dynamic Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#387514" title="Click to go to the Author Index">
             Liu, Zhongyan
            </a>
           </td>
           <td class="r">
            Nankai University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#181761" title="Click to go to the Author Index">
             Lu, Biao
            </a>
           </td>
           <td class="r">
            Nankai University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#387568" title="Click to go to the Author Index">
             Xing, Xinghai
            </a>
           </td>
           <td class="r">
            Nankai University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#387565" title="Click to go to the Author Index">
             Mao, Dun
            </a>
           </td>
           <td class="r">
            Nankai University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#114198" title="Click to go to the Author Index">
             Fang, Yongchun
            </a>
           </td>
           <td class="r">
            Nankai University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab94" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#visual_tracking" title="Click to go to the Keyword Index">
               Visual Tracking
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In the context of tracking multiple targets on a novel mobile robot, it is essential to obtain the three-dimensional coordinates of specified targets based on tracking boxes. Most existing multi-target tracking algorithms neglect the inherent constraints of the novel mobile robot, such as insufficient computational power, dynamically complex working environments, and irregularly occluded targets. To address these limitations, we propose a robust tracking algorithm with occlusion resistance (hereinafter referred to as ROTrack). ROTrack compensates for the predictions of Kalman filter (KF) by incorporating Inertial Measurement Unit (IMU) information, enabling the tracker to achieve more accurate tracking in dynamic environments. Additionally, MobileSAM is employed to handle occlusion issues and obtain the correct three-dimensional coordinates of the targets. At the same time, a depth-triggered segmentation strategy is proposed to reduce computational resource consumption. The effect of ROTrack is demonstrated through alignment between IMU signals and Camera Motion Compensation (CMC) data in BoT-SORT. Real-world tracking tests validate the robustness and real-time capability of ROTrack.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t4_09">
             15:30-16:30, Paper WePI3T4.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('852'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              GroupTrack: Multi-Object Tracking by Using Group Motion Patterns
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372097" title="Click to go to the Author Index">
             Xu, Xinglong
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology(Shenzhen)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#343672" title="Click to go to the Author Index">
             Ren, Weihong
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology (Shenzhen)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#237173" title="Click to go to the Author Index">
             Sun, Gan
            </a>
           </td>
           <td class="r">
            South China University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372315" title="Click to go to the Author Index">
             Ji, Haoyu
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#390724" title="Click to go to the Author Index">
             Gao, Yu
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#112147" title="Click to go to the Author Index">
             Liu, Honghai
            </a>
           </td>
           <td class="r">
            Portsmouth University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab852" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#visual_tracking" title="Click to go to the Keyword Index">
               Visual Tracking
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_detection_and_tracking" title="Click to go to the Keyword Index">
               Human Detection and Tracking
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The main challenge of Multi-Object Tracking (MOT) lies in maintaining a distinctive identity for each target in dense crowds or occluded scenarios. Although the existing methods have achieved significantly progress by using robust object detectors or complex association strategies, they cannot effectively solve long-term tracking due to individually motion or appearance modeling for each single target. In this paper, we propose a novel 2D MOT tracker GroupTrack, to learn reliable motion state for each target using group motion patterns. Specifically, for each tracklet, we first choose its neighboring ones to form a group of motion patterns, which can provide informative clues for the motion estimation of the current tracklet. Then, we apply the group motion patterns to perform tracklet prediction and data association. By integrating prior from neighboring motion patterns into the data association process, GroupTrack provides a new paradigm for target motion modeling in extremely crowded and occluded scenarios. Through extensive experiments on the public MOT17 and MOT20 datasets, we demonstrate the effectiveness of our approach in challenging scenarios and show state-of-the-art performance at various MOT metrics.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t4_10">
             15:30-16:30, Paper WePI3T4.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('981'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              QTrack: Embracing Quality Clues for Robust 3D Multi-Object Tracking
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#336233" title="Click to go to the Author Index">
             Yang, Jinrong
            </a>
           </td>
           <td class="r">
            Huazhong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#336245" title="Click to go to the Author Index">
             Yu, En
            </a>
           </td>
           <td class="r">
            Huazhong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#350638" title="Click to go to the Author Index">
             Li, Zeming
            </a>
           </td>
           <td class="r">
            MEGVII Technolegy
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#247146" title="Click to go to the Author Index">
             Li, Xiaoping
            </a>
           </td>
           <td class="r">
            Huazhong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#221798" title="Click to go to the Author Index">
             Tao, Wenbing
            </a>
           </td>
           <td class="r">
            Huazhong University of Science &amp; Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab981" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#visual_tracking" title="Click to go to the Keyword Index">
               Visual Tracking
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             3D Multi-Object Tracking (MOT) has achieved tremendous achievement thanks to the rapid development of 3D object detection and 2D MOT. Recent advanced works generally employ a series of object attributes, e.g., position, size, velocity, and appearance, to provide the clues for the association in 3D MOT. However, these cues may not be reliable due to some visual noise, such as occlusion and blur, leading to tracking performance bottlenecks. To reveal the dilemma, we conduct extensive empirical analysis to expose the key bottleneck of each clue and how they correlate with each other. The analysis results motivate us to efficiently absorb the merits among all cues and adaptively produce an optimal tracking manner. Specifically, we present Location and Velocity Quality Learning, which efficiently guides the network to estimate the quality of predicted object attributes. Based on these quality estimations, we propose a quality-aware object association (QOA) strategy to leverage the quality score as an important reference factor for achieving robust association. Despite its simplicity, extensive experiments indicate that the proposed strategy significantly boosts tracking performance by 2.2% AMOTA and our method outperforms all existing state-of-the-art works on nuScenes by a large margin. Moreover, QTrack achieves 51.1%, 54.8% and 56.6% AMOTA tracking performance on the nuScenes test sets with BEVDepth, VideoBEV, and StreamPETR models respectively, which significantly reduces the performance gap between the pure camera and LiDAR-based trackers.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t4_11">
             15:30-16:30, Paper WePI3T4.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1063'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              CLAT: Convolutional Local Attention Tracker for Real-Time UAV Target Tracking System with Feedback Information
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#353465" title="Click to go to the Author Index">
             Sun, XiaoLou
            </a>
           </td>
           <td class="r">
            Southeast University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#352188" title="Click to go to the Author Index">
             Quan, Zhibin
            </a>
           </td>
           <td class="r">
            Southeast University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#352145" title="Click to go to the Author Index">
             Wang, Wei
            </a>
           </td>
           <td class="r">
            Nanjing University of Information Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#390683" title="Click to go to the Author Index">
             Si, Wufei
            </a>
           </td>
           <td class="r">
            Purple Mountain Laboratories
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395135" title="Click to go to the Author Index">
             Wang, Chunyan
            </a>
           </td>
           <td class="r">
            Purple Mountain Laboratories
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395133" title="Click to go to the Author Index">
             Li, Yuntian
            </a>
           </td>
           <td class="r">
            PML
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#390678" title="Click to go to the Author Index">
             Wu, Yuan
            </a>
           </td>
           <td class="r">
            Purple Mountain Lab
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#380038" title="Click to go to the Author Index">
             Meng, Shen
            </a>
           </td>
           <td class="r">
            Purple Mountain Laboratories
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1063" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#visual_tracking" title="Click to go to the Keyword Index">
               Visual Tracking
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_servoing" title="Click to go to the Keyword Index">
               Visual Servoing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Real-time UAV vision target tracking systems encounter the intricate challenges of striking a trade-off for tracking speed and performance, and the robustness of the following control. In existing tracking systems, the global attention mechanism enhances tracking performance, but it introduces higher computational complexity, impacting target tracking speed; the local attention mechanism can reduce computational complexity but often exhibits limitations in modeling the receptive field. In this paper, we propose a new framework named Convolutional Local Attention Tracker (CLAT) to address these challenges. Firstly, we design a hierarchical convolutional local attention structure as the feature extractor for CLAT. This leverages convolutional projection before local window partitioning, facilitating connections between non-overlapping windows and expanding the receptive field. Secondly, we introduce a streamlined feature fusion network comprising the unshared-weights convolutional layer and a global attention network. The whole design can balance speed and accuracy. Furthermore, to enhance servo control robustness, we have redesigned the upper-level controller by integrating all bounding box information. To capture feedback spatiotemporal information in CLAT, a dynamic template update is implemented by incorporating an IOU head into the predictor. Extensive experiments on visual tracking benchmarks and in the real world demonstrate that CLAT achieves competitive performance. Moreover, we have developed a comprehensive tracking system demonstration capable of precisely tracking targets across various categories. The tracker code will be released on https://github.com/xiaolousun/refine-pytracking.git
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t4_12">
             15:30-16:30, Paper WePI3T4.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1775'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              FusionTrack: An Online 3D Multi-Object Tracking Framework Based on Camera-LiDAR Fusion
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392573" title="Click to go to the Author Index">
             Zeng, Weizhen
            </a>
           </td>
           <td class="r">
            Tongji University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397012" title="Click to go to the Author Index">
             Fan, Jiaqi
            </a>
           </td>
           <td class="r">
            Tongji University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397037" title="Click to go to the Author Index">
             Tian, Xuelin
            </a>
           </td>
           <td class="r">
            Tongji University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397228" title="Click to go to the Author Index">
             Chu, Hongqing
            </a>
           </td>
           <td class="r">
            Tongji University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397057" title="Click to go to the Author Index">
             Gao, Bingzhao
            </a>
           </td>
           <td class="r">
            Tongji University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1775" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#visual_tracking" title="Click to go to the Keyword Index">
               Visual Tracking
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             3D multi-object tracking is an important component of the perception module in autonomous driving systems. Due to the limitations of a single sensor, tracking methods based on either LiDAR or cameras always have certain deficiencies. Fusion-based tracking methods have received increasing attention. However, existing fusion-based tracking methods often underutilize image information, ignore the respective effects of appearance information and 2D detection results, and lack further analysis on the simultaneous use of both. This paper proposes a novel camera-LiDAR fusion tracking framework that primarily relies on the motion model using 3D objects. It fully leverages the appearance information and 2D detection results simultaneously from images and introduces three modules to reduce the number of false positive samples, false negative samples and ID switches, respectively. Besides, the entire tracking process does not require global processing and achieves online tracking. The proposed method achieves competitive results on the KITTI tracking dataset with 78.50% HOTA. Compared with EagerMOT using the same 3D and 2D detectors, the HOTA metric improved by 4.11%. Code is available on {https://github.com/zengwz/FusionTrack}.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t4_13">
             15:30-16:30, Paper WePI3T4.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1918'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              CR3DT: Camera-RADAR Fusion for 3D Detection and Tracking
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#335794" title="Click to go to the Author Index">
             Baumann, Nicolas
            </a>
           </td>
           <td class="r">
            ETH
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376640" title="Click to go to the Author Index">
             Baumgartner, Michael
            </a>
           </td>
           <td class="r">
            ETH
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#335798" title="Click to go to the Author Index">
             Ghignone, Edoardo
            </a>
           </td>
           <td class="r">
            ETH
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#354236" title="Click to go to the Author Index">
             Kühne, Jonas
            </a>
           </td>
           <td class="r">
            ETH Zürich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#334483" title="Click to go to the Author Index">
             Fischer, Tobias
            </a>
           </td>
           <td class="r">
            ETH Zürich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#377601" title="Click to go to the Author Index">
             Yang, Yung-Hsu
            </a>
           </td>
           <td class="r">
            ETH
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#128027" title="Click to go to the Author Index">
             Pollefeys, Marc
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#335799" title="Click to go to the Author Index">
             Magno, Michele
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1918" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#visual_tracking" title="Click to go to the Keyword Index">
               Visual Tracking
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             To enable self-driving vehicles accurate detection and tracking of surrounding objects is essential. While Light Detection and Ranging (LiDAR) sensors have set the benchmark for high-performance systems, the appeal of camera-only solutions lies in their cost-effectiveness. Notably, despite the prevalent use of Radio Detection and Ranging (RADAR) sensors in automotive systems, their potential in 3D detection and tracking has been largely disregarded due to data sparsity and measurement noise. As a recent development, the combination of RADARs and cameras is emerging as a promising solution. This paper presents Camera-RADAR 3D Detection and Tracking (CR3DT), a camera-RADAR fusion model for 3D object detection, and Multi-Object Tracking (MOT). Building upon the foundations of the State-of-the-Art (SotA) camera-only BEVDet architecture, CR3DT demonstrates substantial improvements in both detection and tracking capabilities, by incorporating the spatial and velocity information of the RADAR sensor. Experimental results demonstrate an absolute improvement in detection performance of 5.3% in mean Average Precision (mAP) and a 14.9% increase in Average Multi-Object Tracking Accuracy (AMOTA) on the nuScenes dataset when leveraging both modalities. CR3DT bridges the gap between high-performance and cost-effective perception systems in autonomous driving, by capitalizing on the ubiquitous presence of RADAR in automotive applications. The code is available at: https://github.com/ETH-PBL/CR3DT
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t4_14">
             15:30-16:30, Paper WePI3T4.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1946'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Robotic-Centric Paradigm for 3D Human Tracking under Complex Environments Using Multi-Modal Adaptation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#346208" title="Click to go to the Author Index">
             Xin, Shuo
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#270935" title="Click to go to the Author Index">
             Zhang, Zhen
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#289314" title="Click to go to the Author Index">
             Liu, Liang
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#355227" title="Click to go to the Author Index">
             Hou, Xiaojun
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#314225" title="Click to go to the Author Index">
             Zhu, Deye
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#191367" title="Click to go to the Author Index">
             Wang, Mengmeng
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#122966" title="Click to go to the Author Index">
             Liu, Yong
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1946" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#visual_tracking" title="Click to go to the Keyword Index">
               Visual Tracking
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_modal_perception_for_hri" title="Click to go to the Keyword Index">
               Multi-Modal Perception for HRI
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_centered_robotics" title="Click to go to the Keyword Index">
               Human-Centered Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The goal of this paper is to strike a feasible tracking paradigm that can make 3D human trackers applicable on robot platforms and enable more high-level tasks. Till now, two fundamental problems haven't been adequately addressed. One is the computational cost lightweight enough for robotic deployment, and the other is the easily-influenced accuracy varied greatly in complex real environments. In this paper, a robotic-centric tracking paradigm called MATNet is proposed that directly matches the LiDAR point clouds and RGB videos through end-to-end learning. To improve the low accuracy of human tracking against disturbance, a coarse-to-fine Transformer along with target-ware augmentation is proposed by fusing RGB videos and point clouds through a pyramid encoding and decoding strategy. To better meet the real-time requirement of actual robot deployment, we introduce the parameter-efficient adaptation tuning that greatly shortens the model's training time. Furthermore, we also propose a five-step Anti-shake Refinement strategy and have added human prior values to overcome the strong shaking on the robot platform. Extensive experiments confirm that MATNet significantly outperforms the previous state-of-the-art on both open-source datasets and large-scale robotic datasets.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t4_15">
             15:30-16:30, Paper WePI3T4.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2108'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Neurosymbolic Approach to Adaptive Feature Extraction in SLAM
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392504" title="Click to go to the Author Index">
             Chandio, Yasra
            </a>
           </td>
           <td class="r">
            University of Massachusetts, Amherst
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392530" title="Click to go to the Author Index">
             Khan, Momin Ahmad
            </a>
           </td>
           <td class="r">
            University of Massachusetts Amherst
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392820" title="Click to go to the Author Index">
             Selialia, Khotso
            </a>
           </td>
           <td class="r">
            University of Massachusetts Amherst
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#276781" title="Click to go to the Author Index">
             Garcia, Luis Antonio
            </a>
           </td>
           <td class="r">
            University of Utah
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#172335" title="Click to go to the Author Index">
             DeGol, Joseph
            </a>
           </td>
           <td class="r">
            University of Illinois Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#276783" title="Click to go to the Author Index">
             Anwar, Fatima M
            </a>
           </td>
           <td class="r">
            UMASS AMHERST
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2108" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#visual_tracking" title="Click to go to the Keyword Index">
               Visual Tracking
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Autonomous robots, autonomous vehicles, and humans wearing mixed-reality headsets require accurate and reliable tracking services for safety-critical applications in dynamically changing real-world environments. However, the existing tracking approaches, such as Simultaneous Localization and Mapping (SLAM), do not adapt well to environmental changes and boundary conditions despite extensive manual tuning. On the other hand, while deep learning-based approaches can better adapt to environmental changes, they typically demand substantial data for training and often lack flexibility in adapting to new domains. To solve this problem, we propose leveraging the neurosymbolic program synthesis approach to construct adaptable SLAM pipelines that integrate the domain knowledge from traditional SLAM approaches while leveraging data to learn complex relationships. While the approach can synthesize end-to-end SLAM pipelines, we focus on synthesizing the feature extraction module. We first devise a domain-specific language (DSL) that can encapsulate domain knowledge on the essential attributes for feature extraction and the real-world performance of various feature extractors. Our neurosymbolic architecture then undertakes adaptive feature extraction, optimizing parameters via learning while employing symbolic reasoning to select the most suitable feature extractor. Our evaluations demonstrate that our approach, neurosymbolic Feature EXtraction (texttt{nFEX}), yields higher-quality features. It also reduces the pose error observed for the state-of-the-art baseline feature extractors ORB and SIFT by up to 90% and up to 66%, respectively, thereby enhancing the system's efficiency and adaptability to novel environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t4_16">
             15:30-16:30, Paper WePI3T4.16
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2115'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SDTrack: Spatially Decoupled Tracker for Visual Tracking
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394309" title="Click to go to the Author Index">
             Xia, Zihao
            </a>
           </td>
           <td class="r">
            Nanjing University of Posts and Telecommunications
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#417294" title="Click to go to the Author Index">
             Bi, Xin
            </a>
           </td>
           <td class="r">
            College of Automotive Studies，Tongji University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#163781" title="Click to go to the Author Index">
             Fan, Baojie
            </a>
           </td>
           <td class="r">
            Nanjing University of Posts and Telecommunications
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394107" title="Click to go to the Author Index">
             Wang, Zhiquan
            </a>
           </td>
           <td class="r">
            Nanjing University of Posts and Telecommunications
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2115" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#visual_tracking" title="Click to go to the Keyword Index">
               Visual Tracking
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recent models based on encoder-decoder architecture have shown excellent performance in visual object tracking. The encoder models the global spatiotemporal feature correlation between the template and the search regions, while the decoder learns query embeddings to predict the spatial location of the target. However, in previous methods, decoders are query shared, which may lead to suboptimal results. We observe that different regions in the visual feature map are suitable for performing different tasks. Salient regions in object provide important information for classification task, while the boundaries around it are more beneficial for box localization task. We therefore propose a spatially decoupled tracker called SDTrack. The tracker contains a query selection module that we carefully design to select appropriate queries for both classification and regression tasks. We divide the crossattention module in the decoder and add the box-to-pixel relative position offset (BoxRPB) term to the cross-attention, so that the attention is more focused on the respective areas of interest while introducing smaller overhead. Finally, we propose an alignment loss to solve the misalignment problem between accurate classification and precise localization, further improving tracking performance. Through extensive experiments, we demonstrate that SDTrack achieves new SOTA performance on multiple benchmarks compared to previous work, while running at real-time speeds.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wepi3t5">
             <b>
              WePI3T5
             </b>
            </a>
           </td>
           <td class="r">
            Room 5
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wepi3t5" title="Click to go to the Program at a Glance">
             <b>
              Deep Learning III
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#115196" title="Click to go to the Author Index">
             Piater, Justus
            </a>
           </td>
           <td class="r">
            University of Innsbruck
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#268360" title="Click to go to the Author Index">
             Betz, Johannes
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t5_01">
             15:30-16:30, Paper WePI3T5.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1193'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Continual Domain Randomization
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#200227" title="Click to go to the Author Index">
             Josifovski, Josip
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#200218" title="Click to go to the Author Index">
             Auddy, Sayantan
            </a>
           </td>
           <td class="r">
            University of Innsbruck
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#299156" title="Click to go to the Author Index">
             Malmir, Mohammadhossein
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#115196" title="Click to go to the Author Index">
             Piater, Justus
            </a>
           </td>
           <td class="r">
            University of Innsbruck
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105608" title="Click to go to the Author Index">
             Knoll, Alois
            </a>
           </td>
           <td class="r">
            Tech. Univ. Muenchen TUM
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#160127" title="Click to go to the Author Index">
             Navarro-Guerrero, Nicolás
            </a>
           </td>
           <td class="r">
            Leibniz Universität Hannover
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1193" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#transfer_learning" title="Click to go to the Keyword Index">
               Transfer Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Domain Randomization (DR) is commonly used for sim2real transfer of reinforcement learning (RL) policies in robotics. Most DR approaches require a simulator with a fixed set of tunable parameters from the start of the training, from which the parameters are randomized simultaneously to train a robust model for use in the real world. However, the combined randomization of many parameters increases the task difficulty and might result in sub-optimal policies. To address this problem and to provide a more flexible training process, we propose Continual Domain Randomization (CDR) for RL that combines domain randomization with continual learning to enable sequential training in simulation on a subset of randomization parameters at a time. Starting from a model trained in a non-randomized simulation where the task is easier to solve, the model is trained on a sequence of randomizations, and continual learning is employed to remember the effects of previous randomizations. Our robotic reaching and grasping tasks experiments show that the model trained in this fashion learns effectively in simulation and performs robustly on the real robot while matching or outperforming baselines that employ combined randomization or sequential randomization without continual learning. Our code and videos are available at https://continual-dr.github.io/.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t5_02">
             15:30-16:30, Paper WePI3T5.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2137'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Hyperbolic Image-And-Pointcloud Contrastive Learning for 3D Classification
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372481" title="Click to go to the Author Index">
             Hu, Naiwen
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#362256" title="Click to go to the Author Index">
             Cheng, Haozhe
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#365633" title="Click to go to the Author Index">
             Xie, Yifan
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#362146" title="Click to go to the Author Index">
             Shi, Pengcheng
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#285126" title="Click to go to the Author Index">
             Zhu, Jihua
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2137" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             3D contrastive representation learning has exhibited remarkable efficacy across various downstream tasks. However, existing contrastive learning paradigms based on cosine similarity fail to deeply explore the potential intra-modal hierarchical and cross-modal semantic correlations about multi-modal data in Euclidean space. In response, we seek solutions in hyperbolic space and propose a hyperbolic image-and-pointcloud contrastive learning method (HyperIPC). For the intra-modal branch, we rely on the intrinsic geometric structure to explore the hyperbolic embedding representation of point cloud to capture invariant features. For the cross-modal branch, we leverage images to guide the point cloud in establishing strong semantic hierarchical correlations. Empirical experiments underscore the outstanding classification performance of HyperIPC. Notably, HyperIPC enhances object classification results by 2.8% and few-shot classification outcomes by 5.9% on ScanObjectNN compared to the baseline. Furthermore, ablation studies and confirmatory testing validate the rationality of HyperIPC's parameter settings and the effectiveness of its submodules.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t5_03">
             15:30-16:30, Paper WePI3T5.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2393'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Exploiting Local Features and Range Images for Small Data Real-Time Point Cloud Semantic Segmentation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#311513" title="Click to go to the Author Index">
             Fusaro, Daniel
            </a>
           </td>
           <td class="r">
            Department of Information Engineering (DEI), University of Padov
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398194" title="Click to go to the Author Index">
             Mosco, Simone
            </a>
           </td>
           <td class="r">
            Università Degli Studi Di Padova
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105144" title="Click to go to the Author Index">
             Menegatti, Emanuele
            </a>
           </td>
           <td class="r">
            The University of Padua
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105120" title="Click to go to the Author Index">
             Pretto, Alberto
            </a>
           </td>
           <td class="r">
            University of Padova
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2393" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Semantic segmentation of point clouds is an essential task for understanding the environment in autonomous driving and robotics. Recent range-based works achieve real-time efficiency, while point- and voxel-based methods produce better results but are affected by high computational complexity. Moreover, highly complex deep learning models are often not suited to efficiently learn from small datasets. Their generalization capabilities can easily be driven by the abundance of data rather than the architecture design. In this paper, we harness the information from the three-dimensional representation to proficiently capture local features, while introducing the range image representation to incorporate additional information and facilitate fast computation. A GPU-based KDTree allows for rapid building, querying, and enhancing projection with straightforward operations. Extensive experiments on SemanticKITTI and nuScenes datasets demonstrate the benefits of our modification in a “small data” setup, in which only one sequence of the dataset is used to train the models, but also in the conventional setup, where all sequences except one are used for training. We show that a reduced version of our model not only demonstrates strong competitiveness against full-scale state-of-the-art models but also operates in real-time, making it a viable choice for real-world case applications. The code of our method is available at https://github.com/Bender97/LocalFeaturesSemSeg.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t5_04">
             15:30-16:30, Paper WePI3T5.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2739'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Single-Shot 6DoF Pose and 3D Size Estimation for Robotic Strawberry Harvesting
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#379085" title="Click to go to the Author Index">
             Li, Lun
            </a>
           </td>
           <td class="r">
            University of Groningen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#169824" title="Click to go to the Author Index">
             Kasaei, Hamidreza
            </a>
           </td>
           <td class="r">
            University of Groningen
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2739" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#agricultural_automation" title="Click to go to the Keyword Index">
               Agricultural Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this study, we introduce a deep-learning approach for determining both the 6DoF pose and 3D size of strawberries, aiming to significantly augment robotic harvesting efficiency. Our model was trained on a synthetic strawberry dataset, which is automatically generated within the Ignition Gazebo simulator, with a specific focus on the inherent symmetry exhibited by strawberries. By leveraging domain randomization techniques, the model demonstrated exceptional performance, achieving an 84.77% average precision (AP) of 3D Intersection over Union (IoU) scores on the simulated dataset. Empirical evaluations, conducted by testing our model on real-world datasets, underscored the model's viability for real-world strawberry harvesting scenarios, even though its training was based on synthetic data. The model also exhibited robust occlusion handling abilities, maintaining accurate detection capabilities even when strawberries were obscured by other strawberries or foliage. Additionally, the model showcased remarkably swift inference speeds, reaching up to 60 frames per second (FPS).
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t5_05">
             15:30-16:30, Paper WePI3T5.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2837'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              D2SR: Decentralized Detection, De-Synchronization, and Recovery of LiDAR Interference
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391393" title="Click to go to the Author Index">
             Rathnayake, Darshana
            </a>
           </td>
           <td class="r">
            Singapore Management University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398668" title="Click to go to the Author Index">
             Sabbella, Hemanth
            </a>
           </td>
           <td class="r">
            Singapore Management University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398666" title="Click to go to the Author Index">
             Radhakrishnan, Meera
            </a>
           </td>
           <td class="r">
            University of Technology Sydney
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#164087" title="Click to go to the Author Index">
             Misra, Archan
            </a>
           </td>
           <td class="r">
            Singapore Management University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2837" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_networks" title="Click to go to the Keyword Index">
               Sensor Networks
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#embedded_systems_for_robotic_and_automation" title="Click to go to the Keyword Index">
               Embedded Systems for Robotic and Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We address the challenge of multi-LiDAR interference, an issue of growing importance as LiDAR sensors are embedded in a growing set of pervasive devices. We introduce a novel approach named D2SR, enabling decentralized interference detection, mitigation, and recovery without explicit coordination among nearby LiDAR devices. D2SR comprises three stages: (a) Detection, which identifies interfered frames, (b) Mitigation, which performs time-shifting of a LiDAR’s active period to reduce interference, and (c) Recovery, which corrects or reconstructs the depth values in interfered regions of a depth frame. Key contributions include a lightweight interference detection algorithm achieving an F1-score of 92%, a simple yet effective decentralized de-synchronization mechanism, and a lightweight depth recovery pipeline that preserves high throughput processing on edge devices. Evaluation on Nvidia Jetson devices demonstrates D2SR’s efficacy: under static settings, D2SR accurately detects interference in 93% of cases (recall=82%) and reduces the depth estimation error by 27% (RMSE= 38.7 cm, compared to RMSE= 60.6 cm for a baseline without D2SR). Furthermore, D2SR is able to reduce the fraction of interfered frames by 75.1% and reduce the depth estimation error (for interfered frames) by 24.9% even for a moving robot scenario.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t5_06">
             15:30-16:30, Paper WePI3T5.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3060'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robust Multi-Camera BEV Perception: An Image-Perceptive Approach to Counter Imprecise Camera Calibration
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#350122" title="Click to go to the Author Index">
             Sun, Rundong
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#128869" title="Click to go to the Author Index">
             Fu, Mengyin
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#324113" title="Click to go to the Author Index">
             Liang, Hao
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#350120" title="Click to go to the Author Index">
             Zhu, Chunhui
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#350140" title="Click to go to the Author Index">
             Dong, Zhipeng
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#128868" title="Click to go to the Author Index">
             Yang, Yi
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3060" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recently, Bird’s Eye View (BEV) detection methodologies that utilize surround-view cameras have seen significant advancements in autonomous driving systems. Traditional methods, however, are constrained by their reliance on specific camera parameters, which poses challenges in generalizing across different vehicle-mounted cameras with varying poses and under adverse conditions. To address these challenges, we propose a robust BEV representation network that integrates Dual-Space Positional Encoding (DSPE) and image perception. This network is designed to enhance resilience to calibration errors and pose fluctuations, resulting in reliable detection performance on the Nuscenes dataset, even with imprecise extrinsic inputs. Our approach demonstrates competitive accuracy when compared to other methods that do not rely on temporal data, highlighting the effectiveness of our DSPE strategy in improving the robustness and accuracy of BEV detection in dynamic and challenging environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t5_07">
             15:30-16:30, Paper WePI3T5.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3100'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Few-Shot Transparent Instance Segmentation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#122330" title="Click to go to the Author Index">
             Cherian, Anoop
            </a>
           </td>
           <td class="r">
            Mitsubishi Electric Research Labs
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#135389" title="Click to go to the Author Index">
             Jain, Siddarth
            </a>
           </td>
           <td class="r">
            Mitsubishi Electric Research Laboratories (MERL)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#114589" title="Click to go to the Author Index">
             Marks, Tim K.
            </a>
           </td>
           <td class="r">
            Mitsubishi Electric Research Laboratories (MERL)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3100" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we consider the problem of segmenting multiple instances of a transparent object from RGB or gray scale camera images in a robotic bin picking setting. Prior methods for solving this task are usually built on the Mask-RCNN framework, but they require large annotated datasets for fine-tuning. Instead, we consider the task in a few-shot setting and present TrInSeg, a data-efficient and robust instance segmentation method for transparent objects based on Mask-RCNN. Our key innovations in TrInSeg are twofold: i) a novel method, dubbed TransMixup, for producing new training images using synthetic transparent object instances created by spatially transforming annotated examples; and ii) a method for scoring the consistency between the predicted segments and rotations of an ideal object template. In our new scoring method, the spatial transformations are produced by an auxiliary neural network, and the scores are then used to filter inconsistent instance predictions. To demonstrate the effectiveness of our method, we present experiments on a new few-shot dataset consisting of seven categories of non-opaque (transparent and translucent) objects, each category varying in the size, shape, and degree of transparency of the objects. Our results show that TrInSeg achieves state-of-the-art performance, improving fine-tuned Mask-RCNN by more than 14% in mIoU, while requiring very few annotated training samples.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t5_08">
             15:30-16:30, Paper WePI3T5.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3522'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SSL-RGB2IR: Semi-Supervised RGB-To-IR Image-To-Image Translation for Enhancing Visual Task Training in Semantic Segmentation and Object Detection
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#377314" title="Click to go to the Author Index">
             Sikdar, Aniruddh
            </a>
           </td>
           <td class="r">
            Indian Institute of Science, Bangalore
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#379443" title="Click to go to the Author Index">
             Saadiyean, Qiranul
            </a>
           </td>
           <td class="r">
            Indian Institute of Science, Banglore
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397881" title="Click to go to the Author Index">
             Anand, Prahlad
            </a>
           </td>
           <td class="r">
            Vellore Institute of Technology, Vellore
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#231176" title="Click to go to the Author Index">
             Sundaram, Suresh
            </a>
           </td>
           <td class="r">
            Indian Institute of Science
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3522" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The scarcity of annotated infrared (IR) image datasets limits deep learning networks from achieving perfor- mances comparable to those achieved with RGB data. To address this, we introduce a novel semi-supervised RGB-to-IR Image-to-Image Translation model (SSL-RGB2IR) that generates synthetic IR data from RGB images. Our model effectively preserves the IR characteristics in the generated images from both syn- thetic and real-world data. Compared to existing image-to-image translation techniques, training models on this generated IR data significantly improves performance in downstream tasks like segmentation and detection. Notably, in sim-to-real transfer, the segmentation model trained on SSL-RGB2IR generated IR images outperforms baselines and other Image-to-Image (I2I) models. Furthermore, for real-world applications utilizing EO/IR fusion images, this approach solves the well-known challenge of co-registering EO and IR images, which often have inherent misalignment’s due to differing sensor characteristics. Our code is available at https://github.com/prahlad-anand/ssl-rgb2ir.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t5_09">
             15:30-16:30, Paper WePI3T5.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1365'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Assessing Monocular Depth Estimation Networks for UAS Deployment in Rainforest Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395421" title="Click to go to the Author Index">
             Tangellapalli, Srisai Anirudh
            </a>
           </td>
           <td class="r">
            University of Nebraska-Lincoln
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#362904" title="Click to go to the Author Index">
             Sangha, Harman Singh
            </a>
           </td>
           <td class="r">
            Iowa State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#152012" title="Click to go to the Author Index">
             Peschel, Joshua
            </a>
           </td>
           <td class="r">
            Iowa State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#127015" title="Click to go to the Author Index">
             Duncan, Brittany
            </a>
           </td>
           <td class="r">
            University of Nebraska, Lincoln
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1365" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__perception_and_autonomy" title="Click to go to the Keyword Index">
               Aerial Systems: Perception and Autonomy
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The primary objective of this study was to utilize state-of-the-art deep learning-based monocular depth estimation models to assist UAS pilots in rainforest canopy data collection and navigation. Monocular depth estimation models provide a complementary technique to other depth measurement and estimation techniques to extend the range and improve measurements. Several state-of-the-art models were evaluated using a novel dataset composed of data from a simulated rainforest environment. In the evaluation, MiDaS outperformed the other models, and a segmentation pipeline was designed using this model to identify the highest areas of the canopies. The segmentation pipeline was evaluated using 1080p and 360p input videos from the simulated rainforest dataset. It was able to achieve an IoU of 0.848 and 0.826 and an F1 score of 0.915 and 0.902 at each resolution, respectively. We incorporated the proposed depth-estimation-based segmentation pipeline into an example application and deployed it on an edge system. Experimental results display the capabilities of a UAS using the segmentation pipeline for rainforest data collection.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t5_10">
             15:30-16:30, Paper WePI3T5.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1947'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Rethinking 3D Geometric Object Features for Enhancing Skeleton-Based Action Recognition
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#323328" title="Click to go to the Author Index">
             Wu, Yuankai
            </a>
           </td>
           <td class="r">
            TUM
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396705" title="Click to go to the Author Index">
             Wang, Chi
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#352814" title="Click to go to the Author Index">
             Salihu, Driton
            </a>
           </td>
           <td class="r">
            Technical University Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#352817" title="Click to go to the Author Index">
             Patsch, Constantin
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#301328" title="Click to go to the Author Index">
             Zakour, Marsil
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#107651" title="Click to go to the Author Index">
             Steinbach, Eckehard
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1947" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#intention_recognition" title="Click to go to the Keyword Index">
               Intention Recognition
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#recognition" title="Click to go to the Keyword Index">
               Recognition
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Human action recognition is crucial for intelligent robots, especially in the realm of human-robot collaboration research. Recent advancements in human pose estimation algorithms have shifted the focus of action recognition towards skeleton-based models, which exhibit robustness to changes in background and illumination. However, many state-of-the-art action recognition models rely on 2D skeleton data, neglecting object features. This limitation becomes obvious in complex scenarios where human interactions with objects are crucial, potentially compromising the reliability of assistive robots in understanding human behavior in their environment. To address this issue, we propose a method that effectively integrates 3D geometric object features into skeleton data using graph convolutional neural networks (GCNs). In addition to analyzing the effectiveness of information from different dimensions such as object center position, category, translation, and rotation, we explore various adjacency matrix designs for graph networks. Our model performance is evaluated on two challenging datasets: IKEA ASM and Bimanual Actions. The results demonstrate a significant improvement in action recognition by integrating object features into skeleton-based models. Specifically, on the IKEA-ASM dataset, our approach achieves a frame-wise Top-1 score improvement of 10.8% and an average F1@k improvement of 13.3%, while on the Bimanual Actions dataset, it achieves a frame-wise Top-1 score improvement of 11.4% and an average F1@k improvement of 5.3%, with negligible increases in model complexity.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t5_11">
             15:30-16:30, Paper WePI3T5.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1256'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Fast Spatial Reasoning of Implicit 3D Maps through Explicit Near-Far Sampling Range Prediction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392475" title="Click to go to the Author Index">
             Min, Chaerin
            </a>
           </td>
           <td class="r">
            Brown University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393581" title="Click to go to the Author Index">
             Cha, Sehyun
            </a>
           </td>
           <td class="r">
            LG Electronics
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#235985" title="Click to go to the Author Index">
             Won, Changhee
            </a>
           </td>
           <td class="r">
            Hanyang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#117882" title="Click to go to the Author Index">
             Lim, Jongwoo
            </a>
           </td>
           <td class="r">
            Hanyang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1256" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             3D mapping is critical for many robotics applications, such as autonomous navigation and object manipulation. Recently, deep implicit mapping approaches have received much attention for their compactness and ability to represent fine-grained details. However, without explicit guidance, such implicit representations are often cumbersome for searching the full range on the rays to find the object surfaces. As a result, several approaches, including hierarchical sampling, occupancy grids, and zero-level set baking, have been proposed to improve sampling where costly forward passes of the neural network should be performed. However, hierarchical sampling is still suboptimal in that it requires uniform coarse samples. Discrete occupancy grids of Instant NGP and zero-level sets of various baking methods are less suitable for large and noisy real scenes. In this paper, we present a novel framework for adaptively predicting the near-far range for sampling the query positions of the deep implicit map. For this purpose, the truncated signed distance grid for the map is pre-constructed and used to provide hints for near-far prediction during rendering. In addition, our recovery algorithm automatically detects failed near-far predictions and recovers only those rays by directly using the implicit map. We conduct extensive experiments on a synthetic dataset, a public real dataset, and a real dataset captured by our multi-camera robot system. The experimental results show that our algorithm achieves the same rendering quality with surprisingly fewer samples compared to the existing methods, which means that the robot can reason about the image and depth properties of the scene much faster. Finally, a thorough analysis of the sample distribution along the rays is provided to give a better understanding of our method's strong efficiency, adaptability, and robustness.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t5_12">
             15:30-16:30, Paper WePI3T5.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2117'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              NeuFlow: Real-Time, High-Accuracy Optical Flow Estimation on Robots Using Edge Devices
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#358356" title="Click to go to the Author Index">
             Zhang, Zhiyong
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105079" title="Click to go to the Author Index">
             Singh, Hanumant
            </a>
           </td>
           <td class="r">
            Northeatern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#239579" title="Click to go to the Author Index">
             Jiang, Huaizu
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2117" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_tracking" title="Click to go to the Keyword Index">
               Visual Tracking
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Real-time high-accuracy optical flow estimation is a crucial component in various applications, including localization and mapping in robotics, object tracking, and activity recognition in computer vision. While recent learning-based optical flow methods have achieved high accuracy, they often come with heavy computation costs. In this paper, we propose a highly efficient optical flow architecture, called NeuFlow, that addresses both high accuracy and computational cost concerns. The architecture follows a global-to-local scheme. Given the features of the input images extracted at different spatial resolutions, global matching is employed to estimate an initial optical flow on the 1/16 resolution, capturing large displacement, which is then refined on the 1/8 resolution with lightweight CNN layers for better accuracy. We evaluate our approach on Jetson Orin Nano and RTX 2080 to demonstrate efficiency improvements across different computing platforms. We achieve a notable 10×-80× speedup compared to several state-of-the-art methods, while maintaining comparable accuracy. Our approach achieves around 30 FPS on edge computing platforms, which represents a significant breakthrough in deploying complex computer vision tasks such as SLAM on small robots like drones. The full training and evaluation code is available at https://github.com/neufieldrobotics/NeuFlow.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t5_13">
             15:30-16:30, Paper WePI3T5.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1594'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Domain Randomization-Free Sim-To-Real : An Attention-Augmented Memory Approach for Robotic Tasks
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394292" title="Click to go to the Author Index">
             Qu, Jia
            </a>
           </td>
           <td class="r">
            Mitsubishi Electric Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#244378" title="Click to go to the Author Index">
             Otsubo, Shun
            </a>
           </td>
           <td class="r">
            Mitsubishi Electric Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#295549" title="Click to go to the Author Index">
             Yamanokuchi, Tomoya
            </a>
           </td>
           <td class="r">
            Nara Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#122480" title="Click to go to the Author Index">
             Matsubara, Takamitsu
            </a>
           </td>
           <td class="r">
            Nara Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394291" title="Click to go to the Author Index">
             Miwa, Shotaro
            </a>
           </td>
           <td class="r">
            Mitsubishi Electric Corp
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1594" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#representation_learning" title="Click to go to the Keyword Index">
               Representation Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The sim-to-real gap, a long-standing challenge in the field of robotics, has garnered significant attention. Essentially, it is important to learn robust representation models that can be seamlessly applied in both simulation and real world. Traditional approaches like domain randomization have demonstrated success in zero-short setting, by creating representations that are resilient and adaptable through the augmentation of diversity within simulations. However, they suffer from the need for extensive training across a range of parameter variances, and dependency on heuristic approaches. In this work, we present a novel reinforcement learning architecture named Soft Attention-Augmented Actor-Critic (Soft3AC) for sim-to-real robotic tasks without the need for heuristic domain randomization. Our approach achieves the learning of semantically task-relevant feature representations that exhibit resilience against appearance gaps. This is realized by employing an architectural design that separates current perceptions from historical perceptions in memory, fostering abstract spatial-temporal understanding. Simultaneously, the introduction of an attention mechanism enables a more contextual processing. We validated our method through conducting a valve rotation task with a robotic hand, under both sim-to-sim and sim-to-real conditions. The results indicate that our model adeptly bridges the appearance gap observed in sim-to-sim and sim-to-real transfers. Our method demonstrated its ability to be deployed directly into the real world in a domain randomization free zero-shot manner.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t5_14">
             15:30-16:30, Paper WePI3T5.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1847'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              MPGNet: Learning Move-Push-Grasping Synergy for Target-Oriented Grasping in Occluded Scenes
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#384300" title="Click to go to the Author Index">
             Li, Dayou
            </a>
           </td>
           <td class="r">
            School of Control Science and Engineering, Shandong Universisty
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#388110" title="Click to go to the Author Index">
             Zhao, Chenkun
            </a>
           </td>
           <td class="r">
            Shandong University, School of Control Science and Engineering
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#245721" title="Click to go to the Author Index">
             Yang, Shuo
            </a>
           </td>
           <td class="r">
            Shandong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#268891" title="Click to go to the Author Index">
             Song, Ran
            </a>
           </td>
           <td class="r">
            Shandong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397292" title="Click to go to the Author Index">
             Li, Xiaolei
            </a>
           </td>
           <td class="r">
            Shandong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#203913" title="Click to go to the Author Index">
             Zhang, Wei
            </a>
           </td>
           <td class="r">
            Shandong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1847" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper focuses on target-oriented grasping in occluded scenes, where the target object is specified by a binary mask and the goal is to grasp the target object with as few robotic manipulations as possible. Most existing methods rely on a push-grasping synergy to complete this task. To deliver a more powerful target-oriented grasping pipeline, we present MPGNet, a three-branch network for learning a synergy between moving, pushing, and grasping actions. We also propose a multi-stage training strategy to train the MPGNet which contains three policy networks corresponding to the three actions. The effectiveness of our method is demonstrated via both simulated and real-world experiments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t5_15">
             15:30-16:30, Paper WePI3T5.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1995'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Progressive Representation Learning for Real-Time UAV Tracking
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#160488" title="Click to go to the Author Index">
             Fu, Changhong
            </a>
           </td>
           <td class="r">
            Tongji University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393297" title="Click to go to the Author Index">
             Lei, Xiang
            </a>
           </td>
           <td class="r">
            Tongji University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#324459" title="Click to go to the Author Index">
             Zuo, Haobo
            </a>
           </td>
           <td class="r">
            University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#339398" title="Click to go to the Author Index">
             Yao, Liangliang
            </a>
           </td>
           <td class="r">
            Tongji University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#287784" title="Click to go to the Author Index">
             Zheng, Guangze
            </a>
           </td>
           <td class="r">
            The University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#131357" title="Click to go to the Author Index">
             Pan, Jia
            </a>
           </td>
           <td class="r">
            University of Hong Kong
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1995" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#representation_learning" title="Click to go to the Keyword Index">
               Representation Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Visual object tracking has significantly promoted autonomous applications for unmanned aerial vehicles (UAVs). However, learning robust object representations for UAV tracking is especially challenging in complex dynamic environments, when confronted with aspect ratio change and occlusion. These challenges severely alter the original information of the object. To handle the above issues, this work proposes a novel progressive representation learning framework for UAV tracking, i.e., PRL-Track. Specifically, PRL-Track is divided into coarse representation learning and fine representation learning. For coarse representation learning, two innovative regulators, which rely on appearance and semantic information, are designed to mitigate appearance interference and capture semantic information. Furthermore, for fine representation learning, a new hierarchical modeling generator is developed to intertwine coarse object representations. Exhaustive experiments demonstrate that the proposed PRL-Track delivers exceptional performance on three authoritative UAV tracking benchmarks. Real-world tests indicate that the proposed PRL-Track realizes superior tracking performance with 42.6 frames per second on the typical UAV platform equipped with an edge smart camera. The code, model, and demo videos are available at https://github.com/vision4robotics/PRL-Track.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t5_16">
             15:30-16:30, Paper WePI3T5.16
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1091'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              WasteGAN: Data Augmentation for Robotic Waste Sorting through Generative Adversarial Networks
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#327826" title="Click to go to the Author Index">
             Bacchin, Alberto
            </a>
           </td>
           <td class="r">
            University of Padua
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#308057" title="Click to go to the Author Index">
             Barcellona, Leonardo
            </a>
           </td>
           <td class="r">
            University of Padova
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#224747" title="Click to go to the Author Index">
             Terreran, Matteo
            </a>
           </td>
           <td class="r">
            University of Padova
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#133197" title="Click to go to the Author Index">
             Ghidoni, Stefano
            </a>
           </td>
           <td class="r">
            University of Padova
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105144" title="Click to go to the Author Index">
             Menegatti, Emanuele
            </a>
           </td>
           <td class="r">
            The University of Padua
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#232912" title="Click to go to the Author Index">
             Kiyokawa, Takuya
            </a>
           </td>
           <td class="r">
            Osaka University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1091" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#energy_and_environment_aware_automation" title="Click to go to the Keyword Index">
               Energy and Environment-Aware Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robotic waste sorting poses significant challenges in both perception and manipulation, given the extreme variability of objects that should be recognized on a cluttered conveyor belt. While deep learning has proven effective in solving complex tasks, the necessity for extensive data collection and labeling limits its applicability in real-world scenarios like waste sorting. To tackle this issue, we introduce a data augmentation method based on a novel GAN architecture called wasteGAN. The proposed method allows to increase the performance of semantic segmentation models, starting from a very limited bunch of labeled examples, such as few as 100. The key innovations of wasteGAN include a novel loss function, a novel activation function, and a larger generator block. Overall, such innovations helps the network to learn from limited number of examples and synthesize data that better mirrors real-world distributions. We then leverage the higher-quality segmentation masks predicted from models trained on the wasteGAN synthetic data to compute semantic-aware grasp poses, enabling a robotic arm to effectively recognizing contaminants and separating waste in a real-world scenario. Through comprehensive evaluation encompassing dataset-based assessments and real-world experiments, our methodology demonstrated promising potential for robotic waste sorting, yielding performance gains of up to 5.8% in picking contaminants. The project page is available at https://github.com/bach05/wasteGAN.git.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wepi3t6">
             <b>
              WePI3T6
             </b>
            </a>
           </td>
           <td class="r">
            Room 6
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wepi3t6" title="Click to go to the Program at a Glance">
             <b>
              Learning II
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#128197" title="Click to go to the Author Index">
             Finzi, Alberto
            </a>
           </td>
           <td class="r">
            University of Naples
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t6_01">
             15:30-16:30, Paper WePI3T6.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('507'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Reward-Driven Automated Curriculum Learning for Interaction-Aware Self-Driving at Unsignalized Intersections
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#302771" title="Click to go to the Author Index">
             Peng, Zengqi
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology (Guangzhou)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#323458" title="Click to go to the Author Index">
             Zhou, Xiao
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#274896" title="Click to go to the Author Index">
             Zheng, Lei
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology (Guangzhou)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#353706" title="Click to go to the Author Index">
             Wang, Yubin
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology (Guangzhou)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#182083" title="Click to go to the Author Index">
             Ma, Jun
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab507" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#learning_from_experience" title="Click to go to the Keyword Index">
               Learning from Experience
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this work, we present a reward-driven automated curriculum reinforcement learning approach for interaction-aware self-driving at unsignalized intersections, taking into account the uncertainties associated with surrounding vehicles (SVs). These uncertainties encompass the uncertainty of SVs' driving intention and also the quantity of SVs. To deal with this problem, the curriculum set is specifically designed to accommodate a progressively increasing number of SVs. By implementing an automated curriculum selection mechanism, the importance weights are rationally allocated across various curricula, thereby facilitating improved sample efficiency and training outcomes. Furthermore, the reward function is meticulously designed to guide the agent towards effective policy exploration. Thus the proposed framework could proactively address the above uncertainties at unsignalized intersections by employing the automated curriculum learning technique that progressively increases task difficulty, and this ensures safe self-driving through effective interaction with SVs. Comparative experiments are conducted in Highway_Env, and the results indicate that our approach achieves the highest task success rate, attains strong robustness to initialization parameters of the curriculum selection module, and exhibits superior adaptability to diverse situational configurations at unsignalized intersections. Furthermore, the effectiveness of the proposed method is validated using the high-fidelity CARLA simulator.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t6_02">
             15:30-16:30, Paper WePI3T6.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1655'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              JUICER: Data-Efficient Imitation Learning for Robotic Assembly
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#389867" title="Click to go to the Author Index">
             Ankile, Lars
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#204026" title="Click to go to the Author Index">
             Simeonov, Anthony
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396095" title="Click to go to the Author Index">
             Shenfeld, Idan
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#204887" title="Click to go to the Author Index">
             Agrawal, Pulkit
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1655" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#assembly" title="Click to go to the Keyword Index">
               Assembly
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             While learning from demonstrations is powerful for acquiring visuomotor policies, high-performance imitation without large demonstration datasets remains challenging for tasks requiring precise, long-horizon manipulation. This paper proposes a pipeline for improving imitation learning performance with a small human demonstration budget. We apply our approach to assembly tasks that require precisely grasping, reorienting, and inserting multiple parts over long horizons and multiple task phases. Our pipeline combines expressive policy architectures and various techniques for dataset expansion and simulation-based data augmentation. These help expand dataset support and supervise the model with locally corrective actions near bottleneck regions requiring high precision. We demonstrate our pipeline on four furniture assembly tasks in simulation, enabling a manipulator to assemble up to five parts over nearly 2500 time steps directly from RGB images, outperforming imitation and data augmentation baselines.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t6_03">
             15:30-16:30, Paper WePI3T6.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2417'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              DexSkills: Skill Segmentation Using Haptic Data for Learning Autonomous Long-Horizon Robotic Manipulation Tasks
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#363708" title="Click to go to the Author Index">
             Mao, Xiaofeng
            </a>
           </td>
           <td class="r">
            Edinburgh University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#358810" title="Click to go to the Author Index">
             Giudici, Gabriele
            </a>
           </td>
           <td class="r">
            Queen Mary University of London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#182956" title="Click to go to the Author Index">
             Coppola, Claudio
            </a>
           </td>
           <td class="r">
            Humanoid AI
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101975" title="Click to go to the Author Index">
             Althoefer, Kaspar
            </a>
           </td>
           <td class="r">
            Queen Mary University of London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#113910" title="Click to go to the Author Index">
             Farkhatdinov, Ildar
            </a>
           </td>
           <td class="r">
            King's College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#125824" title="Click to go to the Author Index">
             Li, Zhibin (Alex)
            </a>
           </td>
           <td class="r">
            University College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#108793" title="Click to go to the Author Index">
             Jamone, Lorenzo
            </a>
           </td>
           <td class="r">
            Queen Mary University London
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2417" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#dexterous_manipulation" title="Click to go to the Keyword Index">
               Dexterous Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Effective execution of long-horizon tasks with dexterous robotic hands remains a significant challenge in real-world problems. While learning from human demonstrations has shown encouraging results, they require extensive data collection for training. Hence, decomposing long-horizon tasks into reusable primitive skills is a more efficient approach. To achieve so, we developed DexSkills, a novel supervised learning framework that addresses long-horizon dexterous manipulation tasks using primitive skills. DexSkills is trained to recognize and replicate a select set of skills using human demonstration data, which can then segment a demonstrated long-horizon dexterous manipulation task into a sequence of primitive skills to achieve one-shot execution by the robot directly. Significantly, DexSkills operates solely on proprioceptive and tactile data, i.e., haptic data. Our real-world robotic experiments show that DexSkills can accurately segment skills, thereby enabling autonomous robot execution of a diverse range of tasks.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t6_04">
             15:30-16:30, Paper WePI3T6.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3048'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Efficient Tactile Sensing-Based Learning from Limited Real-World Demonstrations for Dual-Arm Fine Pinch-Grasp Skills
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#363708" title="Click to go to the Author Index">
             Mao, Xiaofeng
            </a>
           </td>
           <td class="r">
            Edinburgh University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#309718" title="Click to go to the Author Index">
             Xu, Yucheng
            </a>
           </td>
           <td class="r">
            University of Edinburgh
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#248340" title="Click to go to the Author Index">
             Wen, Ruoshi
            </a>
           </td>
           <td class="r">
            Touchlab Limited
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#244242" title="Click to go to the Author Index">
             Kasaei, Mohammadreza
            </a>
           </td>
           <td class="r">
            University of Edinburgh
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#271349" title="Click to go to the Author Index">
             Yu, Wanming
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#155662" title="Click to go to the Author Index">
             Psomopoulou, Efi
            </a>
           </td>
           <td class="r">
            University of Bristol
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#140569" title="Click to go to the Author Index">
             Lepora, Nathan
            </a>
           </td>
           <td class="r">
            University of Bristol
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#125824" title="Click to go to the Author Index">
             Li, Zhibin (Alex)
            </a>
           </td>
           <td class="r">
            University College London
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3048" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#dual_arm_manipulation" title="Click to go to the Keyword Index">
               Dual Arm Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Imitation learning for robot dexterous manipulation, especially with a real robot setup, typically requires a large number of demonstrations. In this paper, we present a data-efficient learning from demonstration framework which exploits the use of rich tactile sensing data and achieves fine bimanual pinch grasping. Specifically, we employ a convolutional autoencoder network that can effectively extract and encode high-dimensional tactile information. Further, we develop a framework that achieves efficient multi-sensor fusion for imitation learning, allowing the robot to learn contact-aware sensorimotor skills from demonstrations. The ablation studies on encoded tactile features highlighted the effectiveness of incorporating rich contact information, which enabled dexterous bimanual grasping with active contact searching. Extensive experiments demonstrated the robustness of the fine pinch grasp policy directly learned from few-shot demonstration, including grasping of the same object with different initial poses, generalizing to ten unseen new objects, robust and firm grasping against external pushes, as well as contact-aware and reactive re-grasping in case of dropping objects under very large perturbations. Furthermore, the saliency map analysis method is used to describe weight distribution across various modalities during pinch grasping, confirming the effectiveness of our framework at leveraging multimodal information.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t6_05">
             15:30-16:30, Paper WePI3T6.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('115'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Beyond Success: Quantifying Demonstration Quality in Learning from Demonstration
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#387690" title="Click to go to the Author Index">
             Bilal, Muhammad
            </a>
           </td>
           <td class="r">
            The University of Melbourne
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#345434" title="Click to go to the Author Index">
             Lipovetzky, Nir
            </a>
           </td>
           <td class="r">
            The University of Melbourne
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#107362" title="Click to go to the Author Index">
             Oetomo, Denny
            </a>
           </td>
           <td class="r">
            The University of Melbourne
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#174011" title="Click to go to the Author Index">
             Johal, Wafa
            </a>
           </td>
           <td class="r">
            University of Melbourne
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab115" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Learning from Demonstration (LfD) empowers novice users to teach robots daily life tasks without writing sophisticated code, thereby promoting the democratization of robotics. However, novice users often provide sub-optimal demonstrations, which can potentially impact the robot's ability to efficiently learn and execute the tasks. Prior research has assessed the quality of demonstrations by evaluating the robot's task performance; however, the approach remains insufficient to qualify individual demonstrations, leaving the reason for classifying demonstrations as high- or low-quality unknown. Therefore, this simulation-based study aims to quantify the quality of individual demonstration at each step by incorporating motion-related quality features such as manipulability and joint-space jerk. To assess the efficacy of these features, we initially evaluated the given demonstrations---taking into account each quality feature---to rank them from high- to low-quality. Subsequently, we investigated the impact of demonstration's quality on task performance and the quality of task execution. In this pursuit, we trained a series of LfD models for distinct manipulation tasks: cube lifting and pick-and-place of soda can. Our results illustrate a strong correlation between ranked demonstrations and the quality of task execution. Interestingly, we observed that the quality features have a significant impact on task performance, particularly when the provided demonstrations exhibit diversity in terms of quality. Overall, this analysis enables quantifying the quality of individual demonstrations based on motion-related quality features, thus improving learning from demonstration.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t6_06">
             15:30-16:30, Paper WePI3T6.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('458'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Knowledge-Based Programming by Demonstration Using Semantic Action Models for Industrial Assembly
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#358928" title="Click to go to the Author Index">
             Ding, Junsheng
            </a>
           </td>
           <td class="r">
            Fortiss GmbH
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375656" title="Click to go to the Author Index">
             Zhang, Haifan
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375655" title="Click to go to the Author Index">
             Li, Weihang
            </a>
           </td>
           <td class="r">
            Fortiss GmbH
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375726" title="Click to go to the Author Index">
             Zhou, Liangwei
            </a>
           </td>
           <td class="r">
            Fortiss GmbH
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#142250" title="Click to go to the Author Index">
             Perzylo, Alexander Clifford
            </a>
           </td>
           <td class="r">
            Fortiss - An-Institut Technische Universität München
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab458" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#intelligent_and_flexible_manufacturing" title="Click to go to the Keyword Index">
               Intelligent and Flexible Manufacturing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we introduce a knowledge-based Programming by Demonstration (kb-PbD) paradigm to facilitate robot programming in small and medium-sized enterprises (SMEs). PbD in production scenarios requires the recognition of product-specific actions but faces challenges in the lack of suitable and comprehensive datasets, due to the large variety of involved hand actions across different production scenarios. To address this issue, we utilize standardized grasp types as the fundamental feature to recognize basic hand movements, where a Long Short-Term Memory (LSTM) network is employed to recognize grasp types from hand landmarks. The product-specific actions, aggregated from the basic hand movements, are formally modeled in a semantic description language based on the Web Ontology Language (OWL). Description Logic (DL) is used to define the actions with their characteristic properties, which enables the efficient classification of new action instances by an OWL reasoner.
             <p>
              The semantic models of hand actions, robot tasks, and workcell resources are interconnected and stored in a Knowledge Base (KB), which enables the efficient pair-wise translation between hand actions and robot tasks. For the reproduction of human assembly processes, actions are converted to robot tasks via skill descriptions, while reusing the action parameters of involved objects to ensure product integrity. We showcase and evaluate our method in an industrial production setting for control cabinet assembly. Demonstration video available at: https://kb-pbd.github.io/.
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t6_07">
             15:30-16:30, Paper WePI3T6.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2368'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              PP-TIL: Personalized Planning for Autonomous Driving with Instance-Based Transfer Imitation Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#374351" title="Click to go to the Author Index">
             Lin, Fangze
            </a>
           </td>
           <td class="r">
            Shenzhen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#374365" title="Click to go to the Author Index">
             He, Ying
            </a>
           </td>
           <td class="r">
            Shenzhen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393394" title="Click to go to the Author Index">
             Yu, Fei
            </a>
           </td>
           <td class="r">
            Guangming Lab
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2368" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#transfer_learning" title="Click to go to the Keyword Index">
               Transfer Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Personalized motion planning holds significant importance within urban automated driving, catering to the unique requirements of individual users. Nevertheless, prior endeavors have frequently encountered difficulties in simultaneously addressing two crucial aspects: personalized planning within intricate urban settings and enhancing planning performance through data utilization. The challenge arises from the expensive and limited nature of user data, coupled with the scene state space tending towards infinity. These factors contribute to overfitting and poor generalization problems during model training. Henceforth, we propose an instance-based transfer imitation learning approach. This method facilitates knowledge transfer from extensive expert domain data to the user domain, presenting a fundamental resolution to these issues. We initially train a pre-trained model using large-scale expert data. Subsequently, during the fine-tuning phase, we feed the batch data, which comprises expert and user data. Employing the inverse reinforcement learning technique, we extract the style feature distribution from user demonstrations, constructing the regularization term for the approximation of user style. In our experiments, we conducted extensive evaluations of the proposed method. Compared to the baseline methods, our approach mitigates the overfitting issue caused by sparse user data. Furthermore, we discovered that integrating the driving model with a differentiable nonlinear optimizer as a safety protection layer for end-to-end personalized fine-tuning results in superior planning performance. The code will be available at https://github.com/LinFunster/PP-TIL.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t6_08">
             15:30-16:30, Paper WePI3T6.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2459'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Riemannian Flow Matching Policy for Robot Motion Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398262" title="Click to go to the Author Index">
             Braun, Max
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology (KIT)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#211075" title="Click to go to the Author Index">
             Jaquier, Noémie
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology (KIT)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#161966" title="Click to go to the Author Index">
             Rozo, Leonel
            </a>
           </td>
           <td class="r">
            Bosch Center for Artificial Intelligence
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102922" title="Click to go to the Author Index">
             Asfour, Tamim
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology (KIT)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2459" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We introduce Riemannian Flow Matching Policies (RFMP), a novel model for learning and synthesizing robot visuomotor policies. RFMP leverages the efficient training and inference capabilities of flow matching methods. By design, RFMP inherits the strengths of flow matching: the ability to encode high-dimensional multimodal distributions, commonly encountered in robotic tasks, and a very simple and fast inference process. We demonstrate the applicability of RFMP to both state-based and vision-conditioned robot motion policies. Notably, as the robot state resides on a Riemannian manifold, RFMP inherently incorporates geometric awareness, which is crucial for realistic robotic tasks. To evaluate RFMP, we conduct two proof-of-concept experiments, comparing its performance against Diffusion Policies. Although both approaches successfully learn the considered tasks, our results show that RFMP provides smoother action trajectories with significantly lower inference times.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t6_09">
             15:30-16:30, Paper WePI3T6.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2461'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SE(3) Linear Parameter Varying Dynamical Systems for Globally Asymptotically Stable End-Effector Control
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#380194" title="Click to go to the Author Index">
             Sun, Sunan
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#151054" title="Click to go to the Author Index">
             Figueroa, Nadia
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2461" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_robot_collaboration" title="Click to go to the Keyword Index">
               Human-Robot Collaboration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Linear Parameter Varying Dynamical Systems (LPV-DS) encode trajectories into an autonomous first-order DS that enables reactive responses to perturbations, while ensuring globally asymptotic stability at the target. However, the current LPV-DS framework is established on Euclidean data only and has not been applicable to broader robotic applications requiring pose control. In this paper we present an extension to the current LPV-DS framework, named Quaternion-DS, which efficiently learns a DS-based motion policy for orientation. Leveraging techniques from differential geometry and Riemannian statistics, our approach properly handles the non-Euclidean orientation data in quaternion space, enabling the integration with positional control, namely SE(3) LPV-DS, so that the synergistic behaviour within the full SE(3) pose is preserved. Through simulation and real robot experiments, we validate our method, demonstrating its ability to efficiently and accurately reproduce the original SE(3) trajectory while exhibiting strong robustness to perturbations in task space.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t6_10">
             15:30-16:30, Paper WePI3T6.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2666'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning Symbolic and Subsymbolic Temporal Task Constraints from Bimanual Human Demonstrations
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#216000" title="Click to go to the Author Index">
             Dreher, Christian R. G.
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology (KIT)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102922" title="Click to go to the Author Index">
             Asfour, Tamim
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology (KIT)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2666" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#bimanual_manipulation" title="Click to go to the Keyword Index">
               Bimanual Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#task_planning" title="Click to go to the Keyword Index">
               Task Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Learning task models of bimanual manipulation from human demonstration and their execution on a robot should take temporal constraints between actions into account. This includes constraints on (i) the symbolic level such as precedence relations or temporal overlap in the execution, and (ii) the subsymbolic level such as the duration of different actions, or their starting and end points in time. Such temporal constraints are crucial for temporal planning, reasoning, and the exact timing for the execution of bimanual actions on a bimanual robot. In our previous work, we addressed the learning of temporal task constraints on the symbolic level and demonstrated how a robot can leverage this knowledge to respond to failures during execution. In this work, we propose a novel model-driven approach for the combined learning of symbolic and subsymbolic temporal task constraints from multiple bimanual human demonstrations. Our main contributions are a subsymbolic foundation of a temporal task model that describes temporal nexuses of actions in the task based on distributions of temporal differences between semantic action keypoints, as well as a method based on fuzzy logic to derive symbolic temporal task constraints from this representation. This complements our previous work on learning comprehensive temporal task models by integrating symbolic and subsymbolic information based on a subsymbolic foundation, while still maintaining the symbolic expressiveness of our previous approach. We compare our proposed approach with our previous pure-symbolic approach and show that we can reproduce and even outperform it. Additionally, we show how the subsymbolic temporal task constraints can synchronize otherwise unimanual movement primitives for bimanual behavior on a humanoid robot.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t6_11">
             15:30-16:30, Paper WePI3T6.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2764'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Diffusion-PbD: Generalizable Robot Programming by Demonstration with Diffusion Features
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#292189" title="Click to go to the Author Index">
             Murray, Michael
            </a>
           </td>
           <td class="r">
            University of Washington
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#315216" title="Click to go to the Author Index">
             Su, Entong
            </a>
           </td>
           <td class="r">
            University of California San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106008" title="Click to go to the Author Index">
             Cakmak, Maya
            </a>
           </td>
           <td class="r">
            University of Washington
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2764" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Programming by Demonstration (PbD) is an intuitive technique for programming robot manipulation skills by demonstrating the desired behavior. However, most existing approaches either require extensive demonstrations or fail to generalize beyond their initial demonstration conditions. We introduce Diffusion-PbD, a novel approach to PbD that enables users to synthesize generalizable robot manipulation skills from a single demonstration by utilizing the representations captured by pre-trained visual foundation models. At demonstration time, hand and object detection priors are used to extract waypoints from the human demonstrations anchored to reference points in the scene. At execution time, features from pre-trained diffusion models are leveraged to identify corresponding reference points in new observations. We validate this approach through a series of real-world robot experiments, showing that Diffusion-PbD is applicable to a wide range of manipulation tasks and has strong ability to generalize to unseen objects, camera viewpoints, and scenes. Code and supplementary videos can be found at https://diffusion-pbd.github.io
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t6_12">
             15:30-16:30, Paper WePI3T6.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2800'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              DragTraffic: Interactive and Controllable Traffic Scene Generation for Autonomous Driving
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#323660" title="Click to go to the Author Index">
             Wang, Sheng
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#305812" title="Click to go to the Author Index">
             Sun, Ge
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#276186" title="Click to go to the Author Index">
             Ma, Fulong
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#315491" title="Click to go to the Author Index">
             Hu, Tianshuai
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#415602" title="Click to go to the Author Index">
             Qin, Qiang
            </a>
           </td>
           <td class="r">
            Department of Production Engineering, KTH Royal Institute of Tec
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376256" title="Click to go to the Author Index">
             Song, Yongkang
            </a>
           </td>
           <td class="r">
            Ningbo Lotus Robotics Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#341869" title="Click to go to the Author Index">
             Zhu, Lei
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology (Guangzhou)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372961" title="Click to go to the Author Index">
             Liang, Junwei
            </a>
           </td>
           <td class="r">
            HKUST (Guangzhou)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2800" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Evaluating and training autonomous driving systems require diverse and scalable corner cases. However, most existing scene generation methods lack controllability, accuracy, and versatility, resulting in unsatisfactory generation results. Inspired by DragGAN in image generation, we propose DragTraffic, a generalized, interactive, and controllable traffic scene generation framework based on conditional diffusion. DragTraffic enables non-experts to generate a variety of realistic driving scenarios for different types of traffic agents through an adaptive mixture expert architecture. We employ a regression model to provide a general initial solution and a refinement process based on the conditional diffusion model to ensure diversity. User-customized context is introduced through cross-attention to ensure high controllability. Experiments on a real-world driving dataset show that DragTraffic outperforms existing methods in terms of authenticity, diversity, and freedom.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t6_13">
             15:30-16:30, Paper WePI3T6.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2873'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Incremental Learning of Robotic Manipulation Tasks through Virtual Reality Demonstrations
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398707" title="Click to go to the Author Index">
             Rauso, Giuseppe
            </a>
           </td>
           <td class="r">
            University of Naples "Federico II"
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#174268" title="Click to go to the Author Index">
             Caccavale, Riccardo
            </a>
           </td>
           <td class="r">
            Università Di Napoli "Federico II"
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#128197" title="Click to go to the Author Index">
             Finzi, Alberto
            </a>
           </td>
           <td class="r">
            University of Naples
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2873" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#incremental_learning" title="Click to go to the Keyword Index">
               Incremental Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#virtual_reality_and_interfaces" title="Click to go to the Keyword Index">
               Virtual Reality and Interfaces
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We propose an incremental, modular, and extensible method for learning robotic manipulation tasks using a limited number of demonstrations provided in Virtual Reality, while assuming minimal prior information about the objects to be manipulated. The developed framework enables an incremental training process in which the operator first demonstrates specialized tasks to the robotic system, and subsequently more complex tasks, exploiting the skills learned during the previous phases. We illustrate and discuss the method at work considering picking tasks performed by manipulators equipped with multi-fingered sensorized hands. The experimental evaluation highlights the feasibility and advantage of the proposed method, particularly in terms of modularity, low number of demonstrations, and reliability of the trained system.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t6_14">
             15:30-16:30, Paper WePI3T6.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3183'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Is a Simulation Better Than Teleoperation for Acquiring Human Manipulation Skill Data?
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#334485" title="Click to go to the Author Index">
             Kim, Donghyeon
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology (KAIST)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#360015" title="Click to go to the Author Index">
             Park, Seong-Su
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#196716" title="Click to go to the Author Index">
             Lee, Kwang-Hyun
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104647" title="Click to go to the Author Index">
             Lee, Dongheui
            </a>
           </td>
           <td class="r">
            Technische Universität Wien (TU Wien)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102369" title="Click to go to the Author Index">
             Ryu, Jee-Hwan
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3183" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#simulation_and_animation" title="Click to go to the Keyword Index">
               Simulation and Animation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#haptics_and_haptic_interfaces" title="Click to go to the Keyword Index">
               Haptics and Haptic Interfaces
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This study explores the feasibility of using simulations as a better interface to collect human object manipulation skills for learning from demonstrations (LfD). Recently, numerous researchers have started introducing teleoperation systems to acquire human manipulation skills. However, capturing the subtle, force-involved interaction skills of humans in teleoperation is still challenging due to its inherent dynamic delays and feedback transparency. This research evaluates the effectiveness of demonstration data obtained through simulation versus teleoperation. To evaluate the efficacy of this approach, tasks such as plane cutting, tight peg-in-hole, and deformable pipe plugging were performed to assess the quality of demonstrations acquired. The experimental results highlight the effectiveness of demonstration through simulation in capturing the operator’s force-involved interaction skills. Simulation creates an environment similar to performing tasks with bare hands by minimising dynamic delays due to the exclusion of physical robots and effectively rendering high stiffness. As a result, the demonstration through simulation method has proven effective in extracting interaction data and capturing physical task performance skills.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t6_15">
             15:30-16:30, Paper WePI3T6.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3268'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Constrained Bootstrapped Learning for Few-Shot Robot Skill Adaptation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398956" title="Click to go to the Author Index">
             Haque, A K M Nadimul
            </a>
           </td>
           <td class="r">
            University of Technology Sydney
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#238113" title="Click to go to the Author Index">
             Sukkar, Fouad
            </a>
           </td>
           <td class="r">
            University of Technology Sydney
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#383452" title="Click to go to the Author Index">
             Tanz, Lukas
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#137844" title="Click to go to the Author Index">
             Carmichael, Marc
            </a>
           </td>
           <td class="r">
            Centre for Autonomous Systems
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103428" title="Click to go to the Author Index">
             Vidal-Calleja, Teresa A.
            </a>
           </td>
           <td class="r">
            University of Technology Sydney
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3268" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#learning_from_experience" title="Click to go to the Keyword Index">
               Learning from Experience
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we propose a robot skill-learning method that facilitates fast adaption to new tasks online. Our method is based on a hybrid learning from demonstration and reinforcement learning approach, which seeds learning with a compact and structured skill model, leading to efficient and stable behaviours. To facilitate fast skill adaption, we propose a bootstrapped learning framework that learns a policy for adapting a skill model across a wide range of initial conditions in simulation. This policy is then used to bootstrap a refinement process that quickly adapts the learnt skill model to new initial conditions in a few learning iterations. Our refined skill model is designed to be deployable on hardware and can correct for discrepancies between the simulation and the real world. Furthermore, we propose a novel method for constraining policy exploration to promising trajectories, which is crucial for enabling manipulation in complex environments. We evaluate our framework in simulation and hardware in multiple environments with varying task complexity. We showcase that compared to the state-of-the-art, which achieves an average success rate of only 56.6% across three different tasks of varying difficulty, our algorithm significantly outperforms it with an average success rate of 90%.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t6_16">
             15:30-16:30, Paper WePI3T6.16
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3467'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning Temporally Composable Task Segmentations with Language
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396845" title="Click to go to the Author Index">
             Raj, Divyanshu
            </a>
           </td>
           <td class="r">
            Arizona State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397757" title="Click to go to the Author Index">
             Patil, Omkar Deepak
            </a>
           </td>
           <td class="r">
            Arizona State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#383430" title="Click to go to the Author Index">
             Gu, Weiwei
            </a>
           </td>
           <td class="r">
            Arizona State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#123602" title="Click to go to the Author Index">
             Baral, Chitta
            </a>
           </td>
           <td class="r">
            Arizona State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#160888" title="Click to go to the Author Index">
             Gopalan, Nakul
            </a>
           </td>
           <td class="r">
            Arizona State University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3467" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#representation_learning" title="Click to go to the Keyword Index">
               Representation Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this work, we present an approach to identify sub-tasks within a demonstrated robot trajectory with the supervision provided by language instructions. Learning longer horizon tasks is challenging with techniques such as reinforcement learning and behavior cloning. Previous approaches have split these long tasks into shorter tasks that are easier to learn by using statistical change point detection methods. However, classical changepoint detection methods function only with low dimensional robot trajectory data and not with high dimensional inputs such as vision. Our goal in this work is to split longer horizon tasks, represented by trajectories into shorter horizon tasks that can be learned using conventional behavior cloning approaches using guidance from language. In our approach we use techniques from the video moment retrieval problem on robot trajectory data to demonstrate a high-dimensional generalizable change-point detection approach. Our proposed moment retrieval-based approach shows a more than 30% improvement in mean average precision (mAP) for identifying trajectory sub-tasks with language guidance compared to that without language. We perform ablations to understand the effects of domain randomization, sample complexity, views, and sim-to-real transfer of our method. In our data ablation we find that just with a 100 labelled trajectories we can achieve a 61.41 mAP, demonstrating the sample efficiency of using such an approach. Further, behavior cloning models trained on our segmented trajectories outperform a single model trained on the whole trajectory by up to 20%.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wepi3t7">
             <b>
              WePI3T7
             </b>
            </a>
           </td>
           <td class="r">
            Room 7
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wepi3t7" title="Click to go to the Program at a Glance">
             <b>
              Grasping &amp; Manipulation II
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#107751" title="Click to go to the Author Index">
             Taniguchi, Tadahiro
            </a>
           </td>
           <td class="r">
            Ritsumeikan University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#164300" title="Click to go to the Author Index">
             Katzschmann, Robert Kevin
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t7_01">
             15:30-16:30, Paper WePI3T7.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('996'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Streamlining Object Pushing: Behavior Tree-Based Coordination of Control and Planning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#268767" title="Click to go to the Author Index">
             Bertoncelli, Filippo
            </a>
           </td>
           <td class="r">
            Technology Innovation Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#122186" title="Click to go to the Author Index">
             Sabattini, Lorenzo
            </a>
           </td>
           <td class="r">
            University of Modena and Reggio Emilia
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab996" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#dexterous_manipulation" title="Click to go to the Keyword Index">
               Dexterous Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#failure_detection_and_recovery" title="Click to go to the Keyword Index">
               Failure Detection and Recovery
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Efficiently navigating and manipulating objects in complex environments is a fundamental challenge in robotics. This paper presents a novel approach to streamline object-pushing tasks by integrating Behavior Trees (BT) to coordinate a control and planning framework. The proposed system optimizes the execution of tasks involving the pushing of objects while ensuring adaptability to varying scenarios.
             <p>
              Our approach employs BTs to encapsulate high-level task specifications and decision-making processes, facilitating a flexible and intuitive representation of robot behaviour. By seamlessly integrating BT technology with a coordinated control and planning system, we enable the robot to make real-time decisions and adapt to dynamic environments.
              <p>
               We present experimental results demonstrating the effectiveness of our approach, highlighting its ability to improve task execution efficiency and adaptability.
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t7_02">
             15:30-16:30, Paper WePI3T7.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2657'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Simulation-Assisted Learning for Efficient Bin-Packing of Deformable Packages in a Bimanual Robotic Cell
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#291782" title="Click to go to the Author Index">
             Manyar, Omey Mohan
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396915" title="Click to go to the Author Index">
             Ye, Hantao
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398477" title="Click to go to the Author Index">
             Sagare, Meghana
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#205606" title="Click to go to the Author Index">
             Mayya, Siddharth
            </a>
           </td>
           <td class="r">
            Amazon Robotics
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#212074" title="Click to go to the Author Index">
             Wang, Fan
            </a>
           </td>
           <td class="r">
            Amazon Robotics
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#107914" title="Click to go to the Author Index">
             Gupta, Satyandra K.
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2657" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#dual_arm_manipulation" title="Click to go to the Keyword Index">
               Dual Arm Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#bimanual_manipulation" title="Click to go to the Keyword Index">
               Bimanual Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Bin-packing is an important problem in the robotic warehouse domain. Traditionally, this problem has been studied only for rigid packages (e.g., boxes or rigid objects). In this work, we tackle the problem of bin-packing with deformable packages that have become a popular choice for fulfillment needs. We present a system that incorporates a dual robot arm bimanual setup, uniquely combining suction and sweeping motions to stably and reliably pack deformable packages in a bin. Additionally, we propose a comprehensive action prediction framework to optimize for bin-packing efficiency by predicting optimal actions for both robots involved. Our methodology leverages a two-pronged learning strategy, where initially, we train a model in a self-supervised manner to predict a scoring metric indicative of bin-packing efficiency and then leverage an online optimization scheme to compute optimal actions in real time. The model is pre-trained in simulation in MuJoCo and fine-tuned on small-scale data from a real-world laboratory setting. Our packing score prediction model predicts bin-packing score in [0,1] with an MSE of 0.003. Real-world experiments validate our method's adaptability to novel scenarios and its effectiveness in packing operations.. Project Website: https://sites.google.com/usc.edu/bimanual-binpacking/
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t7_03">
             15:30-16:30, Paper WePI3T7.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1318'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Soft Robotic Finger Inspired by Biological Perception Models for Tactile Sensing
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376160" title="Click to go to the Author Index">
             Mao, Baijin
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376111" title="Click to go to the Author Index">
             Yuan, Qiangjing
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395941" title="Click to go to the Author Index">
             Xiang, Yuyaocen
            </a>
           </td>
           <td class="r">
            Tsinghua Shenzhen International Graduate School
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376167" title="Click to go to the Author Index">
             Zhou, Kunyu
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376171" title="Click to go to the Author Index">
             Wang, Weichen
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376172" title="Click to go to the Author Index">
             Chen, Yaozhen
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376177" title="Click to go to the Author Index">
             Hao, Hongwei
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#181312" title="Click to go to the Author Index">
             Qu, Juntian
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1318" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Tactile sensing is pivotal for enabling effective human-robot interaction, especially in unstructured environments. This work introduces an innovative bioinspired soft robotic finger endowed with shape-adaptive and multi-modal tactile perception capabilities, drawing inspiration from diverse biological tactile sensing modalities. Through an advanced Fin Ray structure, the soft finger features tactile whiskers on its fingertips, facilitating perception of obstacle orientation, fingertip pressure, surface roughness, and grasping ball size. Leveraging distributed optical fiber sensing technology, we develop a sophisticated multi-point, multi-modal tactile perception neural network tailored for the soft finger. Meticulous integration via advanced 3D printing and silicone coating techniques seamlessly embeds optical fiber sensors within the soft robotic finger, creating an intelligent perception-capable bioinspired mechanical system. Experimental validation confirms the soft robotic finger’s sensitive and precise force perception and curvature recognition abilities, achieving accuracies of up to 100%. In summary, our bioinspired robotic finger holds significant promise for applications in intelligent sensing, non-destructive grasping, and fruit classification within unstructured environments, thus advancing the field of robotics and human-robot interaction.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t7_04">
             15:30-16:30, Paper WePI3T7.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1428'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Development of a Modular Robotic Finger for Gripping Various Shaped Objects
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#320615" title="Click to go to the Author Index">
             Kim, Jisu
            </a>
           </td>
           <td class="r">
            Daegu Gyeongbuk Institute of Science and Technology (DGIST)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#355048" title="Click to go to the Author Index">
             Cho, Jinman
            </a>
           </td>
           <td class="r">
            Daegu Gyeongbuk Institute of Science and Technology (DGIST)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#319062" title="Click to go to the Author Index">
             Kang, Yeon
            </a>
           </td>
           <td class="r">
            Daegu Gyeongbuk Institute of Science and Technology (DGIST)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396574" title="Click to go to the Author Index">
             Lee, Changhwa
            </a>
           </td>
           <td class="r">
            Daegu Gyeongbuk Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#206601" title="Click to go to the Author Index">
             Yun, Dongwon
            </a>
           </td>
           <td class="r">
            Daegu Gyeongbuk Institute of Science and Technology (DGIST)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1428" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#compliant_joints_and_mechanisms" title="Click to go to the Keyword Index">
               Compliant Joints and Mechanisms
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             With the introduction of the Fourth Industrial Revolution and the spread of smart factories, the demand for small-quantity batch production systems is rapidly increasing. As a result, the implementation of robotic gripper systems that can handle various objects is required. Until now, grippers have to be replaced or newly developed each time depending on the object to be gripped. In addition, conventional gripper systems require a picking system based on a sophisticated gripping plan to handle products with complex shapes. This requires the integration of vision and various sensor systems, which in turn increases the cost of the system and makes it challenging to apply it to real industrial sites. To solve this problem, we developed a robotic finger by applying the paired crossed flexure hinge (p-CFH) developed in our previous research. The p-CFH-based robotic finger is driven by an underactuated wire-driven method that can be controlled by a single motor and has compliance and shape adaptive features. It also has the advantage of being modularized, easy to install and replace, and easy to maintain. The proposed finger module has a tip force of about 0.58 kg and its impact absorption capacity has been experimentally verified. In addition, gripping experiments were conducted on a total of four objects with different characteristics, and successful gripping was confirmed.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t7_05">
             15:30-16:30, Paper WePI3T7.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2209'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Haptic Contour Following with the Smart Suction Cup
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#322067" title="Click to go to the Author Index">
             Lee, Sebastian
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#285589" title="Click to go to the Author Index">
             Lee, Jungpyo
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#168436" title="Click to go to the Author Index">
             Stuart, Hannah
            </a>
           </td>
           <td class="r">
            UC Berkeley
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2209" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_based_control" title="Click to go to the Keyword Index">
               Sensor-based Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The Smart Suction Cup is a tactile sensing and gripping system designed to enhance pick-and-place operations in industrial settings. While previous research has primarily focused on utilizing this technology for haptic search in cases of initial grasp failure, this study introduces a novel application: following contours. This function is already established as an important function for object recognition and grasp planning – substantiated by numerous works using other tactile sensors. Here, we explore contour following for a flow-based tactile sensor because it is not susceptible to visual occlusions nor tactile sensor wear. Experimental validation demonstrates the Smart Suction Cup’s ability to track edges at different speeds and navigate various planar contours, showcasing rapid and robust tracking of edges. Notably, the Smart Suction Cup can reliably operate at a speed of 3 cm/s. This is one step towards the adoption of the Smart Suction Cup for real-world applications
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t7_06">
             15:30-16:30, Paper WePI3T7.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3160'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              In-Hand Singulation and Scooping Manipulation with a 5 DOF Tactile Gripper
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#257051" title="Click to go to the Author Index">
             Zhou, Yuhao
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397902" title="Click to go to the Author Index">
             Zhou, Pokuang
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#219804" title="Click to go to the Author Index">
             Wang, Shaoxiong
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#184771" title="Click to go to the Author Index">
             She, Yu
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3160" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#in_hand_manipulation" title="Click to go to the Keyword Index">
               In-Hand Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Manipulation tasks often require a high degree of dexterity, typically necessitating grippers with multiple degrees of freedom (DoF). While a robotic hand equipped with multiple fingers can execute precise and intricate manipulation tasks, the inherent redundancy stemming from its extensive DoF often adds unnecessary complexity. In this paper, we introduce the design of a tactile sensor-equipped gripper with two fingers and five DoF. We present a novel design integrating a GelSight tactile sensor, enhancing sensing capabilities and enabling finer control during specific manipulation tasks. To evaluate the gripper’s performance, we conduct experiments involving two challenging tasks: 1) retrieving, singularizing, and classification of various objects embedded in granular media, and 2) executing scooping manipulations of credit cards in confined environments to achieve precise insertion. Our results demonstrate the efficiency of the proposed approach, with a high success rate for singulation and classification tasks, particularly for spherical objects at high as 94.3%, and a 100% success rate for scooping and inserting credit cards.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t7_07">
             15:30-16:30, Paper WePI3T7.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3445'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              PROSPECT: Precision Robot Spectroscopy Exploration and Characterization Tool
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#311471" title="Click to go to the Author Index">
             Hanson, Nathaniel
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#324799" title="Click to go to the Author Index">
             Lvov, Gary
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398772" title="Click to go to the Author Index">
             Rautela, Vedant
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#355694" title="Click to go to the Author Index">
             Hibbard, Sam
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#355633" title="Click to go to the Author Index">
             Holand, Ethan
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#355686" title="Click to go to the Author Index">
             DiMarzio, Charles A
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#129456" title="Click to go to the Author Index">
             Padir, Taskin
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3445" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#factory_automation" title="Click to go to the Keyword Index">
               Factory Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Near Infrared (NIR) spectroscopy is widely used in industrial quality control and automation to test the purity and grade of items. In this research, we propose a novel sensorized end effector and acquisition strategy to capture spectral signatures from objects and register them with a 3D point cloud. Our methodology first takes a 3D scan of an object generated by a time-of-flight depth camera and decomposes the object into a series of planned viewpoints covering the surface. We generate motion plans for a robot manipulator and end-effector to visit these viewpoints while maintaining a fixed distance and surface normal. This process is enabled by the spherical motion of the end-effector and ensures maximal spectral signal quality. By continuously acquiring surface reflectance values as the end-effector scans the target object, the autonomous system develops a four-dimensional model of the target object: position in an
             <i>
              R
             </i>
             <sup>
              3
             </sup>
             coordinate frame, and a reflectance vector denoting the associated spectral signature. We demonstrate this system in building spectral-spatial object profiles of increasingly complex geometries. We show the proposed system and spectral acquisition planning produce more consistent spectral signals than naive point scanning strategies. Our work represents a significant step towards high-resolution spectral-spatial sensor fusion for automated quality assessment.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t7_08">
             15:30-16:30, Paper WePI3T7.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('565'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Precise Well-Plate Placing Utilizing Contact During Sliding with Tactile-Based Pose Estimation for Laboratory Automation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#341218" title="Click to go to the Author Index">
             Pai, Sameer
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#173446" title="Click to go to the Author Index">
             Takahashi, Kuniyuki
            </a>
           </td>
           <td class="r">
            Preferred Networks, Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#232615" title="Click to go to the Author Index">
             Masuda, Shimpei
            </a>
           </td>
           <td class="r">
            Preferred Networks, Inc / University of Tsukuba
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#137744" title="Click to go to the Author Index">
             Fukaya, Naoki
            </a>
           </td>
           <td class="r">
            Preferred Networks, Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#347163" title="Click to go to the Author Index">
             Yamane, Koki
            </a>
           </td>
           <td class="r">
            University of Tsukuba
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#277693" title="Click to go to the Author Index">
             Ummadisingu, Avinash
            </a>
           </td>
           <td class="r">
            Preferred Networks, Inc
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab565" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#in_hand_manipulation" title="Click to go to the Keyword Index">
               In-Hand Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#software_hardware_integration_for_robot_systems" title="Click to go to the Keyword Index">
               Software-Hardware Integration for Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Micro well-plates are an apparatus commonly used in chemical and biological experiments that are a few centimeters thick and contain wells or divets. In this paper, we aim to solve the task of placing the well-plate onto a well-plate holder (referred to as holder). This task is challenging due to the holder's raised grooves being a few millimeters in height, with a clearance of less than 1 mm between the well-plate and holder, thus requiring precise control during placing. Our placing task has the following challenges: 1) The holder's detected pose is uncertain; 2) the required accuracy is at the millimeter to sub-millimeter level due to the raised groove's shallow height and small clearance; 3) the holder is not fixed to a desk and is susceptible to movement from external forces. To address these challenges, we developed methods including a) using tactile sensors for accurate pose estimation of the grasped well-plate to handle issue (1); b) sliding the well-plate onto the target holder while maintaining contact with the holder's groove and estimating its orientation for accurate alignment. This allows for high precision control (addressing issue (2)) and prevents displacement of the holder during placement (addressing issue (3)). We demonstrate a high success rate for the well-plate placing task, even under noisy observation of the holder's pose.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t7_09">
             15:30-16:30, Paper WePI3T7.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('607'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Contact-Implicit Model Predictive Control for Dexterous In-Hand Manipulation: A Long-Horizon and Robust Approach
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#333148" title="Click to go to the Author Index">
             Jiang, Yongpeng
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#297309" title="Click to go to the Author Index">
             Yu, Mingrui
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#246683" title="Click to go to the Author Index">
             Zhu, Xinghao
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100071" title="Click to go to the Author Index">
             Tomizuka, Masayoshi
            </a>
           </td>
           <td class="r">
            University of California
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#132634" title="Click to go to the Author Index">
             Li, Xiang
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab607" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#in_hand_manipulation" title="Click to go to the Keyword Index">
               In-Hand Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#dexterous_manipulation" title="Click to go to the Keyword Index">
               Dexterous Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Dexterous in-hand manipulation is an essential skill of production and life. Nevertheless, the highly stiff and mutable features of contacts cause limitations to real-time contact discovery and inference, which degrades the performance of model-based methods. Inspired by recent advancements in contact-rich locomotion and manipulation, this paper proposes a novel model-based approach to control dexterous in-hand manipulation and overcome the current limitations. The proposed approach has the attractive feature, which allows the robot to robustly execute long-horizon in-hand manipulation without pre-defined contact sequences or separated planning procedures. Specifically, we design a contact-implicit model predictive controller at high-level to generate real-time contact plans, which are executed by the low-level tracking controller. Compared with other model-based methods, such a long-horizon feature enables replanning and robust execution of contact-rich motions to achieve large-displacement in-hand tasks more efficiently; Compared with existing learning-based methods, the proposed approach achieves the dexterity and also generalizes to different objects without any pre-training. Detailed simulations and ablation studies demonstrate the efficiency and effectiveness of our method. It runs at 20Hz on the 23-degree-of-freedom long-horizon in-hand object rotation task.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t7_10">
             15:30-16:30, Paper WePI3T7.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('846'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Stable Object Placing Using Curl and Diff Features of Vision-Based Tactile Sensors
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#173446" title="Click to go to the Author Index">
             Takahashi, Kuniyuki
            </a>
           </td>
           <td class="r">
            Preferred Networks, Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#232615" title="Click to go to the Author Index">
             Masuda, Shimpei
            </a>
           </td>
           <td class="r">
            Preferred Networks, Inc / University of Tsukuba
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#107751" title="Click to go to the Author Index">
             Taniguchi, Tadahiro
            </a>
           </td>
           <td class="r">
            Ritsumeikan University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab846" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#in_hand_manipulation" title="Click to go to the Keyword Index">
               In-Hand Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Ensuring stable object placement is crucial to prevent objects from toppling over, breaking, or causing spills. When an object makes initial contact to a surface, and some force is exerted, the moment of rotation caused by the instability of the object's placing can cause the object to rotate in a certain direction (henceforth referred to as direction of corrective rotation). Existing methods often employ a Force/Torque (F/T) sensor to estimate the direction of corrective rotation by detecting the moment of rotation as a torque. However, its effectiveness may be hampered by sensor noise and the tension of the external wiring of robot cables. To address these issues, we propose a method for stable object placing using GelSights, vision-based tactile sensors, as an alternative to F/T sensors. Our method estimates the direction of corrective rotation of objects using the displacement of the black dot pattern on the elastomeric surface of GelSight. We calculate the Curl from vector analysis, indicative of the rotational field magnitude and direction of the displacement of the black dots pattern. Simultaneously, we calculate the difference (Diff) of displacement between the left and right fingers' GelSight's black dots. Then, the robot can manipulate the objects' pose using Curl and Diff features, facilitating stable placing. Across experiments, handling 18 differently characterized objects, our method achieves precise placing accuracy (less than 1-degree error) in nearly 100% of cases.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t7_11">
             15:30-16:30, Paper WePI3T7.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1999'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robotic Valve Turning: Axial Misalignment Estimation from Reaction Torques
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#283474" title="Click to go to the Author Index">
             Golani, Gautami
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#180617" title="Click to go to the Author Index">
             Turlapati, Sri Harsha
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#380467" title="Click to go to the Author Index">
             Yang, Lin
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397682" title="Click to go to the Author Index">
             Ariffin, Mohammad
            </a>
           </td>
           <td class="r">
            Nanyang Technological University Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102881" title="Click to go to the Author Index">
             Campolo, Domenico
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1999" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#in_hand_manipulation" title="Click to go to the Keyword Index">
               In-Hand Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#contact_modeling" title="Click to go to the Keyword Index">
               Contact Modeling
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this work, we present a simplified quasi-static model of a two-point contact gripper turning a circular valve to predict the reaction torques produced at the base of the valve as a function of the axis misalignment. Specifically, we learned that textit{geometric features} such as (i) the misalignment vector being tangent to the reaction torques, (ii) length of the misalignment vector being directly proportional to the magnitude of the reaction torques and (iii) small axial misalignments resulting in well defined `double-loops' in the 2D reaction torques space are indicative of axis misalignment.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t7_12">
             15:30-16:30, Paper WePI3T7.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1025'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Task-Oriented Dexterous Hand Pose Synthesis Using Differentiable Grasp Wrench Boundary Estimator
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#338572" title="Click to go to the Author Index">
             Chen, Jiayi
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#379428" title="Click to go to the Author Index">
             Chen, Yuxing
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#338487" title="Click to go to the Author Index">
             Zhang, Jialiang
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#155911" title="Click to go to the Author Index">
             Wang, He
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1025" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multifingered_hands" title="Click to go to the Keyword Index">
               Multifingered Hands
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#contact_modeling" title="Click to go to the Keyword Index">
               Contact Modeling
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This work tackles the problem of task-oriented dexterous hand pose synthesis, which involves generating a static hand pose capable of applying a task-specific set of wrenches to manipulate objects. Unlike previous approaches that focus solely on force-closure grasps, which are unsuitable for non-prehensile manipulation tasks (e.g., turning a knob or pressing a button), we introduce a unified framework covering force-closure grasps, non-force-closure grasps, and a variety of non-prehensile poses. Our key idea is a novel optimization objective quantifying the disparity between the Task Wrench Space (TWS, the desired wrenches predefined as a task prior) and the Grasp Wrench Space (GWS, the achievable wrenches computed from the current hand pose). By minimizing this objective, gradient-based optimization algorithms can synthesize task-oriented hand poses without additional human demonstrations. Our specific contributions include 1) a fast, accurate, and differentiable technique for estimating the GWS boundary; 2) a task-oriented objective function based on the disparity between the estimated GWS boundary and the provided TWS boundary; and 3) an efficient implementation of the synthesis pipeline that leverages CUDA accelerations and supports large-scale paralleling. Experimental results on 10 diverse tasks demonstrate a 72.6% success rate in simulation. Furthermore, real-world validation for 4 tasks confirms the effectiveness of synthesized poses for manipulation. Notably, despite being primarily tailored for task-oriented hand pose synthesis, our pipeline can generate force-closure grasps 50 times faster than DexGraspNet while maintaining comparable grasp quality. Project page: https://pku-epic.github.io/TaskDexGrasp/.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t7_13">
             15:30-16:30, Paper WePI3T7.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1815'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Multi-DoF Anthropomorphic Hand with Integrated Tactile Feedback for Grasping and Manipulation in Human Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#189711" title="Click to go to the Author Index">
             Yang, Sicheng
            </a>
           </td>
           <td class="r">
            Tencent
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#174513" title="Click to go to the Author Index">
             Lee, Wang Wei
            </a>
           </td>
           <td class="r">
            Tencent
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#235836" title="Click to go to the Author Index">
             Zhang, Zhong
            </a>
           </td>
           <td class="r">
            City University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397320" title="Click to go to the Author Index">
             Xiong, Youda
            </a>
           </td>
           <td class="r">
            Tencent
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#290526" title="Click to go to the Author Index">
             Liang, Jiaming
            </a>
           </td>
           <td class="r">
            Tencent
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#374931" title="Click to go to the Author Index">
             Lu, Peng
            </a>
           </td>
           <td class="r">
            Tencent
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397279" title="Click to go to the Author Index">
             Zhu, Yonghui
            </a>
           </td>
           <td class="r">
            Tencent
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#189793" title="Click to go to the Author Index">
             Liu, Tianliang
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#361354" title="Click to go to the Author Index">
             Li, Jingchen
            </a>
           </td>
           <td class="r">
            Tencent
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#361355" title="Click to go to the Author Index">
             Wang, Rui
            </a>
           </td>
           <td class="r">
            Tencent
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#181507" title="Click to go to the Author Index">
             Li, Xiong
            </a>
           </td>
           <td class="r">
            Tencent
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#115743" title="Click to go to the Author Index">
             Zheng, Yu
            </a>
           </td>
           <td class="r">
            Tencent
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1815" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multifingered_hands" title="Click to go to the Keyword Index">
               Multifingered Hands
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Objects of daily life are designed to suit the human hand. Without major modifications to these objects and our environments, robots will need end-effectors with human hand-like configuration and dexterity to efficiently operate on them. Tight integration of tactile and proprioceptive sensors are also critical to ensure robust execution of manipulation policies without sacrificing range-of-motion. Reliability is also key, and a mechanically robust, easy to repair end-effector is important to minimize downtime. To meet these challenges, we designed a 13 degree-of-freedom anthropomorphic hand with over 1000 tactile sensing elements, named TRX-Hand5. Also embedded within are positional encoders and cable tension sensors to provide proprioceptive perception. TRX-Hand5 has a novel biomimetic topology with six small posture motors in the palm to replicate the function of intrinsic hand muscles and five large power motors in the forearm to play the role of forearm flexor muscles. The whole hand weighs 2.6 kg with its dimensions comparable to those of an adult male's hand and is capable of actuating its fingertips at over 200 deg/s while exerting up to 22 N of force. The system can be disassembled in modules for easy maintenance.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t7_14">
             15:30-16:30, Paper WePI3T7.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1968'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Under-Actuated Robotic Gripper with Multiple Grasping Modes Inspired by Human Finger
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375333" title="Click to go to the Author Index">
             Li, Jihao
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391822" title="Click to go to the Author Index">
             Liao, Tingbo
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#251336" title="Click to go to the Author Index">
             Sirag, Hassen Nigatu
            </a>
           </td>
           <td class="r">
            ZJU
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#319078" title="Click to go to the Author Index">
             Guo, Haotian
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#193514" title="Click to go to the Author Index">
             Lu, GuoDong
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#204350" title="Click to go to the Author Index">
             Dong, Huixu
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1968" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multifingered_hands" title="Click to go to the Keyword Index">
               Multifingered Hands
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Under-actuated robot grippers, as a pervasive tool of robots, have become a considerable research focus. Despite their simplicity of mechanical design and control strategy, they suffer from poor versatility and weak adaptability, making widespread applications limited. To better address relevant research gaps, we present a novel 3-finger linkage-based gripper that realizes retractable and reconfigurable multi-mode grasps driven by a single motor. Firstly, inspired by the changes occurred in the contact surface with a human finger moving, we artfully design a slider-slide rail mechanism as the phalanx to achieve retraction of each finger, allowing for better performance in the enveloping grasping mode. Secondly, a reconfigurable structure is constructed to broaden the grasping range of objects’ dimensions for the proposed gripper. By adjusting the configuration and gesture of each finger, the gripper can achieve five grasping modes. Thirdly, the proposed gripper is solely actuated by a single motor, yet it can be capable of grasping and reconfiguring simultaneously. Finally, various experiments on grasps of slender, thin, and large-volume objects are implemented to evaluate the performance of the proposed gripper in practical scenarios, which demonstrates the excellent grasping capabilities of the gripper.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t7_15">
             15:30-16:30, Paper WePI3T7.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2655'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Rotograb: Combining Biomimetic Hands with Industrial Grippers Using a Rotating Thumb
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397956" title="Click to go to the Author Index">
             Bersier, Arnaud
            </a>
           </td>
           <td class="r">
            ETH Zürich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397980" title="Click to go to the Author Index">
             Leonforte, Matteo
            </a>
           </td>
           <td class="r">
            ETH
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397947" title="Click to go to the Author Index">
             Vanetta, Alessio
            </a>
           </td>
           <td class="r">
            ETH Zürich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397940" title="Click to go to the Author Index">
             Wotke, Sarah Lia Andrea
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397927" title="Click to go to the Author Index">
             Nappi, Andrea
            </a>
           </td>
           <td class="r">
            ETH Zürich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398061" title="Click to go to the Author Index">
             Zhou, Yifan
            </a>
           </td>
           <td class="r">
            ETH Zürich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398022" title="Click to go to the Author Index">
             Oliani, Sebastiano
            </a>
           </td>
           <td class="r">
            ETH Zürich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#292602" title="Click to go to the Author Index">
             Kübler, Alexander M.
            </a>
           </td>
           <td class="r">
            ETH Zürich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#164300" title="Click to go to the Author Index">
             Katzschmann, Robert Kevin
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2655" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multifingered_hands" title="Click to go to the Keyword Index">
               Multifingered Hands
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#dexterous_manipulation" title="Click to go to the Keyword Index">
               Dexterous Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#in_hand_manipulation" title="Click to go to the Keyword Index">
               In-Hand Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The development of robotic grippers and hands for automation aims to emulate human dexterity without sacrificing the efficiency of industrial grippers. This study introduces Rotograb, a tendon-actuated robotic hand featuring a novel rotating thumb. The aim is to combine the dexterity of human hands with the efficiency of industrial grippers. The rotating thumb enlarges the workspace and allows in-hand manipulation. A novel joint design minimizes movement interference and simplifies kinematics, using a cutout for tendon routing. We integrate teleoperation, using a depth camera for real-time tracking and autonomous manipulation powered by reinforcement learning with proximal policy optimization. Experimental evaluations demonstrate that Rotograb’s rotating thumb greatly improves both operational versatility and workspace. It can handle various grasping and manipulation tasks with objects from the YCB dataset, with particularly good results when rotating objects within its grasp. Rotograb represents a notable step towards bridging the capability gap between human hands and industrial grippers. The tendon-routing and thumb-rotating mechanisms allow for a new level of control and dexterity. Integrating teleoperation and autonomous learning underscores Rotograb’s adaptability and sophistication, promising substantial advancements in both robotics research and practical applications.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t7_16">
             15:30-16:30, Paper WePI3T7.16
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3343'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              OPENGRASP-LITE Version 1.0: A Tactile Artificial Hand with a Compliant Linkage Mechanism
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#336932" title="Click to go to the Author Index">
             Groß, Sonja
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#399095" title="Click to go to the Author Index">
             Ratzel, Michael
            </a>
           </td>
           <td class="r">
            Munich Institute of Robotics and Machine Intelligence (MIRMI)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396767" title="Click to go to the Author Index">
             Welte, Edgar
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology (KIT)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#298698" title="Click to go to the Author Index">
             Hidalgo Carvajal, Diego Xavier
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#296908" title="Click to go to the Author Index">
             Chen, Lingyun
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#210169" title="Click to go to the Author Index">
             Pozo Fortunić, Edmundo
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#223070" title="Click to go to the Author Index">
             Ganguly, Amartya
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#292159" title="Click to go to the Author Index">
             Swikir, Abdalla
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#108317" title="Click to go to the Author Index">
             Haddadin, Sami
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3343" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multifingered_hands" title="Click to go to the Keyword Index">
               Multifingered Hands
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_sensors_and_actuators" title="Click to go to the Keyword Index">
               Soft Sensors and Actuators
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recent advancements in artificial hand development have primarily concentrated on enhancing adaptive grasping, dexterity, as well as the integration of biomimetic skin. However, few designs have successfully combined lightweight, cost-effective solutions, and tactile sensing along with adaptive grasping in a human-sized prototype. We propose, an open-source, highly integrated artificial hand. It leverages a compliant linkage mechanism for versatile grasping capabilities, featuring six degrees of actuation and MEMS-based tactile sensors on every fingertip.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wepi3t8">
             <b>
              WePI3T8
             </b>
            </a>
           </td>
           <td class="r">
            Room 8
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wepi3t8" title="Click to go to the Program at a Glance">
             <b>
              Robot Motion Planning II
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#200893" title="Click to go to the Author Index">
             Gao, Fei
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t8_01">
             15:30-16:30, Paper WePI3T8.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2753'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Hierarchical Large Scale Multirobot Path (Re)Planning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#305299" title="Click to go to the Author Index">
             Pan, Lishuo
            </a>
           </td>
           <td class="r">
            Brown University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#381695" title="Click to go to the Author Index">
             Hsu, Kevin
            </a>
           </td>
           <td class="r">
            Brown University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#113756" title="Click to go to the Author Index">
             Ayanian, Nora
            </a>
           </td>
           <td class="r">
            Brown University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2753" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#planning__scheduling_and_coordination" title="Click to go to the Keyword Index">
               Planning, Scheduling and Coordination
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We consider a large-scale multi-robot path planning problem in a cluttered environment. Our approach achieves real-time replanning by dividing the workspace into cells and utilizing a hierarchical planner. Specifically, we propose novel multi-commodity flow-based high-level planners that route robots through cells with reduced congestion, along with an anytime low-level planner that computes collision-free paths for robots within each cell in parallel. A highlight of our method is a significant improvement in computation time. Specifically, we show empirical results of a 500-times speedup in computation time compared to the baseline multi-agent pathfinding approach on the environments we study. We account for the robot's embodiment and support non-stop execution with continuous replanning. We demonstrate the real-time performance of our algorithm with up to 142 robots in simulation, and a representative 32 physical Crazyflie nano-quadrotor experiment.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t8_02">
             15:30-16:30, Paper WePI3T8.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1552'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Alternative Connection Radius for Asymptotic Optimality in RRT*
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#176739" title="Click to go to the Author Index">
             Shome, Rahul
            </a>
           </td>
           <td class="r">
            The Australian National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1552" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Connection radius in asymptotically optimal motion planning algorithms is of interest to both understand the theoretical properties of these algorithms, as well as to ensure practical performance by estimating lower bounds. The smaller the connection radius, the sparser the data structures constructed using them, which makes the associated algorithms computationally more efficient. The original radii for both roadmap and tree variants were reported to be asymptotically shrinking functions of n. A recent amendment to the original arguments for trees demonstrated that the radius has to be larger for tree-based variants (RRT*). A practical problem in the newly proposed radius is the persistence of hard-to-estimate or large-valued parameters (like optimal path cost) within the connection radius function. In this short paper, a new perspective is presented of approaching the proof of asymptotic optimality of RRT* from a minimal variant of RRT* that only includes tree additions within connection neighborhoods. The work provides an alternative connection radius that gets rid of unwieldy parameters, presents insights that holds promise in studying the problem and using the result.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t8_03">
             15:30-16:30, Paper WePI3T8.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1583'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              An Actor-Critic Reinforcement Learning Scheme for Reactive 3D Optimal Motion Planning Based on Fluid Dynamics
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396865" title="Click to go to the Author Index">
             Malliaropoulos, Marios
            </a>
           </td>
           <td class="r">
            National Technical University of Athens
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#249383" title="Click to go to the Author Index">
             Rousseas, Panagiotis
            </a>
           </td>
           <td class="r">
            National Technical University of Athens
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#122413" title="Click to go to the Author Index">
             Bechlioulis, Charalampos
            </a>
           </td>
           <td class="r">
            University of Patras
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103188" title="Click to go to the Author Index">
             Kyriakopoulos, Kostas
            </a>
           </td>
           <td class="r">
            New York University - Abu Dhabi
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1583" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This work proposes a novel and provably correct method for three-dimensional optimal motion planning in complex environments. Our approach models the 3D motion planning problem by solving streamlines of the potential fluid flow, filling a gap in traditional motion planning techniques by guaranteeing a closed-loop, smooth and natural-looking navigation solution. Special emphasis is given to an inherent challenge of artificial potential field (APF) methods, namely establishing proofs of safety and stability over the entire optimization process. A model-based actor-critic reinforcement learning algorithm is introduced to approximate the optimal solution to the Hamilton-Jacobi-Bellman equation and update the controller parameters in a deterministic manner. Through a series of ROS-Gazebo software-in-the-loop (SIL) simulations the proposed methodology demonstrates robustness and outperforms widely used methods such as the RRT*, highlighting its contribution to the field of 3D optimal motion planning.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t8_04">
             15:30-16:30, Paper WePI3T8.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1593'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              DTG : Diffusion-Based Trajectory Generation for Mapless Global Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#269549" title="Click to go to the Author Index">
             Liang, Jing
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#350504" title="Click to go to the Author Index">
             Payandeh, Amirreza
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#210737" title="Click to go to the Author Index">
             Song, Daeun
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#177144" title="Click to go to the Author Index">
             Xiao, Xuesu
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106235" title="Click to go to the Author Index">
             Manocha, Dinesh
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1593" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present a novel end-to-end diffusion-based trajectory generation method, DTG, for mapless global navigation in challenging outdoor scenarios with occlusions and unstructured off-road features like grass, buildings, bushes, etc. Given a distant goal, our approach computes a trajectory that satisfies the following goals: (1) minimize the travel distance to the goal; (2) maximize the traversability by choosing paths that do not lie in undesirable areas. Specifically, we present a novel Conditional RNN(CRNN) for diffusion models to efficiently generate trajectories. Furthermore, we propose an adaptive training method that ensures that the diffusion model generates more traversable trajectories. We evaluate our methods in various outdoor scenes and compare the performance with other global navigation algorithms on a Husky robot. In practice, we observe at least a 15% improvement in traveling distance and around a 7% improvement in traversability.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t8_05">
             15:30-16:30, Paper WePI3T8.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1699'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Flexible and Topological Consistent Local Replanning for Multirotors
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#286742" title="Click to go to the Author Index">
             Wang, Dong
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#283970" title="Click to go to the Author Index">
             Ye, Hongkai
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#288062" title="Click to go to the Author Index">
             Pan, Neng
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392134" title="Click to go to the Author Index">
             Huang, Jinxin
            </a>
           </td>
           <td class="r">
            Beijing Sankuai Online Technology Co. Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#347832" title="Click to go to the Author Index">
             Zhang, Bangyan
            </a>
           </td>
           <td class="r">
            Beijing Sankuai Online Technology Co. Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#267538" title="Click to go to the Author Index">
             Mao, Yinian
            </a>
           </td>
           <td class="r">
            Meituan-Dianping Group
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#114431" title="Click to go to the Author Index">
             Huang, Guoquan
            </a>
           </td>
           <td class="r">
            University of Delaware
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#213352" title="Click to go to the Author Index">
             Xu, Chao
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#200893" title="Click to go to the Author Index">
             Gao, Fei
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1699" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In many situations such as city delivery and wild inspection, quadrotors are often required to follow a pre-defined reference trajectory. However, these reference trajectories cannot be perfectly safe, resulting in conflicts between tracking the reference precisely, flying safely, and finishing the mission timely. This paper proposes to solve the above problem, by introducing a replanning framework that first generates a topological consistent collision-free initial path and then flexibly optimizes the rejoin point and trajectory duration to generate a smooth and safe local rejoining trajectory. To avoid local trajectory switching in different directions during high-frequency replanning, we propose a topology-preserving path search algorithm based on kinodynamic RRT*. To satisfy dynamic constraints, avoid delays, and achieve a smooth rejoin of the reference trajectory, we propose an optimization-based approach to refine the initial trajectory. The simulation results confirm that our proposed topological consistency and flexible optimization methods can reduce the risk of local trajectory and decrease obstacle avoidance delay for tracking reference trajectory. We also conduct real-world experiments in challenging environments and verify the effectiveness of our method.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t8_06">
             15:30-16:30, Paper WePI3T8.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1728'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Multi-Fov-Constrained Trajectory Planning for Multirotor Safe Landing
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#286742" title="Click to go to the Author Index">
             Wang, Dong
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#339749" title="Click to go to the Author Index">
             Wang, Jingping
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#272015" title="Click to go to the Author Index">
             He, Suqin
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392134" title="Click to go to the Author Index">
             Huang, Jinxin
            </a>
           </td>
           <td class="r">
            Beijing Sankuai Online Technology Co. Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#347832" title="Click to go to the Author Index">
             Zhang, Bangyan
            </a>
           </td>
           <td class="r">
            Beijing Sankuai Online Technology Co. Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#267538" title="Click to go to the Author Index">
             Mao, Yinian
            </a>
           </td>
           <td class="r">
            Meituan-Dianping Group
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#114431" title="Click to go to the Author Index">
             Huang, Guoquan
            </a>
           </td>
           <td class="r">
            University of Delaware
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#213352" title="Click to go to the Author Index">
             Xu, Chao
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#200893" title="Click to go to the Author Index">
             Gao, Fei
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1728" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__perception_and_autonomy" title="Click to go to the Keyword Index">
               Aerial Systems: Perception and Autonomy
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In recent years, multi-rotors have become more and more widely used, such as aerial photography and delivery. Ensuring a safe landing in emergencies is the most basic requirement, and it is important to make full use of all the sensors of the multi-rotor. To improve the safety of UAV landing in unknown unstructured scenes, this paper proposes a multi-FOV-constrained trajectory planning algorithm. Due to the discontinuity of multi-FOV constraints and the nonlinearity of UAV dynamics, the entire trajectory planning problem is a nonlinear optimization problem with non-convex constraints. To address this problem, our algorithm contains two stages, a multi-fov-constrained path search algorithm and a safe landing trajectory optimization algorithm. The multi-fov-constrained path search algorithm is used to generate a safe initial path that satisfies the FOV constraint. Then, the safe landing trajectory optimization algorithm generates a safe trajectory, which considers FOV constraints, dynamics, smoothness, and obstacle avoidance. We conducted simulation experiments and real-world experiments to verify the robustness and effectiveness of our algorithm.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t8_07">
             15:30-16:30, Paper WePI3T8.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1895'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning Social Cost Functions for Human-Aware Path Planning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#338927" title="Click to go to the Author Index">
             Eirale, Andrea
            </a>
           </td>
           <td class="r">
            Politecnico Di Torino
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#137752" title="Click to go to the Author Index">
             Leonetti, Matteo
            </a>
           </td>
           <td class="r">
            King's College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#298501" title="Click to go to the Author Index">
             Chiaberge, Marcello
            </a>
           </td>
           <td class="r">
            Politecnico Di Torino
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1895" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_aware_motion_planning" title="Click to go to the Keyword Index">
               Human-Aware Motion Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#social_hri" title="Click to go to the Keyword Index">
               Social HRI
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Achieving social acceptance is one of the main goals of Social Robotic Navigation. Despite this topic has received increasing interest in recent years, most of the research has focused on driving the robotic agent along obstacle-free trajectories, planning around estimates of future human motion to respect personal distances and optimize navigation. However, social interactions in everyday life are also dictated by norms that do not strictly depend on movement, such as when standing at the end of a queue rather than cutting it. In this paper, we propose a novel method to recognize common social scenarios and modify a traditional planner's cost function to adapt to them. This solution enables the robot to carry out different social navigation behaviors that would not arise otherwise, maintaining the robustness of traditional navigation. Our approach allows the robot to learn different social norms with a single learned model, rather than having different modules for each task. As a proof of concept, we consider the tasks of queuing and respect interaction spaces of groups of people talking to one another, but the method can be extended to other human activities that do not involve motion.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t8_08">
             15:30-16:30, Paper WePI3T8.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1942'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              LF-3PM: A LiDAR-Based Framework for Perception-Aware Planning with Perturbation-Induced Metric
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#351781" title="Click to go to the Author Index">
             Chai, Kaixin
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#329241" title="Click to go to the Author Index">
             Xu, Long
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#286796" title="Click to go to the Author Index">
             Wang, Qianhao
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#213352" title="Click to go to the Author Index">
             Xu, Chao
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#182817" title="Click to go to the Author Index">
             Yin, Peng
            </a>
           </td>
           <td class="r">
            City University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#200893" title="Click to go to the Author Index">
             Gao, Fei
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1942" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Just as humans can become disoriented in featureless deserts or thick fogs, not all environments are conducive to the Localization Accuracy and Stability (LAS) of autonomous robots. This paper introduces an efficient framework designed to enhance LiDAR-based LAS through strategic trajectory generation, known as Perception-aware Planning. Unlike vision-based frameworks, the LiDAR-based requires different considerations due to unique sensor attributes. Our approach focuses on two main aspects: firstly, assessing the impact of LiDAR observations on LAS. We introduce a perturbation-induced metric to provide a comprehensive and reliable evaluation of LiDAR observations. Secondly, we aim to improve motion planning efficiency. By creating a Static Observation Loss Map (SOLM) as an intermediary, we logically separate the time-intensive evaluation and motion planning phases, significantly boosting the planning process. In the experimental section, we demonstrate the effectiveness of the proposed metrics across various scenes and the feature of trajectories guided by different metrics. Ultimately, our framework is tested in a real-world scenario, enabling the robot to actively choose topologies and orientations preferable for localization. The source code is accessible at https://github.com/ZJU-FAST-Lab/LF-3PM.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t8_09">
             15:30-16:30, Paper WePI3T8.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2061'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              RT-RRT: Reverse Tree Guided Real-Time Path Planning/Replanning in Unpredictable Dynamic Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392258" title="Click to go to the Author Index">
             Cui, Bo
            </a>
           </td>
           <td class="r">
            Northwestern Polytechnical University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#123185" title="Click to go to the Author Index">
             Cui, Rongxin
            </a>
           </td>
           <td class="r">
            Northwestern Polytechnical University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#332585" title="Click to go to the Author Index">
             Yan, Weisheng
            </a>
           </td>
           <td class="r">
            Northwestern Polytechnical University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#370236" title="Click to go to the Author Index">
             Wang, Y.K
            </a>
           </td>
           <td class="r">
            NWPU
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#357958" title="Click to go to the Author Index">
             Zhang, Shi
            </a>
           </td>
           <td class="r">
            Northwestern Polytechnical University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2061" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Path planning in unpredictable dynamic environments remains a challenging problem due to the unpredictable appearance, disappearance, and movement of dynamic obstacles during navigation. To address this problem, we propose a reverse tree guided rapid exploration random tree (RT-RRT) algorithm that can efficiently perform navigation tasks in dynamic environments. The method first constructs a reverse tree rooted as goal state to search for an initial path. If a collision occurs on the path, The RT-RRT constructs a forward tree rooted as the current robot state in the same configuration space, until it connects with the reverse tree to find a new path. Furthermore, The RT-RRT improves the tree construction method and designs a path optimization strategy to reduce the path cost. The method is validated in different scenarios and has excellent navigation capabilities in unpredictable dynamic environments. In the same scenarios, the RT-RRT algorithm improves the success rate by 16.7%, reduces the path length by 20.54% and reduces the travel time by 10X compared to the text{RRT}^text{X} algorithm with the same number of samples.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t8_10">
             15:30-16:30, Paper WePI3T8.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2104'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Can Vehicle Motion Planning Generalize to Realistic Long-Tail Scenarios?
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#371936" title="Click to go to the Author Index">
             Hallgarten, Marcel
            </a>
           </td>
           <td class="r">
            University of Tübingen, Robert Bosch GmbH
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396654" title="Click to go to the Author Index">
             Zapata Manjarres, Julian Jose
            </a>
           </td>
           <td class="r">
            University of Duisburg-Essen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#371934" title="Click to go to the Author Index">
             Stoll, Martin
            </a>
           </td>
           <td class="r">
            Robert Bosch GmbH
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396651" title="Click to go to the Author Index">
             Renz, Katrin
            </a>
           </td>
           <td class="r">
            University of Tübingen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105216" title="Click to go to the Author Index">
             Zell, Andreas
            </a>
           </td>
           <td class="r">
            University of Tübingen
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2104" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Real-world autonomous driving systems must make safe decisions in the face of rare and diverse traffic scenarios. Current state-of-the-art planners are mostly evaluated on real-world datasets like nuScenes (open-loop) or nuplan (closed-loop). In particular, nuPlan seems to be an expressive evaluation method since it is based on real-world data and closed-loop, yet it mostly covers basic driving scenarios. This makes it difficult to judge a planner's capabilities to generalize to rarely-seen situations. Therefore, we propose a novel closed-loop benchmark interPlan containing several edge cases and challenging driving scenarios. We assess existing state-of-the-art planners on our benchmark and show that neither rule-based nor learning-based planners can safely navigate the interPlan scenarios.
             <p>
              A recently evolving direction is the usage of foundation models like large language models (LLM) to handle generalization. We evaluate an LLM-only planner and introduce a novel hybrid planner that combines an LLM-based behavior planner with a rule-based motion planner that achieves state-of-the-art performance on our benchmark. Code will be made publicly available upon acceptance.
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t8_11">
             15:30-16:30, Paper WePI3T8.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2159'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Generating Continuous Paths on Learned Constraint Manifolds Using Policy Search
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397607" title="Click to go to the Author Index">
             Canzini, Ethan
            </a>
           </td>
           <td class="r">
            University of Sheffield
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#186168" title="Click to go to the Author Index">
             Pope, Simon A.
            </a>
           </td>
           <td class="r">
            The University of Sheffield
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397669" title="Click to go to the Author Index">
             Tiwari, Ashutosh
            </a>
           </td>
           <td class="r">
            University of Sheffield
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2159" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Many robotic manipulation tasks are constrained due to kinematic limitations placed on the object being manipulated. This increases the complexity of manipulation tasks that operate in high dimensions, leading to increased risk that sampling based planners are unable to find optimal solutions. Whilst trajectory optimisation methods provide guaranteed optimal solutions when implementing constraints, they only provide locally optimal solutions in sequential decision-making and struggle to provide globally optimal paths. These constraints can be incorporated into the probabilistic latent spaces by using demonstrations that satisfy the constraint function. However whenever constraints change or a manipulator must perform different tasks the network must be retrained to accommodate the new constraints. In this paper, we provide an approach that allows the training of a single learned manifold that can be augmented to determine the constraint manifold for the manipulation task. Using this manifold, the geodesic between two points can be computed using policy search to solve the cost function associated with the geodesic curve length mathcal{L}_gamma. We provide comparisons in terms of path length against popular path planning algorithms with different kinematic constraints, demonstrating our method's ability to find optimal shortest paths on constraint manifolds.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t8_12">
             15:30-16:30, Paper WePI3T8.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2256'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Interactive-FAR: Interactive, Fast and Adaptable Routing for Navigation among Movable Obstacles in Complex Unknown Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#288413" title="Click to go to the Author Index">
             He, Botao
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397800" title="Click to go to the Author Index">
             Chen, Luke
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#171185" title="Click to go to the Author Index">
             Wang, Wenshan
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#125279" title="Click to go to the Author Index">
             Zhang, Ji
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#136632" title="Click to go to the Author Index">
             Fermuller, Cornelia
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#118557" title="Click to go to the Author Index">
             Aloimonos, Yiannis
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2256" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mobile_manipulation" title="Click to go to the Keyword Index">
               Mobile Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper introduces a real-time algorithm for navigating complex unknown environments cluttered with movable obstacles. Our algorithm achieves fast, adaptable routing by actively attempting to manipulate obstacles during path planning and adjusting the global plan from sensor feedback. The main contributions include an improved dynamic Directed Visibility Graph (DV-graph) for rapid global path searching, a real-time interaction planning method that adapts online from new sensory perceptions, and a comprehensive framework designed for interactive navigation in complex unknown or partially known environments. Our algorithm is capable of replanning the global path in several milliseconds and adapting to new sensory perceptions on-the-fly. Extensive experiments validate that our algorithm reduces the travel time by 33%, achieves up to 49% higher path efficiency, and runs faster than traditional methods by orders of magnitude in complex environments. It has been demonstrated to be the most efficient solution in terms of speed and efficiency for interactive navigation in environments of such complexity. We also open-source our code in the docker demo1 to facilitate future research.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t8_13">
             15:30-16:30, Paper WePI3T8.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2322'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Speeding up Path Planning Via Reinforcement Learning in MCTS for Automated Parking
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398118" title="Click to go to the Author Index">
             Zheng, Xinlong
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398112" title="Click to go to the Author Index">
             Zhang, Xiaozhou
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#378613" title="Click to go to the Author Index">
             Xu, Donghao
            </a>
           </td>
           <td class="r">
            Deeproute.ai Ltd
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2322" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we address a method that integrates reinforcement learning into the Monte Carlo tree search to boost online path planning under fully observable environments for automated parking tasks. Sampling-based planning methods under high-dimensional space can be computationally expensive and time-consuming. State evaluation methods are useful by leveraging the prior knowledge into the search steps, making the process faster in a real-time system. Given the fact that automated parking tasks are often executed under complex environments, a solid but lightweight heuristic guidance is challenging to compose in a traditional analytical way. To overcome this limitation, we propose a reinforcement learning pipeline with a Monte Carlo tree search under the path planning framework. By iteratively learning the value of a state and the best action among samples from its previous cycle’s outcomes, we are able to model a value estimator and a policy generator for given states. By doing that, we build up a balancing mechanism between exploration and exploitation, speeding up the path planning process while maintaining its quality without using human expert driver data.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t8_14">
             15:30-16:30, Paper WePI3T8.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2399'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Safety-First Tracker: A Trajectory Planning Framework for Omnidirectional Robot Tracking
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396998" title="Click to go to the Author Index">
             Lin, Yue
            </a>
           </td>
           <td class="r">
            Dalian University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#371741" title="Click to go to the Author Index">
             Liu, Yang
            </a>
           </td>
           <td class="r">
            Dalian University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#234108" title="Click to go to the Author Index">
             Zhang, Pingping
            </a>
           </td>
           <td class="r">
            Dalian University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#381518" title="Click to go to the Author Index">
             Chen, Xin
            </a>
           </td>
           <td class="r">
            Dalian University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#351339" title="Click to go to the Author Index">
             Wang, Dong
            </a>
           </td>
           <td class="r">
            Dalian University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#279865" title="Click to go to the Author Index">
             Lu, Huchuan
            </a>
           </td>
           <td class="r">
            Dalian University of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2399" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_tracking" title="Click to go to the Keyword Index">
               Visual Tracking
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper introduces a Safety-First Tracker (SF-Tracker) designed for omnidirectional autonomous tracking robots. The position and orientation of omnidirectional robots are decoupled for stepwise planning to ensure trajectory safety and maintain target visibility. SF-Tracker puts the trajectory safety in the first place. First, a collision-free and occlusion-free reference path is efficiently initialized by constructing a directed weighted graph. By building upon this path, safe trajectory optimization is implemented to ensure safe movement. Finally, an orientation planner is developed to achieve target visibility based on the safe trajectory. Extensive experimental evaluations in simulated environments and the real world demonstrate that the SF-Tracker outperforms state-of-the-art methods in terms trajectory safety and target visibility. Ablation experiments further demonstrate the significance of each step of the SF-Tracker. The source code and demonstration video can be found at https://github.com/Yue-0/SF-Tracker.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t8_15">
             15:30-16:30, Paper WePI3T8.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2438'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Energy-Efficient Trajectory Planning with Media Transition for a Hybrid Unmanned Aerial-Underwater Vehicle
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#246572" title="Click to go to the Author Index">
             Miranda Pinheiro, Pedro
            </a>
           </td>
           <td class="r">
            Federal University of Rio Grande - FURG
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#122621" title="Click to go to the Author Index">
             Alves Neto, Armando
            </a>
           </td>
           <td class="r">
            Universidade Federal De Minas Gerais
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#127628" title="Click to go to the Author Index">
             G. Macharet, Douglas
            </a>
           </td>
           <td class="r">
            Universidade Federal De Minas Gerais
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#116485" title="Click to go to the Author Index">
             Drews-Jr, Paulo
            </a>
           </td>
           <td class="r">
            Federal University of Rio Grande (FURG)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2438" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#nonholonomic_motion_planning" title="Click to go to the Keyword Index">
               Nonholonomic Motion Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#energy_and_environment_aware_automation" title="Click to go to the Keyword Index">
               Energy and Environment-Aware Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Vehicles capable of operating in more than one environment have been developed to solve real problems. Among them, the hybrid unmanned aerial-underwater vehicle (HUAUV) is receiving attention from the robotics community, mainly with a quadrotor-like configuration. However, this vehicle presents high energy consumption because of the larger mass required compared to the only aerial vehicle, limiting its autonomy. This work addresses the trajectory planning problem for a HUAUV. The method is based on Rapidly-exploring Random Trees (RRTs), a highly customizable planning technique. In addition, we propose two new heuristics to increase the energy efficiency of the hybrid vehicle. The first consists of biasing the tree expansion towards the environment with the lowest navigation cost, while the second one assigns estimated costs to nodes in the tree and chooses the least expensive trajectories. These techniques are evaluated in physically realistic simulation experiments performed in 135 scenarios. A comparative analysis of their performances is presented relative to the state of the art. We show that using efficient heuristics can significantly contribute to reducing energy consumption and even increase the average velocity in the missions performed by these vehicles.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t8_16">
             15:30-16:30, Paper WePI3T8.16
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2441'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              3D Global Path Planning for Walking Robots on Sparse Volumetric Maps
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#291587" title="Click to go to the Author Index">
             Grosse Besselmann, Marvin
            </a>
           </td>
           <td class="r">
            FZI Forschungszentrum Informatik
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#357286" title="Click to go to the Author Index">
             Häuselmann, Ramona
            </a>
           </td>
           <td class="r">
            KTH Royal Institude of Technology, SE-10044 Stockholm, Sweden
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#374337" title="Click to go to the Author Index">
             Mauch, Samuel
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#249072" title="Click to go to the Author Index">
             Puck, Lennart
            </a>
           </td>
           <td class="r">
            FZI Forschungszentrum Informatik
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#249071" title="Click to go to the Author Index">
             Schnell, Tristan
            </a>
           </td>
           <td class="r">
            FZI Forschungszentrum Informatik
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#132558" title="Click to go to the Author Index">
             Roennau, Arne
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology (KIT)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#188556" title="Click to go to the Author Index">
             Dillmann, Rüdiger
            </a>
           </td>
           <td class="r">
            FZI - Forschungszentrum Informatik - Karlsruhe
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2441" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#search_and_rescue_robots" title="Click to go to the Keyword Index">
               Search and Rescue Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The use of mobile robots has become increasingly common in multiple areas of daily life. To increase their autonomy for performing various tasks, efficient navigation skills are essential. The most crucial component of such navigation is the ability to calculate a global path between two points. The global path planning problem for mobile robots is typically limited to two-dimensional environments, in which the environment is projected onto a planar surface. While this approach works well in structured environments like industrial settings, it may not be suitable for all applications of mobile robots. With modern walking robots, capable of navigating complex terrain, more advanced path planning approaches are necessary. This work proposes a path-planning approach that utilizes the entire three-dimensional space, allowing for navigation in even the most challenging terrain. The central idea is to extend a traditional A* path planner to work directly on a fast volumetric map structure to generate optimal paths through the environment. Multiple optimizations and adjustments are introduced to improve the algorithm's performance. By applying morphology operators to sparse maps, sensor inaccuracies during the map construction are mitigated. Additionally, adjustments are made to handle the added complexity introduced by the extra search space dimension and to comply with the limitations of autonomous walking robots. This is paired with an efficient caching strategy to enhance the overall path-planning speed. The capability of the path planning approach is evaluated using both artificial and real-world maps. The results demonstrate that this approach shows great potential for enabling mobile ground robots to autonomously navigate even the most demanding terrains utilizing the entire three-dimensional space.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wepi3t9">
             <b>
              WePI3T9
             </b>
            </a>
           </td>
           <td class="r">
            Room 9
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wepi3t9" title="Click to go to the Program at a Glance">
             <b>
              Navigation II
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#177144" title="Click to go to the Author Index">
             Xiao, Xuesu
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#214687" title="Click to go to the Author Index">
             Zeng, Long
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t9_01">
             15:30-16:30, Paper WePI3T9.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3456'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Terrain-Attentive Learning for Efficient 6-DoF Kinodynamic Modeling on Vertically Challenging Terrain
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#354757" title="Click to go to the Author Index">
             Datar, Aniket
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#349237" title="Click to go to the Author Index">
             Pan, Chenhui
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#349198" title="Click to go to the Author Index">
             Nazeri, Mohammad
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#399211" title="Click to go to the Author Index">
             Pokhrel, Anuj
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#177144" title="Click to go to the Author Index">
             Xiao, Xuesu
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3456" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#model_learning_for_control" title="Click to go to the Keyword Index">
               Model Learning for Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Wheeled robots have recently demonstrated superior mechanical capability to traverse vertically challenging terrain (e.g., extremely rugged boulders comparable in size to the vehicles themselves). Negotiating such terrain introduces significant variations of vehicle pose in all six Degrees-of-Freedom (DoFs), leading to imbalanced contact forces, varying momentum, and chassis deformation due to non-rigid tires and suspensions. To autonomously navigate on vertically challenging terrain, all these factors need to be efficiently reasoned within limited onboard computation and strict real-time constraints. In this paper, we propose a 6-DoF kinodynamics learning approach that is attentive (only) to the specific underlying terrain critical to the current vehicle-terrain interaction, so that it can be efficiently queried in real-time motion planners onboard small robots. Physical experiment results show our Terrain-Attentive Learning (TAL) demonstrates on average 51.1% reduction in model prediction error among all 6 DoFs compared to another state-of-the-art model for vertically challenging terrain.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t9_02">
             15:30-16:30, Paper WePI3T9.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('518'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Efficient Incremental Penetration Depth Estimation between Convex Geometries
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#204380" title="Click to go to the Author Index">
             Gao, Wei
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab518" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computational_geometry" title="Click to go to the Keyword Index">
               Computational Geometry
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#simulation_and_animation" title="Click to go to the Keyword Index">
               Simulation and Animation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Penetration depth (PD) is essential for robotics due to its extensive applications in dynamic simulation, motion planning, haptic rendering, etc. The Expanding Polytope Algorithm (EPA) is the de facto standard for this problem, which estimates PD by expanding an inner polyhedral approximation of an implicit set. In this paper, we propose a novel optimization-based algorithm that incrementally estimates minimum penetration depth and its direction. One major advantage of our method is the capability to be warm-started by leveraging the spatial and temporal coherence. This coherence emerges naturally in many robotic applications (e.g., the temporal coherence between adjacent simulation time knots). As a result, our algorithm achieves substantial speedup –- we demonstrate it is 5-30x faster than EPA on several benchmarks. Moreover, our approach is built upon the same implicit geometry representation as EPA, which enables easy integration into existing software stacks. The code and supplemental document are available at: https://github.com/weigao95/mmind-fcl
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t9_03">
             15:30-16:30, Paper WePI3T9.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1064'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Collision-Free Robot Navigation in Crowded Environments Using Learning Based Convex Model Predictive Control
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391557" title="Click to go to the Author Index">
             Wen, ZhuangLei
            </a>
           </td>
           <td class="r">
            China Jiliang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391415" title="Click to go to the Author Index">
             Dong, Mingze
            </a>
           </td>
           <td class="r">
            China Jiliang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392039" title="Click to go to the Author Index">
             Chen, Xiai
            </a>
           </td>
           <td class="r">
            China Jiliang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1064" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Navigating robots safely and efficiently in crowded and complex environments remains a significant challenge. However, due to the dynamic and intricate nature of these settings, planning efficient and collision-free paths for robots to track is particularly difficult. In this paper, we uniquely bridge the robot’s perception, decision-making and control processes by utilizing the convex obstacle-free region computed from 2D LiDAR data. The overall pipeline is threefold: (1) We proposes a robot navigation framework that utilizes deep reinforcement learning (DRL), conceptualizing the observation as the convex obstacle-free region, a departure from general reliance on raw sensor inputs. (2) We design the action space, derived from the intersection of the robot’s kinematic limits and the convex region, to enable efficient sampling of inherently collision-free reference points. These actions assists in guiding the robot to move towards the goal and interact with other obstacles during navigation. (3) We employ model predictive control (MPC) to track the trajectory formed by the reference points while satisfying constraints imposed by the convex obstacle-free region and the robot’s kinodynamic limits. The effectiveness of proposed improvements has been validated through two sets of ablation studies and a comparative experiment against the Timed Elastic Band (TEB), demonstrating improved navigation performance in crowded and complex environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t9_04">
             15:30-16:30, Paper WePI3T9.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1889'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Generating Force Vectors from Projective Truncated Signed Distance Fields for Collision Avoidance and Haptic Feedback
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#341897" title="Click to go to the Author Index">
             Bien, Seongjin
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#239366" title="Click to go to the Author Index">
             Naceri, Abdeldjallil
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#156255" title="Click to go to the Author Index">
             Figueredo, Luis
            </a>
           </td>
           <td class="r">
            University of Nottingham (UoN)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#108317" title="Click to go to the Author Index">
             Haddadin, Sami
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1889" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Signed Distance Fields are a common surface representation method widely used for both 3D mapping and obstacle avoidance. While the former traditionally uses projective Truncated Signed Distance Fields (TSDF), the latter often requires a complete Euclidean Signed Distance Field (ESDF) representation of the environment. In this paper, we propose a unified system by combining both methods to generate force vectors to nearby obstacles from a TSDF-based 3D reconstruction. We introduce a new merging scheme to better capture the geometry of the object, with no post-processing requirements, and a way to increase the effective range of the system. Validation experiments demonstrate the accuracy of the force vector calculation by comparing it against an ideal simulated environment. Additionally, the flexibility of the system is demonstrated by implementing a haptic feedback teleoperation setup, which is validated through a user study in a teleoperation task. Through this, it is shown that the proposed method provides a statistically significant improvement to the task. Finally, a brief description on future improvements to the system is presented.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t9_05">
             15:30-16:30, Paper WePI3T9.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2201'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              LDP: A Local Diffusion Planner for Efficient Robot Navigation and Collision Avoidance
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#341896" title="Click to go to the Author Index">
             Yu, Wenhao
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#291010" title="Click to go to the Author Index">
             Peng, Jie
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397553" title="Click to go to the Author Index">
             Yang, Huanyu
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397937" title="Click to go to the Author Index">
             Zhang, Junrui
            </a>
           </td>
           <td class="r">
            University of Science &amp; Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#231281" title="Click to go to the Author Index">
             Duan, Yifan
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#148006" title="Click to go to the Author Index">
             Ji, Jianmin
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#291452" title="Click to go to the Author Index">
             Zhang, Yanyong
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2201" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The conditional diffusion model has been demonstrated as an efficient tool for learning robot policies, owing to its advancement to accurately model the conditional distribution of policies. The intricate nature of real-world scenarios, characterized by dynamic obstacles and maze-like structures, underscores the complexity of robot local navigation decision-making as a conditional distribution problem. Nevertheless, leveraging the diffusion model for robot local navigation is not trivial and encounters several under-explored challenges: (1) Data Urgency. The complex conditional distribution in local navigation needs training data to include diverse policy in diverse real-world scenarios; (2) Myopic Observation. Due to the diversity of the perception scenarios, diffusion decisions based on the local perspective of robots may prove suboptimal for completing the entire task, as they often lack foresight. In certain scenarios requiring detours, the robot may become trapped. To address these issues, our approach begins with an exploration of a diverse data generation mechanism that encompasses multiple agents exhibiting distinct preferences through target selection informed by integrated global-local insights. Then, based on this diverse training data, a diffusion agent is obtained, capable of excellent collision avoidance in diverse scenarios. Subsequently, we augment our Local Diffusion Planner, also known as LDP by incorporating global observations in a lightweight manner. This enhancement broadens the observational scope of LDP, effectively mitigating the risk of becoming ensnared in local optima and promoting more robust navigational decisions. Our experimental results demonstrated that the LDP outperforms other baseline algorithms in navigation performance, exhibiting enhanced robustness across diverse scenarios with different policy preferences and superior generalization capabilities for unseen scenarios. Moreover, we highlighted the competitive advantage of the LDP within real-world settings.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t9_06">
             15:30-16:30, Paper WePI3T9.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2769'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Dynamic Reconfiguration Integrated Nested A*: A Path Planner for Reconfigurable Robot to Improve Performance in Confined Spaces
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#367142" title="Click to go to the Author Index">
             Rishan Sachinthana, Wijenayaka Kankanamge
            </a>
           </td>
           <td class="r">
            Singapore University of Technology and Design
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#219480" title="Click to go to the Author Index">
             Samarakoon Mudiyanselage, Bhagya Prasangi Samarakoon
            </a>
           </td>
           <td class="r">
            Singapore University of Technology and Design
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#191819" title="Click to go to the Author Index">
             Muthugala Arachchige, Viraj Jagathpriya Muthugala
            </a>
           </td>
           <td class="r">
            Singapore University of Technology and Design
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#107677" title="Click to go to the Author Index">
             Elara, Mohan Rajesh
            </a>
           </td>
           <td class="r">
            Singapore University of Technology and Design
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2769" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#service_robotics" title="Click to go to the Keyword Index">
               Service Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Path planning is crucial in numerous robotic applications. Reconfigurable robots possess the capability to alter their shape, enabling access to confined spaces, a task challenging for fixed-shape robots. However, existing path planners for reconfigurable robots are typically designed with predefined motion patterns for reconfiguration, lacking adaptation to space availability and executing reconfiguration only when the robot is static. This reliance on predefined patterns limits the potential of reconfigurable robots to navigate through confined spaces. This paper proposes a novel path-planning approach based on dynamic reconfiguration to address this limitation. The proposed method employs two nested A* algorithms modified to handle reconfiguration and efficient search, termed Dynamic Reconfiguration integrated Nested A* (DRiNA*). Experimental results demonstrate the proposed method's ability to find feasible paths for robot navigation using dynamic reconfigurations in confined spaces, surpassing the capabilities of existing path planners. The scalability of the proposed method to reconfigurable robots with varying numbers of blocks is also confirmed. Additionally, DRiNA* significantly reduces energy consumption compared to existing path planners.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t9_07">
             15:30-16:30, Paper WePI3T9.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2992'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Visual Forecasting As a Mid-Level Representation for Avoidance
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#318190" title="Click to go to the Author Index">
             Yang, Hsuan-Kung
            </a>
           </td>
           <td class="r">
            National Tsing Hua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#354089" title="Click to go to the Author Index">
             Chiang, Tsung-Chih
            </a>
           </td>
           <td class="r">
            National Tsing Hua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#351028" title="Click to go to the Author Index">
             Liu, Ting-Ru
            </a>
           </td>
           <td class="r">
            National Tsing Hua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#351081" title="Click to go to the Author Index">
             Liu, Jou-Min
            </a>
           </td>
           <td class="r">
            National Tsing Hua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#351149" title="Click to go to the Author Index">
             Huang, Chun-Wei
            </a>
           </td>
           <td class="r">
            National Tsing Hua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#246632" title="Click to go to the Author Index">
             Lee, Chun-Yi
            </a>
           </td>
           <td class="r">
            National Tsing Hua University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2992" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The challenge of navigation in environments with dynamic objects continues to be a central issue in the study of autonomous agents. While predictive methods hold promise, their reliance on precise state information makes them less practical for real-world implementation. This study presents visual forecasting as an innovative alternative. By introducing intuitive visual cues, this approach projects the future trajectories of dynamic objects to improve agent perception and enable anticipatory actions. Our research explores two distinct strategies for conveying predictive information through visual forecasting: (1) sequences of bounding boxes, and (2) augmented paths. To validate the proposed visual forecasting strategies, we initiate evaluations in simulated environments using the Unity engine and then extend these evaluations to real-world scenarios to assess both practicality and effectiveness. The results confirm the viability of visual forecasting as a promising solution for navigation and obstacle avoidance in dynamic environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t9_08">
             15:30-16:30, Paper WePI3T9.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1443'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Two-Stage Reinforcement Learning Approach for Robot Navigation in Long-Range Indoor Dense Crowd Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#349300" title="Click to go to the Author Index">
             Jing, Xinghui
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#349112" title="Click to go to the Author Index">
             Xiong, Xin
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391007" title="Click to go to the Author Index">
             Li, Fuhao
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#349302" title="Click to go to the Author Index">
             Zhang, Tao
            </a>
           </td>
           <td class="r">
            Pudu Technology Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#214687" title="Click to go to the Author Index">
             Zeng, Long
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1443" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_centered_robotics" title="Click to go to the Keyword Index">
               Human-Centered Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Safe and efficient mobility is vital for mobile robots navigating long-range indoor crowd environments, such as supermarkets, restaurants, and railway stations. Traditional path planning methods are challenged because of the high dynamics of pedestrians and constrained feasible regions. Existing long-range deep reinforcement learning (DRL) path planning methods often exhibit low success rates and driving speeds in long-range navigation tasks under crowded conditions. To overcome these issues, we propose a new two-stage DRL method, known as TSDRL, where the long-range navigation task is divided into subgoals generation (SG) and planning refinement (PR) stages. In the SG stage, the agent is trained to learn a decision-making policy to generate subgoals at each decision time to avoid dense crowds. In the PR stage, the agent learns a safer and more efficient planning policy based on each subgoals generated in the SG stage to improve the robot's movement safety and speed. Simulated experiments show that our method outperforms traditional and long-range DRL path planning methods in terms of safety, efficiency, generalization, and robustness. Furthermore, we evaluate our approach using the Turtlebot2 platform in a real-world setting, demonstrating that the robot can navigate safely and efficiently while avoiding dense crowds.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t9_09">
             15:30-16:30, Paper WePI3T9.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3106'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              MPP: Multiscale Path Planning for UGV Navigationin Semi-Structured Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#390408" title="Click to go to the Author Index">
             Cao, Rui
            </a>
           </td>
           <td class="r">
            Shandong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#390082" title="Click to go to the Author Index">
             Yang, Zhiqiang
            </a>
           </td>
           <td class="r">
            Shandong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#268891" title="Click to go to the Author Index">
             Song, Ran
            </a>
           </td>
           <td class="r">
            Shandong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398927" title="Click to go to the Author Index">
             Meng, Ziyu
            </a>
           </td>
           <td class="r">
            Shandong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398879" title="Click to go to the Author Index">
             Wang, Ruifeng
            </a>
           </td>
           <td class="r">
            Jinan Preschool Education College
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#203913" title="Click to go to the Author Index">
             Zhang, Wei
            </a>
           </td>
           <td class="r">
            Shandong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3106" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Autonomous navigation of unmanned ground vehicles (UGVs) in structured road and indoor environments has made significant progress in recent years. However, navigation in outdoor semi-structured environments remains a challenge. This paper presents the multiscale path planning (MPP) method for UGV navigation in semi-structured environments. MPP leverages global, mid-layer and local planners to obtain global path and handle local obstacles of different sizes. First, the global planner provides guidance based on road connection relationships, selecting optimal connections by evaluating the distance between road nodes. Next, the mid-layer planner perceives large-scale obstacles and constructs the costmap, generating a mid-layer path that offers a general direction for the UGV. Finally, a local trajectory planning algorithm, namely terrain-considering timed elastic band (TC-TEB), is used to obtain local trajectory. This algorithm incorporates terrain-velocity constraints into the TEB algorithm to ensure the vehicle's vertical stability. We demonstrate the safety and effectiveness of MPP through experiments in both simulated and real-world environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t9_10">
             15:30-16:30, Paper WePI3T9.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2200'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Preventing Catastrophic Forgetting in Continuous Online Learning for Autonomous Driving
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#301174" title="Click to go to the Author Index">
             Yang, Rui
            </a>
           </td>
           <td class="r">
            Université De Technologie De Belfort Montbéliard
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#276733" title="Click to go to the Author Index">
             Yang, Tao
            </a>
           </td>
           <td class="r">
            Northwestern Polytechnical University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#141450" title="Click to go to the Author Index">
             Yan, Zhi
            </a>
           </td>
           <td class="r">
            University of Technology of Belfort-Montbéliard (UTBM)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#167573" title="Click to go to the Author Index">
             Krajník, Tomáš
            </a>
           </td>
           <td class="r">
            Czech Technical University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#127659" title="Click to go to the Author Index">
             Ruichek, Yassine
            </a>
           </td>
           <td class="r">
            University of Technology of Belfort-Montbeliard - France
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2200" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#continual_learning" title="Click to go to the Keyword Index">
               Continual Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Autonomous vehicles require online learning capabilities to enable long-term, unattended operation. However, long-term online learning is accompanied by the problem of forgetting previously learned knowledge. This paper introduces an online learning framework that includes a catastrophic forgetting prevention mechanism, named Long-Short-Term Online Learning (LSTOL). The framework consists of a set of short-term learners and a long-term controller, where the former is based on the concept of ensemble learning and aims to achieve rapid learning iterations, while the latter contains a simple yet efficient probabilistic decision-making mechanism combined with four control primitives to achieve effective knowledge maintenance. A novel feature of the proposed LSTOL is that it avoids forgetting while learning autonomously. In addition, LSTOL makes no assumptions about the model type of short-term learners and the continuity of the data. The effectiveness of the proposed framework is demonstrated through experiments across well-known datasets in autonomous driving, including KITTI and Waymo. The source code for the method implementation is publicly available at https://github.com/epan-utbm/lstol.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t9_11">
             15:30-16:30, Paper WePI3T9.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2642'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              TRAVERSE: Traffic-Responsive Autonomous Vehicle Experience &amp; Rare-Event Simulation for Enhanced Safety
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397005" title="Click to go to the Author Index">
             Thalapanane, Sandeep
            </a>
           </td>
           <td class="r">
            University of Maryland, College Park
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396027" title="Click to go to the Author Index">
             Senthil Kumar, Sandip Sharan
            </a>
           </td>
           <td class="r">
            University of Maryland, College Park
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398250" title="Click to go to the Author Index">
             Appiya Dilipkumar Peethambari, Guru Nandhan
            </a>
           </td>
           <td class="r">
            University of Maryland College Park
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397586" title="Click to go to the Author Index">
             Sri hari, Sourang
            </a>
           </td>
           <td class="r">
            University of Maryland College Park
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#277405" title="Click to go to the Author Index">
             Zheng, Laura
            </a>
           </td>
           <td class="r">
            University of Maryland, College Park
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#352866" title="Click to go to the Author Index">
             Poveda, Julio
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101887" title="Click to go to the Author Index">
             Lin, Ming C.
            </a>
           </td>
           <td class="r">
            University of Maryland at College Park
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2642" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#virtual_reality_and_interfaces" title="Click to go to the Keyword Index">
               Virtual Reality and Interfaces
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#simulation_and_animation" title="Click to go to the Keyword Index">
               Simulation and Animation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Data for training learning-enabled self-driving cars in the physical world are typically collected in a safe, normal environment. Such data distribution often engenders a strong bias towards safe driving, making self-driving cars unprepared when encountering adversarial scenarios like unexpected accidents. Due to a dearth of such adverse data that is unrealistic for drivers to collect, autonomous vehicles can perform poorly when experiencing such rare events. This work addresses much-needed research by having participants drive a VR vehicle simulator going through simulated traffic with various types of accidental scenarios. It aims to understand human responses and behaviors in simulated accidents, contributing to our understanding of driving dynamics and safety. The simulation framework adopts a robust traffic simulation and is rendered using the Unity Game Engine. Furthermore, the simulation framework is built with portable, light-weight immersive driving simulator hardware, lowering the resource barrier for studies in autonomous driving research.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t9_12">
             15:30-16:30, Paper WePI3T9.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2431'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Context-Aware GAN-Based Image Retrieval for Coarse Localization of Autonomous Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#286606" title="Click to go to the Author Index">
             Swaminathan, Ruphan
            </a>
           </td>
           <td class="r">
            OttonomyIO
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#154275" title="Click to go to the Author Index">
             Korupolu, Pradyot
            </a>
           </td>
           <td class="r">
            Ottonomy Inc
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2431" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Effective localization is crucial for the reliable operation of autonomous delivery robots. This paper introduces ConLocGAN, a novel context-aware GAN, addressing challenges in Lidar-based localization. Our approach employs a two-step process, integrating image retrieval with Lidar-based localization. ConLocGAN extracts robust global descriptors for coarse pose estimator, which acts as a precursor for Lidar-based pose refinement. The discriminator in ConLocGAN identifies differences in images of the same scene under diverse conditions at the feature level. This information is then utilized to enhance localization-specific feature extraction by the generator in a self-supervised setting. Additionally, we present a simple data collection pipeline that is seamlessly integrated into routine robot operations. Using heatmaps for visualization, we demonstrate that our network learns robust descriptors by prioritizing static components of the scene while effectively disregarding environmental changes such as illumination and weather, as well as dynamic objects like people and vehicles. We further validate our method on the challenging CMU seasons dataset, where it outperforms state-of-the-art retrieval-based methods in coarse pose estimation.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t9_13">
             15:30-16:30, Paper WePI3T9.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2533'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Embodiment Randomization for Cross Embodiment Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392374" title="Click to go to the Author Index">
             Putta, Pranav
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#357700" title="Click to go to the Author Index">
             Aggarwal, Gunjan
            </a>
           </td>
           <td class="r">
            Georgia Tech
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#203121" title="Click to go to the Author Index">
             Mottaghi, Roozbeh
            </a>
           </td>
           <td class="r">
            Meta
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#238503" title="Click to go to the Author Index">
             Batra, Dhruv
            </a>
           </td>
           <td class="r">
            Georgia Tech / Facebook AI Research
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#295864" title="Click to go to the Author Index">
             Yokoyama, Naoki
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#275570" title="Click to go to the Author Index">
             Truong, Joanne
            </a>
           </td>
           <td class="r">
            The Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#300187" title="Click to go to the Author Index">
             Majumdar, Arjun
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2533" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present Embodiment Randomization, a simple, inexpensive, and intuitive technique for training robust behavior policies that can be transferred to multiple robot embodiments. While prior works require real-world data from multiple robots, or complex algorithmic adjustments to address the challenge of embodiment generalization, our approach leverages the power of simulation and large-scale reinforcement learning and can be easily integrated within existing policy learning methods. We show that policies trained with embodiment randomization implicitly perform system identification, enabling them to adapt to new embodiments during deployment. Our approach not only shows significant improvements in adapting to novel robot configurations, but also in generalizing from simulation to reality and contending with real-world perturbations, highlighting the potential of embodiment randomization in creating versatile and adaptable robotic navigation policies.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t9_14">
             15:30-16:30, Paper WePI3T9.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2646'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Camera Pose Estimation from Bounding Boxes
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398429" title="Click to go to the Author Index">
             Vavra, Vaclav
            </a>
           </td>
           <td class="r">
            Visual Recognition Group, FEE, CTU in Prague
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#178498" title="Click to go to the Author Index">
             Sattler, Torsten
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#220907" title="Click to go to the Author Index">
             Kukelova, Zuzana
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2646" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Visual localization is an important part of many interesting applications, including robotics. The dominant localization strategy is to estimate the camera pose from 2D-3D matches between 2D pixel positions and 3D points. Yet, such approaches can be quite memory intensive and can lead to privacy risks. An interesting alternative to point-based matches is to use higher-level primitives for pose estimation. Consequently, this work investigates using correspondences between 2D and 3D bounding boxes for camera pose estimation. The resulting scene representation is compact and poses fewer privacy risks. In this setting, there are typically orders of magnitude fewer matches available compared to classical feature-based methods. In addition, the available correspondences are significantly more noisy. We investigate multiple strategies based on converting bounding box correspondences to point correspondences and propose a novel and simple 2-point camera absolute pose solver (DP2P) that exploits the fact that the depths of the objects can be approximated from the sizes of their bounding boxes.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t9_15">
             15:30-16:30, Paper WePI3T9.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2846'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              HM3D-OVON: A Dataset and Benchmark for Open-Vocabulary Object Goal Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#295864" title="Click to go to the Author Index">
             Yokoyama, Naoki
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#364361" title="Click to go to the Author Index">
             Ramrakhya, Ram
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#238496" title="Click to go to the Author Index">
             Das, Abhishek
            </a>
           </td>
           <td class="r">
            Georgia Tech
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#238503" title="Click to go to the Author Index">
             Batra, Dhruv
            </a>
           </td>
           <td class="r">
            Georgia Tech / Facebook AI Research
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#180081" title="Click to go to the Author Index">
             Ha, Sehoon
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2846" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present the Habitat-Matterport 3D Open Vocabulary Object Goal Navigation dataset (HM3D-OVON), a large-scale benchmark that broadens the scope and semantic range of prior Object Goal Navigation (ObjectNav) benchmarks. Leveraging the HM3DSem dataset, HM3D-OVON incorporates over 15k annotated instances of household objects across 379 distinct categories, derived from photo-realistic 3D scans of real-world environments. In contrast to earlier ObjectNav datasets, which limit goal objects to a predefined set of 6-20 categories, HM3D-OVON facilitates the training and evaluation of models with an open-set of goals defined through free-form language at test-time. Through this open-vocabulary formulation, HM3D-OVON encourages progress towards learning visuo-semantic navigation behaviors that are capable of searching for any object specified by text in an open- vocabulary manner. Additionally, we systematically evaluate and compare several different types of approaches on HM3D- OVON. We find that HM3D-OVON can be used to train an open-vocabulary ObjectNav agent that achieves both higher performance and is more robust to localization and actuation noise than the state-of-the-art ObjectNav approach. We hope that our benchmark and baseline results will drive interest in developing embodied agents that can navigate real-world spaces to find household objects specified through free-form language, taking a step towards more flexible and human-like semantic visual navigation. Code and videos available at: naoki.io/ovon.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t9_16">
             15:30-16:30, Paper WePI3T9.16
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2193'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Cross-Observability Learning for Vehicle Routing Problems
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397984" title="Click to go to the Author Index">
             Liu, Ruifan
            </a>
           </td>
           <td class="r">
            Cranfield University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#161438" title="Click to go to the Author Index">
             Shin, Hyo-Sang
            </a>
           </td>
           <td class="r">
            Cranfield University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104866" title="Click to go to the Author Index">
             Tsourdos, Antonios
            </a>
           </td>
           <td class="r">
            Cranfield University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2193" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#planning__scheduling_and_coordination" title="Click to go to the Keyword Index">
               Planning, Scheduling and Coordination
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This study seeks towards a better understanding of multi-vehicle routing problems (VRPs) under restricted observability. Unlike most of the prior research where full knowledge of tasks and vehicles is assumed, this paper addresses VRPs where each vehicle's observation is confined to a specific number of nearest tasks. Vehicles make decisions based on localized policies in a fully decentralized manner. We theoretically show that for imitate policy, the marginal increase of value functions diminishes as the neighbourhood range expands, if the reward function is also submodular. Subsequently, we employed a multi-agent cross-observability policy optimization (MACOPO) algorithm to solve the VRPs with restricted observability. The algorithm optimizes a cross-entropy term taking advantage of a fully observable expert to guide the training. Empirical results supported both the theoretical finding and the effectiveness of the multi-agent learning algorithm.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t9_17">
             15:30-16:30, Paper WePI3T9.17
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('806'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              StereoNavNet: Learning to Navigate Using Stereo Cameras with Auxiliary Occupancy Voxels
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#324814" title="Click to go to the Author Index">
             Li, Hongyu
            </a>
           </td>
           <td class="r">
            Brown University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#129456" title="Click to go to the Author Index">
             Padir, Taskin
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#239579" title="Click to go to the Author Index">
             Jiang, Huaizu
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab806" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#perception_action_coupling" title="Click to go to the Keyword Index">
               Perception-Action Coupling
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Visual navigation has received significant attention recently. Most of the prior works focus on predicting navigation actions based on semantic features extracted from visual encoders. However, these approaches often rely on large datasets and exhibit limited generalizability. In contrast, our approach draws inspiration from traditional navigation planners that operate on geometric representations, such as occupancy maps. We propose StereoNavNet (SNN), a novel visual navigation approach employing a modular learning framework comprising perception and policy modules. Within the perception module, we estimate an auxiliary 3D voxel occupancy grid from stereo RGB images and extract geometric features from it. These features, along with user-defined goals, are utilized by the policy module to predict navigation actions. Through extensive empirical evaluation, we demonstrate that SNN outperforms baseline approaches in terms of success rates, success weighted by path length, and navigation error. Furthermore, SNN exhibits better generalizability, characterized by maintaining leading performance when navigating across previously unseen environments.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wepi3t10">
             <b>
              WePI3T10
             </b>
            </a>
           </td>
           <td class="r">
            Room 10
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wepi3t10" title="Click to go to the Program at a Glance">
             <b>
              Simultaneous Localization and Mapping (SLAM) III
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#132320" title="Click to go to the Author Index">
             Weiss, Stephan
            </a>
           </td>
           <td class="r">
            Universität Klagenfurt
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t10_01">
             15:30-16:30, Paper WePI3T10.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1678'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Tightly Coupled Passive UWB Localization for Low-Density Anchor Networks
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#212119" title="Click to go to the Author Index">
             Senevirathna, Nushen M
            </a>
           </td>
           <td class="r">
            Memorial University of Newfoundland
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#150372" title="Click to go to the Author Index">
             De Silva, Oscar
            </a>
           </td>
           <td class="r">
            Memorial University of Newfoundland
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#111050" title="Click to go to the Author Index">
             Mann, George K. I.
            </a>
           </td>
           <td class="r">
            Memorial University of Newfoundland
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#111047" title="Click to go to the Author Index">
             Gosine, Raymond G.
            </a>
           </td>
           <td class="r">
            Memorial University of Newfoundland
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1678" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_networks" title="Click to go to the Keyword Index">
               Sensor Networks
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#range_sensing" title="Click to go to the Keyword Index">
               Range Sensing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This study investigates the effectiveness of a passive tightly coupled ultra-wideband (UWB) based inertial navigation system for indoor positioning of mobile platforms. Unlike conventional methods that rely on time difference of arrival (TDOA) or two-way ranging (TWR) measurements, the proposed approach utilizes local reception timestamps directly. An error state Kalman filter with right quaternion error definition is used in the state estimation process. Evaluation is performed first in a Matlab simulation environment and then, using a dataset acquired by flying a quadcopter while monitored by a motion capture system. Timestamp measurements were acquired using custom firmware flashed onto Decawave DWM 1000-DEV hardware. Our findings demonstrate that the proposed system outperforms traditional TDOA methods, providing accurate measurements even in the presence of communication interruptions, with as few as one anchor.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t10_02">
             15:30-16:30, Paper WePI3T10.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1750'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Indoor Position Estimation Using NLoS Reflected Path with Wireless Distance Sensors
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#335944" title="Click to go to the Author Index">
             Itsuka, Tomoya
            </a>
           </td>
           <td class="r">
            Kyushu University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103231" title="Click to go to the Author Index">
             Kurazume, Ryo
            </a>
           </td>
           <td class="r">
            Kyushu University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1750" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Indoor robot localization is important for the realization of autonomous service robots. Various studies have been conducted on "indoor GPS" measurements using wireless distance sensors such as ultrasonic beacons. However, when these beacons encounter non-line-of-sight (NLoS) conditions due to obstacles, accurate distance measurements become challenging because of multipath and other effects. In this study, we propose a method for simultaneously estimating a robot's position and distance to reflective surfaces in an environment using wireless distance sensors. The proposed method can estimate not only the robot's position but also the reflection of the beacon signal. First, the wheel odometry of the robot is assumed to be the initial value, and the measured distance from the beacon to the robot is used as a factor to construct the factor graph. Second, the distance to the reflective surface of the beacon signal, which is parallel to the robot's movement plane, was estimated from the robot position sequence using the GMM and used as a noise model in the factor graph. Finally, the method is evaluated by acquiring data in a real environment with obstacles. Compared with a method that does not consider reflection paths, this method demonstrated improved accuracy and effectiveness.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t10_03">
             15:30-16:30, Paper WePI3T10.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1777'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Leveraging Neural Radiance Field in Descriptor Synthesis for Keypoints Scene Coordinate Regression
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#387509" title="Click to go to the Author Index">
             Bui, Huy Hoang
            </a>
           </td>
           <td class="r">
            Ritsumeikan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#330184" title="Click to go to the Author Index">
             Bui, Bach-Thuan
            </a>
           </td>
           <td class="r">
            Ritsumeikan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#184289" title="Click to go to the Author Index">
             Tran, Dinh Tuan
            </a>
           </td>
           <td class="r">
            College of Information Science and Engineering, Ritsumeikan Univ
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100204" title="Click to go to the Author Index">
             Lee, Joo-Ho
            </a>
           </td>
           <td class="r">
            Ritsumeikan University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1777" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Classical structural-based visual localization methods offer high accuracy but face trade-offs in terms of storage, speed, and privacy. A recent innovation, keypoint scene coordinate regression (KSCR) named D2S addresses these issues by leveraging graph attention networks to enhance keypoint relationships and predict their 3D coordinates using a simple multilayer perceptron (MLP). Camera pose is then determined via PnP+RANSAC, using established 2D-3D correspondences. While KSCR achieves competitive results, rivaling state-of-the-art image-retrieval methods like HLoc across multiple benchmarks, its performance is hindered when data samples are limited due to the deep learning model's reliance on extensive data. This paper proposes a solution to this challenge by introducing a pipeline for keypoint descriptor synthesis using Neural Radiance Field (NeRF). By generating novel poses and feeding them into a trained NeRF model to create new views, our approach enhances the KSCR's generalization capabilities in data-scarce environments. The proposed system could significantly improve localization accuracy by up to 50% and cost only a fraction of time for data synthesis. Furthermore, its modular design allows for the integration of multiple NeRFs, offering a versatile and efficient solution for visual localization. The implementation is publicly available at: https://github.com/ais-lab/DescriptorSynthesis4Feat2Map.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t10_04">
             15:30-16:30, Paper WePI3T10.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1869'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Geolocation on Cartographic Maps with Multi-Modal Fusion
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#289502" title="Click to go to the Author Index">
             Zhou, Mengjie
            </a>
           </td>
           <td class="r">
            University of Bristol
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#176643" title="Click to go to the Author Index">
             Liu, Liu
            </a>
           </td>
           <td class="r">
            Huawei
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#316932" title="Click to go to the Author Index">
             Zhong, Yiran
            </a>
           </td>
           <td class="r">
            SenseTime
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#118860" title="Click to go to the Author Index">
             Calway, Andrew
            </a>
           </td>
           <td class="r">
            University of Bristol
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1869" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We explore the geolocation problem, aiming to localize ground-view images on cartographic maps, without the need of any GPS priors. This task mimics the human wayfinding ability and offers high scalability and robustness by using the compact and semantic representations of maps. Current methods often rely on 2D maps to encode dense contextual information for ground-to-map matching. In this paper, we lift ground-to-map matching to a 2.5D space, where heights of structures (e.g, buildings) provide richer geometric information to guide the matching process. We propose a new approach to learning representative embeddings from multi-modal data. Specifically, we establish a projection relationship between 2D and 2.5D space. The projection is further used to combine multi-modal features from the 2D and 2.5D maps using an effective pixel-to-point fusion method. By encoding crucial geometric cues, our method learns discriminative location embeddings for matching panoramic images and maps. Additionally, we construct the first large-scale multi-modal geolocation dataset to validate our method and facilitate future research. Both single-image based and route based geolocation experiments are conducted to test our method. Extensive experiments demonstrate that the proposed method achieves significantly higher geolocation accuracy and faster convergence than previous 2D map-based approaches.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t10_05">
             15:30-16:30, Paper WePI3T10.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1964'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              U-BEV: Height-Aware Bird's-Eye-View Segmentation and Neural Map-Based Relocalization
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#377321" title="Click to go to the Author Index">
             Boscolo Camiletto, Andrea
            </a>
           </td>
           <td class="r">
            Huawei
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#279728" title="Click to go to the Author Index">
             Bochicchio, Alfredo
            </a>
           </td>
           <td class="r">
            Huawei
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#225689" title="Click to go to the Author Index">
             Liniger, Alexander
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#198373" title="Click to go to the Author Index">
             Dai, Dengxin
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#191825" title="Click to go to the Author Index">
             Gawel, Abel Roman
            </a>
           </td>
           <td class="r">
            Boston Dynamics AI Institute
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1964" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#omnidirectional_vision" title="Click to go to the Keyword Index">
               Omnidirectional Vision
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Efficient relocalization is essential for intelligent vehicles when GPS reception is insufficient or sensor-based localization fails. Recent advances in Bird's-Eye-View (BEV) segmentation allow for accurate estimation of local scene appearance and in turn, can benefit the relocalization of the vehicle. However, one downside of BEV methods is the heavy computation required to leverage the geometric constraints. This paper presents U-BEV, a U-Net inspired architecture that extends the current state-of-the-art by allowing the BEV to reason about the scene on multiple height layers before flattening the BEV features. We show that this extension boosts the performance of the U-BEV by up to 4.11 IoU. Additionally, we combine the encoded neural BEV with a differentiable template matcher to perform relocalization on neural SD-map data. The model is fully end-to-end trainable and outperforms transformer-based BEV methods of similar computational complexity by 1.7 to 2.8 mIoU and BEV-based relocalization by over 26% Recall Accuracy on the nuScenes dataset.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t10_06">
             15:30-16:30, Paper WePI3T10.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2272'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              ReLoc-Aligner : Orientation-Aware Scene Descriptor for Re-Localization within a 3D Point Cloud Map
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#359782" title="Click to go to the Author Index">
             Cho, SungJoon
            </a>
           </td>
           <td class="r">
            Korea Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#111012" title="Click to go to the Author Index">
             Kim, Jun-Sik
            </a>
           </td>
           <td class="r">
            Korea Institute of Science &amp; Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2272" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#range_sensing" title="Click to go to the Keyword Index">
               Range Sensing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We propose a new orientation-aware scene descriptor ReLoc-Aligner for re-localization of a 3D point cloud. Re-localization within a 3D point cloud map is crucial for conducting Simultaneous Localization and Mapping (SLAM). Existing re-localization or place recognition methods of 3D LiDAR sensor data aim to estimate the current position of the sensor robustly to orientation changes. However, they do not determine the current orientation of the sensor within a 3D point cloud map, which limits their applications to re-localization or loop closing in SLAM. On the other hand, existing methods capable of orientation estimation tend to be slower than them. Our scene descriptor has a property of orientation awareness that enables us to extract the orientation difference between two scans directly from the descriptor. This is useful for the registration of point clouds from a good initial estimate, which leads to better re-localization of a scan. We propose a training method for the new descriptor. In addition, we develop fast querying and re-localization methods using the descriptors. Intensive experiments demonstrate that the proposed method is superior to the existing state-of-the-art methods in both place recognition and orientation estimation.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t10_07">
             15:30-16:30, Paper WePI3T10.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2298'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SOS-Match: Segmentation for Open-Set Robust Correspondence Search and Robot Localization in Unstructured Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#365694" title="Click to go to the Author Index">
             Thomas, Annika
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#297074" title="Click to go to the Author Index">
             Kinnari, Jouko
            </a>
           </td>
           <td class="r">
            Saab Finland Oy
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#241322" title="Click to go to the Author Index">
             Lusk, Parker C.
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#339128" title="Click to go to the Author Index">
             Kondo, Kota
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104610" title="Click to go to the Author Index">
             How, Jonathan
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2298" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_slam" title="Click to go to the Keyword Index">
               Data Sets for SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present SOS-Match, a novel framework for detecting and matching objects in unstructured environments. Our system consists of 1) a front-end mapping pipeline using a zero-shot segmentation model to extract object masks from images and track them across frames and 2) a frame alignment pipeline that uses the geometric consistency of object relationships to efficiently localize across a variety of conditions. We evaluate SOS-Match on the Batvik seasonal dataset which includes drone flights collected over a coastal plot of southern Finland during different seasons and lighting conditions. Results show that our approach is more robust to changes in lighting and appearance than classical image feature-based approaches or global descriptor methods, and it provides more viewpoint invariance than learning-based feature detection and description approaches. SOS-Match localizes within a reference map up to 46x faster than other feature-based approaches and has a map size less than 0.5% the size of the most compact other maps. SOS-Match is a promising new approach for landmark detection and correspondence search in unstructured environments that is robust to changes in lighting and appearance and is more computationally efficient than other approaches, suggesting that the geometric arrangement of segments is a valuable localization cue in unstructured environments. We release our datasets at https://acl.mit.edu/SOS-Match/.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t10_08">
             15:30-16:30, Paper WePI3T10.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2343'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              3D Localization of Objects Buried within Granular Material Using a Distributed 3-Axis Tactile Sensor
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#356255" title="Click to go to the Author Index">
             Chen, Zhengqi
            </a>
           </td>
           <td class="r">
            Queen Mary University of London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#301188" title="Click to go to the Author Index">
             Versace, Elisabetta
            </a>
           </td>
           <td class="r">
            Queen Mary University of London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#108793" title="Click to go to the Author Index">
             Jamone, Lorenzo
            </a>
           </td>
           <td class="r">
            Queen Mary University London
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2343" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             While visual sensing is often the predominant modality for a robot to localize objects in the environment, tactile and force sensing become crucial when objects are occluded, poorly visible, or buried. However, existing works on locating buried objects rely solely on force measurements at a single contact point on the robot end-effector, making 3D localization very challenging. This paper presents an alternative approach using a tactile sensor that measures both normal and shear forces (i.e. 3-axis) on distributed points; three Long Short- Term Memory (LSTM) models are trained with real-world data to perform real-time 3D localization (i.e. distance, direction and depth) of an object buried within a granular material. Our experimental results suggest that measuring both normal and shear forces (instead of just normal) on distributed contact points (instead of only one point) is essential for the accurate 3D localization of buried objects.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t10_09">
             15:30-16:30, Paper WePI3T10.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2545'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Modular Meshed Ultra-Wideband Aided Inertial Navigation with Robust Anchor Calibration
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#237988" title="Click to go to the Author Index">
             Jung, Roland
            </a>
           </td>
           <td class="r">
            University of Klagenfurt
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#346407" title="Click to go to the Author Index">
             Santoro, Luca
            </a>
           </td>
           <td class="r">
            University of Trento
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#378589" title="Click to go to the Author Index">
             Brunelli, Davide
            </a>
           </td>
           <td class="r">
            University of Trento
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#112613" title="Click to go to the Author Index">
             Fontanelli, Daniele
            </a>
           </td>
           <td class="r">
            University of Trento
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#132320" title="Click to go to the Author Index">
             Weiss, Stephan
            </a>
           </td>
           <td class="r">
            Universität Klagenfurt
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2545" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#range_sensing" title="Click to go to the Keyword Index">
               Range Sensing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper introduces a generic filter-based state estimation framework that supports two state-decoupling strategies based on cross-covariance factorization. These strategies reduce the computational complexity and inherently support true modularity -- a perquisite for handling and processing meshed range measurements among a time-varying set of devices. In order to utilize these measurements in the estimation framework, positions of newly detected stationary devices (anchors) and the pairwise biases between the ranging devices are required. In this work an autonomous calibration procedure for new anchors is presented, that utilizes range measurements from multiple tags as well as already known anchors. To improve the robustness, an outlier rejection method is introduced. After the calibration is performed, the sensor fusion framework obtains initial beliefs of the anchor positions and dictionaries of pairwise biases, in order to fuse range measurements obtained from new anchors tightly-coupled. The effectiveness of the filter and calibration framework has been validated through evaluations on a recorded dataset and real-world experiments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t10_10">
             15:30-16:30, Paper WePI3T10.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2724'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Renderable Street View Map-Based Localization: Leveraging 3D Gaussian Splatting for Street-Level Positioning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#225162" title="Click to go to the Author Index">
             Jun, Howoong
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#209868" title="Click to go to the Author Index">
             Yu, Hyeonwoo
            </a>
           </td>
           <td class="r">
            SungKyunKwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#119971" title="Click to go to the Author Index">
             Oh, Songhwai
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2724" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we introduce a new method for street-level localization that first utilizes 3D Gaussian splatting in street-level localization problem. Robust localization with street-level real-world images such as street view is a major issue for autonomous vehicle, augmented reality (AR) naviga- tion, and outdoor mobile robots. The objective is to determine the position and orientation of a query image that matches a street view database composed of RGB images. However, given the limited information available in the street view images, accurately determining the location solely based on this data presents a significant challenge. To address this challenge, we propose a novel method called renderable street view map- based localization (RSM-Loc). This approach enhances the localization process by augmenting 2D street view images into a renderable map using 3D Gaussian splatting, to resolve street- level localization problems. Upon receiving a query RGB image without geometry information, the proposed method renders 2D images from a pre-made renderable map and compares image pose similarities between the rendered images and the query image. Through iterations of this process, the proposed method eventually estimates the pose of the given query image. The experimental results demonstrate that RSM-Loc outperforms the baselines with neural-field-based localization. Additionally, we conduct deep analysis on the proposed method to show that our method can serve as a new concept for the street-level localization problem.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t10_11">
             15:30-16:30, Paper WePI3T10.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2875'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              LiDAR-Visual-Inertial Tightly-Coupled Odometry with Adaptive Learnable Fusion Weights
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398680" title="Click to go to the Author Index">
             Hulchuk, Vsevolod
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#218032" title="Click to go to the Author Index">
             Bayer, Jan
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#130305" title="Click to go to the Author Index">
             Faigl, Jan
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2875" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#learning_from_experience" title="Click to go to the Keyword Index">
               Learning from Experience
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we address the sensitivity of the 3D LiDAR-based localization to environmental structural ambiguity. Although existing approaches employ additional sensors, such as cameras and inertial measurement units, to account for such ambiguities, multi-sensor localization is still an open problem. Limitations are from the need to tune fusion parameters to compensate for limited ambiguity detection manually. Therefore, we propose a feature-based localization method that learns the fusion parameters using ground truth and thus supports autonomous mobile robotic systems in new locations. The method combines planar surface LiDAR features with close and far camera features, and its further advantage is an online adjustment of the feature weights based on the measured environment ambiguity. The evaluation has been performed on the existing M2DGR dataset and custom dataset with geometrical ambiguities. The proposed method is competitive to or outperforms the existing LiDAR-based methods F-LOAM and LIO-SAM and the Visual-Inertial localization method VINS-Mono. Based on the reported results, the proposed method is a vital combination of LiDAR-based and visual features.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t10_12">
             15:30-16:30, Paper WePI3T10.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2902'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              LF2SLAM: Learning-Based Features for Visual SLAM
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#287126" title="Click to go to the Author Index">
             Legittimo, Marco
            </a>
           </td>
           <td class="r">
            University of Perugia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#172497" title="Click to go to the Author Index">
             Crocetti, Francesco
            </a>
           </td>
           <td class="r">
            University of Perugia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#160710" title="Click to go to the Author Index">
             Fravolini, Mario Luca
            </a>
           </td>
           <td class="r">
            University of Perugia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#295389" title="Click to go to the Author Index">
             Mollica, Giuseppe
            </a>
           </td>
           <td class="r">
            University of Perugia - Department of Engineering
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#150020" title="Click to go to the Author Index">
             Costante, Gabriele
            </a>
           </td>
           <td class="r">
            University of Perugia
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2902" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Autonomous robot navigation relies on the robot's ability to understand its environment for localization, typically using a Visual Simultaneous Localization And Mapping (SLAM) algorithm that processes image sequences. While state-of-the-art methods have shown remarkable performance, they still have limitations. Geometric VO algorithms that leverage hand-crafted feature extractors require careful hyper-parameter tuning. Conversely, end-to-end data-driven VO algorithms suffer from limited generalization capabilities and require large datasets for their proper optimizations. Recently, promising results have been shown by hybrid approaches that integrate robust data-driven feature extraction with the geometric estimation pipeline. In this work, we follow these intuitions and propose a hybrid VO method, namely Learned Features For SLAM (LF^2SLAM), that combines a deep neural network for feature extraction with a standard VO pipeline. The network is trained in a data-driven framework that includes a pose estimation component to learn feature extractors that are tailored for VO tasks. A novel loss function modification is introduced, using a binary mask that considers only the informative features. The experimental evaluation performed shows that our approach has remarkable generalization capabilities in scenarios that differ from those used for training. Furthermore, LF^2SLAM exhibits robust
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t10_13">
             15:30-16:30, Paper WePI3T10.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2995'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              BEVLoc: Cross-View Localization and Matching Via Birds-Eye-View Synthesis
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#382100" title="Click to go to the Author Index">
             Klammer, Christopher
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104298" title="Click to go to the Author Index">
             Kaess, Michael
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2995" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Ground to aerial matching is a crucial and challenging task in outdoor robotics, particularly when GPS is absent or unreliable. Structures like buildings or large dense forests create interference, requiring GNSS replacements for global positioning estimates. The true difficulty lies in reconciling the perspective difference between the ground and air images for acceptable localization.
             <p>
              Taking inspiration from the autonomous driving community, we propose a novel framework for synthesizing a birds-eye-view (BEV) scene representation to match and localize against an aerial map in off-road environments. We leverage contrastive learning with domain specific hard negative mining to train a network to learn similar representations between the synthesized BEV and the aerial map.
              <p>
               During inference, BEVLoc guides the identification of the most probable locations within the aerial map through a coarse-to-fine matching strategy. Our results demonstrate promising initial outcomes in extremely difficult forest environments with limited semantic diversity. We analyze our model's performance for coarse and fine matching, assessing both the raw matching capability of our model and its performance as a GNSS replacement.
               <p>
                Our work delves into off-road map localization while establishing a foundational baseline for future developments in localization. Our code is available at: https://github.com/rpl-cmu/bevloc
               </p>
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t10_14">
             15:30-16:30, Paper WePI3T10.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3126'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              GSLoc: Visual Localization with 3D Gaussian Splatting
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#354775" title="Click to go to the Author Index">
             Botashev, Kazii
            </a>
           </td>
           <td class="r">
            Skolkovo Institute of Science and Technology (Skoltech)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394995" title="Click to go to the Author Index">
             Pyatov, Vladislav
            </a>
           </td>
           <td class="r">
            Skolkovo Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#141803" title="Click to go to the Author Index">
             Ferrer, Gonzalo
            </a>
           </td>
           <td class="r">
            Skolkovo Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394996" title="Click to go to the Author Index">
             Lefkimmiatis, Stamatios
            </a>
           </td>
           <td class="r">
            MTS AI
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3126" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present GSLoc: a new visual localization method that performs dense camera alignment using 3D Gaussian Splatting as a map representation of the scene. GSLoc backpropagetes pose gradients over the rendering pipeline to align the rendered and target images and proposes a coarse-to-fine strategy by blurring kernels to mitigate the non-convexity of the problem and improve the convergence. The results show that our approach succeeds at visual localization in challenging conditions of relatively small overlap between initial and target frames inside textureless environments when state-of-the-art neural sparse methods provide inferior results. Using the byproduct of realistic rendering from the 3DGS map representation, we show how to enhance localization results by mixing a set of observed and virtual reference keyframes when solving the image retrieval problem. We evaluate our method both on synthetic and real-world data discussing its advantages and application potential.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t10_15">
             15:30-16:30, Paper WePI3T10.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3384'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Joint Pedestrian Trajectory Prediction through Posterior Sampling
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#399096" title="Click to go to the Author Index">
             Lin, Haotian
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#358483" title="Click to go to the Author Index">
             Wang, Yixiao
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395983" title="Click to go to the Author Index">
             Huo, Mingxiao
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#313654" title="Click to go to the Author Index">
             Peng, Chensheng
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397651" title="Click to go to the Author Index">
             Liu, Zhiyuan
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100071" title="Click to go to the Author Index">
             Tomizuka, Masayoshi
            </a>
           </td>
           <td class="r">
            University of California
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3384" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#modeling_and_simulating_humans" title="Click to go to the Keyword Index">
               Modeling and Simulating Humans
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Joint pedestrian trajectory prediction has long grappled with the inherent unpredictability of human behaviors. Recent works employing conditional diffusion models in trajectory prediction have exhibited notable success. Nevertheless, the heavy dependence on accurate historical data results in their vulnerability to noise disturbances and data incompleteness. To improve the robustness and reliability, we introduce the Guided Full Trajectory Diffuser (GFTD), a novel diffusion-based framework that translates prediction as the inverse problem of spatial-temporal inpainting and models the full joint trajectory distribution which includes both history and the future. By learning from the full trajectory and leveraging flexible posterior sampling methods, GFTD can produce accurate predictions while improving the robustness that can generalize to scenarios with noise perturbation or incomplete historical data. Moreover, the pre-trained model enables controllable generation without an additional training budget. Through rigorous experimental evaluation, GFTD exhibits superior performance in joint trajectory prediction with different data quality and in controllable generation tasks. See more results at https://sites.google.com/andrew.cmu.edu/posterior-sampling-prediction.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t10_16">
             15:30-16:30, Paper WePI3T10.16
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3226'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Optimizing Interaction Space: Enlarging the Capture Volume for Multiple Portable Motion Capture Devices
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396502" title="Click to go to the Author Index">
             Fatoni, Muhammad Hilman
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#319823" title="Click to go to the Author Index">
             Herneth, Christopher
            </a>
           </td>
           <td class="r">
            Technical University Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#338803" title="Click to go to the Author Index">
             Li, Junnan
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397580" title="Click to go to the Author Index">
             Budiman, Fajar
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#223070" title="Click to go to the Author Index">
             Ganguly, Amartya
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#108317" title="Click to go to the Author Index">
             Haddadin, Sami
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3226" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#datasets_for_human_motion" title="Click to go to the Keyword Index">
               Datasets for Human Motion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_detection_and_tracking" title="Click to go to the Keyword Index">
               Human Detection and Tracking
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#kinematics" title="Click to go to the Keyword Index">
               Kinematics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Markerless motion capture devices such as the Leap Motion Controller (LMC) have been extensively used for tracking hand, wrist, and forearm positions as an alternative to Marker-based Motion Capture (MMC). However, previous studies have highlighted the subpar performance of LMC in reliably recording hand kinematics. In this study, we employ four LMC devices to optimize their collective tracking volume, aiming to enhance the accuracy and precision of hand kinematics. Through Monte Carlo simulation, we determine an optimized layout for the four LMC devices and subsequently conduct reliability and validity experiments encompassing 1560 trials across ten subjects. The combined tracking volume is validated against an MMC system, particularly for kinematic movements involving wrist, index, and thumb flexion. Utilizing calculation resources in one computer, our result of the optimized configuration has a better visibility rate with a value of 0.05 ± 0.55 compared to the initial configuration with -0.07 ± 0.40. Multiple Leap Motion Controllers (LMCs) have proven to increase the interaction space of capture volume but are still unable to give agreeable measurements from dynamic movement.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wepi3t11">
             <b>
              WePI3T11
             </b>
            </a>
           </td>
           <td class="r">
            Room 11
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wepi3t11" title="Click to go to the Program at a Glance">
             <b>
              Multi-Robot Systems and Swarms II
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#113384" title="Click to go to the Author Index">
             Saska, Martin
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#185040" title="Click to go to the Author Index">
             Luo, Wenhao
            </a>
           </td>
           <td class="r">
            University of North Carolina at Charlotte
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t11_01">
             15:30-16:30, Paper WePI3T11.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('359'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              MERSYS: A Collaborative Estimation and Dense Mapping System for Multi-Agent Generic SLAM
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392147" title="Click to go to the Author Index">
             Lai, Qianhua
            </a>
           </td>
           <td class="r">
            University of Electronic Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#297938" title="Click to go to the Author Index">
             Zhao, Enhao
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#353607" title="Click to go to the Author Index">
             Fan, Shicai
            </a>
           </td>
           <td class="r">
            University of Electronic Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#198408" title="Click to go to the Author Index">
             Zou, Jianxiao
            </a>
           </td>
           <td class="r">
            UESTC
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab359" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_slam" title="Click to go to the Keyword Index">
               Multi-Robot SLAM
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Multi-agent collaborative Simultaneous Localization and Mapping (SLAM) is an effective way for large-scale mapping. However, this approach, which relies on Visual-Inertial Odometry(VIO) as input, suffers from limitations such as susceptibility to environmental influences and the difficulty in accurately constructing dense 3D maps. To address these challenges, this paper presents Multi-Estimation Robust SLAM System (MERSYS), a novel framework for three-dimensional dense mapping based on the fusion of Lidar-Inertial Odometry(LIO) and VIO. Benefiting from lower communication's costs and dense information acquisition capability, the proposed framework aims to achieve compatibility in processing both LIO and VIO inputs, establish joint loop closure detection to enable multi-map fusion, and then create a comprehensive global 3D dense point cloud map. Furthermore, an efficient communication strategy has been proposed to enable bidirectional transmission of dense and voluminous data.Experimental evaluations conducted on the publicly available HILTI SLAM 2021 dataset as well as a real world dataset. Experimental results show that MERSYS achieves better results than state-of-the-art methods. The source code is available on the GitHub.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t11_02">
             15:30-16:30, Paper WePI3T11.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1471'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Decentralized Collaborative Localization and Map Update with Buildings
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395703" title="Click to go to the Author Index">
             Escourrou, Maxime
            </a>
           </td>
           <td class="r">
            Université De Technologie De Compiègne
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#331294" title="Click to go to the Author Index">
             Al Hage, Joelle
            </a>
           </td>
           <td class="r">
            Univeristé De Technologie De Compiègne
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105182" title="Click to go to the Author Index">
             Bonnifait, Philippe
            </a>
           </td>
           <td class="r">
            Univ. of Technology of Compiegne
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1471" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_slam" title="Click to go to the Keyword Index">
               Multi-Robot SLAM
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#distributed_robot_systems" title="Click to go to the Keyword Index">
               Distributed Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In urban environments where GNSS performance is degraded, localization can be performed using stable and geo-referenced map features detected by on-board sensors. Prior maps are prone to errors which have a direct impact on localization accuracy. By exchanging observed features and sharing their maps, vehicles can simultaneously improve their localization and update the map. This paper deals with indirect collaboration, where vehicles do not observe each other directly. The features are obtained from building facades using 3D lidar sensors. The paper emphasizes real-time decentralized collaboration with direct communication between vehicles, without the need for a central server. The collaboration takes place when vehicles perceive the same geo-referenced facades. Vehicle poses and maps are collaboratively updated using a Schmidt Kalman filter that carefully manages the cross-covariance terms. To maintain consistent estimates, the Kullback-Leibler Average is used. We also present a lidar data processing pipeline to obtain reliable observations from building facades. Real tests carried out with experimental vehicles on the university campus are reported. The results show that indirect collaboration makes a significant contribution to localization and map update when compared to a standalone method.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t11_03">
             15:30-16:30, Paper WePI3T11.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2978'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Scalable Networked Feature Selection with Randomized Algorithm for Robot Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393540" title="Click to go to the Author Index">
             Pandey, Vivek
            </a>
           </td>
           <td class="r">
            Lehigh University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#239486" title="Click to go to the Author Index">
             Amini, Arash
            </a>
           </td>
           <td class="r">
            Lehigh UNiversity
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#256302" title="Click to go to the Author Index">
             Liu, Guangyi
            </a>
           </td>
           <td class="r">
            Lehigh University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#131686" title="Click to go to the Author Index">
             Topcu, Ufuk
            </a>
           </td>
           <td class="r">
            The University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398765" title="Click to go to the Author Index">
             Sun, Qiyu
            </a>
           </td>
           <td class="r">
            University of Central Florida
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101818" title="Click to go to the Author Index">
             Daniilidis, Kostas
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#123133" title="Click to go to the Author Index">
             Motee, Nader
            </a>
           </td>
           <td class="r">
            Lehigh Universitty
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2978" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_slam" title="Click to go to the Keyword Index">
               Multi-Robot SLAM
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#networked_robots" title="Click to go to the Keyword Index">
               Networked Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We address the problem of sparse selection of visual features for localizing a team of robots navigating in an unknown environment, where robots can exchange relative position measurements with neighbors. We select a set of the most informative features by anticipating their importance in robots localization by simulating trajectories of robots over a prediction horizon. Through theoretical proofs, we establish a crucial connection between graph Laplacian and the importance of features. We leverage a scalable randomized algorithm for sparse sums of positive semidefinite matrices to efficiently select a set of the most informative features.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t11_04">
             15:30-16:30, Paper WePI3T11.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2604'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Autonomous Localization of Multiple Ionizing Radiation Sources Using Miniature Single-Layer Compton Cameras Onboard a Group of Micro Aerial Vehicles
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396644" title="Click to go to the Author Index">
             Werner, Michal
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#192414" title="Click to go to the Author Index">
             Baca, Tomas
            </a>
           </td>
           <td class="r">
            Ceske Vysoke Uceni Technicke V Praze, FEL
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#243329" title="Click to go to the Author Index">
             Stibinger, Petr
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#290974" title="Click to go to the Author Index">
             Doubravova, Daniela
            </a>
           </td>
           <td class="r">
            Advacam, S.r.o
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#290980" title="Click to go to the Author Index">
             Solc, Jaroslav
            </a>
           </td>
           <td class="r">
            Czech Metrology Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#290982" title="Click to go to the Author Index">
             Rusnak, Jan
            </a>
           </td>
           <td class="r">
            Czech Metrology Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#113384" title="Click to go to the Author Index">
             Saska, Martin
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2604" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#robotics_in_hazardous_fields" title="Click to go to the Keyword Index">
               Robotics in Hazardous Fields
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#environment_monitoring_and_management" title="Click to go to the Keyword Index">
               Environment Monitoring and Management
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             A novel method for autonomous localization of multiple sources of gamma radiation using a group of Micro Aerial Vehicles (MAVs) is presented in this paper. The method utilizes an extremely lightweight (44 g) Compton camera Minipix Timepix3. The compact size of the detector allows for deployment onboard safe and agile small-scale UAVs. The proposed radiation mapping approach fuses measurements from multiple distributed Compton camera sensors to accurately estimate the positions of multiple radioactive sources in real time. Unlike commonly used intensity-based detectors, the Compton camera reconstructs the set of possible directions towards a radiation source from just a single ionizing particle. Therefore, the proposed approach can localize radiation sources without having to estimate the gradient of a radiation field or contour lines, which require longer measurements. The instant estimation is able to fully exploit the potential of highly mobile MAVs. The radiation mapping method is combined with an active search strategy, which coordinates the future actions of the MAVs in order to improve the quality of the estimate of the sources' positions, as well as to explore the area of interest faster. The proposed solution is evaluated in simulation and real-world experiments with multiple Cesium-137 radiation sources.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t11_05">
             15:30-16:30, Paper WePI3T11.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1067'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Behavior Tree Based Decentralized Multi-Agent Coordination for Balanced Servicing of Time Varying Task Queues
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#325318" title="Click to go to the Author Index">
             Dahlquist, Niklas
            </a>
           </td>
           <td class="r">
            Luleå University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#341005" title="Click to go to the Author Index">
             Saradagi, Akshit
            </a>
           </td>
           <td class="r">
            Luleå University of Technology, Luleå, Sweden
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105882" title="Click to go to the Author Index">
             Nikolakopoulos, George
            </a>
           </td>
           <td class="r">
            Luleå University of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1067" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#agent_based_systems" title="Click to go to the Keyword Index">
               Agent-Based Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#task_planning" title="Click to go to the Keyword Index">
               Task Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this article, we present a reactive multi-agent coordination architecture for the management of material flows between production/pickup stages and delivery/drop-off stages, in scenarios such as underground mines and automated factory floors. The pickup and delivery stages are modelled as variable task queues, with no a priori information about the inflow into the production queues. The proposed solution coordinates the movement of a group of mobile agents operating between the two stages in a reactive and scalable manner, so that the material is transported from multiple production queues to multiple delivery queues in a balanced/equalized manner. In such a scenario, centralized planners suffer from low reactivity and poor scaling, as the number of agents and number of queues increases. To overcome this problem, we propose a decentralized approach comprising of two separate auction-based task distribution systems for the production and delivery stages, along with behavior-tree based management of agent autonomy and task bidding. Each auction system tracks the length of production/delivery queues and solves the optimal task assignment, based on the bids submitted by the agents. The agents participate in one of the two auction systems at any given time, based on the status of the behavior tree executing the two-stage tasks. We analytically show that the proposed decentralized auctioning approach along with agent autonomy and bidding managed by behavior trees, offers better scalability and reactiveness compared to the centralized approach. The proposed methodology is experimentally validated in a lab environment, in three illustrative material flow management scenarios, using TurtleBot3 robots as agents.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t11_06">
             15:30-16:30, Paper WePI3T11.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2984'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              MAP-NBV: Multi-Agent Prediction-Guided Next-Best-View Planning for Active 3D Object Reconstruction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#256871" title="Click to go to the Author Index">
             Dhami, Harnaik
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#192654" title="Click to go to the Author Index">
             Sharma, Vishnu D.
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#128263" title="Click to go to the Author Index">
             Tokekar, Pratap
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2984" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#planning__scheduling_and_coordination" title="Click to go to the Keyword Index">
               Planning, Scheduling and Coordination
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Next-Best View (NBV) planning is a long-standing problem of determining where to obtain the next best view of an object from, by a robot that is viewing the object. There are a number of methods for choosing NBV based on the observed part of the object. In this paper, we investigate how predicting the unobserved part helps with the efficiency of reconstructing the object. We present, Multi-Agent Prediction-Guided NBV (MAP-NBV), a decentralized coordination algorithm for active 3D reconstruction with multi-agent systems. Prediction-based approaches have shown great improvement in active perception tasks by learning the cues about structures in the environment from data. However, these methods primarily focus on single-agent systems. We design a decentralized next-best-view approach that utilizes geometric measures over the predictions and jointly optimizes the information gain and control effort for efficient collaborative 3D reconstruction of the object. Our method achieves 19% improvement over the non-predictive multi-agent approach in simulations using AirSim and ShapeNet. We make our code publicly available through our project website: http://raaslab.org/projects/MAPNBV/.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t11_07">
             15:30-16:30, Paper WePI3T11.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3056'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Graph Neural Network-Based Multi-Agent Reinforcement Learning for Resilient Distributed Coordination of Multi-Robot Systems
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#386233" title="Click to go to the Author Index">
             Goeckner, Anthony
            </a>
           </td>
           <td class="r">
            Northwestern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398858" title="Click to go to the Author Index">
             Sui, Yueyuan
            </a>
           </td>
           <td class="r">
            Northwestern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398861" title="Click to go to the Author Index">
             Martinet, Nicolas
            </a>
           </td>
           <td class="r">
            Northwestern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#386234" title="Click to go to the Author Index">
             Li, Xinliang
            </a>
           </td>
           <td class="r">
            Northwestern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#238604" title="Click to go to the Author Index">
             Zhu, Qi
            </a>
           </td>
           <td class="r">
            Northwestern University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3056" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#robotics_in_hazardous_fields" title="Click to go to the Keyword Index">
               Robotics in Hazardous Fields
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#planning__scheduling_and_coordination" title="Click to go to the Keyword Index">
               Planning, Scheduling and Coordination
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Existing multi-agent coordination techniques are often fragile and vulnerable to anomalies such as agent attrition and communication disturbances, which are quite common in the real-world deployment of systems like field robotics. To better prepare these systems for the real world, we present a graph neural network (GNN)-based multi-agent reinforcement learning (MARL) method for resilient distributed coordination of a multi-robot system. Our method, Multi-Agent Graph Embedding-based Coordination (MAGEC), is trained using multi-agent proximal policy optimization (PPO) and enables distributed coordination around global objectives under agent attrition, partial observability, and limited or disturbed communications. We use a multi-robot patrolling scenario to demonstrate our MAGEC method in a ROS~2-based simulator and then compare its performance with prior coordination approaches. Results demonstrate that MAGEC outperforms existing methods in several experiments involving agent attrition and communication disturbance, and provides competitive results in scenarios without such anomalies.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t11_08">
             15:30-16:30, Paper WePI3T11.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3272'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Distributed Model Predictive Covariance Steering
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#334252" title="Click to go to the Author Index">
             Saravanos, Augustinos
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#339419" title="Click to go to the Author Index">
             Balci, Isin
            </a>
           </td>
           <td class="r">
            University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#162425" title="Click to go to the Author Index">
             Bakolas, Efstathios
            </a>
           </td>
           <td class="r">
            The University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#110087" title="Click to go to the Author Index">
             Theodorou, Evangelos
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3272" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper proposes Distributed Model Predictive Covariance Steering (DiMPCS) for multi-agent control under stochastic uncertainty. The scope of our approach is to blend covariance steering theory, distributed optimization and model predictive control (MPC) into a single framework that is safe, scalable and decentralized. Initially, we pose a problem formulation that uses the Wasserstein distance to steer the state distributions of a multi-agent system to desired targets, and probabilistic constraints to ensure safety. We then transform this problem into a finite-dimensional optimization one by utilizing a disturbance feedback policy parametrization for covariance steering and a tractable approximation of the safety constraints. To solve the latter problem, we derive a decentralized consensus-based algorithm using the Alternating Direction Method of Multipliers. This method is then extended to a receding horizon form, which yields the proposed DiMPCS algorithm. Simulation experiments on a variety of multi-robot tasks with up to hundreds of robots demonstrate the effectiveness of DiMPCS. The superior scalability and performance of the proposed method is also highlighted through a comparison against related stochastic MPC approaches. Finally, hardware results on a multi-robot platform also verify the applicability of DiMPCS on real systems.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t11_09">
             15:30-16:30, Paper WePI3T11.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3368'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Team Coordination on Graphs: Problem, Analysis, and Algorithms
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398225" title="Click to go to the Author Index">
             Zhou, Yanlin
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#354437" title="Click to go to the Author Index">
             Limbu, Manshi
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#205862" title="Click to go to the Author Index">
             Stein, Gregory
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#280358" title="Click to go to the Author Index">
             Wang, Xuan
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#235890" title="Click to go to the Author Index">
             Shishika, Daigo
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#177144" title="Click to go to the Author Index">
             Xiao, Xuesu
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3368" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#planning__scheduling_and_coordination" title="Click to go to the Keyword Index">
               Planning, Scheduling and Coordination
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Team Coordination on Graphs with Risky Edges(TCGRE) is a recently emerged problem, in which a robot team collectively reduces graph traversal cost through support from one robot to another when the latter traverses a risky edge. Resembling the traditional Multi-Agent Path Finding (MAPF) problem, both classical and learning-based methods have been proposed to solve TCGRE either with low computation efficiency or lacking optimality assurance. In this paper, we reformulate TCGRE in a constrained optimization framework, present an rigorous mathematical analysis, design three classes of algo-rithms to solve TCGRE, and conduct extensive experiments to benchmark each method. Our theoretical analysis shows the NP-hardness of TCGRE by reduction from the Maximum 3D Matching problem and that efficient decomposition is a key to tackle this combinatorial optimization problem. The three classes of algorithms to solve TCGRE, i.e., Joint State Graph (JSG) based, coordination based, and receding-horizon sub-team based solutions show different provable optimality and efficiency characteristics in our experiments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t11_10">
             15:30-16:30, Paper WePI3T11.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3448'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              MULAN-WC: Multi-Robot Localization Uncertainty-Aware Active NeRF with Wireless Coordination
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#251780" title="Click to go to the Author Index">
             Wang, Weiying
            </a>
           </td>
           <td class="r">
            Harvard University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396964" title="Click to go to the Author Index">
             Cai, Victor
            </a>
           </td>
           <td class="r">
            Harvard University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#129572" title="Click to go to the Author Index">
             Gil, Stephanie
            </a>
           </td>
           <td class="r">
            Harvard University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3448" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#perception_action_coupling" title="Click to go to the Keyword Index">
               Perception-Action Coupling
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents MULAN-WC, a novel multi-robot 3D reconstruction framework that leverages wireless signal-based coordination between robots and Neural Radiance Fields(NeRF). Our approach addresses key challenges in multi-robot 3D reconstruction, including inter-robot pose estimation, localization uncertainty quantification, and active best-next-view selection. We introduce a method for using wireless Angle-of-Arrival (AoA) and ranging measurements to estimate relative poses between robots, as well as quantifying and incorporating the uncertainty embedded in the wireless localization of these pose estimates into the NeRF training loss to mitigate the impact of inaccurate camera poses. Furthermore, we propose an active view selection approach that accounts for robot pose uncertainty when determining the next-best views to improve the 3D reconstruction, enabling faster convergence through intelligent view selection. Extensive experiments on both synthetic and real-world datasets demonstrate the effectiveness of our framework in theory and in practice. Leveraging wireless coordination and localization uncertainty-aware training, MULAN-WC can achieve high-quality 3d reconstruction which is close to applying the ground truth camera poses. Furthermore, the quantification of the information gain from a novel view enables consistent rendering quality improvement with incrementally captured images by commending the robot the novel view position. Our hardware experiments showcase the practicality of deploying MULAN-WC to real robotic systems.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t11_11">
             15:30-16:30, Paper WePI3T11.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1002'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Solving Multi-Robot Task Allocation and Planning in Trans-Media Scenarios
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372397" title="Click to go to the Author Index">
             de La Rochefoucauld, Virgile
            </a>
           </td>
           <td class="r">
            Osaka University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101697" title="Click to go to the Author Index">
             Lacroix, Simon
            </a>
           </td>
           <td class="r">
            LAAS/CNRS
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#137805" title="Click to go to the Author Index">
             Ratsamee, Photchara
            </a>
           </td>
           <td class="r">
            Department of Robotic and Design, Osaka Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#123179" title="Click to go to the Author Index">
             Takemura, Haruo
            </a>
           </td>
           <td class="r">
            Osaka University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1002" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#planning__scheduling_and_coordination" title="Click to go to the Keyword Index">
               Planning, Scheduling and Coordination
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Trans-media robots, capable of operating across diverse environments, add significant complexity for multi-robot task allocation and planning problems. This paper introduces a novel approach to plan missions for such multi-robot systems, that addresses the associated specific complexities and constraints. It streamlines the overall mission planning process by decomposing it into tractable sub-problems, and addresses the issues of coalition formation, path planning, and task scheduling. It provides mission plans in very little computation time and allows to tackle large missions intractable by global planners, with negligible loss in plan optimality.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t11_12">
             15:30-16:30, Paper WePI3T11.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3052'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Integrating Online Learning and Connectivity Maintenance for Communication-Aware Multi-Robot Coordination
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#326194" title="Click to go to the Author Index">
             Yang, Yupeng
            </a>
           </td>
           <td class="r">
            University of North Carolina at Charlotte
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#244910" title="Click to go to the Author Index">
             Lyu, Yiwei
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376188" title="Click to go to the Author Index">
             Zhang, Yanze
            </a>
           </td>
           <td class="r">
            University of North Carolina at Charlotte
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#399419" title="Click to go to the Author Index">
             Gao, Ian
            </a>
           </td>
           <td class="r">
            University of North Carolina at Charlotte
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#185040" title="Click to go to the Author Index">
             Luo, Wenhao
            </a>
           </td>
           <td class="r">
            University of North Carolina at Charlotte
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3052" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#networked_robots" title="Click to go to the Keyword Index">
               Networked Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#cooperating_robots" title="Click to go to the Keyword Index">
               Cooperating Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper proposes a novel data-driven control strategy for maintaining connectivity in networked multi-robot systems. Existing approaches often rely on a pre-determined communication model specifying whether pairwise robots can communicate given their relative distance to guide the connectivity-aware control design, which may not capture real-world communication conditions. To relax that assumption, we present the concept of Data-driven Connectivity Barrier Certificates, which utilize Control Barrier Functions (CBF) and Gaussian Processes (GP) to characterize the admissible control space for pairwise robots based on communication performance observed online. This allows robots to maintain a satisfying level of pairwise communication quality (measured by the received signal strength) while in motion. Then we propose a Data-driven Connectivity Maintenance (DCM) algorithm that combines (1) online learning of the communication signal strength and (2) a bi-level optimization-based control framework for the robot team to enforce global connectivity of the realistic multi-robot communication graph and minimally deviate from their task-related motions. We provide theoretical proofs to justify the properties of our algorithm and demonstrate its effectiveness through simulations with up to 20 robots.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t11_13">
             15:30-16:30, Paper WePI3T11.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('655'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Decentralized Acceleration-Based Bird-Inspired Flocking
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#356635" title="Click to go to the Author Index">
             Iacone, Luca
            </a>
           </td>
           <td class="r">
            Università Degli Studi Di Napoli Federico II
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393405" title="Click to go to the Author Index">
             Lejeune, Erwin Edouard Kossi
            </a>
           </td>
           <td class="r">
            Technology Innovation Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#215263" title="Click to go to the Author Index">
             Manoni, Tiziano
            </a>
           </td>
           <td class="r">
            Technology Innovation Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#220650" title="Click to go to the Author Index">
             Manfredi, Sabato
            </a>
           </td>
           <td class="r">
            Università Degli Studi Di Napoli - Federico II
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#210977" title="Click to go to the Author Index">
             Albani, Dario
            </a>
           </td>
           <td class="r">
            Technology Innovation Institure
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab655" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#swarm_robotics" title="Click to go to the Keyword Index">
               Swarm Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In the following, we analyze and discuss the implementation of a novel approach for distributed flocking behavior applied to a group of uavs, also referred to as drones. Inspired by natural flocking phenomena observed in birds, which demonstrate coordinated movement in response to internal and external stimuli, we tackle the problem of robust and dynamic aerial motion for robots and design a control law based on a novel physical model. In contrast to previous works that rely on velocity or position-based references, this approach leverages an acceleration-based law to describe the collective dynamics of many interacting particles. As observed in the following, a third-order control possesses several advantages compared to first or second-order control, such as smoother transitions, better force balancing, and more responsive and dynamic behaviors. These advantages are thoroughly analyzed in the following, thanks to physics-based realistic simulations and field experiments with medium-sized uavs in an unstructured outdoor environment.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t11_14">
             15:30-16:30, Paper WePI3T11.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2323'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Risk-Aware Non-Myopic Motion Planner for Large-Scale Robotic Swarm Using CVaR Constraints
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#384425" title="Click to go to the Author Index">
             Yang, Xuru
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397152" title="Click to go to the Author Index">
             Hu, Yunze
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#362706" title="Click to go to the Author Index">
             Gao, Han
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397142" title="Click to go to the Author Index">
             Ding, Kang
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397143" title="Click to go to the Author Index">
             Li, Zhaoyang
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#299303" title="Click to go to the Author Index">
             Zhu, Pingping
            </a>
           </td>
           <td class="r">
            Marshall University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397709" title="Click to go to the Author Index">
             Sun, Ying
            </a>
           </td>
           <td class="r">
            The Pennsylvania State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#191913" title="Click to go to the Author Index">
             Liu, Chang
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2323" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#swarm_robotics" title="Click to go to the Keyword Index">
               Swarm Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Swarm robotics has garnered significant attention due to its ability to accomplish elaborate and synchronized tasks. Existing methodologies for motion planning of swarm robotic systems mainly encounter difficulties in scalability and safety guarantee. To address these limitations, we propose a Risk-aware swarm mOtion planner using conditional ValuE-at-Risk (ROVER) that systematically navigates large-scale swarms through cluttered environments while ensuring safety. ROVER formulates a finite-time model predictive control (FTMPC) problem predicated upon the macroscopic state of the robot swarm represented by a Gaussian Mixture Model (GMM) and integrates conditional value-at-risk (CVaR) to ensure collision avoidance. The key component of ROVER is imposing a CVaR constraint on the distribution of the Signed Distance Function between the swarm GMM and obstacles in the FTMPC to enforce collision avoidance. Utilizing the analytical expression of CVaR of a GMM derived in this work, we develop a Computationally efficient solution to solve the non-linear constrained FTMPC through sequential linear programming. Simulations and comparisons with representative benchmark approaches demonstrate the effectiveness of ROVER in flexibility, scalability, and safety guarantee.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t11_15">
             15:30-16:30, Paper WePI3T11.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2467'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Automatic Design of Robot Swarms That Perform Composite Missions: An Approach Based on Inverse Reinforcement Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376603" title="Click to go to the Author Index">
             Szpirer, Jeanne
            </a>
           </td>
           <td class="r">
            IRIDIA, Université Libre De Bruxelles, Brussels, Belgium
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#303018" title="Click to go to the Author Index">
             Garzón Ramos, David
            </a>
           </td>
           <td class="r">
            University of Bristol
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#138052" title="Click to go to the Author Index">
             Birattari, Mauro
            </a>
           </td>
           <td class="r">
            Université Libre De Bruxelles
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2467" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#swarm_robotics" title="Click to go to the Keyword Index">
               Swarm Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We investigate the automatic design of robot swarms that perform composite missions—that is, missions specified as the composition of consecutive sub-missions. Automatic design through performance optimization has become a viable and appealing approach to designing robot swarms. First, a user defines a mission by specifying a performance measure: a function indicating to what extent the swarm has attained its goal. An optimization process then generates suitable control software for the robots by maximizing the performance measure. The definition of a performance measure is a challenging task that requires expert input, which hinders the automatic nature of the approach. Recently, inverse reinforcement learning was introduced to minimize the need for human intervention in the automatic design of robot swarms. However, this method was only applied to single-objective missions. In this paper, we extend the method to address composite missions, by formulating and solving the design problem as a multi-objective optimization problem. We conduct simulations with a swarm of twenty e-puck robots that perform twelve composite missions. We compare the performance of the swarm when the robots operate with control software produced manually or using inverse reinforcement learning.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t11_16">
             15:30-16:30, Paper WePI3T11.16
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1569'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Comprehensive Modeling and Scheduling Approach for Allocating Distributed Multi-Robot Software to the Edge/Cloud
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#278086" title="Click to go to the Author Index">
             Zhang, Yongzhou
            </a>
           </td>
           <td class="r">
            Karlsruhe University of Applied Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#156257" title="Click to go to the Author Index">
             Mirus, Florian
            </a>
           </td>
           <td class="r">
            Intel Labs
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375581" title="Click to go to the Author Index">
             Pasch, Frederik
            </a>
           </td>
           <td class="r">
            Intel
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#348937" title="Click to go to the Author Index">
             Scholl, Kay-Ulrich
            </a>
           </td>
           <td class="r">
            Intel
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#310335" title="Click to go to the Author Index">
             Wurll, Christian
            </a>
           </td>
           <td class="r">
            Karlsruhe University of Applied Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103218" title="Click to go to the Author Index">
             Hein, Björn
            </a>
           </td>
           <td class="r">
            Karlsruhe University of Applied Sciences
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1569" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#networked_robots" title="Click to go to the Keyword Index">
               Networked Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#distributed_robot_systems" title="Click to go to the Keyword Index">
               Distributed Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Offloading software modules to the edge/cloud can enhance a robot’s capabilities by leveraging massive computing power. However, determining which software module should be offloaded and scheduled to which robot/edge/cloud node is a challenging task, particularly for robot fleets with diverse tasks. In this paper, we tackle the software scheduling problem and introduce a taxonomy to categorize software modules and classify their applicability and requirements for offloading. Additionally, by using prior measurements, we model the compute cluster and formalize software scheduling as a multi-objective optimization problem which we tackle with a genetic algorithm. To evaluate our approach with a challenging setup, we build a mobile manipulation task using open-source frameworks and libraries in the Robot Operating System (ROS2) community in simulation as well as a mildly simplified real-world variant. Our evaluation shows significant improvements compared to the built-in scheduler of Kubernetes (K8s) regarding robotic specific metrics such as the rate of missed cycle time in both simulated and real-world experiments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t11_17">
             15:30-16:30, Paper WePI3T11.17
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2208'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Frontier-Based Exploration for Multi-Robot Rendezvous in Communication-Restricted Unknown Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397767" title="Click to go to the Author Index">
             Tellaroli, Mauro
            </a>
           </td>
           <td class="r">
            Università Degli Studi Di Milano
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#180015" title="Click to go to the Author Index">
             Luperto, Matteo
            </a>
           </td>
           <td class="r">
            Università Degli Studi Di Milano
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#325292" title="Click to go to the Author Index">
             Antonazzi, Michele
            </a>
           </td>
           <td class="r">
            University of Milan
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#120727" title="Click to go to the Author Index">
             Basilico, Nicola
            </a>
           </td>
           <td class="r">
            University of Milan
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2208" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#planning__scheduling_and_coordination" title="Click to go to the Keyword Index">
               Planning, Scheduling and Coordination
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#cooperating_robots" title="Click to go to the Keyword Index">
               Cooperating Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Multi-robot rendezvous and exploration are fundamental challenges in the domain of mobile robotic systems. This paper addresses multi-robot rendezvous within an initially unknown environment where communication is only possible after the rendezvous. Traditionally, exploration has been focused on rapidly mapping the environment, often leading to suboptimal rendezvous performance in later stages. We adapt a standard frontier-based exploration technique to integrate exploration and rendezvous into a unified strategy, with a mechanism that allows robots to re-visit previously explored regions thus enhancing rendezvous opportunities. We validate our approach in 3D realistic simulations using ROS, showcasing its effectiveness in achieving faster rendezvous times compared to exploration strategies.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wepi3t12">
             <b>
              WePI3T12
             </b>
            </a>
           </td>
           <td class="r">
            Room 12
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wepi3t12" title="Click to go to the Program at a Glance">
             <b>
              Simulators, Datasets and Benchmarks
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#171078" title="Click to go to the Author Index">
             Nguyen, Anh
            </a>
           </td>
           <td class="r">
            University of Liverpool
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#199076" title="Click to go to the Author Index">
             Vinciarelli, Alessandro
            </a>
           </td>
           <td class="r">
            University of Glasgow
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t12_01">
             15:30-16:30, Paper WePI3T12.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1128'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robot Generating Data for Learning Generalizable Visual Robotic Manipulation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#299378" title="Click to go to the Author Index">
             Li, Yunfei
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372338" title="Click to go to the Author Index">
             Yuan, Ying
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395525" title="Click to go to the Author Index">
             Cui, Jingzhi
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395587" title="Click to go to the Author Index">
             Huan, Haoran
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#374301" title="Click to go to the Author Index">
             Fu, Wei
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#312472" title="Click to go to the Author Index">
             Gao, Jiaxuan
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395508" title="Click to go to the Author Index">
             Xu, Zekai
            </a>
           </td>
           <td class="r">
            Shanghai JiaoTong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#239398" title="Click to go to the Author Index">
             Wu, Yi
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1128" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#continual_learning" title="Click to go to the Keyword Index">
               Continual Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robot_learning" title="Click to go to the Keyword Index">
               Data Sets for Robot Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             It has been a popular trend in AI to pretrain foundation models on massive data. However, collecting sufficient offline training trajectories for robot learning is particularly expensive since valid control actions are required. Therefore, most existing robotic datasets are collected from human experts. We tackle such a data collection issue with a new framework called “robot self-teaching”, which asks the robot to self-generate effective training data instead of relying on human demonstrators. Our key idea is to train a separate data-generation policy operating on the state space to automatically generate meaningful actions and trajectories with ever-growing complexities. Then, these generated data can be further used to train a visual policy with strong compositional generalization capabilities. We validate our framework in two visual manipulation testbeds, including a multi-object stacking domain and a popular RL benchmark “Franka kitchen”. Experiments show that the final visual policy trained on self-generated data can accomplish novel testing goals that require long-horizon robot executions. Project website https://sites.google.com/view/robot-self-teaching.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t12_02">
             15:30-16:30, Paper WePI3T12.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('735'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              HabiCrowd: A High Performance Simulator for Crowd-Aware Visual Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#350994" title="Click to go to the Author Index">
             Vuong, An Dinh
            </a>
           </td>
           <td class="r">
            MBZUAI
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#350822" title="Click to go to the Author Index">
             Nguyen, Tien Toan
            </a>
           </td>
           <td class="r">
            FPT Software
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#196876" title="Click to go to the Author Index">
             Vu, Minh Nhat
            </a>
           </td>
           <td class="r">
            TU Wien, Austria
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#234039" title="Click to go to the Author Index">
             Huang, Baoru
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#309220" title="Click to go to the Author Index">
             Binh, Huynh Thi Thanh
            </a>
           </td>
           <td class="r">
            School of Information and Communication Technology (Hanoi Univer
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#351899" title="Click to go to the Author Index">
             Vo, Thieu
            </a>
           </td>
           <td class="r">
            Ton Duc Thang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#171078" title="Click to go to the Author Index">
             Nguyen, Anh
            </a>
           </td>
           <td class="r">
            University of Liverpool
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab735" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Visual navigation, a foundational aspect of Embodied AI (E-AI) and robotics has been extensively studied in the past few years. While many 3D simulators have been introduced for visual navigation tasks, scarcely any works have combined human dynamics, creating the gap between simulation and real-world applications. Furthermore, current 3D simulators incorporating human dynamics have several limitations, particularly in terms of computational efficiency, which is a promise of modern simulators. To overcome these issues, we introduce HabiCrowd, the new standard benchmark for crowd-aware visual navigation that includes a crowd dynamics model with diverse human settings in photorealistic environments. Empirical evaluations demonstrate that our proposed human dynamics model achieves state-of-the-art performance in collision avoidance while exhibiting superior computational efficiency compared to its counterparts. We leverage HabiCrowd to conduct several comprehensive studies on crowd-aware visual navigation tasks and human-robot interactions. The source code and data can be found at https://habicrowd.github.io/.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t12_03">
             15:30-16:30, Paper WePI3T12.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1390'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Exploring 3D Human Pose Estimation and Forecasting from the Robot’s Perspective: The HARPER Dataset
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393171" title="Click to go to the Author Index">
             Avogaro, Andrea
            </a>
           </td>
           <td class="r">
            University of Verona
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393174" title="Click to go to the Author Index">
             Toaiari, Andrea
            </a>
           </td>
           <td class="r">
            University of Verona
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393175" title="Click to go to the Author Index">
             Cunico, Federico
            </a>
           </td>
           <td class="r">
            University of Verona
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393181" title="Click to go to the Author Index">
             Xu, Xiangmin
            </a>
           </td>
           <td class="r">
            University of Glasgow
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393199" title="Click to go to the Author Index">
             Dafas, Haralambos
            </a>
           </td>
           <td class="r">
            University of Glasgow
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#199076" title="Click to go to the Author Index">
             Vinciarelli, Alessandro
            </a>
           </td>
           <td class="r">
            University of Glasgow
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#324367" title="Click to go to the Author Index">
             Li, Liying Emma
            </a>
           </td>
           <td class="r">
            University of Glasgow
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#166506" title="Click to go to the Author Index">
             Cristani, Marco
            </a>
           </td>
           <td class="r">
            University of Verona
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1390" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#datasets_for_human_motion" title="Click to go to the Keyword Index">
               Datasets for Human Motion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We introduce HARPER, a novel dataset for 3D body pose estimation and forecasting in dyadic interactions between users and Spot, the quadruped robot manufactured by Boston Dynamics. The key-novelty of HARPER is its focus on the robot's perspective, i.e., on the data captured by the robot's sensors. This makes 3D body pose analysis challenging, as being close to the ground results in only partial captures of humans. The scenario underlying HARPER includes 15 actions, of which 10 involve physical contact between the robot and users. The corpus contains recordings not only from Spot's built-in stereo cameras but also from a 6-camera OptiTrack system, with all recordings synchronized. This setup leads to ground-truth skeletal representations with a precision of less than a millimeter. Additionally, the corpus includes reproducible benchmarks for 3D Human Pose Estimation, Human Pose Forecasting, and Collision Prediction, all based on publicly available baseline approaches. This enables future HARPER users to rigorously compare their results with those provided in this work.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t12_04">
             15:30-16:30, Paper WePI3T12.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1446'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              UMAD: University of Macau Anomaly Detection Benchmark Dataset
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395306" title="Click to go to the Author Index">
             Li, Dong
            </a>
           </td>
           <td class="r">
            University of Macau
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#336441" title="Click to go to the Author Index">
             Chen, Lineng
            </a>
           </td>
           <td class="r">
            Nanjing University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#259738" title="Click to go to the Author Index">
             Xu, Chengzhong
            </a>
           </td>
           <td class="r">
            University of Macau
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#204275" title="Click to go to the Author Index">
             Kong, Hui
            </a>
           </td>
           <td class="r">
            University of Macau
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1446" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#surveillance_robotic_systems" title="Click to go to the Keyword Index">
               Surveillance Robotic Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Anomaly detection (AD) is critical in surveillance systems and patrol robots by identifying anomalous regions in images for early warning. Depending on whether reference data are utilized, anomaly detection can be categorized into anomaly detection with reference (ADr) and anomaly detection without reference (ADwr). Currently, anomaly detection without reference, which is closely related to out-of-distribution (OoD) object detection, struggles with learning anomalous patterns due to the difficulty of collecting sufficiently large and diverse anomaly datasets with the inherent rarity and novelty of anomalies. Alternatively, anomaly detection with reference employs the scheme of change detection (CD) to identify anomalies by comparing semantic changes between a reference image and a query one. However, there are very few ADr works due to the scarcity of public datasets in this domain. In this paper, we aim to address this gap by introducing the University of Macau Anomaly Detection (UMAD) Benchmark Dataset. To our best knowledge, this is the first benchmark dataset designed specifically for anomaly detection with reference in robotic patrolling scenarios, e.g., where an autonomous robot is employed to detect anomalous objects by comparing a reference and a query video sequences. The reference sequences can be taken by the robot along a specified route when there are no anomalous objects in the scene. The query sequences are captured online by the robot when it is patrolling in the same scene following the same route. Our benchmark dataset is elaborated such that each query image can find a corresponding reference based on accurate robot localization along the same route in the pre-built 3D map, with which the reference and query images can be geometrically aligned using adaptive warping. Besides the proposed benchmark dataset, we evaluate the baseline models of ADr on this dataset. We hope this benchmark dataset will facilitate the advancement of ADr methods in the future. Our UMAD benchmark dataset will be publicly accessible at https://github.com/IMRL/UMAD.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t12_05">
             15:30-16:30, Paper WePI3T12.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1819'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              VRSO: Visual-Centric Reconstruction for Static Object Annotation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395453" title="Click to go to the Author Index">
             Yu, Chenyao
            </a>
           </td>
           <td class="r">
            Soochow University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#313900" title="Click to go to the Author Index">
             Cai, Yingfeng
            </a>
           </td>
           <td class="r">
            Tongji University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#285193" title="Click to go to the Author Index">
             Zhang, Jiaxin
            </a>
           </td>
           <td class="r">
            Soochow University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#287085" title="Click to go to the Author Index">
             Sui, Wei
            </a>
           </td>
           <td class="r">
            Soochow University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#204275" title="Click to go to the Author Index">
             Kong, Hui
            </a>
           </td>
           <td class="r">
            University of Macau
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#336495" title="Click to go to the Author Index">
             Yang, Cong
            </a>
           </td>
           <td class="r">
            Soochow University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1819" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             As a part of the perception results of intelligent driving systems, static object detection (SOD) in 3D space provides crucial cues for driving environment understanding. With the rapid deployment of deep neural networks for SOD tasks, the demand for high-quality training samples soars. The traditional, also reliable, way is manual labelling over the dense LiDAR point clouds and reference images. Though most public driving datasets adopt this strategy to provide SOD ground truth (GT), it is still expensive and time-consuming in practice. This paper introduces VRSO, a visual-centric approach for static object annotation. Experiments on the Waymo Open Dataset show that the mean reprojection error from VRSO annotation is only 2.6 pixels, around four times lower than the Waymo Open Dataset labels (10.6 pixels). VRSO is distinguished in low cost, high efficiency, and high quality: (1) It recovers static objects in 3D space with only camera images as input, and (2) manual annotation is barely involved since GT for SOD tasks is generated based on an automatic reconstruction and annotation pipeline.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t12_06">
             15:30-16:30, Paper WePI3T12.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2424'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SpectralWaste Dataset: Multimodal Data for Waste Sorting Automation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#286645" title="Click to go to the Author Index">
             Casao, Sara
            </a>
           </td>
           <td class="r">
            Unversity of Zaragoza
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398231" title="Click to go to the Author Index">
             Peña, Fernando
            </a>
           </td>
           <td class="r">
            Universidad De Zaragoza
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#270287" title="Click to go to the Author Index">
             Sabater, Alberto
            </a>
           </td>
           <td class="r">
            Universidad De Zaragoza
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398224" title="Click to go to the Author Index">
             Castillón, Rosa
            </a>
           </td>
           <td class="r">
            Universidad De Zaragoza
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398227" title="Click to go to the Author Index">
             Suárez, Darío
            </a>
           </td>
           <td class="r">
            Universidad De Zaragoza
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#117412" title="Click to go to the Author Index">
             Montijano, Eduardo
            </a>
           </td>
           <td class="r">
            Universidad De Zaragoza
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104884" title="Click to go to the Author Index">
             Murillo, Ana Cristina
            </a>
           </td>
           <td class="r">
            University of Zaragoza
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2424" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The increase in non-biodegradable waste is a worldwide concern. Recycling facilities play a crucial role, but their automation is hindered by the complex characteristics of waste recycling lines like clutter or object deformation. In addition, the lack of publicly available labeled data for these environments makes developing robust perception systems challenging. Our work explores the benefits of multimodal perception for object segmentation in real waste management scenarios. First, we present SpectralWaste, the first dataset collected from an operational plastic waste sorting facility that provides synchronized hyperspectral and conventional RGB images. This dataset contains labels for several categories of objects that commonly appear in sorting plants and need to be detected and separated from the main trash flow for several reasons, such as security in the management line or reuse. Additionally, we propose a pipeline employing different object segmentation architectures and evaluate the alternatives on our dataset, conducting an extensive analysis for both multimodal and unimodal alternatives. Our evaluation pays special attention to efficiency and suitability for real-time processing and demonstrates how hyperspectral imaging can bring a boost to RGB-only perception in these realistic industrial settings without much computational overhead.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t12_07">
             15:30-16:30, Paper WePI3T12.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2484'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              FEDORA: A Flying Event Dataset for Reactive BehAvior
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391577" title="Click to go to the Author Index">
             Joshi, Amogh
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#335431" title="Click to go to the Author Index">
             Ponghiran, Wachirawit
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#273795" title="Click to go to the Author Index">
             Kosta, Adarsh Kumar
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#336454" title="Click to go to the Author Index">
             Nagaraj, Manish
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#299278" title="Click to go to the Author Index">
             Roy, Kaushik
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2484" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robot_learning" title="Click to go to the Keyword Index">
               Data Sets for Robot Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_slam" title="Click to go to the Keyword Index">
               Data Sets for SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The ability of resource-constrained biological systems such as fruitflies to perform complex and high-speed maneuvers in cluttered environments has been one of the prime sources of inspiration for developing vision-based autonomous systems. To emulate this capability, the perception pipeline of such systems must integrate information cues from tasks including optical flow and depth estimation, object detection and tracking, and segmentation, among others. However, the conventional approach of employing slow, synchronous inputs from standard frame-based cameras constrains these perception capabilities, particularly during high-speed maneuvers. Recently, event-based sensors have emerged as low latency and low energy alternatives to standard frame-based cameras for capturing high-speed motion, effectively speeding up perception and hence navigation. For coherence, all the perception tasks must be trained on the same input data. However, present-day datasets are curated mainly for a single or a handful of tasks and are limited in the rate of the provided ground truths. To address these limitations, we present Flying Event Dataset fOr Reactive behAviour (FEDORA) - a fully synthetic dataset for perception tasks, with raw data from frame-based cameras, event-based cameras, and Inertial Measurement Units (IMU), along with ground truths for depth, pose, and optical flow at a rate much higher than existing datasets.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t12_08">
             15:30-16:30, Paper WePI3T12.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2527'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Nerve Block Target Localization and Needle Guidance for Autonomous Robotic Ultrasound Guided Regional Anesthesia
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#360750" title="Click to go to the Author Index">
             Tyagi, Abhishek
            </a>
           </td>
           <td class="r">
            Asian Institute of Gastroenterology, Hyderabad
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398298" title="Click to go to the Author Index">
             Tyagi, Abhay
            </a>
           </td>
           <td class="r">
            St. Elizabeth’s Medical Center, Boston University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398316" title="Click to go to the Author Index">
             Kaur, Manpreet
            </a>
           </td>
           <td class="r">
            Milton S Hershey Medical Center, Penn State Health
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398324" title="Click to go to the Author Index">
             Aggarwal, Richa
            </a>
           </td>
           <td class="r">
            All India Institute of Medical Sciences, New Delhi
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398315" title="Click to go to the Author Index">
             Soni, Kapil Dev
            </a>
           </td>
           <td class="r">
            All India Institute of Medical Sciences, New Delhi
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#117317" title="Click to go to the Author Index">
             Sivaswamy, Jayanthi
            </a>
           </td>
           <td class="r">
            IIIT-Hyderabad
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398330" title="Click to go to the Author Index">
             Trikha, Anjan
            </a>
           </td>
           <td class="r">
            Milton S Hershey Medical Center, Penn State Health
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2527" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_medical_robotics" title="Click to go to the Keyword Index">
               Computer Vision for Medical Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#surgical_robotics__planning" title="Click to go to the Keyword Index">
               Surgical Robotics: Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Visual servoing for the development of autonomous robotic systems capable of administering UltraSound (US) guided regional anesthesia requires real-time segmentation of nerves, needle tip localization and needle trajectory extrapolation. First, we recruited 227 patients to build a large dataset of 41,000 anesthesiologist annotated images from US videos of brachial plexus nerves and developed models to localize nerves in the US images. Generalizability of the best suited model was tested on the datasets constructed from separate US scanners. Using these nerve segmentation predictions, we define automated anesthesia needle targets by fitting an ellipse to the nerve contours. Next, we developed an image analysis tool to guide the needle toward their targets. For the segmentation of the needle, a natural RGB pre-trained neural network was first fine-tuned on a large US dataset for domain transfer and then adapted for the needle using a small dataset. The segmented needle’s trajectory angle is calculated using Radon transformation and the trajectory is extrapolated from the needle tip. The intersection of the extrapolated trajectory with the needle target guides the needle navigation for drug delivery. The needle trajectory’s average error was within acceptable range of 5 mm as per experienced anesthesiologists. The entire dataset has been released publicly for further study by the research community at https://github.com/Regional-US/
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t12_09">
             15:30-16:30, Paper WePI3T12.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('495'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Skin the Sheep Not Only Once: Reusing Various Depth Datasets to Drive the Learning of Optical Flow
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#367925" title="Click to go to the Author Index">
             Huang, Sheng Chi
            </a>
           </td>
           <td class="r">
            National Yang Ming Chiao Tung University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#238086" title="Click to go to the Author Index">
             Chiu, Wei-Chen
            </a>
           </td>
           <td class="r">
            National Chiao Tung University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab495" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Optical flow estimation is crucial for various applications in vision and robotics. As the difficulty of collecting ground truth optical flow in real-world scenarios, most of the existing methods of learning optical flow still adopt synthetic dataset for supervised training or utilize photometric consistency across temporally adjacent video frames to drive the unsupervised learning, where the former typically has issues of generalizability while the latter usually performs worse than the supervised ones. To tackle such challenges, we propose to leverage the geometric connection between optical flow estimation and stereo matching (based on the similarity upon finding pixel correspondences across images) to unify various real-world depth estimation datasets for generating supervised training data upon optical flow. Specifically, we turn the monocular depth datasets into stereo ones via synthesizing virtual disparity, thus leading to the flows along the horizontal direction; moreover, we introduce virtual camera motion into stereo data to produce additional flows along the vertical direction. Furthermore, we propose applying geometric augmentations on one image of an optical flow pair, encouraging the optical flow estimator to learn from more challenging cases. Lastly, as the optical flow maps under different geometric augmentations actually exhibit distinct characteristics, an auxiliary classifier which trains to identify the type of augmentation from the appearance of the flow map is utilized to further enhance the learning of the optical flow estimator. Our proposed method is general and is not tied to any particular flow estimator, where extensive experiments based on various datasets and optical flow estimation models verify its efficacy and superiority.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t12_10">
             15:30-16:30, Paper WePI3T12.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('532'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Deformable Objects Perception Is Just a Few Clicks Away – Dense Annotations from Sparse Inputs
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#275384" title="Click to go to the Author Index">
             Caporali, Alessio
            </a>
           </td>
           <td class="r">
            University of Bologna
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#297357" title="Click to go to the Author Index">
             Galassi, Kevin
            </a>
           </td>
           <td class="r">
            Università Di Bologna
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#282996" title="Click to go to the Author Index">
             Pantano, Matteo
            </a>
           </td>
           <td class="r">
            Siemens AG
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103582" title="Click to go to the Author Index">
             Palli, Gianluca
            </a>
           </td>
           <td class="r">
            University of Bologna
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab532" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Deformable Objects (DOs), e.g. clothes, garments, cables, wires, and ropes, are pervasive in our everyday environment. Despite their importance and widespread presence, many limitations exist when deploying robotic systems to interact with DOs. One source of challenges arises from their complex perception. Deep learning algorithms can address these issues; however, extensive training data is usually required. This paper introduces a method for efficiently labeling DOs in images at the pixel level, starting from sparse annotations of key points. The method allows for the generation of a real-world dataset of DO images for segmentation purposes with minimal human effort. The approach comprises three main steps. First, a set of images is collected by a camera-equipped robotic arm. Second, a user performs sparse annotation via key points on just one image from the collected set. Third, the initial sparse annotations are converted into dense labels ready for segmentation tasks by leveraging a foundation model in zero-shot settings. Validation of the method on three different sets of DOs, comprising cloth and rope-like objects, showcases its practicality and efficiency. Consequently, the proposed method lays the groundwork for easy DO labeling and the seamless integration of deep learning perception of DOs into robotic agents.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t12_11">
             15:30-16:30, Paper WePI3T12.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1849'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Subtle-Diff: A Dataset for Precise Recognition of Subtle Differences among Visually Similar Objects
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#340183" title="Click to go to the Author Index">
             Matsuzawa, Fumiya
            </a>
           </td>
           <td class="r">
            National Institute of Advanced Industrial Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#340195" title="Click to go to the Author Index">
             Qiu, Yue
            </a>
           </td>
           <td class="r">
            National Institute of Advanced Industrial Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#350829" title="Click to go to the Author Index">
             Sun, Yanjun
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#218763" title="Click to go to the Author Index">
             Iwata, Kenji
            </a>
           </td>
           <td class="r">
            AIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#218739" title="Click to go to the Author Index">
             Kataoka, Hirokatsu
            </a>
           </td>
           <td class="r">
            National Institute of Advanced Industrial Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#218755" title="Click to go to the Author Index">
             Satoh, Yutaka
            </a>
           </td>
           <td class="r">
            AIST
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1849" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Visual inspection robots used in factories and outdoor environments require the ability to accurately recognize visual differences between similar objects and further verbalize the recognition results to present the differences to humans. Despite the application of Large Language Models (LLMs) and multimodal LLMs across various domains, our research highlights their insufficiency in verbalizing nuanced differences across images. To address this, we leveraged LLMs and image generation AI to develop a dataset aimed at assessing difference recognition capabilities. We introduced two novel tasks using this dataset: selecting images based on their visual differences and a conditional difference captioning task, and evaluated existing Vision-Language Models (VLMs) on these tasks. Our findings reveal that advanced models like GPT-4V can describe subtle differences with comparative expressions, yet they fall short of matching human performance across all attributes. This discrepancy between model and human recognition, especially in identifying easily discernible differences, suggests that most current models lack the ability to directly compare image pairs for difference detection. Consequently, we propose a new model that incorporates an image-text similarity approach in the difference recognition task, showing superior performance over existing models, including GPT-4V. Our dataset and findings will contribute to advancements in differencing objects and improve robotic applications in visual inspection and object picking.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t12_12">
             15:30-16:30, Paper WePI3T12.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2815'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#277769" title="Click to go to the Author Index">
             Theisen, Nick
            </a>
           </td>
           <td class="r">
            University Koblenz-Landau
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#379072" title="Click to go to the Author Index">
             Bartsch, Robin
            </a>
           </td>
           <td class="r">
            University Koblenz
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#131675" title="Click to go to the Author Index">
             Paulus, Dietrich
            </a>
           </td>
           <td class="r">
            Universtät Koblenz-Landau
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#137411" title="Click to go to the Author Index">
             Neubert, Peer
            </a>
           </td>
           <td class="r">
            University of Koblenz
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2815" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#performance_evaluation_and_benchmarking" title="Click to go to the Keyword Index">
               Performance Evaluation and Benchmarking
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Semantic segmentation is an essential step for many vision applications in order to understand a scene and the objects within. Recent progress in hyperspectral imaging technology enables the application in driving scenarios and the hope is that the devices perceptive abilities provide an advantage over RGB-cameras. Even though some datasets exist, there is no standard benchmark available to systematically measure progress on this task and evaluate the benefit of hyperspectral data. In this paper, we work towards closing this gap by providing the HyperSpectral Semantic Segmentation benchmark (HS3-Bench). It combines annotated hyperspectral images from three driving scenario datasets and provides standardized metrics, implementations, and evaluation protocols. We use the benchmark to derive two strong baseline models that surpass the previous state-of-the-art performances with and without pre-training on the individual datasets. Further, our results indicate that the existing learning-based methods benefit more from leveraging additional RGB training data than from leveraging the additional hyperspectral channels. This poses important questions for future research on hyperspectral imaging for semantic segmentation in driving scenarios. Code to run the benchmark and the strong baseline approaches are available under https://github.com/nickstheisen/hyperseg.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t12_13">
             15:30-16:30, Paper WePI3T12.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3054'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Enhancing Nighttime UAV Tracking with Light Distribution Suppression
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#339398" title="Click to go to the Author Index">
             Yao, Liangliang
            </a>
           </td>
           <td class="r">
            Tongji University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#160488" title="Click to go to the Author Index">
             Fu, Changhong
            </a>
           </td>
           <td class="r">
            Tongji University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393299" title="Click to go to the Author Index">
             Wang, Yiheng
            </a>
           </td>
           <td class="r">
            Tongji University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#324459" title="Click to go to the Author Index">
             Zuo, Haobo
            </a>
           </td>
           <td class="r">
            University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#326955" title="Click to go to the Author Index">
             Lu, Kunhan
            </a>
           </td>
           <td class="r">
            Tongji University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3054" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Visual object tracking has boosted extensive intelligent applications for unmanned aerial vehicles (UAVs). However, the state-of-the-art (SOTA) enhancers for nighttime UAV tracking always neglect the uneven light distribution in low-light images, inevitably leading to excessive enhancement in scenarios with complex illumination. To address these issues, this work proposes a novel enhancer, i.e., LDEnhancer, enhancing nighttime UAV tracking with light distribution suppression. Specifically, a novel image content refinement module is developed to decompose the light distribution information and image content information in the feature space, allowing for the targeted enhancement of the image content information. Then this work designs a new light distribution generation module to capture light distribution effectively. The features with light distribution information and image content information are fed into the different parameter estimation modules, respectively, for the parameter map prediction. Finally, leveraging two parameter maps, an innovative interweave iteration adjustment is proposed for the collaborative pixel-wise adjustment of low-light images. Additionally, a challenging nighttime UAV tracking dataset with uneven light distribution, namely NAT2024-2, is constructed to provide a comprehensive evaluation, which contains 40 challenging sequences with over 74K frames in total. Experimental results on the authoritative UAV benchmarks and the proposed NAT2024-2 demonstrate that LDEnhancer outperforms other SOTA low-light enhancers for nighttime UAV tracking. Furthermore, real-world tests on a typical UAV platform with an NVIDIA Orin NX confirm the practicality and efficiency of LDEnhancer. The code is available at https: //github.com/vision4robotics/LDEnhancer.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t12_14">
             15:30-16:30, Paper WePI3T12.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3320'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Pre-Training on Synthetic Driving Data for Trajectory Prediction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372209" title="Click to go to the Author Index">
             Li, Yiheng
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372215" title="Click to go to the Author Index">
             Zhao, Zhihao
            </a>
           </td>
           <td class="r">
            University of California, Los Angeles
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#295784" title="Click to go to the Author Index">
             Xu, Chenfeng
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#238358" title="Click to go to the Author Index">
             Tang, Chen
            </a>
           </td>
           <td class="r">
            University of California Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#309158" title="Click to go to the Author Index">
             Li, Chenran
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#266445" title="Click to go to the Author Index">
             Ding, Mingyu
            </a>
           </td>
           <td class="r">
            UC Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100071" title="Click to go to the Author Index">
             Tomizuka, Masayoshi
            </a>
           </td>
           <td class="r">
            University of California
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#170266" title="Click to go to the Author Index">
             Zhan, Wei
            </a>
           </td>
           <td class="r">
            Univeristy of California, Berkeley
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3320" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Accumulating substantial volumes of real-world driving data proves pivotal in the realm of trajectory forecasting for autonomous driving. Given the heavy reliance of current trajectory forecasting models on data-driven methodologies, we aim to tackle the challenge of learning general trajectory forecasting representations under limited data availability. We propose a pipeline-level solution to mitigate the issue of data scarcity in trajectory forecasting. The solution is composed of two parts: firstly, we adopt HD map augmentation and trajectory synthesis for generating driving data, and then we learn representations by pre-training on them. Specifically, we apply vector transformations to reshape the maps, and then employ a rule-based model to generate trajectories on both original and augmented scenes; thus enlarging the driving data without collecting additional real ones. To foster the learning of general representations within this augmented dataset, we comprehensively explore the different pre-training strategies, including extending the concept of a Masked AutoEncoder (MAE) for trajectory forecasting. Without bells and whistles, our proposed pipeline-level solution is general, simple, yet effective: we conduct extensive experiments to demonstrate the effectiveness of our data expansion and pre-training strategies, which outperform the baseline prediction model by large margins, e.g., 5.04%, 3.84%, and 8.30% in terms of MR_6, minADE_6, and minFDE_6. The pre-training dataset and the codes for pre-training and fine-tuning are released at https://github.com/yhli123/Pretraining_on_Synthetic_Driving_Data_for_Trajectory_Prediction.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t12_15">
             15:30-16:30, Paper WePI3T12.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2335'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              MQE: Unleashing the Power of Interaction with Multi-Agent Quadruped Environment
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396992" title="Click to go to the Author Index">
             Xiong, Ziyan
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397098" title="Click to go to the Author Index">
             Chen, Bo
            </a>
           </td>
           <td class="r">
            Beijing University of Posts and Telecommunications
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397072" title="Click to go to the Author Index">
             Huang, Shiyu
            </a>
           </td>
           <td class="r">
            Zhipu AI
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397912" title="Click to go to the Author Index">
             Tu, Wei-Wei
            </a>
           </td>
           <td class="r">
            4Paradigm
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397106" title="Click to go to the Author Index">
             He, Zhaofeng
            </a>
           </td>
           <td class="r">
            Beijing University of Posts and Telecommunications
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#191564" title="Click to go to the Author Index">
             Gao, Yang
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2335" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The advent of deep reinforcement learning (DRL) has significantly advanced the field of robotics, particularly in the control and coordination of quadruped robots. However, the complexity of real-world tasks often necessitates the deployment of multi-robot systems capable of sophisticated interaction and collaboration. To address this need, we introduce the Multi-agent Quadruped Environment (MQE), a novel platform designed to facilitate the development and evaluation of multi-agent reinforcement learning (MARL) algorithms in realistic and dynamic scenarios. MQE emphasizes complex interactions between robots and objects, hierarchical policy structures, and challenging evaluation scenarios that reflect real-world applications. We present a series of collaborative and competitive tasks within MQE, ranging from simple coordination to complex adversarial interactions, and benchmark state-of-the-art MARL algorithms. Our findings indicate that hierarchical reinforcement learning can simplify task learning, but also highlight the need for advanced algorithms capable of handling the intricate dynamics of multi-agent interactions. MQE serves as a stepping stone towards bridging the gap between simulation and practical deployment, offering a rich environment for future research in multi-agent systems and robot learning. For open-sourced code and more details of MQE, please refer to https://ziyanx02.github.io/multiagent-quadruped-environment /
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wepi3t12_16">
             15:30-16:30, Paper WePI3T12.16
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3444'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Scalable Platform for Robot Learning and Physical Skill Data Collection
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#310692" title="Click to go to the Author Index">
             Schneider, Samuel
            </a>
           </td>
           <td class="r">
            TUM
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#299533" title="Click to go to the Author Index">
             Wu, Yansong
            </a>
           </td>
           <td class="r">
            Technische Universität München
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#212176" title="Click to go to the Author Index">
             Wu, Fan
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#181009" title="Click to go to the Author Index">
             Johannsmeier, Lars
            </a>
           </td>
           <td class="r">
            Franka Robotics GmbH
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#108317" title="Click to go to the Author Index">
             Haddadin, Sami
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3444" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#transfer_learning" title="Click to go to the Keyword Index">
               Transfer Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The intersection of robotics and artificial intelligence led to a profound paradigm shift in Robot Learning. Robots have the capacity to replicate human actions and also dynamically adapt, innovate, and excel across a spectrum of tasks. However, the heterogeneity in the deployment of robot platforms and software frameworks poses considerable challenges in terms of systematic testing and comparative analyses. Additionally, the data scarcity of especially force controlled robot manipulation is still restraining the development of advanced foundation models. A reference platform with default software stack can help to increase comparability, reducing development time and collect a large amount of tactile robot manipulation data. To approach this problem, we developed a Parallel and Distributed Robot AI (PD.RAI) framework, comprising a scalable ensemble of Robot Learning Units (RLUs), a global database, and the Robot Cluster Intelligence (RoCI). Each RLU is endowed with robot arms, cameras, and local computational units to autonomously engage in planning, control, and local machine learning of tactile manipulation skills. The RoCI system oversees the learning process and schedules the RLUs tasks. To show the functionality of the system, two black-box optimization algorithms are compared within the robot skill learning domain. An experiment with 25 different optimization tasks is conducted in parallel. The algorithms are incorporated into the same existing default modules acting as a reference environment. This allows for a realistic comparison without sacrificing diversity of possible configurations and testing environments.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wect1">
             <b>
              WeCT1
             </b>
            </a>
           </td>
           <td class="r">
            Room 1
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wect1" title="Click to go to the Program at a Glance">
             <b>
              Best Application Papers (ICROS)
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect1_01">
             16:30-16:45, Paper WeCT1.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1561'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Barely-Visible Surface Crack Detection for Wind Turbine Sustainability
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396807" title="Click to go to the Author Index">
             Agrawal, Sourav
            </a>
           </td>
           <td class="r">
            Zeitview
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396802" title="Click to go to the Author Index">
             Corley, Isaac
            </a>
           </td>
           <td class="r">
            University of Texas at San Antonio
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396809" title="Click to go to the Author Index">
             Wallace, Conor
            </a>
           </td>
           <td class="r">
            Zeitview
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396805" title="Click to go to the Author Index">
             Vaughn, Clovis
            </a>
           </td>
           <td class="r">
            Zeitview
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#190856" title="Click to go to the Author Index">
             Lwowski, Jonathan
            </a>
           </td>
           <td class="r">
            The University of Texas at San Antonio
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1561" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#manufacturing__maintenance_and_supply_chains" title="Click to go to the Keyword Index">
               Manufacturing, Maintenance and Supply Chains
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_manufacturing" title="Click to go to the Keyword Index">
               Computer Vision for Manufacturing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The production of wind energy is a crucial part of sustainable development and reducing the reliance on fossil fuels. Maintaining the integrity of wind turbines to produce this energy is a costly and time-consuming task requiring repeated inspection and maintenance. While autonomous drones have proven to make this process more efficient, the algorithms for detecting anomalies to prevent catastrophic damage to turbine blades have fallen behind due to some dangerous defects, such as hairline cracks, being barely-visible. Existing datasets and literature are lacking and tend towards detecting obvious and visible defects in addition to not being geographically diverse. In this paper we introduce a novel and diverse dataset of barely-visible hairline cracks collected from numerous wind turbine inspections. To prove the efficacy of our dataset, we detail our end-to-end deployed turbine crack detection pipeline from the image acquisition stage to the use of predictions in providing automated maintenance recommendations to extend the life and efficiency of wind turbines.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect1_02">
             16:45-17:00, Paper WeCT1.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1919'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SCANet: Correcting LEGO Assembly Errors with Self-Correct Assembly Network
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#390843" title="Click to go to the Author Index">
             Wan, Yuxuan
            </a>
           </td>
           <td class="r">
            Southeast University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376394" title="Click to go to the Author Index">
             Zhou, Kaichen
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393486" title="Click to go to the Author Index">
             Chen, Jinhong
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#280114" title="Click to go to the Author Index">
             Dong, Hao
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1919" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#assembly" title="Click to go to the Keyword Index">
               Assembly
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Autonomous assembly in robotics and 3D vision presents significant challenges, particularly in ensuring assembly correctness. Presently, predominant methods such as MEPNet focus on assembling components based on manually provided images. However, these approaches often fall short in achieving satisfactory results for tasks requiring long-term planning. Concurrently, we observe that integrating a self-correction module can partially alleviate such issues. Motivated by this concern, we introduce the Single-Step Assembly Error Correction Task, which involves identifying and rectifying misassembled components. To support research in this area, we present the LEGO Error Correction Assembly Dataset (LEGO-ECA), comprising manual images for assembly steps and instances of assembly failures. Additionally, we propose the Self-Correct Assembly Network (SCANet), a novel method to address this task. SCANet treats assembled components as queries, determining their correctness in manual images and providing corrections when necessary. Finally, we utilize SCANet to correct the assembly results of MEPNet. Experimental results demonstrate that SCANet can identify and correct MEPNet's misassembled results, significantly improving the correctness of assembly. Our code and dataset are available at https://github.com/Yaser-wyx/SCANet.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect1_03">
             17:00-17:15, Paper WeCT1.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3000'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Toward Perpetual Occlusion-Aware Observation of Comb States in Living Honeybee Colonies
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#256939" title="Click to go to the Author Index">
             Blaha, Jan
            </a>
           </td>
           <td class="r">
            CTU FEE, Departement of Computer Science
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#218041" title="Click to go to the Author Index">
             Vintr, Tomas
            </a>
           </td>
           <td class="r">
            FEE, Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#316650" title="Click to go to the Author Index">
             Mikula, Jan
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#256942" title="Click to go to the Author Index">
             Janota, Jiří
            </a>
           </td>
           <td class="r">
            Faculty of Electrical Engineering in Prague
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#256915" title="Click to go to the Author Index">
             Rouček, Tomáš
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#233152" title="Click to go to the Author Index">
             Ulrich, Jiri
            </a>
           </td>
           <td class="r">
            Faculty of Electrical Engineering, Czech Technical University In
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#343858" title="Click to go to the Author Index">
             Rekabi Bana, Fatemeh
            </a>
           </td>
           <td class="r">
            Durham University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#410092" title="Click to go to the Author Index">
             Fedotoff, Laurenz Alexander
            </a>
           </td>
           <td class="r">
            Karl-Franzens-University Graz, Institute of Biology, Artificial
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#410107" title="Click to go to the Author Index">
             Stefanec, Martin
            </a>
           </td>
           <td class="r">
            University of Graz
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#117782" title="Click to go to the Author Index">
             Schmickl, Thomas
            </a>
           </td>
           <td class="r">
            University of Graz
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#354577" title="Click to go to the Author Index">
             Arvin, Farshad
            </a>
           </td>
           <td class="r">
            Durham University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#119465" title="Click to go to the Author Index">
             Kulich, Miroslav
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#354572" title="Click to go to the Author Index">
             Krajnik, Tomas
            </a>
           </td>
           <td class="r">
            Czech Technical University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3000" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#robotics_and_automation_in_life_sciences" title="Click to go to the Keyword Index">
               Robotics and Automation in Life Sciences
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Honeybees are one of the most important pollinators in the ecosystem. Unfortunately, the dynamics of living honeybee colonies are not well understood due to their complexity and difficulty of observation. In our project “RoboRoyale”, we build and operate a robot to be a part of a bio-hybrid system, which currently observes the honeybee queen in the colony and physically tracks it with a camera. Apart from tracking and observing the queen, the system needs to monitor the state of the honeybee comb, which is most of the time occluded by the workerbees. This introduces a necessary tradeoff between tracking the queen and visiting the rest of the hive to create a daily map. We aim to collect the necessary data more effectively. We evaluate several mapping methods that consider the previous observations and forecasted densities of bees occluding the view. To predict the presence of bees, we use previously established maps of dynamics developed for autonomy in human-populated environments. Using data from the last observational season, we show significant improvement of the informed comb mapping methods over our current system. This will allow us to use our resources more effectively in the upcoming season.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect1_04">
             17:15-17:30, Paper WeCT1.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1924'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              ProSIP: Probabilistic Surface Interaction Primitives for Learning of Robotic Cleaning of Edges
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397505" title="Click to go to the Author Index">
             Unger, Christoph
            </a>
           </td>
           <td class="r">
            TU Wien
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#273720" title="Click to go to the Author Index">
             Hartl-Nesic, Christian
            </a>
           </td>
           <td class="r">
            TU Wien
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#196876" title="Click to go to the Author Index">
             Vu, Minh Nhat
            </a>
           </td>
           <td class="r">
            TU Wien, Austria
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#115936" title="Click to go to the Author Index">
             Kugi, Andreas
            </a>
           </td>
           <td class="r">
            TU Wien
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1924" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#intelligent_and_flexible_manufacturing" title="Click to go to the Keyword Index">
               Intelligent and Flexible Manufacturing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#industrial_robots" title="Click to go to the Keyword Index">
               Industrial Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Learning from demonstration (LfD) has emerged as a promising approach enabling robots to acquire complex tasks directly from human demonstrations. However, tasks involving surface interactions on freeform 3D surfaces present unique challenges in modeling and execution, especially when geometric variations exist between demonstrations and robot execution. This paper proposes a novel framework called probabilistic surface interaction primitives (ProSIP), which systematically incorporates the surface path and the local surface features into the learning procedure. An instrumented tool allows seamless recording and execution of human demonstrations. By design, ProSIPs are independent of time, invariant to rigid-body displacements, and can be applied to any robotic platform with a Cartesian controller. The framework is employed for an edge-cleaning task of bathroom sinks. The generalization capability to various object geometries and significantly distorted objects is demonstrated. Simulations and an experimental setup with a 9-degrees-of-freedom robotic platform confirm the performance.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wect2">
             <b>
              WeCT2
             </b>
            </a>
           </td>
           <td class="r">
            Room 2
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wect2" title="Click to go to the Program at a Glance">
             <b>
              Best Entertainment and Amusement Papers (JTCF)
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect2_01">
             16:30-16:45, Paper WeCT2.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3481'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Flying Robotics Art: ROS-Based Drone Draws the Record-Breaking Mural
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393257" title="Click to go to the Author Index">
             Korigodskii, Andrei
            </a>
           </td>
           <td class="r">
            Lomonosov Moscow State University, Sverk Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#399053" title="Click to go to the Author Index">
             Kalachev, Oleg
            </a>
           </td>
           <td class="r">
            Copter Express Technologies Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398383" title="Click to go to the Author Index">
             Vasiunik, Artem
            </a>
           </td>
           <td class="r">
            NUST MISiS, Cognitive Pilot
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#400508" title="Click to go to the Author Index">
             Urvantsev, Matvei
            </a>
           </td>
           <td class="r">
            Sverk Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398605" title="Click to go to the Author Index">
             Bondar, Georgii
            </a>
           </td>
           <td class="r">
            NUST MISiS
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3481" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#art_and_entertainment_robotics" title="Click to go to the Keyword Index">
               Art and Entertainment Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents the innovative design and successful deployment of a pioneering autonomous unmanned aerial system developed for executing the world's largest mural painted by a drone. Addressing the dual challenges of maintaining artistic precision and operational reliability under adverse outdoor conditions such as wind and direct sunlight, our work introduces a robust system capable of navigating and painting outdoors with unprecedented accuracy. Key to our approach is a novel navigation system that combines an infra-red (IR) motion capture camera and LiDAR technology, enabling precise location tracking tailored specifically for large-scale artistic applications. We employ a unique control architecture that uses different regulation in tangential and normal directions relative to the planned path, enabling precise trajectory tracking and stable line rendering. We also present algorithms for trajectory planning and path optimization, allowing for complex curve drawing and area filling. The system includes a custom-designed paint spraying mechanism, specifically engineered to function effectively amidst the turbulent airflow generated by the drone's propellers, which also protects the drone's critical components from paint-related damage, ensuring longevity and consistent performance. Experimental results demonstrate the system's robustness and precision in varied conditions, showcasing its potential for autonomous large-scale art creation and expanding the functional applications of robotics in creative fields.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect2_02">
             16:45-17:00, Paper WeCT2.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('775'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              An Intelligent Robotic System for Perceptive Pancake Batter Stirring and Precise Pouring
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393902" title="Click to go to the Author Index">
             Luo, Xinyuan
            </a>
           </td>
           <td class="r">
            University of Illinois at Urbana Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393269" title="Click to go to the Author Index">
             Jin, Shengmiao
            </a>
           </td>
           <td class="r">
            University of Illinois Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#220233" title="Click to go to the Author Index">
             Huang, Hung-Jui
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#172670" title="Click to go to the Author Index">
             Yuan, Wenzhen
            </a>
           </td>
           <td class="r">
            University of Illinois
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab775" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#perception_action_coupling" title="Click to go to the Keyword Index">
               Perception-Action Coupling
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Cooking robots have long been desired by the commercial market, while the technical challenge is still significant. A major difficulty comes from the demand of perceiving and handling liquid with different properties. This paper presents a robot system that mixes batter and makes pancakes out of it, where understanding and handling the viscous liquid is an essential component. The system integrates Haptic Sensing and control algorithms to autonomously stir flour and water to achieve the desired batter uniformity, estimate the batter's properties such as the water-flour ratio and liquid level, as well as perform precise manipulations to pour the batter into any specified shape. Experimental results show the system's capability to always produce batter of desired uniformity, estimate water-flour ratio and liquid level precisely, and accurately pour it into complex shapes. This research showcases the potential for robots to assist in kitchens and step towards commercial culinary automation.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect2_03">
             17:00-17:15, Paper WeCT2.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1031'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Low-Cost Air Hockey Robot Using a Five-Bar Linkage Mechanism Driven by Position-Control Servomotors
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#379706" title="Click to go to the Author Index">
             Shinjo, Mirai
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#165436" title="Click to go to the Author Index">
             Beltran-Hernandez, Cristian Camilo
            </a>
           </td>
           <td class="r">
            OMRON SINIC X Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#178939" title="Click to go to the Author Index">
             Hamaya, Masashi
            </a>
           </td>
           <td class="r">
            OMRON SINIC X Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#158337" title="Click to go to the Author Index">
             Tanaka, Kazutoshi
            </a>
           </td>
           <td class="r">
            OMRON SINIC X Corporation
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1031" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#engineering_for_robotic_systems" title="Click to go to the Keyword Index">
               Engineering for Robotic Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#software_hardware_integration_for_robot_systems" title="Click to go to the Keyword Index">
               Software-Hardware Integration for Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#art_and_entertainment_robotics" title="Click to go to the Keyword Index">
               Art and Entertainment Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In human-robot interaction (HRI) research, ball games pose significant challenges that demand robotic solutions that are both cost-effective and user-friendly for non-experts. Air hockey, characterized by safe, non-direct-contact play and a simplified state-action space, emerges as an ideal platform for such research. Despite the availability of various air hockey robots, their high cost and complexity have limited widespread use among researchers requiring robotics expertise. Addressing this gap, we introduce a low-cost, accessible air hockey robot designed to facilitate HRI studies. Featuring a lightweight five-bar linkage mechanism powered by low-cost servomotors for position control, this robot combines efficiency with ease of use. The complete robot's cost is estimated at 346.8, with the arm weighing a mere 19 grams. The robot precisely returns the puck by intermittently adjusting its target joint positions, achieving a play with an average return error of 42.6 mm. These characteristics affirm the robot's potential as a valuable tool for advancing HRI research.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect2_04">
             17:15-17:30, Paper WeCT2.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3046'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robot Synesthesia: A Sound and Emotion Guided Robot Painter
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398871" title="Click to go to the Author Index">
             Misra, Vihaan
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#339311" title="Click to go to the Author Index">
             Schaldenbrand, Peter
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#179403" title="Click to go to the Author Index">
             Oh, Jean
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3046" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#art_and_entertainment_robotics" title="Click to go to the Keyword Index">
               Art and Entertainment Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#emotional_robotics" title="Click to go to the Keyword Index">
               Emotional Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             If a picture paints a thousand words, sound may voice a million. While recent robotic painting and image synthesis methods have achieved progress in generating visuals from text inputs, the translation of sound into images is vastly unexplored. Generally, sound-based interfaces and sonic interactions have the potential to expand accessibility and control for the user and provide a means to convey complex emotions and the dynamic aspects of the real world. In this paper, we propose an approach for using sound and speech to guide a robotic painting process, known here as robot synesthesia. For general sound, we encode the simulated paintings and input sounds into the same latent space. For speech, we decouple speech into its transcribed text and the tone of the speech. Whereas we use the text to control the content, we estimate the emotions from the tone to guide the mood of the painting. Our approach has been fully integrated with FRIDA, a robotic painting framework, adding sound and speech to FRIDA's existing input modalities such as text and style. In two surveys, participants were able to correctly guess the emotion or natural sound used to generate a given painting more than twice as likely as random chance. On our sound-guided image manipulation and music-guided paintings, we discuss the results qualitatively.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wect3">
             <b>
              WeCT3
             </b>
            </a>
           </td>
           <td class="r">
            Room 3
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wect3" title="Click to go to the Program at a Glance">
             <b>
              Force and Tactile Sensing
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#122480" title="Click to go to the Author Index">
             Matsubara, Takamitsu
            </a>
           </td>
           <td class="r">
            Nara Institute of Science and Technology
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect3_01">
             16:30-16:45, Paper WeCT3.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('17'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Optical-Waveguide Based 3-Axial Tactile Sensor for Minimally Invasive Surgical Instruments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#310760" title="Click to go to the Author Index">
             Li, Yue
            </a>
           </td>
           <td class="r">
            King’s College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#294283" title="Click to go to the Author Index">
             Gaozhang, Wenlong
            </a>
           </td>
           <td class="r">
            University College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#356320" title="Click to go to the Author Index">
             Hu, Jian
            </a>
           </td>
           <td class="r">
            Institute of Automation, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#309232" title="Click to go to the Author Index">
             Cao, Danqian
            </a>
           </td>
           <td class="r">
            King's Collge London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#133196" title="Click to go to the Author Index">
             Dasgupta, Prokar
            </a>
           </td>
           <td class="r">
            King's College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104575" title="Click to go to the Author Index">
             Liu, Hongbin
            </a>
           </td>
           <td class="r">
            Hong Kong Institute of Science &amp; Innovation, Chinese Academy Of
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab17" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Force feedback is of importance in Minimally Invasive Surgery (MIS) as it reduces surgical risks and enhances surgical safety. However, equipping force sensing to the tip of surgical instruments presents challenges due to their diminutive dimensions and often curved shapes. To address this issue, a novel and compact optical-based 3-Axial force sensor used for the surgical forceps is proposed. Based on the extent of disruption to the total internal reflection (TIR), the magnitude and
             <p>
              the direction of the force can be detected by measuring the light intensity patterns from three intersecting channels. The calibration experiments validate the capability of the proposed sensor to accurately measure forces within the range of 0 to 3N, achieving a measurement accuracy of 97.27%. Subsequently, the sensor, along with the detection circuit, are integrated onto a surgical forcep, and verification experiments are conducted. The results indicate that the proposed sensor can provide effective 3-Axial force sensing during the surgical process such as grasping, manipulation, and pulling. The characteristics of compact size, high precision, and integrability of the sensor make it highly promising for providing force feedback in MIS.
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect3_02">
             16:45-17:00, Paper WeCT3.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('147'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Incipient Slip Detection by Vibration Injection into Soft Sensor
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#293784" title="Click to go to the Author Index">
             Komeno, Naoto
            </a>
           </td>
           <td class="r">
            Nara Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#122480" title="Click to go to the Author Index">
             Matsubara, Takamitsu
            </a>
           </td>
           <td class="r">
            Nara Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab147" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_sensors_and_actuators" title="Click to go to the Keyword Index">
               Soft Sensors and Actuators
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In robotic manipulation, preventing objects from slipping and establishing a secure grip on them is critical. Successful manipulation requires tactile sensors that detect the microscopic incipient slip phenomenon at the contact surface. Unfortunately, the tiny signals generated by incipient slip are quickly buried by environmental noise, and precise stress-distribution measurement requires an extensive optical system and integrated circuits. In this study, we focus on the macroscopic deformation of the entire fingertip's soft structure instead of directly observing the contact surface and its role as a vibration medium for sensing. The proposed method compresses the stick ratio's information into a one-dimensional pressure signal using the change in the propagation characteristics by vibration injection into the soft structure, which magnifies the microscopic incipient slip phenomena into the entire deformation. This mechanism allows a tactile sensor to use just a single vibration sensor. In the implemented system, a biomimetic tactile sensor is vibrated using a white signal from a PZT motor and utilizes frequency spectrum change of the propagated vibration as features. We investigated the proposed method's effectiveness on stick-ratio estimation and red{stick-ratio stabilization} control during incipient slip. Our estimation error and the control performance results significantly outperformed the conventional methods.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect3_03">
             17:00-17:15, Paper WeCT3.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3538'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Fiber-Optic Force Sensing of Modular Robotic Skin for Remote and Autonomous Robot Control (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#315506" title="Click to go to the Author Index">
             Lee, Sudong
            </a>
           </td>
           <td class="r">
            EPFL (École Polytechnique Fédérale De Lausanne)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#235962" title="Click to go to the Author Index">
             Kim, Jae In
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#333708" title="Click to go to the Author Index">
             Baek, Youngjoon
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#141685" title="Click to go to the Author Index">
             Chang, Dongjune
            </a>
           </td>
           <td class="r">
            Arizona State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#219533" title="Click to go to the Author Index">
             Lee, Jeongseob
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#139120" title="Click to go to the Author Index">
             Park, Young Soo
            </a>
           </td>
           <td class="r">
            Argonne National Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104207" title="Click to go to the Author Index">
             Lee, Dongjun
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106679" title="Click to go to the Author Index">
             Park, Yong-Lae
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3538" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#fiber_bragg_grating" title="Click to go to the Keyword Index">
               Fiber Bragg grating
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#dexterous_manipulation" title="Click to go to the Keyword Index">
               Dexterous Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robots have taken the place of human operators in hazardous and challenging jobs requiring high dexterity in manipulation, and robots with skin for force and tactile sensing that mimics the function of mechanoreception in animals will be highly dexterous in performing complex tasks. In this study, we propose the design of modular robotic skin, capable of detecting the magnitude and the location of a contact force simultaneously. Each skin module needs three degrees of freedom in sensing in order to estimate the horizontal and the vertical locations of the contact force as well as its magnitude. Force sensing in the proposed skin is enabled by a custom-designed triangular beam structure underneath the skin cover. A force applied to the skin cover causes the bending of the beam, which is detected by fiber optic strain sensors. The result shows the resolutions of 1.45 N for force estimation and 1.85 mm and 1.91 mm for contact localization in horizontal and vertical directions, respectively. We also demonstrate how the proposed skin can be used for remote and autonomous control of commercial robotic arms equipped with an array of the skin modules.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect3_04">
             17:15-17:30, Paper WeCT3.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3724'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              VTTB: A Visuo-Tactile Learning Approach for Robot-Assisted Bed Bathing
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#281891" title="Click to go to the Author Index">
             Gu, Yijun
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#114394" title="Click to go to the Author Index">
             Demiris, Yiannis
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3724" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#physical_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical Human-Robot Interaction
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_modal_perception_for_hri" title="Click to go to the Keyword Index">
               Multi-Modal Perception for HRI
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#physically_assistive_devices" title="Click to go to the Keyword Index">
               Physically Assistive Devices
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robot-assisted bed bathing holds the potential to enhance the quality of life for older adults and individuals with mobility impairments. Yet, accurately sensing the human body in such a contact-rich manipulation task remains challenging. To address this challenge, we propose a multimodal sensing approach that perceives the 3D contour of body parts using visual modality while capturing local contact details using tactile modality. We employ a Transformer-based imitation learning model to interact with multimodal information and learn to focus on crucial visuo-tactile task features for action prediction. We demonstrate our approach using a Baxter robot and a medical manikin to simulate the robot-assisted bed bathing scenario with bedridden individuals. The robot adeptly follows the contours of the manikin's body parts and cleans the surface based on its curve. Experimental results show that our method can adapt to nonlinear surface curves and generalize across multiple surface geometries and human subjects. Overall, our research presents a promising approach for robots to accurately sense the human body and perform safe contact-rich interaction during assistive bed bathing.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wect4">
             <b>
              WeCT4
             </b>
            </a>
           </td>
           <td class="r">
            Room 4
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wect4" title="Click to go to the Program at a Glance">
             <b>
              Soft Sensors and Actuators I
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#206601" title="Click to go to the Author Index">
             Yun, Dongwon
            </a>
           </td>
           <td class="r">
            Daegu Gyeongbuk Institute of Science and Technology (DGIST)
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#427976" title="Click to go to the Author Index">
             Khan, Kamran
            </a>
           </td>
           <td class="r">
            Khalifa University of Science and Technology
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect4_01">
             16:30-16:45, Paper WeCT4.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3633'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Two-Chamber Soft Actuator with an Expansion Limit Line for Force Enhancement
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#319056" title="Click to go to the Author Index">
             Yoon, Jingon
            </a>
           </td>
           <td class="r">
            Daegu Gyeongbuk Institute of Science and Technology (DGIST), Dae
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#269427" title="Click to go to the Author Index">
             Yang, Junmo
            </a>
           </td>
           <td class="r">
            Daegu Gyeongbuk Institute of Science and Technology (DGIST)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#206601" title="Click to go to the Author Index">
             Yun, Dongwon
            </a>
           </td>
           <td class="r">
            Daegu Gyeongbuk Institute of Science and Technology (DGIST)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3633" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_sensors_and_actuators" title="Click to go to the Keyword Index">
               Soft Sensors and Actuators
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Soft pneumatic actuators (SPAs) that can perform three-dimensional movements are being developed to perform more diverse tasks beyond simple bending. The conventional PneuNet actuators have expansion limit layers, which can obtain more tip force by limiting the expansion of the bottom. However, the presence of the expansion limit layer impedes other motions, such as rotation, when configured with multiple channels. In this study, we propose a two-chamber PneuNet actuator (TPA) to which the expansion limit line (ELLINE) is applied to obtain a force gain without a limitation on rotational motion due to the expansion limit layer. We perform a finite element analysis (FEA) on three designs that can rotate and bend using two chamber to find the optimal design. The effects on twisting, bending, and tip force according to the width of the ELLINE on the selected design were then verified through an FEA. After measuring rotation and bending for the fabricated actuator with and without the ELLINE. In the case of the fabricated TPA with the ELLINE, the bending decreased by 19.8%. However, rotation increased by 22.8 %, tip force increased by 1.53 times (with the ELLINE the force is 2.77 N in 70 kPa; without the ELLINE it is 1.8 N in 70 kPa), and grasping force increased by 5 times (with the ELLINE the force is 500 gf in 70 kPa, without the ELLINE it is 100 gf in 70 kPa). Furthermore, we fabricated a gripper using three actuators, capable of holding a weight of 505 g and objects of various shapes.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect4_02">
             16:45-17:00, Paper WeCT4.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('7'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Rapid De-Electroadhesion with Exponential Decay Alternating Voltages
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#272746" title="Click to go to the Author Index">
             Yan, Peinan
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#235454" title="Click to go to the Author Index">
             Zou, Jiang
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#203333" title="Click to go to the Author Index">
             Guo, Jianglong
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology (Shenzhen)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#252466" title="Click to go to the Author Index">
             Leng, Jinsong
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#134597" title="Click to go to the Author Index">
             Gu, Guoying
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab7" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#soft_sensors_and_actuators" title="Click to go to the Keyword Index">
               Soft Sensors and Actuators
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Due to the existence of residual charges, electroadhesion usually suffers from slow de-electroadhesion (in the range of several minutes to hours), significantly limiting its application in handling lightweight objects. To date, mechanical push or vibration is the main solution to achieve rapid de-electroadhesion, resulting in the complexity and inefficiency of electroadhesive devices. Inversely charging provides an ideal solution, but the voltage form remains elusive. In this work, we report an electrical solution that can achieve rapid de-electroadhesion by applying a programmable exponential decay alternative voltage. We investigate the influence of voltage parameters (including the decay factor, lasting time, and the number of alternations) on de-electroadhesion time. The results reveal that the de-electroadhesion time can be reduced by decreasing the decay factor and lasting time and increasing the number of alternations. The experimental results of different substrates (regular paper, copper, and kraft paper) demonstrate that our method can achieve fast release of the electroadhesion and the release time can be reduced by three orders, verifying the effectiveness of the electrically controlled rapid de-electroadhesion method.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect4_03">
             17:00-17:15, Paper WeCT4.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('61'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              How Fast Can a Robotic Drummer Beat Using Dielectric Elastomer Actuators?
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#380950" title="Click to go to the Author Index">
             Wakle, Sudhir
            </a>
           </td>
           <td class="r">
            Indian Institute of Technology Kanpur and National Yang Ming Chi
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#380953" title="Click to go to the Author Index">
             Lin, Tze-Han
            </a>
           </td>
           <td class="r">
            National Yang Ming Chiao Tung University, Taiwan
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#133947" title="Click to go to the Author Index">
             Huang, Shu
            </a>
           </td>
           <td class="r">
            Industrial Technology Research Institute, Taiwan
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#380952" title="Click to go to the Author Index">
             Basu, Sumit
            </a>
           </td>
           <td class="r">
            Indian Institute of Technology Kanpur
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#153048" title="Click to go to the Author Index">
             Lau, Gih Keong
            </a>
           </td>
           <td class="r">
            National Yang Ming Chiao Tung University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab61" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#soft_sensors_and_actuators" title="Click to go to the Keyword Index">
               Soft Sensors and Actuators
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Fast drumming presents a speed challenge to many robotic arms. To meet the simultaneous needs for speed, stroke, and force, we proposed and tested a new double-saddle dielectric elastomer actuator (DEA) as the artificial biceps for driving a lightweight robotic drummer. This work finds that fast force induction is instrumental to the fast drumming by a DEA-supported drumstick that makes a pivoted forearm. While a large pre-stretch and lateral reinforcement in a pure-shear series of DEA was good for generating a large isotonic stroke, it is not fast in isometric force induction. Instead, this work found a double-saddle DEA, which is a degenerated two-segment pure-shear DEA with a middle lateral beam reinforcement, managed to induce fast isometric force at down time constant of 0.8s when its ultimate actuation tapered due to substantial strain stiffening effect. As such, this double-saddle DEA-driven drummer suffered a less dynamic stroke decrement than the 8-segment DEA did. A 4.4-gram DEA managed to swing freely a 7.8-gram drumstick up to nearly 60 degrees at 5.5-6kV and a maximum tip speed of up to 0.45m/s. The drumming frequency upon 5.5kV activation was up to 2-2.5Hz. Interestingly, a slower stroke can excite multiple drumbeats due to secondary bounces. The present prototype of the DEA-driven drumstick did not beat a drum as fast as a human drummer. It is foreseen that a harder dielectric elastomer material will help drive a faster soft robot.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect4_04">
             17:15-17:30, Paper WeCT4.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('112'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Variable Stiffness, Sensing, and Healing in FESTO's FinRay Gripper: An Industry-Driven Design (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#305927" title="Click to go to the Author Index">
             Kashef Tabrizian, Seyedreza
            </a>
           </td>
           <td class="r">
            Vrije Universiteit Brussel
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#178528" title="Click to go to the Author Index">
             Terryn, Seppe
            </a>
           </td>
           <td class="r">
            Vrije Universiteit Brussel (VUB)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#370733" title="Click to go to the Author Index">
             Brauchle, Daniel
            </a>
           </td>
           <td class="r">
            FESTO
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#314717" title="Click to go to the Author Index">
             Seyler, Jan Reinke
            </a>
           </td>
           <td class="r">
            Festo SE &amp; Co. KG
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#178537" title="Click to go to the Author Index">
             Brancart, Joost
            </a>
           </td>
           <td class="r">
            Vrije Universiteit Brussel (VUB)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#178534" title="Click to go to the Author Index">
             Van Assche, Guy
            </a>
           </td>
           <td class="r">
            Vrije Universiteit Brussel (VUB)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101955" title="Click to go to the Author Index">
             Vanderborght, Bram
            </a>
           </td>
           <td class="r">
            Vrije Universiteit Brussel
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab112" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#soft_sensors_and_actuators" title="Click to go to the Keyword Index">
               Soft Sensors and Actuators
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Soft grippers' rising popularity in industries is due to their impressive adaptability. Yet, this adaptability requires flexibility which often sacrifices grip firmness and complicates sensor integration. This paper introduces two additional innovations, variable stiffness and pneumatic sensing, into a FinRay adaptive gripper. The approach and design for incorporating these innovations are guided by requirements outlined by FESTO. Regarding this, a layer jamming-based variable stiffness skin broadens gripper applications, manipulating objects of varying hardness and weight, while a pneumatic sensor skin detects contact and loss of contact. Both functionalities rely on the airtightness of the skins, which is compromised if damaged. To address this, both the skins and the gripper were crafted using self-healing polymers. The sensing and modulated mechanical performance of the gripper were evaluated experimentally and through simulations, and the self-healing ability was assessed by recharacterization after a damage-healing. This work showcases the promising synergy between robotics and self-healing materials, demonstrating mutual reinforcement to a highly efficient gripping system.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wect5">
             <b>
              WeCT5
             </b>
            </a>
           </td>
           <td class="r">
            Room 5
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wect5" title="Click to go to the Program at a Glance">
             <b>
              Dynamics
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#175411" title="Click to go to the Author Index">
             Behl, Madhur
            </a>
           </td>
           <td class="r">
            University of Virginia
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#179240" title="Click to go to the Author Index">
             Della Santina, Cosimo
            </a>
           </td>
           <td class="r">
            TU Delft
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect5_01">
             16:30-16:45, Paper WeCT5.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3707'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Deep Dynamics: Vehicle Dynamics Modeling with a Physics-Constrained Neural Network for Autonomous Racing
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#351915" title="Click to go to the Author Index">
             Chrosniak, John
            </a>
           </td>
           <td class="r">
            University of Virginia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#340631" title="Click to go to the Author Index">
             Ning, Jingyun
            </a>
           </td>
           <td class="r">
            University of Virginia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#175411" title="Click to go to the Author Index">
             Behl, Madhur
            </a>
           </td>
           <td class="r">
            University of Virginia
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3707" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#model_learning_for_control" title="Click to go to the Keyword Index">
               Model Learning for Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#dynamics" title="Click to go to the Keyword Index">
               Dynamics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Autonomous racing is a critical research area for autonomous driving, presenting significant challenges in vehicle dynamics modeling, such as balancing model precision and computational efficiency at high speeds (&gt;280 km/h), where minor errors in modeling have severe consequences. Existing physics-based models for vehicle dynamics require elaborate testing setups and tuning, which are hard to implement, time-intensive, and cost-prohibitive. Conversely, purely data-driven approaches do not generalize well and cannot adequately ensure physical constraints on predictions. This paper introduces Deep Dynamics, a physics-constrained neural network (PCNN) for autonomous racecar vehicle dynamics modeling. It merges physics coefficient estimation and dynamical equations to accurately predict vehicle states at high speeds. A unique Physics Guard layer ensures internal coefficient estimates remain within their nominal physical ranges. Open-loop and closed-loop performance assessments, using a physics-based simulator and full-scale autonomous Indy racecar data, highlight Deep Dynamics as a promising approach for modeling racecar vehicle dynamics.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect5_02">
             16:45-17:00, Paper WeCT5.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('51'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Monte Carlo Approach to Koopman Direct Encoding and Its Application to the Learning of Neural-Network Observables
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#378480" title="Click to go to the Author Index">
             Nozawa, Itta
            </a>
           </td>
           <td class="r">
            Sumitomo Heavy Industries, Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#290372" title="Click to go to the Author Index">
             Kamienski, Emily
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#286143" title="Click to go to the Author Index">
             O'Neill, Cormac
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100069" title="Click to go to the Author Index">
             Asada, Harry
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab51" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#dynamics" title="Click to go to the Keyword Index">
               Dynamics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a computational method, called Bootstrapped Koopman Direct Encoding (B-KDE) that allows us to approximate the Koopman operator with high accuracy by combining Koopman Direct Encoding (KDE) with a deep neural network. Deep learning has been applied to the Koopman operator method for finding an effective set of observable functions. Training the network, however, inevitably faces difficulties such as local minima, unless enormous computational efforts are made. Incorporating KDE can solve or alleviate this problem, producing an order of magnitude more accurate prediction. KDE converts the state transition function of a nonlinear system to a linear model in the lifted space of observables that are generated by deep learning. The combined KDE-deep model achieves higher accuracy than that of the deep learning alone. In B-KDE, the combined model is further trained until it reaches a plateau, and this computation is alternated between the neural network learning and the KDE computation. The result of the MSE loss implies that the neural network may get rid of local minima or at least find a smaller local minimum, and further improve the prediction accuracy. The KDE computation however, entails an effective algorithm for computing the inner products of observables and the nonlinear functions of the governing dynamics. Here, a computational method based on the Quasi-Monte Carlo integration is presented. The method is applied to a three-cable suspension robot, which exhibits complex switched nonlinear dynamics due to slack in each cable. The prediction accuracy is compared against its traditional counterparts.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect5_03">
             17:00-17:15, Paper WeCT5.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3725'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Breaking Symmetries Leads to Diverse Quadrupedal Gaits
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#354307" title="Click to go to the Author Index">
             Ding, Jiayu
            </a>
           </td>
           <td class="r">
            Syracuse University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#171554" title="Click to go to the Author Index">
             Gan, Zhenyu
            </a>
           </td>
           <td class="r">
            Syracuse University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3725" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#dynamics" title="Click to go to the Keyword Index">
               Dynamics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Symmetry manifests itself in legged locomotion in a variety of ways: A legged system can maintain consistent gaits from any spatial starting point, exhibiting the same leg movements on either side of the torso in phase, and some even demonstrate forward and backward movements so similar they seem to reverse time. This work aims to generalize these phenomena and proposes formal definitions of symmetries in legged locomotion using terminology from group theory. In this research, we uncovered an intrinsic connection among a broad spectrum of quadrupedal gaits, which can be systematically identified via numerical continuations and distinguished by elements within a symmetry group. These gaits, within the hybrid dynamical system, are not merely isolated movements but part of a continuum, seamlessly transitioning from one to another at precise parameter bifurcation points. Altering specific symmetries at these junctures leads to the emergence of distinct gaits with unique footfall patterns, a phenomenon we’ve generalized through dimensional analysis in this study. Consequently, each gait manifests distinct preferred speed ranges and specific transition speeds. This work offers a comprehensive method to solve the gait generation problem for a quadruped, including pronking, two types of bounding, four variations of half-bounding, and two forms of galloping, and it also elucidates the mechanical rationale behind the necessity of gait transitions, providing a high-level insight into the diversity and underlying mechanics of quadrupedal locomotion.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect5_04">
             17:15-17:30, Paper WeCT5.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('374'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Input Decoupling of Lagrangian Systems Via Coordinate Transformation: General Characterization and Its Application to Soft Robotics (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#310584" title="Click to go to the Author Index">
             Pustina, Pietro
            </a>
           </td>
           <td class="r">
            Sapienza University of Rome
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#179240" title="Click to go to the Author Index">
             Della Santina, Cosimo
            </a>
           </td>
           <td class="r">
            TU Delft
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102398" title="Click to go to the Author Index">
             Boyer, Frédéric
            </a>
           </td>
           <td class="r">
            Ecole Des Mines De Nantes
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102949" title="Click to go to the Author Index">
             De Luca, Alessandro
            </a>
           </td>
           <td class="r">
            Sapienza University of Rome
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#150250" title="Click to go to the Author Index">
             Renda, Federico
            </a>
           </td>
           <td class="r">
            Khalifa University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab374" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#underactuated_robots" title="Click to go to the Keyword Index">
               Underactuated Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#dynamics" title="Click to go to the Keyword Index">
               Dynamics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#modeling__control__and_learning_for_soft_robots" title="Click to go to the Keyword Index">
               Modeling, Control, and Learning for Soft Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Suitable representations of dynamical systems can simplify their analysis and control. On this line of thought, this paper considers the input decoupling problem for input-affine Lagrangian dynamics, namely the problem of finding a transformation of the generalized coordinates that decouples the input channels. We identify a class of systems for which this problem is solvable. Such systems are called collocated because the decoupling variables correspond to the coordinates on which the actuators directly perform work. Under mild conditions on the input matrix, a simple test is presented to verify whether a system is collocated or not. By exploiting power invariance, it is proven that a change of coordinates decouples the input channels if and only if the dynamics is collocated. We illustrate the theoretical results by considering several Lagrangian systems, focusing on underactuated mechanical systems, for which novel controllers that exploit input decoupling are designed.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wect6">
             <b>
              WeCT6
             </b>
            </a>
           </td>
           <td class="r">
            Room 6
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wect6" title="Click to go to the Program at a Glance">
             <b>
              Aerial Systems: Applications I
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#190182" title="Click to go to the Author Index">
             Hamaza, Salua
            </a>
           </td>
           <td class="r">
            TU Delft
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect6_01">
             16:30-16:45, Paper WeCT6.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('14'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Thrust Microstepping Via Acceleration Feedback in Quadrotor Control for Aerial Grasping of Dynamic Payload
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#211512" title="Click to go to the Author Index">
             Kumar, Ashish
            </a>
           </td>
           <td class="r">
            Indian Institute of Technology, Kanpur
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#121875" title="Click to go to the Author Index">
             Behera, Laxmidhar
            </a>
           </td>
           <td class="r">
            IIT Kanpur
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab14" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this work, we propose an end-to-end Thrust Microstepping and Decoupled Control (TMDC) of quadrotors. TMDC focuses on precise off-centered aerial grasping of payloads dynamically, which are attached rigidly to the UAV body via a gripper contrary to the swinging payload. The dynamic payload grasping quickly changes UAV’s mass, inertia etc, causing instability while performing a grasping operation in-air. We identify that to handle unknown payload grasping, the role of thrust controller is crucial. Hence, we focus on thrust control without involving system parameters such as mass etc. TMDC is based on our novel Thrust Microstepping via Acceleration Feedback (TMAF) thrust controller and Decoupled Motion Control (DMC). TMAF precisely estimates the desired thrust even at smaller loop rates while DMC decouples the horizontal and vertical motion to counteract disturbances in the case of dynamic payloads. We prove the controller’s efficacy via exhaustive experiments in practically interesting and adverse real-world cases, such as fully onboard state estimation without any positioning sensor, narrow and indoor flying workspaces with intense wind turbulence, heavy payloads, non-uniform loop rates, etc. Our TMDC outperforms recent direct acceleration feedback thrust controller in flying stably before and after the grasping operation and also outperforms the geometric tracking control for attitude estimation right after payload attachment.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect6_02">
             16:45-17:00, Paper WeCT6.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('22'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              ALBERO: Agile Landing on Branches for Environmental Robotics Operations
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#283689" title="Click to go to the Author Index">
             Zheng, Liming
            </a>
           </td>
           <td class="r">
            Delft University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#190182" title="Click to go to the Author Index">
             Hamaza, Salua
            </a>
           </td>
           <td class="r">
            TU Delft
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab22" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#environment_monitoring_and_management" title="Click to go to the Keyword Index">
               Environment Monitoring and Management
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Drones have been increasingly used in various domains, including ecological monitoring in forests. However, the endurance and noise of drones have limited their deployment to short flight missions above canopies. To address these limitations, we introduce ALBERO: a framework comprising a mechanical solution and an optimal planner to realise agile quadrotor perching on tree branches of steep incline. The gripper features an ultra-fast active mechanism inspired by birds' claws that enables quadrotors to perch swiftly on randomly-oriented tree branches. By perching, the drone can preserve energy for extended periods of time, while silently gathering forest data in the canopy. The intrinsic properties of the gripper allow for extra flexibility in size, surface roughness and shape imperfections of natural perches, such as those found in the wild. The gripper also has good scalability properties and can be easily matched to different drones' sizes and weights. The biggest advantage of this novel design lays in its ability to close reactively and ultra-fast (67~ms on the large gripper, 42~ms on the small gripper), enabling the quadrotor to perform agile perching manoeuvres from different angles and at different approach speeds. ALBERO's software module comprises of a trajectory planning algorithm adapted for branch perching, ensuring that the drone can perch on inclined cylindrical targets from any starting location in the proximity of the branch. These requirements translate in stringent positioning and orientation accuracy, but they enable the drone to land dynamically from a variety of positions within the forest.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect6_03">
             17:00-17:15, Paper WeCT6.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('49'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Assessment and Modeling of the Aerodynamic Ground Effect of a Fully-Actuated Hexarotor with Tilted Propellers
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#266618" title="Click to go to the Author Index">
             Garofano-Soldado, Ambar
            </a>
           </td>
           <td class="r">
            University of Seville
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#267920" title="Click to go to the Author Index">
             Gonzalez-Morgado, Antonio
            </a>
           </td>
           <td class="r">
            Universidad De Sevilla
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106094" title="Click to go to the Author Index">
             Heredia, Guillermo
            </a>
           </td>
           <td class="r">
            University of Seville
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104455" title="Click to go to the Author Index">
             Ollero, Anibal
            </a>
           </td>
           <td class="r">
            AICIA. G41099946
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab49" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#calibration_and_identification" title="Click to go to the Keyword Index">
               Calibration and Identification
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#performance_evaluation_and_benchmarking" title="Click to go to the Keyword Index">
               Performance Evaluation and Benchmarking
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This letter investigates the ground proximity effects of a fully-actuated multirotor unmanned aerial vehicle (UAV). Different configurations of tilted rotors and a wide range of UAV heights relative to the ground are considered. In order to characterize the effect, an extensive experimental study was conducted on a static test-bench. The experimental results display a behavior differing from that previously observed for multirotors with co-planar propellers and single-tilted rotors. We demonstrate that the ground effect increases with angle when the UAV is near the ground, while the opposite occurs for areas further away. Two new ground effect models are proposed, one for co-planar and another for fully-actuated configuration. In both cases, the models are dependent on the propeller radius, the distance between the rotors, the height of the UAV and the fountain effect. In addition, in the fully-actuated configuration, the model also depends on the inclination of the rotors. Finally, the proposed models are integrated into the UAV control architecture using the Aerodynamic Power Model Inversion (APMI) module, showing a significant improvement in flight accuracy when the ground effect is considered.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect6_04">
             17:15-17:30, Paper WeCT6.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3696'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Image-Based Time-Varying Contact Force Control of Aerial Manipulator Using Robust Impedance Filter
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#298635" title="Click to go to the Author Index">
             Byun, Jeonghyun
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#267786" title="Click to go to the Author Index">
             Kim, Junha
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#354060" title="Click to go to the Author Index">
             Eom, Dohyun
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#256238" title="Click to go to the Author Index">
             Lee, Dongjae
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#216299" title="Click to go to the Author Index">
             Kim, Changhyeon
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103663" title="Click to go to the Author Index">
             Kim, H. Jin
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3696" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#force_control" title="Click to go to the Keyword Index">
               Force Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The use of aerial manipulators for safe and efficient physical interaction with their surrounding environments has been gaining attention within the aerial robotics research community. In this paper, we present an image-based time-varying force tracking controller for an aerial manipulator conducting forceful interaction with a static surface. To this end, we first extract visual features from the surface using a monocular camera and calculate image feature vectors for the rotational and translational movements of the camera. Then, the RISATE (Robust Integral of SATuration Error)-based impedance filter continuously updates the desired values of the image features based on the previously designated force profile. Our stability analysis verifies that the error between the desired and actual contact force is uniformly ultimately bounded in an arbitrarily small bound with the proposed strategy even with the switching between free-flight and contact modes. Moreover, through time-varying force-tracking experiments with a quadrotor-based aerial manipulator, we validate the reproducibility and improved force-tracking performance of the proposed method.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wect7">
             <b>
              WeCT7
             </b>
            </a>
           </td>
           <td class="r">
            Room 7
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wect7" title="Click to go to the Program at a Glance">
             <b>
              Medical Robotics I
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#160079" title="Click to go to the Author Index">
             Nasseri, M. Ali
            </a>
           </td>
           <td class="r">
            Technische Universitaet Muenchen
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#117023" title="Click to go to the Author Index">
             Tamadazte, Brahim
            </a>
           </td>
           <td class="r">
            CNRS
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect7_01">
             16:30-16:45, Paper WeCT7.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('20'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Automatic Spinal Canal Breach Detection During Pedicle Screw Placement
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#223870" title="Click to go to the Author Index">
             Leblanc, Lilyan
            </a>
           </td>
           <td class="r">
            Sorbonne Université
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#364358" title="Click to go to the Author Index">
             Saghbini, Elie
            </a>
           </td>
           <td class="r">
            ISIR, Sorbonne Université, CNRS UMR 7222, INSERM U1150
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#237506" title="Click to go to the Author Index">
             Da Silva, Jimmy
            </a>
           </td>
           <td class="r">
            Sorbonne Université, CNRS, INSERM, ISIR-Agathe
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#345725" title="Click to go to the Author Index">
             Harle, Antoine
            </a>
           </td>
           <td class="r">
            ISIR, UMR 7222 Sorbonne University, CNRS, ERL AGATHE, U1150 INSE
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#310365" title="Click to go to the Author Index">
             Vafadar, Saman
            </a>
           </td>
           <td class="r">
            ISIR, UMR 7222 Sorbonne University, CNRS, ERL AGATHE, U1150 INSE
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#291184" title="Click to go to the Author Index">
             Chandanson, Thibault
            </a>
           </td>
           <td class="r">
            SpineGuard
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#364357" title="Click to go to the Author Index">
             Vialle, Raphael
            </a>
           </td>
           <td class="r">
            ISIR, Sorbonne Université, CNRS UMR 7222, INSERM U1150
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104642" title="Click to go to the Author Index">
             Morel, Guillaume
            </a>
           </td>
           <td class="r">
            Sorbonne Université, CNRS, INSERM
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#117023" title="Click to go to the Author Index">
             Tamadazte, Brahim
            </a>
           </td>
           <td class="r">
            CNRS
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab20" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_based_control" title="Click to go to the Keyword Index">
               Sensor-based Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#probability_and_statistical_methods" title="Click to go to the Keyword Index">
               Probability and Statistical Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Precise pedicle screw placement is imperative for a range of spinal procedures, demanding exact geometric alignment while also carrying inherent risks. The literature reports a complication rate in the case of screw mispositioning of up to 18%. To increase the accuracy of pedicle screw placement, we developed a robotic setup and a breach detection algorithm that could detect a possible perforation of the spinal canal. The robotic setup includes a robotic arm, a drilling system, and specific sensors, e.g., electrical conductivity at the drill bit's tip. The breach detection algorithm consists of a Bayesian-based method providing online and real-time analysis of the electrical conductivity signal to predict a breach. The robotic setup and the perforation detection algorithm were assessed in two ex-vivo experiments. First, data collection was performed by drilling 80 fresh pig vertebrae pedicles, followed by precise data labelling by a surgeon. The evaluation of the proposed algorithm was conducted numerically. Finally, the assessment was performed online by automatically drilling into pedicles in conditions similar to the operating room.
             <p>
              The results demonstrated that the algorithm could predict perforations and prevent the robotic setup from going through in 100% of 24 drilled vertebrae.
              <p>
               Results demonstrate that using electrical conductivity combined with a robotic setup allows the detection of imminent perforations of the spinal canal during pedicle drilling. This was the first study to evaluate spinal canal perforation detection during ex-vivo pig pedicle drilling.
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect7_02">
             16:45-17:00, Paper WeCT7.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('202'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              EyeLS: Shadow-Guided Instrument Landing System for Intraocular Target Approaching in Robotic Eye Surgery
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#310783" title="Click to go to the Author Index">
             Yang, Junjie
            </a>
           </td>
           <td class="r">
            TUM
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#368476" title="Click to go to the Author Index">
             Zhao, Zhihao
            </a>
           </td>
           <td class="r">
            Technische Universität München
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#368472" title="Click to go to the Author Index">
             Shen, Siyuan
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#160087" title="Click to go to the Author Index">
             Zapp, Daniel
            </a>
           </td>
           <td class="r">
            Klinikum Rechts Der Isar Der TU München
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#160084" title="Click to go to the Author Index">
             Maier, Mathias
            </a>
           </td>
           <td class="r">
            Klinikum Rechts Der Isar Der TU München
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#193739" title="Click to go to the Author Index">
             Huang, Kai
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#107647" title="Click to go to the Author Index">
             Navab, Nassir
            </a>
           </td>
           <td class="r">
            TU Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#160079" title="Click to go to the Author Index">
             Nasseri, M. Ali
            </a>
           </td>
           <td class="r">
            Technische Universitaet Muenchen
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab202" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_medical_robotics" title="Click to go to the Keyword Index">
               Computer Vision for Medical Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robotic ophthalmic surgery is an emerging technology to facilitate high-precision interventions such as subretinal injection and removing swinging tissues in retinal detachment using microscopy and iOCT. However, locating the instrument tip outside iOCT's range-limited ROI is challenging, especially at the initial target-approaching stage. Meanwhile, due to 2D perspective projection and the lack of depth perception with the required micron precision, current image-based methods cannot effectively navigate the instrument tip's trajectory towards both intra-retinal and above-retinal target points. To address this limitation, we propose using shadows of the instrument tip and target to estimate their relative depth position and optimize the instrument tip's insertion trajectory until it approaches targets within the iOCT's scanning area. Our method achieves a mean depth error of 0.0127 mm for above-retinal targets and 0.3473 mm for intra-retinal targets in the surgical simulator without damaging the retina, triggering subsequent iOCT-dominant micron-precision manipulations. This method also succeeds in the experiment of target approaching on a retina model.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect7_03">
             17:00-17:15, Paper WeCT7.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3717'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robot-Assisted Deep Venous Thrombosis Ultrasound Examination Using Virtual Fixture (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#216297" title="Click to go to the Author Index">
             Huang, Dianye
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#107047" title="Click to go to the Author Index">
             Yang, Chenguang
            </a>
           </td>
           <td class="r">
            University of Liverpool
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#195341" title="Click to go to the Author Index">
             Zhou, Mingchuan
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#291100" title="Click to go to the Author Index">
             Karlas, Angelos
            </a>
           </td>
           <td class="r">
            TranslaTUM, Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#107647" title="Click to go to the Author Index">
             Navab, Nassir
            </a>
           </td>
           <td class="r">
            TU Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#191552" title="Click to go to the Author Index">
             Jiang, Zhongliang
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3717" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_medical_robotics" title="Click to go to the Keyword Index">
               Computer Vision for Medical Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Deep Venous Thrombosis (DVT) is a common vascular disease with blood clots inside deep veins, which may block blood flow or even cause a life-threatening pulmonary embolism. A typical exam for DVT using ultrasound (US) imaging is by pressing the target vein until its lumen is fully compressed. However, the compression exam is highly operator-dependent. To alleviate intra- and inter-variations, we present a robotic US system with a novel hybrid force motion control scheme ensuring position and force tracking accuracy, and soft landing of the probe onto the target surface. In addition, a path-based virtual fixture is proposed to realize easy human-robot interaction for repeat compression operation at the lesion location. To ensure the biometric measurements obtained in different examinations are comparable, the 6D scanning path is determined in a coarse-to-fine manner using both an external RGBD camera and US images. The RGBD camera is first used to extract a rough scanning path on the object. Then, the segmented vascular lumen from US images is used to optimize the scanning path to ensure the visibility of the target object. To generate a continuous scan path for developing virtual fixtures, an arc-length based path fitting model considering both position and orientation is proposed. Finally, the whole system is evaluated on a human-like arm phantom with an uneven surface.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect7_04">
             17:15-17:30, Paper WeCT7.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('71'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Enhancing Elderly Mobility: A Sturdy, Two-Body Robot for Handlebar Placement in Any Location
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#339264" title="Click to go to the Author Index">
             Bolli, Roberto
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100069" title="Click to go to the Author Index">
             Asada, Harry
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab71" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#physically_assistive_devices" title="Click to go to the Keyword Index">
               Physically Assistive Devices
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#domestic_robotics" title="Click to go to the Keyword Index">
               Domestic Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#nonholonomic_mechanisms_and_systems" title="Click to go to the Keyword Index">
               Nonholonomic Mechanisms and Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Grab bars are widely used to provide elderly persons with support for daily activities, but their utility is limited by room geometry, cost of installation, and potential obstruction of other movements. We address these challenges through a mobile robot that can place a handlebar at any point in space, to optimally support postural transitions. Informed by a survey of elderly people and care professionals, we propose a novel two-body robot structure, consisting of two small-footprint mobile bases connected by a four bar linkage. Kinematic analysis shows that the structure can bear the entire weight of a human body, and provides secure support without sliding or tipping. The robot has a minimum width of 29.2 cm to be maneuverable within confined spaces, making it likely the slimmest robot ever developed for mobile postural assistance. A control plan for geometric path tracking is proposed that is generalizable to all robots with two coupled, nonholonomic, mobile bases. This consists of a leader-follower scheme as well as various enhancements to path tracking and dead reckoning that allow the robot to accurately follow a series of waypoints. On an 0.4 meter long test path, despite significant tread slippage, a 1:4 scale model of the robot achieved a root mean square error of 0.01 m and a deviation of 0.015 m from the path terminus, using only the encoders on the treads and robot frame. Finally, the robot's utility for supporting activities of daily living is demonstrated as a proof of concept.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wect8">
             <b>
              WeCT8
             </b>
            </a>
           </td>
           <td class="r">
            Room 8
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wect8" title="Click to go to the Program at a Glance">
             <b>
              Localization II
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#107437" title="Click to go to the Author Index">
             Lima, Pedro U.
            </a>
           </td>
           <td class="r">
            Instituto Superior Técnico - Institute for Systems and Robotics
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect8_01">
             16:30-16:45, Paper WeCT8.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('314'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Spatial Graph-Based Localization and Navigation on Scaleless Floorplan
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#285498" title="Click to go to the Author Index">
             Ewe, Zu Lin
            </a>
           </td>
           <td class="r">
            National Taiwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#383493" title="Click to go to the Author Index">
             Chang, Fu-Hao
            </a>
           </td>
           <td class="r">
            National Taiwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#383494" title="Click to go to the Author Index">
             Huang, Yi-Shiang
            </a>
           </td>
           <td class="r">
            National Taiwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100096" title="Click to go to the Author Index">
             Fu, Li-Chen
            </a>
           </td>
           <td class="r">
            National Taiwan University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab314" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Effective navigation in unfamiliar environments remains a critical challenge for successful deployment. Current navigation methods, which rely on autonomous or teleoperated exploration and map building, pose technical difficulties for inexperienced end-users. In contrast, humans can effectively navigate using abstract floorplans, suggesting the potential for service robots to leverage similar techniques. The practical application of floorplan-based navigation, however, is currently limited by methods that require pre-exploration or floorplan with accurate measurements or scale. This paper aims to address the aforementioned challenges and investigate the feasibility of floorplan-based navigation in unfamiliar environments. Specifically, we propose a novel scale-invariant floorplan localization method, enabling navigation without relying on precise scale information. Furthermore, we introduce an incremental graph augmentation approach that enriches the floorplan representation with traversability information derived from robot observations. Finally, we develop an efficient navigation framework capable of utilizing both the inherent structure of the floorplan and real-time observations. Experimental results demonstrate that our scale-invariant floorplan localization method outperforms baseline methods in most cases when floorplan scale information is unavailable, and our graph-based navigation system exhibits superior success and efficiency as compared to grid-based counterparts. The outcomes of this research contribute to the advancement of service robot deployment in unfamiliar environments, particularly in scenarios where extensive exploration and map building may be impractical or technically challenging for end-users.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect8_02">
             16:45-17:00, Paper WeCT8.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('778'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Enhancing VIO Robustness under Sudden Lighting Variation: A Learning-Based IMU Dead-Reckoning for UAV Localization
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#368179" title="Click to go to the Author Index">
             Yang, Daolong
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#307640" title="Click to go to the Author Index">
             Haoyuan, Liu
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#358479" title="Click to go to the Author Index">
             Jin, XueYing
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#215186" title="Click to go to the Author Index">
             Chen, Jiawei
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#183938" title="Click to go to the Author Index">
             Wang, Chengcai
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#125304" title="Click to go to the Author Index">
             Ding, Xilun
            </a>
           </td>
           <td class="r">
            Beijing University of Aeronautics &amp; Astronautics(BUAA)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#141192" title="Click to go to the Author Index">
             Xu, Kun
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab778" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__perception_and_autonomy" title="Click to go to the Keyword Index">
               Aerial Systems: Perception and Autonomy
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Visual Inertial Odometry (VIO) is commonly used for real-time Unmanned Aerial Vehicle (UAV) localization. However, the performance of VIO significantly deteriorates when UAV encounters sudden lighting variation in the environment, which poses a significant risk during flight. To address this issue without introducing additional sensors, a learning-based dead-reckoning algorithm relying solely on inertial measurement, which shares the same source with VIO, is proposed. The core idea of our method tightly couples a model-based Left Invariant Extended Kalman Filter (LIEKF) with a statistical neural network, both driven by raw inertial measurement. We have validated our algorithm for comparable accuracy with commonly deployed VIO methods under favorable lighting conditions and outperforms other IMU dead-reckoning algorithms in open-source datasets and real-world scenarios. To further enhance localization robustness while UAV traverses environments with different lighting conditions, we introduce an approach that tightly integrates our algorithm with VIO, and validate its effectiveness in real-world scenarios. It is believed that our work presents a promising way for enhancing robustness in vision-based localization methods within the robotics society.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect8_03">
             17:00-17:15, Paper WeCT8.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3624'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Vision-Based Topological Localization for MAVs
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#287125" title="Click to go to the Author Index">
             Felicioni, Simone
            </a>
           </td>
           <td class="r">
            University of Perugia - Department of Engineering
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#363679" title="Click to go to the Author Index">
             Rizzo, Biagio Maria
            </a>
           </td>
           <td class="r">
            Università Degli Studi Di Perugia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#305691" title="Click to go to the Author Index">
             Tortorici, Claudio
            </a>
           </td>
           <td class="r">
            Technology Innovation Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#150020" title="Click to go to the Author Index">
             Costante, Gabriele
            </a>
           </td>
           <td class="r">
            University of Perugia
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3624" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__perception_and_autonomy" title="Click to go to the Keyword Index">
               Aerial Systems: Perception and Autonomy
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Vision-based topological localization is recently emerging as a promising alternative to metric pose estimation techniques in robotic navigation systems. Contrarily to the latter, which suffer from a quick degradation of their performance under non-ideal conditions (e.g., scenes with poor illumination and low amount of textures), topological localization trades off precise metric positioning with a more robust and higher-level location representation. State-of-the-art works in this direction, however, often neglect the spatiotemporal relationships between poses that are naturally induced by robotic navigation. Furthermore, these techniques are nearly unexplored for autonomous flying platforms. Inspired by these considerations, in this work, we propose a vision-based topological localization approach designed for Micro Aerial Vehicles (MAVs) applications. Our strategy exploits the framework of graph recurrent neural networks to model the spatial and temporal dependencies and estimate the location of the robot with respect to a topological graph representing the environment. We demonstrate with experiments on different sets of scenarios, including scenes that considerably differ from those used in the training phase, that our approach is able to outperform state-of-the-art place recognition baselines.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect8_04">
             17:15-17:30, Paper WeCT8.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3640'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              GEERS: Georeferenced Enhanced EKF Using Point Cloud Registration and Segmentation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#293447" title="Click to go to the Author Index">
             Bettencourt, Rui
            </a>
           </td>
           <td class="r">
            Institute for Systems and Robotics / Instituto Superior Técnico
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#226850" title="Click to go to the Author Index">
             Lewis, John
            </a>
           </td>
           <td class="r">
            Instituto Superior Técnico, Lisboa
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#340251" title="Click to go to the Author Index">
             Serra, Rodrigo
            </a>
           </td>
           <td class="r">
            Institute for Systems and Robotics / Instituto Superior Técnico
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#132090" title="Click to go to the Author Index">
             Basiri, Meysam
            </a>
           </td>
           <td class="r">
            Instituto Superior Técnico
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#146225" title="Click to go to the Author Index">
             Vale, Alberto
            </a>
           </td>
           <td class="r">
            Instituto Superior Técnico
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#107437" title="Click to go to the Author Index">
             Lima, Pedro U.
            </a>
           </td>
           <td class="r">
            Instituto Superior Técnico - Institute for Systems and Robotics
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3640" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Georeferenced Enhanced EKF using point cloud Registration and Segmentation (GEERS) is a high-accuracy and consistent-rate localization method for outdoor robots. The localization is estimated by an EKF that fuses wheel odometry, IMU and GNSS measurements, in addition to feedback corrections from a registration step. The method improves localization accuracy by registering range sensors with pre-obtained georeferenced 3D maps and providing feedback corrections to the EKF. The continuous fusion of GNSS measurements naturally provides an initial estimate and reduces kidnapped robot situations in symmetric environments. The proposed method can integrate any range sensor (such as RBG-D cameras or 2D and 3D LiDAR). Experimental results in a real-world solar farm, its simulated digital twin, and an open dataset demonstrate localization accuracy improvements. Real-world experiments on a solar farm demonstrated the flexibility and reliability of the proposed method, exposing its advantages towards GNSS-only-based approaches.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wect9">
             <b>
              WeCT9
             </b>
            </a>
           </td>
           <td class="r">
            Room 9
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wect9" title="Click to go to the Program at a Glance">
             <b>
              Motion and Path Planning II
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#100088" title="Click to go to the Author Index">
             Siegwart, Roland
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect9_01">
             16:30-16:45, Paper WeCT9.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3535'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Planning with Purpose: Task-Specific Trajectory Optimization
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#273194" title="Click to go to the Author Index">
             Pei, Yinan
            </a>
           </td>
           <td class="r">
            Amazon
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#384628" title="Click to go to the Author Index">
             Ivanov, Yuri
            </a>
           </td>
           <td class="r">
            Amazon
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3535" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#redundant_robots" title="Click to go to the Keyword Index">
               Redundant Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper we propose an approach to trajectory planning based on the purpose of the task. For a redundant manipulator, many end effector poses in the task space can be achieved with multiple joint configurations. In planning the motion, we are free to choose the configuration that is optimal for the particular task requirement. Many previous motion planning approaches have been proposed for sole purpose of maximizing manipulability, or minimizing effort. However, there is a lack of formulation that is flexible enough to allow the designer to purposefully define the motion and force priority of the planned trajectory. Our approach exploits both velocity and force manipulability, depending on the purpose of the task. In this formulation, the purpose of the task is defined by the motion preference (“fast” or “strong”), which can be characterized by a direction of the desired motion, or force. These two directions can be used to evaluate the compatibility of a chosen configuration with the given task. We first demonstrate the possibility of generating two distinct motion plans by the kinematic alignment of desired velocity and force directions with the manipulator’s velocity and force manipulability ellipses. Next, this configuration selection strategy is incorporated into a task-specific trajectory optimization formulation to generate dynamically feasible trajectories. Two distinct motions (forceoriented lifting motion and velocity-oriented ballistic motion) are planned. We also propose a blending method to generate a single motion plan that considers both force and velocity, each to a specified degree. Together the three motions (force, velocity, and blended) are successfully planned and executed on a three-link serial robotic manipulator.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect9_02">
             16:45-17:00, Paper WeCT9.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3750'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Safe Low-Altitude Navigation in Steep Terrain with Fixed-Wing Aerial Vehicles
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#193069" title="Click to go to the Author Index">
             Lim, Jaeyoung
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#236361" title="Click to go to the Author Index">
             Achermann, Florian
            </a>
           </td>
           <td class="r">
            ETH Zurich, ASL
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#196356" title="Click to go to the Author Index">
             Girod, Rik
            </a>
           </td>
           <td class="r">
            ETH Zürich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#122930" title="Click to go to the Author Index">
             Lawrance, Nicholas
            </a>
           </td>
           <td class="r">
            CSIRO Data61
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100088" title="Click to go to the Author Index">
             Siegwart, Roland
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3750" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__perception_and_autonomy" title="Click to go to the Keyword Index">
               Aerial Systems: Perception and Autonomy
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Fixed-wing aerial vehicles provide an efficient way to navigate long distances or cover large areas for environmental monitoring applications. By design, they also require large open spaces due to limited maneuverability. However, strict regulatory and safety altitude
             <p>
              limits constrain the available space. Especially in complex, confined, or steep terrain, ensuring the vehicle does not enter an inevitable collision state (ICS) can be challenging. In this work, we propose a strategy to find safe paths that do not enter an ICS while navigating within tight altitude constraints. The method uses periodic paths to efficiently classify ICSs. A sampling-based planner creates collision-free and kinematically feasible paths that begin and end in safe periodic (circular) paths. We show that, in realistic terrain, using circular periodic paths can simplify the goal selection process by making it yaw agnostic and constraining yaw. We demonstrate our approach by dynamically planning safe paths in real-time while navigating steep terrain on a flight test in complex alpine terrain.
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect9_03">
             17:00-17:15, Paper WeCT9.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3765'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Biased-MPPI: Informing Sampling-Based Model Predictive Control by Fusing Ancillary Controllers
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#309938" title="Click to go to the Author Index">
             Trevisan, Elia
            </a>
           </td>
           <td class="r">
            Delft University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#142433" title="Click to go to the Author Index">
             Alonso-Mora, Javier
            </a>
           </td>
           <td class="r">
            Delft University of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3765" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Motion planning for autonomous robots in dynamic environments poses numerous challenges due to uncertainties in the robot's dynamics and interaction with other agents. Sampling-based MPC approaches, such as Model Predictive Path Integral (MPPI) control, have shown promise in addressing these complex motion planning problems. However, the performance of MPPI relies heavily on the choice of sampling distribution. Existing literature often uses the previously computed input sequence as the mean of a Gaussian distribution for sampling, leading to potential failures and local minima. We propose a novel derivation of MPPI that allows for arbitrary sampling distributions to enhance efficiency, robustness, and convergence while alleviating the problem of local minima. We present an efficient importance sampling scheme that combines classical and learning-based ancillary controllers simultaneously, resulting in more informative sampling and control fusion. Several simulated and real-world experiments demonstrate the validity of our approach.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect9_04">
             17:15-17:30, Paper WeCT9.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3784'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              CCTV-Informed Human-Aware Robot Navigation in Crowded Indoor Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#324479" title="Click to go to the Author Index">
             Kim, Mincheul
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#192764" title="Click to go to the Author Index">
             Kwon, Youngsun
            </a>
           </td>
           <td class="r">
            Electronics and Telecommunications Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#287304" title="Click to go to the Author Index">
             Lee, Sebin
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#120231" title="Click to go to the Author Index">
             Yoon, Sung-eui
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3784" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_aware_motion_planning" title="Click to go to the Keyword Index">
               Human-Aware Motion Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Mobile robot navigation in crowded indoor environments is a challenging task due to the limited sensing capabilities of onboard sensors. In this study, we propose a mobile robot navigation framework that utilizes external CCTV data to address the limitations of local sensors in a crowded environment. This approach enables mobile robots to navigate safely and efficiently in complex environments by encapsulating human movements from CCTVs to anticipate the human impact on the unclear navigational trajectory of our robot and devise human-aware paths that mitigate collision risks and minimize social intrusions. Further, we integrate a deep reinforcement learning (DRL) algorithm into a generated global path to fine-tune robotic navigation in human-populated areas, enabling the robot to learn efficiently and socially acceptable navigation compared to methods based solely on local sensors. Our experiments further validate the efficiency of using CCTVs to supplement robots with constrained sensing across varied sensor capabilities and CCTVs configurations.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wect10">
             <b>
              WeCT10
             </b>
            </a>
           </td>
           <td class="r">
            Room 10
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wect10" title="Click to go to the Program at a Glance">
             <b>
              Deep Learning for Vision
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#370437" title="Click to go to the Author Index">
             Cui, Zhenchao
            </a>
           </td>
           <td class="r">
            Hebei University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#235964" title="Click to go to the Author Index">
             Nava, Mirko
            </a>
           </td>
           <td class="r">
            IDSIA
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect10_01">
             16:30-16:45, Paper WeCT10.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('16'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              OKR-Net: Overlapping Keypoints Registration Network for Large-Scale LiDAR Point Clouds
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#370310" title="Click to go to the Author Index">
             Wang, Zijian
            </a>
           </td>
           <td class="r">
            Southeast University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#235772" title="Click to go to the Author Index">
             Xu, Xiaosu
            </a>
           </td>
           <td class="r">
            Southeast University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#371193" title="Click to go to the Author Index">
             Yao, Yiqing
            </a>
           </td>
           <td class="r">
            Southeast University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#371078" title="Click to go to the Author Index">
             Li, Nuo
            </a>
           </td>
           <td class="r">
            Southeast University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#371065" title="Click to go to the Author Index">
             Liu, Yehao
            </a>
           </td>
           <td class="r">
            Southeast University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab16" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#range_sensing" title="Click to go to the Keyword Index">
               Range Sensing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Point cloud registration is a fundamental task in various intelligence applications, including simultaneous localization and mapping as well as scene reconstruction. However, in large-scale scenes, the majority of point clouds exhibit partial overlap, posing a significant challenge
             <p>
              to the registration process. This study introduces a registration network, named OKR-Net, specifically designed to efficiently align partially overlapping point clouds. The OKR-Net comprises two innovative modules: a joint estimation module adept at identifying the keypoints within the overlapping region; and a coarse-to-fine registration module designed to aggregate the overlap and descriptor information, thereby reducing the outliers and yielding robust corresponding point pairs. In addition, an overlap labeling method for generated keypoints is introduced. The efficiency of the proposed registration network is validated utilizing two large-scale outdoor datasets: KITTI and NuScenes. The results demonstrate that the proposed
              <p>
               method outperforms existing global registration methods, encompassing both classical and learning-based methods in real-world scenarios.
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect10_02">
             16:45-17:00, Paper WeCT10.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('106'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Self-Supervised Learning of Visual Robot Localization Using LED State Prediction As a Pretext Task
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#235964" title="Click to go to the Author Index">
             Nava, Mirko
            </a>
           </td>
           <td class="r">
            IDSIA
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#374333" title="Click to go to the Author Index">
             Carlotti, Nicholas
            </a>
           </td>
           <td class="r">
            Dalle Molle Institute for Artificial Intelligence (IDSIA)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#341131" title="Click to go to the Author Index">
             Crupi, Luca
            </a>
           </td>
           <td class="r">
            IDSIA USI-SUPSI
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#270112" title="Click to go to the Author Index">
             Palossi, Daniele
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#155801" title="Click to go to the Author Index">
             Giusti, Alessandro
            </a>
           </td>
           <td class="r">
            IDSIA USI-SUPSI
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab106" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#micro_nano_robots" title="Click to go to the Keyword Index">
               Micro/Nano Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We propose a novel self-supervised approach for learning to visually localize robots equipped with controllable LEDs. We rely on a few training samples labeled with position ground truth and many training samples in which only the LED state is known, whose collection is cheap. We show that using LED state prediction as a pretext task significantly
             <p>
              helps to learn the visual localization end task.The resulting model does not require knowledge of LED states during inference. We instantiate the approach to visual relative localization of nano-quadrotors: experimental results show that using our pretext task significantly improves localization accuracy (from 68.3% to 76.2%) and outperforms alternative strategies, such as a supervised baseline, model pre-training, and an autoencoding pretext task. We deploy our model aboard a 27-g Crazyflie nano-drone, running at 21 fps, in a position-tracking task of a peer nano-drone. Our approach, relying on position labels for only 300 images, yields a mean tracking error of 4.2 cm versus 11.9 cm of a supervised baseline model trained without our pretext task.
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect10_03">
             17:00-17:15, Paper WeCT10.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('194'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              FGDSNet: A Lightweight Hand Gesture Recognition Network for Human Robot Interaction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#373472" title="Click to go to the Author Index">
             Zhou, Guoyu
            </a>
           </td>
           <td class="r">
            Hebei University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#370437" title="Click to go to the Author Index">
             Cui, Zhenchao
            </a>
           </td>
           <td class="r">
            Hebei University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#309360" title="Click to go to the Author Index">
             Qi, Jing
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab194" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_robot_collaboration" title="Click to go to the Keyword Index">
               Human-Robot Collaboration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Computer vision-based gesture recognition methods play a significant role in robot visual gesture interaction. since of low accuracy leading by insuffcient feature representation and fusion, the existing gesture segmentation and recognition methods fail to meet the requirements of practical applications. To address these issues, a lightweight two-stage end-to-end gesture recognition network called Fusing Gate Dual Stages Network (FGDSNet) is proposed. This network adopts a dual-branch network structure in the segmentation stage. Existing dual-branch network models often directly fuse detailed features and semantic features, which leads to detailed information being obscured by blurry semantic information. Additionally, there are redundant issues in the feature maps at different levels during the network inference process. Therefore, we embed Cosine Similarity-KL Divergence Attention Module (CoSKLAM) and Gate Filtering Module (GFM) between the local detail branch and the contextual semantic branch. The role of these two modules is to facilitate the fusion of local and global features during the feature extraction process and filter out redundant information. Finally, the segmentation result and original gesture image are used as inputs for the recognition network to predict gesture categories. The relevant experiments show that the proposed network performs well in both gesture segmentation and gesture recognition, while also having real-time inference speed and a smaller parameter size.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect10_04">
             17:15-17:30, Paper WeCT10.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3626'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Adaptive Robot Traversability Estimation Based on Self-Supervised Online Continual Learning in Unstructured Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#275915" title="Click to go to the Author Index">
             Yoon, Hyung-Suk
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#384436" title="Click to go to the Author Index">
             Hwang, Ji-Hoon
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#266457" title="Click to go to the Author Index">
             Kim, Chan
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#361215" title="Click to go to the Author Index">
             Son, E-In
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#309483" title="Click to go to the Author Index">
             Yoo, Se-Wook
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#205194" title="Click to go to the Author Index">
             Seo, Seung-Woo
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3626" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#robotics_in_hazardous_fields" title="Click to go to the Keyword Index">
               Robotics in Hazardous Fields
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#continual_learning" title="Click to go to the Keyword Index">
               Continual Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Traversability estimation is a core function for robot navigation in off-road unstructured environments and diverse research results have been published so far. One of the recent approaches is using the self-supervised learning (SSL) technique. SSL has been focused on as a breakthrough technique for situations where environments keep changing and thus traversability estimation is a challenging task. However, most of the research efforts based on SSL have several limitations: (i) they operate in an offline manner that is vulnerable to the domain distribution shift and therefore, they cannot be adaptive to the current navigation environment; and (ii) they do not take into consideration the aleatoric uncertainty of the dataset which is particularly critical in unstructured environments. In this paper, we propose an adaptive robot traversability estimation framework that considers the current navigation environment based on self-supervised online continual learning. In addition, we propose an algorithm called experience replay with uncertainty, which considers the aleatoric uncertainty of the dataset while training the traversability estimation model, thus enabling our framework to robustly estimate robot traversability. We validate our methods in various real-world environments using the Clearpath Husky robot and evaluate that our methods show better navigation performance than offline learning and rule-based methods. Moreover, we also evaluate that the proposed algorithm based on experience replay with uncertainty performs better for the benchmark dataset (ImageNet, CORe50) than the baseline algorithms.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wect11">
             <b>
              WeCT11
             </b>
            </a>
           </td>
           <td class="r">
            Room 11
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wect11" title="Click to go to the Program at a Glance">
             <b>
              Multi-Robot Systems II
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#280460" title="Click to go to the Author Index">
             Sun, Guibin
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#152911" title="Click to go to the Author Index">
             Parasuraman, Ramviyas
            </a>
           </td>
           <td class="r">
            University of Georgia
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect11_01">
             16:30-16:45, Paper WeCT11.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3697'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              MARRGM: Learning Framework for Multi-Agent Reinforcement Learning Via Reinforcement Recommendation and Group Modification
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#345320" title="Click to go to the Author Index">
             Wu, Peiliang
            </a>
           </td>
           <td class="r">
            Yanshan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#364584" title="Click to go to the Author Index">
             Tian, Liqiang
            </a>
           </td>
           <td class="r">
            Yanshan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#364679" title="Click to go to the Author Index">
             Zhang, Qian
            </a>
           </td>
           <td class="r">
            Nankai University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#345319" title="Click to go to the Author Index">
             Mao, BingYi
            </a>
           </td>
           <td class="r">
            Yanshan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#289771" title="Click to go to the Author Index">
             Chen, Wenbai
            </a>
           </td>
           <td class="r">
            Beijing Information Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3697" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#agent_based_systems" title="Click to go to the Keyword Index">
               Agent-Based Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Sample usage efficiency is an important factor affecting the convergence speed of multi-agent deep reinforcement learning (MADRL) algorithms. Most existing experience replay (ER) methods manually select experience samples to update the agent's policy. It is difficult to give suitable and efficient experience samples for different stages of agent policy learning as well as to effectively mine the potential value of experience samples in the replay buffer. Inspired by the idea of recommendation systems, this paper proposes a MADRL framework based on reinforcement recommendation and group modification to improve sample use efficiency and the ability to find the optimal solution of the multi-agent system in different task scenario categories. First, we use the sampling probability of each experience sample output from the recommendation network to recommend sampling instead of manual sampling; simultaneously, we collect the performance of the multi-agent system after updating the policy with the experience sample of recommendation sampling and construct the reinforcement learning process of the recommendation network. Next, we modify the individual policy of the agent according to the group rewards to improve the agent's ability to learn the optimal solution. We then combine and embed the reinforcement recommendation and group modification modules into the MADRL algorithm MAAC. Finally, we experiment with task scenarios, including cooperative collection, command movement, and target navigation, and extend this framework to the MADDPG algorithm to verify its scalability. The experimental results show that the off-policy MADRL algorithms combined with the proposed framework outperform the baseline algorithm in terms of sample usage efficiency and have better universality for
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect11_02">
             16:45-17:00, Paper WeCT11.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('331'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              MCCA: A Decentralized Method for Collision and Deadlock Avoidance with Nonholonomic Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#351277" title="Click to go to the Author Index">
             Zheng, Ruochen
            </a>
           </td>
           <td class="r">
            Megvii Automation &amp; Robotics
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#350136" title="Click to go to the Author Index">
             Li, Siyu
            </a>
           </td>
           <td class="r">
            Megvii Automation and Robotics
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab331" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#nonholonomic_motion_planning" title="Click to go to the Keyword Index">
               Nonholonomic Motion Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Navigation in dense and narrow environments with multiple robots is a standing challenge since deadlock is prone to occur. In this letter we present masked cooperative collision avoidance (MCCA), a fully decentralized method to avoid both collision and deadlock effectively. The concept of masked velocity is introduced, which is an implicit state of each robot and acts as an intention of avoiding deadlock. Robots are prioritized by a decentralized mechanism and masked velocities of robots with different priorities propagate among robots, promoting fluent and efficient deadlock avoiding behaviors in a local and collective manner. The solving process is reduced to a quadratic programming problem. Nonholonomic constraints are taken into account. We conduct extensive experiments in both simulation and real-world application, and the results verify the effectiveness of our method.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect11_03">
             17:00-17:15, Paper WeCT11.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3746'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Online Path Repair: Adapting to Robot Failures in Multi-Robot Aerial Surveys
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#324203" title="Click to go to the Author Index">
             Clark, Jaden
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#207142" title="Click to go to the Author Index">
             Shah, Kunal
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106233" title="Click to go to the Author Index">
             Schwager, Mac
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3746" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Multiple Unpiloted Aerial Vehicles (UAVs) working together have the potential to efficiently survey large geographical areas. Unfortunately, UAVs in the field may fail midway through a survey due to adverse weather, faster-than-expected battery drain, or mechanical malfunction, leaving part of the survey area uncovered. Here we propose
             <p>
              an algorithm to re-plan coverage routes online for multiple UAVs to take over the remaining route of a failed team member. We first present
              <p>
               a greedy path recovery algorithm whereby each UAV greedily absorbs the closest remaining vertices from the failed UAV's route into its own route. This method is then extended using a Tabu search method for multi-agent path repair to give successively better quality paths. We call the new path repair algorithm GRIT (Greedy Repair Initializes Tabu
               <p>
                search), and demonstrate it performing path repair for nominal paths planned with both a traditional lawnmower-style planner and a more sophisticated integer program based planner. We show that GRIT achieves
                <p>
                 adequate re-plans 10-50 times faster than two benchmark planners, making it ideal for online path repair in mid-flight, although the benchmarks eventually outperform GRIT if given unlimited computation time.
                </p>
               </p>
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect11_04">
             17:15-17:30, Paper WeCT11.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3730'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              HMA-SAR: Multi-Agent Search and Rescue for Unknown Located Dynamic Targets in Completely Unknown Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#385459" title="Click to go to the Author Index">
             Cao, Xiao
            </a>
           </td>
           <td class="r">
            University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#331343" title="Click to go to the Author Index">
             Li, Mingyang
            </a>
           </td>
           <td class="r">
            The University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#385684" title="Click to go to the Author Index">
             Tao, Yuting
            </a>
           </td>
           <td class="r">
            Hong Kong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#183721" title="Click to go to the Author Index">
             Lu, Peng
            </a>
           </td>
           <td class="r">
            The University of Hong Kong
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3730" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#search_and_rescue_robots" title="Click to go to the Keyword Index">
               Search and Rescue Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Multi-Agent Search and Rescue (MASAR) tasks, challenged by unknown environments and the unpredictable movements of unknown dynamic targets, suffer from inefficiencies in traditional map coverage techniques which require repeated sweeps. Addressing this, our study introduces a novel MASAR framework based on Multi-Agent Reinforcement Learning (MARL), featuring innovative elements like state, reward, and network structure design, alongside a Heterogeneous Curriculum Training
             <p>
              algorithm and a hybrid decision mechanism. These components collectively enhance performance in dynamic environments, improve model
              <p>
               generalization, and mitigate issues like sparse rewards and policy bias. In grid map simulations, our approach, HMA-SAR (Heterogeneous Multi-Agent Search and Rescue Framework), demonstrated consistent superiority over the traditional frontier-based method and other MARL algorithms, in metrics such as success rate, steps count, and the number of targets fetched. The practical applicability of our approach was further validated through experiments in Gazebo and real-world scenarios. Additionally, scalability tests in grid maps revealed substantial improvements in success rates and task completion times with increased agent deployment.
              </p>
             </p>
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wect12">
             <b>
              WeCT12
             </b>
            </a>
           </td>
           <td class="r">
            Room 12
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wect12" title="Click to go to the Program at a Glance">
             <b>
              Reinforcement Learning III
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#106824" title="Click to go to the Author Index">
             Kelly, Jonathan
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect12_01">
             16:30-16:45, Paper WeCT12.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3719'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Adaptive Curriculum Learning with Successor Features for Imbalanced Compositional Reward Functions
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#384014" title="Click to go to the Author Index">
             Szoke, Laszlo
            </a>
           </td>
           <td class="r">
            Budapest University of Technology and Economics, Robert Bosch Kf
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#384018" title="Click to go to the Author Index">
             Shperberg, Shahaf
            </a>
           </td>
           <td class="r">
            Ben-Gurion University of the Negev
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#195409" title="Click to go to the Author Index">
             Holtz, Jarrett
            </a>
           </td>
           <td class="r">
            University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#384019" title="Click to go to the Author Index">
             Allievi, Alessandro Gabriele
            </a>
           </td>
           <td class="r">
            Bosch
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3719" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#continual_learning" title="Click to go to the Keyword Index">
               Continual Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This work addresses the challenge of reinforcement learning with reward functions that feature highly imbalanced components in terms of importance and scale. Reinforcement learning algorithms generally struggle to handle such imbalanced reward functions effectively. Consequently, they often converge to suboptimal policies that favor only the dominant reward component. For example, agents might adopt passive strategies, avoiding any action to evade potentially unsafe outcomes entirely. To mitigate the adverse effects of imbalanced reward functions, we introduce a curriculum learning approach based on the successor features representation. This novel approach enables our learning system to acquire policies that take into account all reward components, allowing for a more balanced and versatile decision-making process.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect12_02">
             16:45-17:00, Paper WeCT12.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3721'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning Locomotion for Quadruped Robots Via Distributional Ensemble Actor-Critic
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#306391" title="Click to go to the Author Index">
             Li, Sicen
            </a>
           </td>
           <td class="r">
            Harbin Engineering University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#370390" title="Click to go to the Author Index">
             Pang, YiMing
            </a>
           </td>
           <td class="r">
            Harbin Engineering University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#370387" title="Click to go to the Author Index">
             Bai, Panju
            </a>
           </td>
           <td class="r">
            Harbin Engineering University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#370513" title="Click to go to the Author Index">
             Li, Jiawei
            </a>
           </td>
           <td class="r">
            Harbin Engineering University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#370512" title="Click to go to the Author Index">
             Liu, Zhaojin
            </a>
           </td>
           <td class="r">
            Harbin Engineering University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#306439" title="Click to go to the Author Index">
             Hu, Shihao
            </a>
           </td>
           <td class="r">
            Harbin Engineering University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#130828" title="Click to go to the Author Index">
             Wang, Li-Quan
            </a>
           </td>
           <td class="r">
            Harbin Engineering University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#136594" title="Click to go to the Author Index">
             Wang, Gang
            </a>
           </td>
           <td class="r">
            Harbin Engineering University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3721" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Domain randomization introduces perturbations in the simulation to make controllers less susceptible to the reality gap, which enables remarkable sim-to-real transfer on real quadruped robots. However, aleatoric uncertainty originating from perturbations could often lead to suboptimal controllers. In this work, we present a novel algorithm called Distributional Ensemble Actor-Critic (DEAC) that blends three ideas: distributional representation of a critic, lower bounds of the value distribution, and ensembling of multiple critics and actors. Distributional representation and ensembling provide reasonable uncertainty estimates, while lower bounds of the value distribution offer finer-grained error control. The simulation results show that the controller trained by DEAC outperforms the other baselines in the domain randomization setting. The trained controller is deployed on an A1-like robot, demonstrating high-speed running and the ability to traverse diverse terrains such as slippery plates, grassland, and wet dirt.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect12_03">
             17:00-17:15, Paper WeCT12.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3782'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              An End-To-End Deep Reinforcement Learning Based Modular Task Allocation Framework for Autonomous Mobile Systems (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#354819" title="Click to go to the Author Index">
             Ma, Song
            </a>
           </td>
           <td class="r">
            University College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#366084" title="Click to go to the Author Index">
             Ruan, Jingqing
            </a>
           </td>
           <td class="r">
            Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#280092" title="Click to go to the Author Index">
             Du, Yali
            </a>
           </td>
           <td class="r">
            King's College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#293917" title="Click to go to the Author Index">
             Bucknall, Richard
            </a>
           </td>
           <td class="r">
            University College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#293915" title="Click to go to the Author Index">
             Liu, Yuanchang
            </a>
           </td>
           <td class="r">
            University College London
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3782" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#task_planning" title="Click to go to the Keyword Index">
               Task Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Intelligent decision-making systems that can solve task allocation problems are critical for multi-robot systems to conduct industrial applications in a collaborative and automated way, such as warehouse inspection using mobile robots, hydrographic surveying using unmanned surface vehicles, etc. This paper, therefore, aims to address the task allocation problem for multi-agent autonomous mobile systems to autonomously and intelligently allocate multiple tasks to a fleet of robots. Such a problem is normally regarded as an independent decision-making process decoupled from the following task planning for the member robots. To avoid the sub-optimal allocation caused by the decoupling, an end-to-end task allocation framework is proposed to tackle this combinatorial optimisation problem while taking the succeeding task planning into account during the optimisation process. The problem is formulated as a special variant of the multi-depot multiple travelling salesmen problem (mTSP). The proposed end-to-end task allocation framework employs deep reinforcement learning methods to replace the handcrafted heuristics used in previous works. The proposed framework features a modular design of the reinforcement learning agent which can be customised for various applications. Moreover, a real-robot implementation setup based on the Robot Operating System 2 is presented to fulfil the simulation-to-reality gap. A warehouse inspection mission is executed to validate the training outcome of the proposed framework. The framework has been cross-validated via both simulated and real-robot tests with various parameter settings, where adaptability and performance are well demonstrated.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect12_04">
             17:15-17:30, Paper WeCT12.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('104'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Multi-Camera Unified Pre-Training Via 3D Scene Reconstruction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#293244" title="Click to go to the Author Index">
             Min, Chen
            </a>
           </td>
           <td class="r">
            Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#236360" title="Click to go to the Author Index">
             Xiao, Liang
            </a>
           </td>
           <td class="r">
            Defense Innovation Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#293266" title="Click to go to the Author Index">
             Zhao, Dawei
            </a>
           </td>
           <td class="r">
            DII
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#236367" title="Click to go to the Author Index">
             Nie, Yiming
            </a>
           </td>
           <td class="r">
            National Innovation Institute of Defense Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#295717" title="Click to go to the Author Index">
             Dai, Bin
            </a>
           </td>
           <td class="r">
            National Innovation Institute of Defense Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab104" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#representation_learning" title="Click to go to the Keyword Index">
               Representation Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Multi-camera 3D perception has emerged as a prominent research field in autonomous driving, offering a viable and cost-effective alternative to LiDAR-based solutions. The existing multi-camera algorithms primarily rely on monocular 2D pre-training. However, the monocular 2D pre-training overlooks the spatial and temporal correlations among the multi-camera system. To address this limitation, we propose the first multi-camera unified pre-training framework, called UniScene, which involves initially reconstructing the 3D scene as the foundational stage and subsequently fine-tuning the model on downstream tasks. Specifically, we employ Occupancy as the general representation for the 3D scene, enabling the model to grasp geometric priors of the surrounding world through pre-training. A significant benefit of UniScene is its capability to utilize a considerable volume of unlabeled image-LiDAR pairs for pre-training purposes. The proposed multi-camera unified pre-training framework demonstrates promising results in key tasks such as multi-camera 3D object detection and surrounding semantic scene completion. When compared to monocular pre-training methods, UniScene shows a significant improvement of about 2.0% in mAP and 2.0% in NDS for multi-camera 3D object detection, as well as a 3% increase in mIoU for surrounding semantic scene completion. By adopting our unified pre-training method, a 25% reduction in 3D training annotation costs can be achieved, offering significant practical value for the implementation of real-world autonomous driving. Codes are publicly available at https://github.com/chaytonmin/UniScene.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wect13">
             <b>
              WeCT13
             </b>
            </a>
           </td>
           <td class="r">
            Room 13
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wect13" title="Click to go to the Program at a Glance">
             <b>
              Human-Centered Robotics
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#101240" title="Click to go to the Author Index">
             Hasegawa, Yasuhisa
            </a>
           </td>
           <td class="r">
            Nagoya University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect13_01">
             16:30-16:45, Paper WeCT13.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3762'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Whole-Body Integrated AVATAR System: Implementation of Telepresence with Intuitive Control and Immersive Feedback (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#210209" title="Click to go to the Author Index">
             Park, Sungman
            </a>
           </td>
           <td class="r">
            UNIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#319504" title="Click to go to the Author Index">
             Junsoo, Kim
            </a>
           </td>
           <td class="r">
            UNIST, Ulsan, Korea
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#361068" title="Click to go to the Author Index">
             Lee, Hojae
            </a>
           </td>
           <td class="r">
            Ulsan National Institute of Science &amp; Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#361160" title="Click to go to the Author Index">
             Jo, Minwoong
            </a>
           </td>
           <td class="r">
            Korea, UNIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#361153" title="Click to go to the Author Index">
             Gong, Dohoon
            </a>
           </td>
           <td class="r">
            UNIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#361152" title="Click to go to the Author Index">
             Ju, Dawon
            </a>
           </td>
           <td class="r">
            UNIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#361157" title="Click to go to the Author Index">
             Won, Dami
            </a>
           </td>
           <td class="r">
            UNIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#361155" title="Click to go to the Author Index">
             Kim, Sihyeon
            </a>
           </td>
           <td class="r">
            UNIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#218214" title="Click to go to the Author Index">
             Oh, Jinhyeok
            </a>
           </td>
           <td class="r">
            UNIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#361162" title="Click to go to the Author Index">
             Jang, Hun
            </a>
           </td>
           <td class="r">
            Ulsan National Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#109405" title="Click to go to the Author Index">
             Bae, Joonbum
            </a>
           </td>
           <td class="r">
            Korea University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3762" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#haptics_and_haptic_interfaces" title="Click to go to the Keyword Index">
               Haptics and Haptic Interfaces
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_centered_robotics" title="Click to go to the Keyword Index">
               Human-Centered Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper proposes an intuitive and immersive whole-body teleoperation system with motion-based control and multi-modal feedback. The system consists of an anthropomorphic teleoperated robot and a haptic interface platform. The teleoperated robot has dual arms with dexterous hands, a head with a neck, a waist, giving it a human-like appearance and a large range of motion (ROM), as well as an omnidirectional mobile platform for improved mobility. The haptic interface platform enables a human operator to control the robot intuitively by measuring the operator's motion with a motion capture system, providing haptic feedback to the user's arms, fingers, and feet, and providing 3D image feedback. Additionally, facial animation further enhances immersion by synchronizing the face expression of the robot with the user’s voice. The proposed teleoperation system offers a promising solution for the human-oriented robotic avatar system, which was verified through a global competition, the 10M ANA Avatar XPRIZE. The system was successfully evaluated with 45 minutes of training time for users who were new to our system. And the lessons learned from the competition and future improvements are discussed.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect13_02">
             16:45-17:00, Paper WeCT13.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('128'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Real-Time Spatiotemporal Assistance for Micromanipulation Using Imitation Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#379781" title="Click to go to the Author Index">
             Mori, Ryoya
            </a>
           </td>
           <td class="r">
            Nagoya University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#114338" title="Click to go to the Author Index">
             Aoyama, Tadayoshi
            </a>
           </td>
           <td class="r">
            Nagoya University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#155380" title="Click to go to the Author Index">
             Kobayashi, Taisuke
            </a>
           </td>
           <td class="r">
            National Institute of Informatics
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#368533" title="Click to go to the Author Index">
             Sakamoto, Kazuya
            </a>
           </td>
           <td class="r">
            Nagoya University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#123774" title="Click to go to the Author Index">
             Takeuchi, Masaru
            </a>
           </td>
           <td class="r">
            Nagoya University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101240" title="Click to go to the Author Index">
             Hasegawa, Yasuhisa
            </a>
           </td>
           <td class="r">
            Nagoya University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab128" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#human_performance_augmentation" title="Click to go to the Keyword Index">
               Human Performance Augmentation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_centered_robotics" title="Click to go to the Keyword Index">
               Human-Centered Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             There has been an increasing demand for microscopic work using optical microscopes and micromanipulators for applications in various fields. However, microinjection requires skilled operators, and the considerable shortage of experts has become a recent challenge. To overcome this challenge, we propose an assistance system based on force
             <p>
              and visual presentation using artificial intelligence technology for simplifying cell rotation manipulation, which is difficult in microinjection. The proposed system employs imitation learning for an expert with a Gaussian mixture model (GMM) to obtain the ideal pipette trajectory and long short-term memory (LSTM) to infer the pipette operation at the next time step. The assistance position is calculated from the spatial component with GMM and the time-series component with LSTM. We conducted a subjective experiment using mature porcine oocytes as targets for manipulation to evaluate the effectiveness of the proposed system. The results indicated that, compared to the conventional system, the proposed system reduced the pipette operation time for single-oocyte rotation and the damage to the cells caused by the pipette-oocyte collision by approximately 27.0% and 82.0%, respectively. Therefore, the proposed system is expected to enable beginners to reproduce high-level skills and address the shortage of experts.
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect13_03">
             17:00-17:15, Paper WeCT13.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('90'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              MAVERIC: A Data-Driven Approach to Personalized Autonomous Driving (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#250086" title="Click to go to the Author Index">
             Schrum, Mariah
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#325807" title="Click to go to the Author Index">
             Sumner, Emily
            </a>
           </td>
           <td class="r">
            Toyota Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#160727" title="Click to go to the Author Index">
             Gombolay, Matthew
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#192996" title="Click to go to the Author Index">
             Best, Andrew
            </a>
           </td>
           <td class="r">
            Toyota Research Institute
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab90" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#human_centered_robotics" title="Click to go to the Keyword Index">
               Human-Centered Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_in_robotics_and_automation" title="Click to go to the Keyword Index">
               Deep Learning in Robotics and Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#personalization" title="Click to go to the Keyword Index">
               Personalization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Personalization of autonomous vehicles (AVs) may significantly increase acceptance. In particular, we hypothesize that the similarity of an AV’s driving style compared to a user’s driving style, the level of aggressiveness of the driving style, and other subjective factors (e.g., personality) will have a major impact on user’s willingness to use the AV. In this work, we 1) develop a data driven approach to personalize driving style and calibrate the level of aggressiveness and 2) investigate the subjective factors that impact user preference. Across two human subject studies (n = 54), we demonstrate that our approach can mimic the driving styles and tune the level of aggressiveness. Second, we leverage our framework to investigate the factors that impact homophily. We demonstrate that our approach generates driving styles objectively (p &lt; .001) and subjectively (p = .002) consistent with end-user styles (p &lt; .001) and can effectively isolate and modulate a dimension of style (i.e., aggressiveness) (p &lt; .001). Furthermore, we find that personality (p &lt; .001), perceived similarity (p &lt; .001), and high-velocity driving style (p = .0031) significantly modulate the effect of homophily.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect13_04">
             17:15-17:30, Paper WeCT13.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3647'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Field Experiments on the Effects of Multiple-Robot Expressions for Robot Influence in Recommendation Situations
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#327184" title="Click to go to the Author Index">
             Hatano, Yota
            </a>
           </td>
           <td class="r">
            Osaka University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#244527" title="Click to go to the Author Index">
             Baba, Jun
            </a>
           </td>
           <td class="r">
            CyberAgent, Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#231165" title="Click to go to the Author Index">
             Nakanishi, Junya
            </a>
           </td>
           <td class="r">
            Osaka Univ
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106455" title="Click to go to the Author Index">
             Yoshikawa, Yuichiro
            </a>
           </td>
           <td class="r">
            Osaka University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101596" title="Click to go to the Author Index">
             Ishiguro, Hiroshi
            </a>
           </td>
           <td class="r">
            Osaka University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3647" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Teleoperated social robots are becoming increasingly prevalent in society. To address the issue of their lack of influence, researchers have explored the use of multiple robots. Previous studies comprehensively investigated interactions with multiple robots, conducted web surveys, and revealed attributes that had positive, negative, and neutral effects on robot influence. In this study, we formulated hypotheses regarding multiple-robot expressions in the recommendation scenarios based on previous research findings and tested them through field experiments. We suggested that multiple-robot expressions with the attribute known as ``Single-Sympathy,'' which represents that robots have a single role conveying a single intention, enhance robot influence, and there may be positive effect attributes specific to the field experiment. Additionally, our results indicate that other than multiple-robot expressions, such as drawing the attention of passersby, are also important, and non-operating robots possibly affect the sales of recommended products, indicating the importance of designing interactions throughout the entire recommendation situation. Our study provides new insights into the designing of multiple-robot interactions.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wedt1">
             <b>
              WeDT1
             </b>
            </a>
           </td>
           <td class="r">
            Room 1
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wedt1" title="Click to go to the Program at a Glance">
             <b>
              Sponsored Award Papers
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#190182" title="Click to go to the Author Index">
             Hamaza, Salua
            </a>
           </td>
           <td class="r">
            TU Delft
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt1_01">
             17:30-17:45, Paper WeDT1.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('275'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              An Autonomous, 3D Printed, Waterjet-Powered, Open-Source Robotic Trimaran for Environmental Inspection and Monitoring
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#311330" title="Click to go to the Author Index">
             O’Brien, Reuben
            </a>
           </td>
           <td class="r">
            The University of Auckland
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397050" title="Click to go to the Author Index">
             Lambrechtse-Reid, Martin
            </a>
           </td>
           <td class="r">
            The University of Auckland
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#136999" title="Click to go to the Author Index">
             Liarokapis, Minas
            </a>
           </td>
           <td class="r">
            The University of Auckland
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab275" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#marine_robotics" title="Click to go to the Keyword Index">
               Marine Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#environment_monitoring_and_management" title="Click to go to the Keyword Index">
               Environment Monitoring and Management
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Versatile, autonomous robotic boats can offer excellent environmental inspection and monitoring solutions for remote, dangerous, hard to reach, or access protected water bodies. This paper introduces such a platform in the form of an autonomous, cost-effective, waterjet-powered robotic trimaran. Motivated by the need for an efficient aquatic monitoring, particularly in Aotearoa - New Zealand's diverse environments, the trimaran provides an efficient, low-cost, and easy to replicate alternative to resource-intensive research vessels. The proposed platform, costs 600-1,500 USD to develop (depending on the sensing system configuration), weighs under 5 kg, and excels in bathymetry and water quality testing. The trimaran can reach speeds of up to 2 m/s offering obstacle avoidance of natural features, such as rocks. Utilizing off-the-shelf components and 3D printing technology, the proposed platform offers excellent reproducibility and robustness while operating in shallow waters with its jet propulsion system. The paper presents in detail the design characteristics, the sensing system employed, testing results focusing on bathymetry, and highlights the ability of vessel and the potential for future research and data collection.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt1_02">
             17:45-18:00, Paper WeDT1.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('396'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Revolutionizing Battery Disassembly: The Design and Implementation of a Battery Disassembly Autonomous Mobile Manipulator Robot(BEAM-1)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#387687" title="Click to go to the Author Index">
             Peng, Yanlong
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#215661" title="Click to go to the Author Index">
             Wang, Zhigang
            </a>
           </td>
           <td class="r">
            Intel Labs China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#345980" title="Click to go to the Author Index">
             Zhang, Yisheng
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#347129" title="Click to go to the Author Index">
             Zhang, Shengmin
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391511" title="Click to go to the Author Index">
             Cai, Nan
            </a>
           </td>
           <td class="r">
            Kunming University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#390875" title="Click to go to the Author Index">
             Wu, Fan
            </a>
           </td>
           <td class="r">
            Beijing University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#163692" title="Click to go to the Author Index">
             Chen, Ming
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab396" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mobile_manipulation" title="Click to go to the Keyword Index">
               Mobile Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#disassembly" title="Click to go to the Keyword Index">
               Disassembly
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The efficient disassembly of end-of-life electric vehicle batteries(EOL-EVBs) is crucial for green manufacturing and sustainable development. The current pre-programmed disassembly conducted by the Autonomous Mobile Manipulator Robot(AMMR) struggles to meet the disassembly requirements in dynamic environments, complex scenarios, and unstructured processes. In this paper, we propose a Battery Disassembly AMMR(BEAM-1) system based on NeuralSymbolic AI. It detects the environmental state by leveraging a combination of multi-sensors and neural predicates and then translates this information into a quasi-symbolic space. In real-time, it identifies the optimal sequence of action primitives through LLM-heuristic tree search, ensuring high-precision execution of these primitives. Additionally, it employs positional speculative sampling using intuitive networks and achieves the disassembly of various bolt types with a meticulously designed end-effector. Importantly, BEAM-1 is a continuously learning embodied intelligence system capable of subjective reasoning like a human, and possessing intuition. A large number of real scene experiments have proved that it can autonomously perceive, decide, and execute to complete the continuous disassembly of bolts in multiple, multi-category, and complex situations, with a success rate of 98.78%. This research attempts to use NeuroSymbolic AI to give robots real autonomous reasoning, planning, and learning capabilities. BEAM-1 realizes the revolution of battery disassembly. Its framework can be easily ported to any robotic system to realize different application scenarios, which provides a ground-breaking idea for the design and implementation of future embodied intelligent robotic systems.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt1_03">
             18:00-18:15, Paper WeDT1.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('763'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Spatio-Temporal Consistent Mapping of Growing Plants for Agricultural Robots in the Wild
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#354300" title="Click to go to the Author Index">
             Lobefaro, Luca
            </a>
           </td>
           <td class="r">
            University of Bonn
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#354333" title="Click to go to the Author Index">
             Malladi, Meher Venkata Ramakrishna
            </a>
           </td>
           <td class="r">
            University of Bonn
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#246518" title="Click to go to the Author Index">
             Guadagnino, Tiziano
            </a>
           </td>
           <td class="r">
            University of Bonn
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101642" title="Click to go to the Author Index">
             Stachniss, Cyrill
            </a>
           </td>
           <td class="r">
            University of Bonn
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab763" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#robotics_and_automation_in_agriculture_and_forestry" title="Click to go to the Keyword Index">
               Robotics and Automation in Agriculture and Forestry
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Tracking changes in growing plants is important for automating phenotyping and robots managing crops. In this paper, we propose a system that uses a 3D model of plants along crop rows to enable a robotic platform to localize itself even in the presence of heavy changes and deforming the model to adapt the scene description to the new measurements. In particular, we focus on consumer RGB-D cameras due to their cost-effectiveness and ease of deployment on real platforms. Our approach exploits modern deep-learning-based feature descriptors and geometric information to obtain matches between 3D points corresponding to temporally distant sessions. We then use the associations in a non-rigid registration pipeline to obtain the final result, an updated representation of the 3D model that reflects plant changes. Using a standard mbox{RGB-D} sensor, we validate our approach on a real-world dataset recorded in a glasshouse. We obtain accurate 4D models of the plants and track the plant traits' evolution over time. We show, through experiments, that our method is applicable to interpolate plant organs' evolution, a helpful result for phenotypic trait measurement. We see our approach as a relevant step toward 4D reconstruction for robotic agriculture in the wild.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt1_04">
             18:15-18:30, Paper WeDT1.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1308'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Safe and Efficient Auto-Tuning to Cross Sim-To-Real Gap for Bipedal Robot
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#314763" title="Click to go to the Author Index">
             Du, Yidong
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#139013" title="Click to go to the Author Index">
             Chen, Xuechao
            </a>
           </td>
           <td class="r">
            Beijing Insititute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#116950" title="Click to go to the Author Index">
             Yu, Zhangguo
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#300618" title="Click to go to the Author Index">
             Zhang, YuanXi
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396244" title="Click to go to the Author Index">
             Zhou, Zishun
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414050" title="Click to go to the Author Index">
             Zhang, Jindai
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#364096" title="Click to go to the Author Index">
             Zhang, Jintao
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#239845" title="Click to go to the Author Index">
             Liu, Botao
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100171" title="Click to go to the Author Index">
             Huang, Qiang
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1308" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#humanoid_and_bipedal_locomotion" title="Click to go to the Keyword Index">
               Humanoid and Bipedal Locomotion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recent advances in both legged robot locomotion and Reinforcement Learning have shown a promising path for developing bipedal robot controllers. While the difference in dynamics between real world and simulation, also known as reality gap, still hinders the use. In this paper, we focus on sim-to-real bipedal robot locomotion task. We leverage the recent advances in auto-tuning sim-to-real transfer and use it to address sim-to-real bipedal robot locomotion problem. Similar to existing work, we first train a parameter searching model with dataset collected from simulator and use real-world data to tune the simulation parameters. However, the prediction tuning can be unreliable if the training dataset distribution fails to cover the real-world data. We address this problem by formulating this problem as an Out-of-distribution problem and further extending the current framework with a dataset verification model. With extended module, our method is capable of tuning the simulation parameters safely and efficiently. We demonstrate our method outperforms existing work and achieves sim-to-real bipedal robot locomotion on bipedal robot BITeno.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wedt2">
             <b>
              WeDT2
             </b>
            </a>
           </td>
           <td class="r">
            Room 2
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wedt2" title="Click to go to the Program at a Glance">
             <b>
              Marine Robotics I
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#102952" title="Click to go to the Author Index">
             Yamashita, Atsushi
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#193655" title="Click to go to the Author Index">
             Gao, Zhi
            </a>
           </td>
           <td class="r">
            Temasek Laboratories @ NUS
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt2_01">
             17:30-17:45, Paper WeDT2.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('31'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Swift: Transition Characterization and Motion Analysis of a Multimodal Underwater Vehicle
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#234419" title="Click to go to the Author Index">
             Zhou, Hexiong
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#362390" title="Click to go to the Author Index">
             Cao, Junjun
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#362403" title="Click to go to the Author Index">
             Fu, Jian
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#169130" title="Click to go to the Author Index">
             Zeng, Zheng
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#208373" title="Click to go to the Author Index">
             Yao, Baoheng
            </a>
           </td>
           <td class="r">
            Shanghai Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#362391" title="Click to go to the Author Index">
             Mao, Zhihua
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#208372" title="Click to go to the Author Index">
             Lian, Lian
            </a>
           </td>
           <td class="r">
            Shanghai Jiaotong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab31" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#marine_robotics" title="Click to go to the Keyword Index">
               Marine Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#dynamics" title="Click to go to the Keyword Index">
               Dynamics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#underactuated_robots" title="Click to go to the Keyword Index">
               Underactuated Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This letter proposes a novel conceptual multimodal underwater vehicle, named "Swift", which is capable of dexterous attitude transition for multiple operation modes. Aside from being competent to adjust pitch and roll angles in the range of -90° to 90°, it can achieve in-situ heading angle maneuvering adjustment with nearly 150° in cramped space,
             <p>
              without any assistance of external driving mechanisms such as propeller
              <p>
               or rudder. Ingenious configuration, design principles, and maneuvering
               <p>
                control sequences of actuators are proposed for innovative attitude transition. Other characteristics, such as the shape and internal drive
                <p>
                 structures, are identical to classic underwater gliders without further
                 <p>
                  upgrading, which offers great portability and extensibility. The description of the transient behavior during agile attitude transitions, particularly the effective estimation of in-situ heading angle adjustment, is greatly facilitated by transition dynamics with modified hydrodynamic compositions. The consistent results of dynamics simulation and various experiments demonstrate the performance of multi-mode locomotion and promote the transition characterization of the prototype.
                 </p>
                </p>
               </p>
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt2_02">
             17:45-18:00, Paper WeDT2.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('37'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Acoustic-N-Point for Solving 2D Forward Looking Sonar Pose Estimation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#233430" title="Click to go to the Author Index">
             Wang, Yusheng
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#179460" title="Click to go to the Author Index">
             Ji, Yonghoon
            </a>
           </td>
           <td class="r">
            JAIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#275312" title="Click to go to the Author Index">
             Tsuchiya, Hiroshi
            </a>
           </td>
           <td class="r">
            Wakachiku Construction Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102224" title="Click to go to the Author Index">
             Ota, Jun
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106691" title="Click to go to the Author Index">
             Asama, Hajime
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102952" title="Click to go to the Author Index">
             Yamashita, Atsushi
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab37" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#marine_robotics" title="Click to go to the Keyword Index">
               Marine Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             2D forward looking sonar (FLS) has gained widespread application in underwater robotics research, primarily due to its capacity to produce high-resolution images in diverse aquatic environments. This study deals with pose estimation with given 3D positions and corresponding 2D pixels, which is a fundamental problem for computer vision, denoted as acoustic-n-point (AnP) problem. It is the key part for object pose estimation, extrinsic calibration, localization, and structure from motion (SfM). We propose two methods to acquire a closed-form solution of 5 degree-of-freedom (DoF) pose. The first utilizes a non-approximated model and eliminates the cosine terms. The singular value decomposition (SVD)-based method is proposed and the nullity is discussed. The second method approximates the projection model as a linear system and conducts null space analysis for more accurate solutions. After acquiring the initial 5DoF pose. The last DoF can be acquired by constrained nonlinear least square optimization. We take advantage of both methods by selecting solutions with the smallest reprojection error. Furthermore, we explore the potential for further refinement by utilizing this solution as the initial pose with 6DoF-constrained iterative optimization. Results are evaluated on both simulation and real data.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt2_03">
             18:00-18:15, Paper WeDT2.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('40'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              WaterFormer: Global-Local Transformer for Underwater Image Enhancement with Environment Adaptor (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#319735" title="Click to go to the Author Index">
             Wen, Junjie
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#171201" title="Click to go to the Author Index">
             Cui, Jinqiang
            </a>
           </td>
           <td class="r">
            Peng Cheng Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#351220" title="Click to go to the Author Index">
             Yang, Guidong
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#351216" title="Click to go to the Author Index">
             Zhao, Benyun
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#355251" title="Click to go to the Author Index">
             Zhai, Yu
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#193655" title="Click to go to the Author Index">
             Gao, Zhi
            </a>
           </td>
           <td class="r">
            Temasek Laboratories @ NUS
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#116498" title="Click to go to the Author Index">
             Dou, Lihua
            </a>
           </td>
           <td class="r">
            Beijing Institue of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#171587" title="Click to go to the Author Index">
             Chen, Ben M.
            </a>
           </td>
           <td class="r">
            Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab40" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#marine_robotics" title="Click to go to the Keyword Index">
               Marine Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Underwater image enhancement (UIE) is of significant importance for underwater robotic tasks associated with high-level vision. Although convolutional neural networks (CNNs) have achieved great success in UIE in recent years, the locality nature of convolution poses a challenge in capturing the global context, which can lead to suboptimal performance. In contrast, the recently proposed Transformer-based networks show superior performance in a variety of discriminative vision tasks by the capability of taking long-range dependencies. Nonetheless, directly applying Transformer to UIE faces critical challenges: 1) it tends to produce results with coarse details due to the negligence of local texture; 2) the varicolored degraded images require the network to be adaptable to different underwater environments. In this paper, we propose a novel Transformer-based network that can effectively leverage both the global contextual and local detailed information with some key designs (global-local Transformer block and detail-enhanced skip connector) while being computationally efficient. Moreover, by introducing a simple but effective learnable environment adaptor, the proposed network is flex
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt2_04">
             18:15-18:30, Paper WeDT2.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('59'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              An Autonomous Underwater Architecture for Long-Term Deep-Ocean Inspection with Opportunistic (Re)planning (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#158487" title="Click to go to the Author Index">
             Tosello, Elisa
            </a>
           </td>
           <td class="r">
            Fondazione Bruno Kessler
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#366489" title="Click to go to the Author Index">
             Bonel, Paolo
            </a>
           </td>
           <td class="r">
            Saipem SpA
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#366490" title="Click to go to the Author Index">
             Buranello, Alberto
            </a>
           </td>
           <td class="r">
            Saipem SpA
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#186466" title="Click to go to the Author Index">
             Carraro, Marco
            </a>
           </td>
           <td class="r">
            Univ. of Padua
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#151812" title="Click to go to the Author Index">
             Cimatti, Alessandro
            </a>
           </td>
           <td class="r">
            IRST - Istituto Per La Ricerca Scientifica E Tecnologica
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#366333" title="Click to go to the Author Index">
             Granelli, Lorenzo
            </a>
           </td>
           <td class="r">
            SAIPEM SpA
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#366492" title="Click to go to the Author Index">
             Panjkovic, Stefan
            </a>
           </td>
           <td class="r">
            Fondazione Bruno Kessler
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#246303" title="Click to go to the Author Index">
             Micheli, Andrea
            </a>
           </td>
           <td class="r">
            Fondazione Bruno Kessler
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab59" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#marine_robotics" title="Click to go to the Keyword Index">
               Marine Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#embedded_systems_for_robotic_and_automation" title="Click to go to the Keyword Index">
               Embedded Systems for Robotic and Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robots are increasingly used in subsea environments due to their positive impact on human safety and operational capabilities in the deep ocean. However, achieving full autonomy remains challenging due to the extreme conditions they encounter. In this context, we propose an Autonomous Underwater Architecture for long-term deep-ocean inspection that robustly plans activities and efficiently deliberates with no human help. It combines the innovative Saipem’s Hydrone-R subsea vehicle with an advanced planning architecture, resulting in a robot that autonomously perceives its surroundings, plans a mission, and adapts in real-time to contingencies and opportunities. After describing the robot hardware, we present the technological advancements achieved in building its software, along with several compelling use cases. We explore scenarios where the robot conducts long-term underwater missions operating under resource constraints while remaining responsive to opportunities, such as new inspection points. Our solution gained significant reliability and acceptance within the Oil &amp; Gas community, as evidenced by its current deployment on a real field in Norway.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wedt3">
             <b>
              WeDT3
             </b>
            </a>
           </td>
           <td class="r">
            Room 3
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wedt3" title="Click to go to the Program at a Glance">
             <b>
              Deep Learning in Grasping and Manipulation I
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#144407" title="Click to go to the Author Index">
             Walas, Krzysztof, Tadeusz
            </a>
           </td>
           <td class="r">
            Poznan University of Technology
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt3_01">
             17:30-17:45, Paper WeDT3.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('63'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Deformable Linear Objects Manipulation with Online Model Parameters Estimation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#275384" title="Click to go to the Author Index">
             Caporali, Alessio
            </a>
           </td>
           <td class="r">
            University of Bologna
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#232689" title="Click to go to the Author Index">
             Kicki, Piotr
            </a>
           </td>
           <td class="r">
            Poznan University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#297357" title="Click to go to the Author Index">
             Galassi, Kevin
            </a>
           </td>
           <td class="r">
            Università Di Bologna
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#196331" title="Click to go to the Author Index">
             Zanella, Riccardo
            </a>
           </td>
           <td class="r">
            Universita' Degli Studi Di Bologna
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#144407" title="Click to go to the Author Index">
             Walas, Krzysztof, Tadeusz
            </a>
           </td>
           <td class="r">
            Poznan University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103582" title="Click to go to the Author Index">
             Palli, Gianluca
            </a>
           </td>
           <td class="r">
            University of Bologna
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab63" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Manipulating Deformable Linear Objects (DLOs) is a challenging task for
             <p>
              a robotic system due to their unpredictable configuration, high-dimensional state space and complex nonlinear dynamics. This paper presents a framework addressing the manipulation of DLOs, specifically targeting the model-based shape control task with the simultaneous online gradient-based estimation of model parameters. In the proposed framework, a neural network is trained to mimic the DLO
              <p>
               dynamics using the data generated with an analytical DLO model for a broad spectrum of its parameters. The neural network-based DLO model is conditioned on these parameters and employed in an online phase to perform the shape control task by estimating the optimal manipulative action through a gradient-based procedure. In parallel, gradient-based optimization is used to adapt the DLO model
               <p>
                parameters to make the neural network-based model better capture the dynamics of the real-world DLO being manipulated and match the observed
                <p>
                 deformations. To assess its effectiveness, the framework is tested across a variety of DLOs, surfaces, and target shapes in a series of experiments. The results of these experiments demonstrate the validity and efficiency of
                 <p>
                  the proposed methodology compared to existing methods.
                 </p>
                </p>
               </p>
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt3_02">
             17:45-18:00, Paper WeDT3.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('124'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              TraKDis: A Transformer-Based Knowledge Distillation Approach for Visual Reinforcement Learning with Application to Cloth Manipulation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#332538" title="Click to go to the Author Index">
             Chen, Wei
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#138488" title="Click to go to the Author Index">
             Rojas, Nicolas
            </a>
           </td>
           <td class="r">
            The AI Institute
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab124" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#transfer_learning" title="Click to go to the Keyword Index">
               Transfer Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#service_robotics" title="Click to go to the Keyword Index">
               Service Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Approaching robotic cloth manipulation using reinforcement learning based on visual feedback is appealing as robot perception and control can be learned simultaneously. However, major challenges result due to the intricate dynamics of cloth and the high dimensionality of the corresponding states, what shadows the practicality of the idea. To tackle these issues, we propose TraKDis, a novel Transformer-based Knowledge Distillation approach that decomposes the visual reinforcement learning problem into two distinct stages. In the first stage, a privileged agent is trained, which possesses complete knowledge of the cloth state information. This privileged agent acts as
             <p>
              a teacher, providing valuable guidance and training signals for subsequent stages. The second stage involves a knowledge distillation procedure, where the knowledge acquired by the privileged agent is transferred to a vision-based agent by leveraging pre-trained state estimation and weight initialization. TraKDis demonstrates better performance when compared to state-of-the-art RL techniques, showing a higher performance of 21.9%, 13.8% and 8.3% in cloth folding tasks in simulation. Furthermore, to validate robustness, we evaluate the agent in a noisy environment; the results indicate its ability to handle and adapt to environmental uncertainties effectively. Real robot experiments are also conducted to showcase the efficiency of our method
              <p>
               in real-world scenarios. Supplementary material is available at https://sites.google.com/view/trakdis.
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt3_03">
             18:00-18:15, Paper WeDT3.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('173'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning to Place Unseen Objects Stably Using a Large-Scale Simulation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#313355" title="Click to go to the Author Index">
             Noh, Sangjun
            </a>
           </td>
           <td class="r">
            Gwangju Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#313204" title="Click to go to the Author Index">
             Kang, Raeyoung
            </a>
           </td>
           <td class="r">
            Gwangju Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#255137" title="Click to go to the Author Index">
             Kim, Taewon
            </a>
           </td>
           <td class="r">
            Gwangju Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#270223" title="Click to go to the Author Index">
             Back, Seunghyeok
            </a>
           </td>
           <td class="r">
            Gwangju Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#205560" title="Click to go to the Author Index">
             Bak, Seongho
            </a>
           </td>
           <td class="r">
            Gwangju Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100825" title="Click to go to the Author Index">
             Lee, Kyoobin
            </a>
           </td>
           <td class="r">
            Gwangju Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab173" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Object placement is a fundamental task for robots, yet it remains challenging for partially observed objects. Existing methods for object
             <p>
              placement have limitations, such as the requirement for a complete 3D model of the object or the inability to handle complex shapes and novel
              <p>
               objects that restrict the applicability of robots in the real world. Herein, we focus on addressing the Unseen Object Placement (UOP) problem. We tackled the UOP problem using two methods: (1) UOP-Sim, a large-scale dataset to accommodate various shapes and novel objects, and (2) UOP-Net, a point cloud segmentation-based approach that directly detects the most stable plane from partial point clouds. Our UOP approach enables robots to place objects stably, even when the object’s shape and properties are not fully known, thus providing a promising solution for object placement in various environments. We verify our approach through simulation and real-world robot experiments, demonstrating state-of-the-art performance for placing single-view and partial objects. Robot demos, codes, and dataset are available at https://gistailab.github.io/uop/.
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt3_04">
             18:15-18:30, Paper WeDT3.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3676'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              CenterGrasp: Object-Aware Implicit Representation Learning for Simultaneous Shape Reconstruction and 6-DoF Grasp Estimation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#289597" title="Click to go to the Author Index">
             Chisari, Eugenio
            </a>
           </td>
           <td class="r">
            University of Freiburg
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#324871" title="Click to go to the Author Index">
             Heppert, Nick
            </a>
           </td>
           <td class="r">
            University of Freiburg
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#177085" title="Click to go to the Author Index">
             Welschehold, Tim
            </a>
           </td>
           <td class="r">
            Albert-Ludwigs-Universität Freiburg
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101785" title="Click to go to the Author Index">
             Burgard, Wolfram
            </a>
           </td>
           <td class="r">
            University of Technology Nuremberg
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#160427" title="Click to go to the Author Index">
             Valada, Abhinav
            </a>
           </td>
           <td class="r">
            University of Freiburg
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3676" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Reliable object grasping is a crucial capability for autonomous robots. However, many existing grasping approaches focus on general clutter removal without explicitly modeling objects and thus only relying on the visible local geometry. We introduce CenterGrasp, a novel framework that combines object awareness and holistic grasping. CenterGrasp learns a general object prior by encoding shapes and valid grasps in a continuous latent space. It consists of an RGB-D image encoder that leverages recent advances to detect objects and infer their pose and latent code, and a decoder to predict shape and grasps for each object in the scene. We perform extensive experiments on simulated as well as real-world cluttered scenes and demonstrate strong scene reconstruction and 6-DoF grasp-pose estimation performance. Compared to the state of the art, CenterGrasp achieves an improvement of 38.5 mm in shape reconstruction and 33 percentage points on average in grasp success. We make the code and trained models publicly available at http://centergrasp.cs.uni-freiburg.de.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wedt4">
             <b>
              WeDT4
             </b>
            </a>
           </td>
           <td class="r">
            Room 4
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wedt4" title="Click to go to the Program at a Glance">
             <b>
              Soft Sensors and Actuators II
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#148776" title="Click to go to the Author Index">
             Mintchev, Stefano
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt4_01">
             17:30-17:45, Paper WeDT4.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('197'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Multidirectional Bending Soft Pneumatic Actuator with Fishbone-Like Strain-Limiting Layer for Dexterous Manipulation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#374737" title="Click to go to the Author Index">
             Yang, Xinyu
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#195269" title="Click to go to the Author Index">
             Zhang, Ningbin
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#277654" title="Click to go to the Author Index">
             Huang, Xinjia
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#381809" title="Click to go to the Author Index">
             Bian, Rong
            </a>
           </td>
           <td class="r">
            Shanghai Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#286334" title="Click to go to the Author Index">
             Feng, Miao
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#112990" title="Click to go to the Author Index">
             Zhu, Xiangyang
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#134597" title="Click to go to the Author Index">
             Gu, Guoying
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab197" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#soft_sensors_and_actuators" title="Click to go to the Keyword Index">
               Soft Sensors and Actuators
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Soft pneumatic actuators (SPAs), due to their compliance and adaptiveness, are promising solutions for manipulation. However, most SPAs have only simple motion modes and cannot perform the compound motion required for complex manipulation. In this work, we propose a parallel-chamber actuator capable of multidirectional compound bending, short for CBPCA, to provide compound motion. The key component of the actuator is the specially trimmed fishbone-like strain-limiting layer. By differentially limiting the strain on the CBPCA surface, the layer induces the main bending while allowing lateral bending to enable multidirectional compound bending of CBPCA. Further, the layer is designable to tune the motion and mechanical properties of CBPCA. We develop a kinematic model based on constant curvature assumptions to analyze and forecast the motion of CBPCA. Further, we characterize the manipulation-related indicators of the CBPCA, including workspace, passive stiffness, and blocked force. The proposed CBPCA can achieve a wide-range kite-shaped spatial workspace with a motion range of 80.5% and 76.9% actuator length in main and lateral bending directions, respectively. To verify the manipulation capability of the CBPCA, we developed two typical forms of manipulators: a four-finger gripper and a three-finger anthropomorphic hand to conduct experiments. The results show that the CBPCA performs effectively in dexterous manipulation where basic motion primitives and complex manipulation in activities of daily living, such as setting workpieces and installing bulbs, are well-completed.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt4_02">
             17:45-18:00, Paper WeDT4.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3658'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Vine-Like, Power Soft Gripper Based on Euler's Belt Theory
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#371440" title="Click to go to the Author Index">
             Kodama, Hiroto
            </a>
           </td>
           <td class="r">
            Tokyo Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#208273" title="Click to go to the Author Index">
             Ide, Tohru
            </a>
           </td>
           <td class="r">
            Tokyo Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#275132" title="Click to go to the Author Index">
             Feng, Yunhao
            </a>
           </td>
           <td class="r">
            Tokyo Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#190813" title="Click to go to the Author Index">
             Nabae, Hiroyuki
            </a>
           </td>
           <td class="r">
            Tokyo Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100766" title="Click to go to the Author Index">
             Suzumori, Koichi
            </a>
           </td>
           <td class="r">
            Tokyo Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3658" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#soft_sensors_and_actuators" title="Click to go to the Keyword Index">
               Soft Sensors and Actuators
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Soft robots hold the potential for use in disaster sites where it is difficult to predict the external environment and the manipulation of irregularly shaped heavy objects is required. However, existing soft robots possess the low load capacity. Therefore, we propose a vine-like, power soft gripper that grasps an object by wrapping it, and we fabricated a prototype. The gripper is based on Euler’s belt theory, the load capacity increases with the wrap angle and it is demonstrated by load capacity measurements. A grasping experiment demonstrated that the gripper could grasp objects of various shapes. This gripper wraps around an object using the restoring force exerted by the constant-force spring. Hence, the gripper cannot lift heavy objects that tend to rotate during lifting. However, it was confirmed that a twin-gripper with opposite helical directions could grasp such objects. It was also confirmed that twin-gripper could grasp an object weighing 1660 N although its two constant-force springs possess a small load of 43 N. This indicates that the grasping load force surpassed that generated by the spring coiling force. Finally, the gripper was attached to a construction machine robot, and a pick-and-place demonstration was conducted.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt4_03">
             18:00-18:15, Paper WeDT4.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3673'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Self-Sensing Origami-Inspired Soft Twisting Actuators and Its Application in Soft Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#181709" title="Click to go to the Author Index">
             Yang, Yang
            </a>
           </td>
           <td class="r">
            Nanjing University of Information Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#380496" title="Click to go to the Author Index">
             Yan, Shaoyang
            </a>
           </td>
           <td class="r">
            Nanjing University of Information Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#380498" title="Click to go to the Author Index">
             Xie, Yuan
            </a>
           </td>
           <td class="r">
            Nanjing University of Information Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#384135" title="Click to go to the Author Index">
             Wang, Yuchao
            </a>
           </td>
           <td class="r">
            Nanjing University of Information Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#246690" title="Click to go to the Author Index">
             Liu, Jia
            </a>
           </td>
           <td class="r">
            Nanjing University of Information Science &amp; Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#328602" title="Click to go to the Author Index">
             Li, Yunquan
            </a>
           </td>
           <td class="r">
            South China University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#208757" title="Click to go to the Author Index">
             Zhou, Jianshu
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3673" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#soft_sensors_and_actuators" title="Click to go to the Keyword Index">
               Soft Sensors and Actuators
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The good compliance of soft robots provides a reliable safety environment for human-robot interaction; however, it also creates challenges for adding sensors to soft robots. In this letter, we propose a self-sensing origami-inspired soft twisting actuator. The actuator is designed based on the structure of origami, enabling the compound motion of twist and contraction. The position sensor made from
             <p>
              flexible fabric material is integrated in the soft actuator body. With twisting angle feedback, the self-sensing twisting actuator can not only provide expected motion but also acquire additional environment information based on real-time sensing. This paper discusses the design, fabrication, and experimental validation of proposed self-sensing twisting actuator. Based on the self-sensing twisting actuator, a soft gripper, a soft robotic arm, and a soft hexapod robot,
              <p>
               all vacuum-powered, are designed and prototyped to validate their performance. The proposed soft actuator has great potential for applications in scenarios that require self-sensing information and closed-loop control.
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt4_04">
             18:15-18:30, Paper WeDT4.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3711'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Novel Design of a Pneumatic Longitudinal Actuator for Both Extending and Contracting Motions
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#369099" title="Click to go to the Author Index">
             Tago, Yasuka
            </a>
           </td>
           <td class="r">
            Waseda University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#272496" title="Click to go to the Author Index">
             Satake, Yuki
            </a>
           </td>
           <td class="r">
            Ritsumeikan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102723" title="Click to go to the Author Index">
             Ishii, Hiroyuki
            </a>
           </td>
           <td class="r">
            Waseda University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3711" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#soft_sensors_and_actuators" title="Click to go to the Keyword Index">
               Soft Sensors and Actuators
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#hydraulic_pneumatic_actuators" title="Click to go to the Keyword Index">
               Hydraulic/Pneumatic Actuators
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Various types of extendable and contractible soft actuators have been developed by utilizing their strength, lightweight, and flexibility. Most soft actuators focus on either the extending or contracting motion. In this study, we aim to achieve both motions in a single actuator. We propose a novel lightweight soft extendible actuator driven solely by air. Driven in low pressure, this actuator exhibits a high contraction rate and extends without the aid of any external force, such as gravity, and contracts under tension loads. The actuator weighed 191 g and realized a maximum length of 980 mm at extension and contraction rates of 870%. We experimentally evaluated the performance of the actuator with respect to the operating parameters and internal pressure during the extending motion and with respect to the exhaust air volume and contraction rate during the contracting motion under the application of a contraction force. The results indicate that the actuation principle can effectively prevent buckling. Additionally, an efficient contracting motion can be achieved as the contraction force relies on the exhaust volume and length.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wedt5">
             <b>
              WeDT5
             </b>
            </a>
           </td>
           <td class="r">
            Room 5
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wedt5" title="Click to go to the Program at a Glance">
             <b>
              Kinematics
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#238518" title="Click to go to the Author Index">
             Laha, Riddhiman
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#103731" title="Click to go to the Author Index">
             Mueller, Andreas
            </a>
           </td>
           <td class="r">
            Johannes Kepler University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt5_01">
             17:30-17:45, Paper WeDT5.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('80'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Enhanced Dexterity Maps (EDM): A New Map for Manipulator Capability Analysis
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#355185" title="Click to go to the Author Index">
             Yao, Haowen
            </a>
           </td>
           <td class="r">
            Technical Univerity of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#238518" title="Click to go to the Author Index">
             Laha, Riddhiman
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#156255" title="Click to go to the Author Index">
             Figueredo, Luis
            </a>
           </td>
           <td class="r">
            University of Nottingham (UoN)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#108317" title="Click to go to the Author Index">
             Haddadin, Sami
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab80" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#kinematics" title="Click to go to the Keyword Index">
               Kinematics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#redundant_robots" title="Click to go to the Keyword Index">
               Redundant Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The ability of a manipulator to compute a geometry- aware quality index for general tasks with different joint configurations is essential. Such workspace assessment is a well-known and studied field in existing robotics literature, often deployed through embodied structures such as voxelized maps. Notwithstanding, existing literature solely focuses on the assessment of a single pose (end-effector), neglecting the whole- body structure and its dexterity, which allows for secondary task optimization, nullspace motion, body placement, and improved manipulability. The proposed Enhanced Dexterity Maps (EDM) aims to close these gaps using an augmented data structure. It offers a systematic analysis of disjoint flip solutions and accommodates additional performance metrics. Further analysis of EDMs through case studies highlights the limitations of existing methods and supports the need for a whole-body analysis.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt5_02">
             17:45-18:00, Paper WeDT5.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3641'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              An Inverse Kinematics Algorithm with Smooth Task Switching for Redundant Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#332021" title="Click to go to the Author Index">
             Gamper, Hannes
            </a>
           </td>
           <td class="r">
            CERN - European Organization for Nuclear Research
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#365474" title="Click to go to the Author Index">
             Rodrigo Perez, Laura
            </a>
           </td>
           <td class="r">
            CERN
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103731" title="Click to go to the Author Index">
             Mueller, Andreas
            </a>
           </td>
           <td class="r">
            Johannes Kepler University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#332023" title="Click to go to the Author Index">
             Díaz Rosales, Alejandro
            </a>
           </td>
           <td class="r">
            CERN; Delft University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#184518" title="Click to go to the Author Index">
             Di Castro, Mario
            </a>
           </td>
           <td class="r">
            CERN, European Organization for Nuclear Research
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3641" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#kinematics" title="Click to go to the Keyword Index">
               Kinematics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#redundant_robots" title="Click to go to the Keyword Index">
               Redundant Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#control_architectures_and_programming" title="Click to go to the Keyword Index">
               Control Architectures and Programming
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents an inverse kinematics approach that combines two well-known Jacobian based methods, the task-priority framework and an optimization-based approach, such that tracking and optimization tasks can be executed simultaneously. textcolor{red}{The novelty of the proposed algorithm lies in the ability to smoothly switch between different tasks and thus to allow for a seamless and safe transition during robot operation.} This has shown to improve the efficiency and user experience, especially during tele-operated interventions in complex environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt5_03">
             18:00-18:15, Paper WeDT5.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3741'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Globally Optimal Inverse Kinematics As a Non-Convex Quadratically Constrained Quadratic Program
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#385475" title="Click to go to the Author Index">
             Votroubek, Tomáš
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague, Faculty of Electrical Engi
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#385486" title="Click to go to the Author Index">
             Kroupa, Tomas
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3741" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#kinematics" title="Click to go to the Keyword Index">
               Kinematics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#redundant_robots" title="Click to go to the Keyword Index">
               Redundant Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We show how to compute globally optimal solutions to inverse kinematics
             <p>
              (IK) by formulating the problem as a non-convex quadratically constrained quadratic program. Our approach makes it feasible to solve IK instances of generic redundant manipulators. We demonstrate the performance on randomly generated designs and on real-world robots with
              <p>
               up to ten revolute joints. The same technique can be used for manipulator design by introducing kinematic parameters as variables.
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt5_04">
             18:15-18:30, Paper WeDT5.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('111'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Kinematics-Informed Neural Networks: Enhancing Generalization Performance of Soft Robot Model Identification
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#336020" title="Click to go to the Author Index">
             Yoon, Taerim
            </a>
           </td>
           <td class="r">
            Korea University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#312208" title="Click to go to the Author Index">
             Chai, Yoonbyung
            </a>
           </td>
           <td class="r">
            Korea University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#318549" title="Click to go to the Author Index">
             Jang, Yeonwoo
            </a>
           </td>
           <td class="r">
            Ulsan National Institute of Science and Technology (UNIST)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#340601" title="Click to go to the Author Index">
             Lee, Hajun
            </a>
           </td>
           <td class="r">
            Ulsan National Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#340286" title="Click to go to the Author Index">
             Kim, Junghyo
            </a>
           </td>
           <td class="r">
            Ulsan National Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#223528" title="Click to go to the Author Index">
             Kwon, Jaewoon
            </a>
           </td>
           <td class="r">
            NAVER LABS
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#318116" title="Click to go to the Author Index">
             Kim, Jiyun
            </a>
           </td>
           <td class="r">
            Ulsan National Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#163618" title="Click to go to the Author Index">
             Choi, Sungjoon
            </a>
           </td>
           <td class="r">
            Korea University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab111" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#modeling__control__and_learning_for_soft_robots" title="Click to go to the Keyword Index">
               Modeling, Control, and Learning for Soft Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#model_learning_for_control" title="Click to go to the Keyword Index">
               Model Learning for Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             A hybrid system combining rigid and soft robots (e.g., soft fingers attached to a rigid arm) ensures safe and dexterous interaction with humans. Nevertheless, modeling complex movements involving both soft and rigid robots presents a challenge. Additionally, the difficulty of obtaining large datasets for soft robots, due to the risk of damage by repetitive and extreme actuations, hiders the utilization of data-driven approaches. In this study, we present a Kinematics-Informed Neural Network (KINN), which incorporates rigid body kinematics as an inductive bias to enhance sample efficiency and provide holistic control for the hybrid system. The model identification performance of the proposed method is extensively evaluated in simulated and real-world environments using pneumatic and tendon-driven soft robots. The evaluation result shows employing a kinematic prior leads to an 80.84% decrease in positional error measured in the L1-norm for extrapolation tasks in real-world tendon-driven soft robots. We also demonstrate the dexterous and holistic control of the rigid arm with soft fingers by opening bottles and painting letters. The codes and dataset are made available at https://github.com/terry97-guel/KINN.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wedt6">
             <b>
              WeDT6
             </b>
            </a>
           </td>
           <td class="r">
            Room 6
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wedt6" title="Click to go to the Program at a Glance">
             <b>
              Aerial Systems: Applications II
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#113384" title="Click to go to the Author Index">
             Saska, Martin
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#200893" title="Click to go to the Author Index">
             Gao, Fei
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt6_01">
             17:30-17:45, Paper WeDT6.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('89'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Energy-Aware Multi-UAV Coverage Mission Planning with Optimal Speed of Flight
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#369701" title="Click to go to the Author Index">
             Datsko, Denys
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#285936" title="Click to go to the Author Index">
             Nekovar, Frantisek
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#181627" title="Click to go to the Author Index">
             Penicka, Robert
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#113384" title="Click to go to the Author Index">
             Saska, Martin
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab89" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#planning__scheduling_and_coordination" title="Click to go to the Keyword Index">
               Planning, Scheduling and Coordination
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper tackles the problem of planning minimum-energy coverage paths for multiple UAVs. The addressed Multi-UAV Coverage Path Planning~(mCPP) is a crucial problem for many UAV applications such as inspection and aerial survey. However, the typical path-length objective of existing approaches does not directly minimize the energy consumption, nor allows for constraining energy of individual paths by the battery capacity. To this end, we propose a novel mCPP method that uses the optimal flight speed for minimizing energy consumption per traveled distance and a simple yet precise energy consumption estimation algorithm that is utilized during the mCPP planning phase. The method decomposes a given area with boustrophedon decomposition and represents the mCPP as an instance of Multiple Set Traveling Salesman Problem with a minimum energy objective and energy consumption constraint. The proposed method is shown to outperform state-of-the-art methods in terms of computational time and energy efficiency of produced paths. The experimental results show that the accuracy of the energy consumption estimation is on average 97% compared to real flight consumption. The feasibility of the proposed method was verified in a real-world coverage experiment with two UAVs.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt6_02">
             17:45-18:00, Paper WeDT6.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('437'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              High-Speed Detector for Low-Powered Devices in Aerial Grasping
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#211512" title="Click to go to the Author Index">
             Kumar, Ashish
            </a>
           </td>
           <td class="r">
            Indian Institute of Technology, Kanpur
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#121875" title="Click to go to the Author Index">
             Behera, Laxmidhar
            </a>
           </td>
           <td class="r">
            IIT Kanpur
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab437" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#agricultural_automation" title="Click to go to the Keyword Index">
               Agricultural Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Autonomous aerial harvesting is a highly complex problem because it requires numerous interdisciplinary algo- rithms to be executed on mini low-powered computing devices. Object detection is one such algorithm that is compute-hungry. In this context, we make the following contributions: (i) Fast Fruit Detector (FFD), a resource-efficient, single-stage, and postprocessing-free object detector based on our novel latent object representation (LOR) module, query assignment, and prediction strategy. FFD achieves 100FPS@FP32 precision on the latest 10W NVIDIA Jetson-NX embedded device while co- existing with other time-critical sub-systems such as control, grasping, SLAM, a major achievement of this work. (ii) a method to generate vast amounts of training data without exhaustive manual labelling of fruit images since they consist of a large number of instances, which increases the labelling cost and time. (iii) an open-source fruit detection dataset having plenty of very small-sized instances that are difficult to detect. Our exhaustive evaluations on our and MinneApple dataset show that FFD, being only a single-scale detector, is more accurate than many representative detectors, e.g. FFD is better than single-scale Faster-RCNN by 10.7AP, multi-scale Faster-RCNN by 2.3AP, and better than latest single-scale YOLO-v8 by 8AP and multi-scale YOLO-v8 by 0.3 while being considerably faster.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt6_03">
             18:00-18:15, Paper WeDT6.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2407'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Autonomous Landing on a Moving Platform Using Vision-Based Deep Reinforcement Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#305538" title="Click to go to the Author Index">
             Ladosz, Pawel
            </a>
           </td>
           <td class="r">
            University of Manchester
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#339826" title="Click to go to the Author Index">
             Mammadov, Meraj
            </a>
           </td>
           <td class="r">
            Ulsan National Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#339757" title="Click to go to the Author Index">
             Shin, Heejung
            </a>
           </td>
           <td class="r">
            Ulsan National Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#339751" title="Click to go to the Author Index">
             Shin, Woojae
            </a>
           </td>
           <td class="r">
            Ulsan National Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#148890" title="Click to go to the Author Index">
             Oh, Hyondong
            </a>
           </td>
           <td class="r">
            UNIST
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2407" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper describes autonomous landing of an unmanned aircraft system on a moving platform using vision and deep reinforcement learning. Landing on the moving platform offers several benefits such as more mission flexibility and reduced flight time. In particular, the end-to-end vision approach (i.e., an input to the reinforcement learning is a raw image from the camera) with the deep regularized Q algorithm and custom designed reward is utilized. The custom reward was specifically devised to encourage useful feature extraction from the state space. Additionally, the proposed reinforcement learning algorithm has full 3D velocity control including the vertical channel. The simulation results show that the proposed approach can outperform existing approaches which use high-level extracted features (such as relative position and velocity of the landing pad). The simulation results are then successfully transferred to the real-world experiment by utilizing domain randomization.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt6_04">
             18:15-18:30, Paper WeDT6.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3702'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Impact-Aware Planning and Control for Aerial Robots with Suspended Payloads (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#255045" title="Click to go to the Author Index">
             Wang, Haokun
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#291103" title="Click to go to the Author Index">
             Li, Haojia
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#225160" title="Click to go to the Author Index">
             Zhou, Boyu
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#200893" title="Click to go to the Author Index">
             Gao, Fei
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#142354" title="Click to go to the Author Index">
             Shen, Shaojie
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3702" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             A quadrotor with a cable-suspended payload imposes great challenges in impact-aware planning and control. This joint system has dual motion modes, depending on whether the cable is slack or not, and presents complicated dynamics. Therefore, generating feasible agile flight while
             <p>
              preserving the retractable nature of the cable is still a challenging task. In this paper, we propose a novel impact-aware planning and control framework that resolves potential impacts caused by motion mode
              <p>
               switching. Our method leverages the augmented Lagrangian method (ALM) to solve an optimization problem with nonlinear complementarity constraints (ONCC), which ensures trajectory feasibility with high accuracy while maintaining efficiency. We further propose a hybrid nonlinear model predictive control method to address the model mismatch
               <p>
                issue in agile flight. Our methods have been comprehensively validated in both simulation and experiments, demonstrating superior performance compared to existing approaches. To the best of our knowledge, we are the first to successfully perform automatic multiple motion mode switching for aerial payload systems in real-world experiments.
               </p>
              </p>
             </p>
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wedt7">
             <b>
              WeDT7
             </b>
            </a>
           </td>
           <td class="r">
            Room 7
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wedt7" title="Click to go to the Program at a Glance">
             <b>
              Surgical Robotics I
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#100085" title="Click to go to the Author Index">
             Hollis, Ralph
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#101725" title="Click to go to the Author Index">
             Fiorini, Paolo
            </a>
           </td>
           <td class="r">
            University of Verona
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt7_01">
             17:30-17:45, Paper WeDT7.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('698'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Novel Miniature Flexible Instrument with Unfolding and Decoupling Design for Endoscopic Surgery
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#334545" title="Click to go to the Author Index">
             Zhang, Chi
            </a>
           </td>
           <td class="r">
            Tianjin University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#365922" title="Click to go to the Author Index">
             Wang, Yi
            </a>
           </td>
           <td class="r">
            Tianjin University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#315347" title="Click to go to the Author Index">
             Liang, Tao
            </a>
           </td>
           <td class="r">
            Tianjin University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#208000" title="Click to go to the Author Index">
             Kong, Kang
            </a>
           </td>
           <td class="r">
            Tianjin University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#365861" title="Click to go to the Author Index">
             Yao, Qiwen
            </a>
           </td>
           <td class="r">
            Tianjin University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#168140" title="Click to go to the Author Index">
             Zuo, Siyang
            </a>
           </td>
           <td class="r">
            Tianjin University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab698" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#flexible_robotics" title="Click to go to the Keyword Index">
               Flexible Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#surgical_robotics__laparoscopy" title="Click to go to the Keyword Index">
               Surgical Robotics: Laparoscopy
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Nowadays, gastrointestinal cancer has widely impacted people's health worldwide due to its high mortality rate. Early treatment of gastrointestinal cancer by endoscopic procedure can greatly increase survival rates of patients. However, current flexible endoscopic instruments lack of degree of freedom and surgical triangulation, which
             <p>
              makes the endoscopic procedure difficult. To solve these problems, this
              <p>
               paper proposes a new type of miniature dual-bending flexible instrument
               <p>
                with an outer diameter of 2.8 mm and a length of 1100 mm, which is compatible with commercial endoscope and various endoscopic platforms. Discrete frame stacking structure with unfolding and decoupling design makes the instrument achieving high flexibility, accurate bending motions and surgical triangulation. The flexible instrument can achieve
                <p>
                 a large hemi-spherical workspace with a radius of 24 mm without considering linear movement. The measured tip positioning accuracy is better than 0.59 mm for wrist bending motion. Combined with the various
                 <p>
                  end effectors, the instrument can perform complex endoscopic procedures
                  <p>
                   through the master-slave control method. Through in-vivo animal experiments, the clinical potential and practicality of the instrument have been demonstrated.
                  </p>
                 </p>
                </p>
               </p>
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt7_02">
             17:45-18:00, Paper WeDT7.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('64'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              DaFoEs: Mixing Datasets towards the Generalization of Vision-State Deep-Learning Force Estimation in Minimally Invasive Robotic Surgery
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#332711" title="Click to go to the Author Index">
             De Iturrate Reyzabal, Mikel
            </a>
           </td>
           <td class="r">
            King's College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#337750" title="Click to go to the Author Index">
             Chen, Mingcong
            </a>
           </td>
           <td class="r">
            City University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#366899" title="Click to go to the Author Index">
             Huang, Wei
            </a>
           </td>
           <td class="r">
            CAIR
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#124246" title="Click to go to the Author Index">
             Ourselin, Sebastien
            </a>
           </td>
           <td class="r">
            University College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104575" title="Click to go to the Author Index">
             Liu, Hongbin
            </a>
           </td>
           <td class="r">
            Hong Kong Institute of Science &amp; Innovation, Chinese Academy Of
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab64" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#surgical_robotics__laparoscopy" title="Click to go to the Keyword Index">
               Surgical Robotics: Laparoscopy
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robot_learning" title="Click to go to the Keyword Index">
               Data Sets for Robot Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Precisely determining the contact force during safe interaction in Minimally Invasive Robotic Surgery (MIRS) is still an open research challenge. Inspired by post-operative qualitative analysis from surgical videos, the use of cross- modality data driven deep neural network models has been one of the newest approaches to predict sensorless force trends. However, these methods required for large and variable datasets which are not currently available. In this paper, we present a new vision-haptic dataset (DaFoEs) with variable soft environments for the training of deep neural models. In order to reduce the bias from a single dataset, we present a pipeline to generalize different vision and state data inputs for mixed dataset training, using a previously validated dataset with different setup. Finally, we present a variable encoder-decoder architecture to predict the forces done by the laparoscopic tool using single input or sequence of inputs. For input sequence, we use a recurrent decoder, named with the prefix R, and a new temporal sampling to represent the acceleration of the tool. During our training, we demonstrate that single dataset training tends to overfit to the training data domain, but has difficulties on translating the results across new domains. However, dataset mixing presents a good translation with a mean relative estimated force error of 5% and 12% for the recurrent and non-recurrent models respectively. Our method, also marginally increase the effectiveness of transformers for force estimation up to a maximum of ≃ 15%, as the volume of available data is increase by 150%. In conclusion, we demonstrate that mixing experimental set ups for vision-state force estimation in MIRS is a possible approach towards the general
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt7_03">
             18:00-18:15, Paper WeDT7.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3537'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              FNPG-NH: A Reinforcement Learning Framework for Flexible Needle Path Generation with Nonholonomic Constraints
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#361663" title="Click to go to the Author Index">
             Shah, Mukund
            </a>
           </td>
           <td class="r">
            IIT Madras
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#221695" title="Click to go to the Author Index">
             Patel, Niravkumar
            </a>
           </td>
           <td class="r">
            Indian Institute of Technology Madras
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3537" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#surgical_robotics__planning" title="Click to go to the Keyword Index">
               Surgical Robotics: Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#surgical_robotics__steerable_catheters_needles" title="Click to go to the Keyword Index">
               Surgical Robotics: Steerable Catheters/Needles
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Path planning algorithms for minimally invasive neurosurgery involve avoiding critical structures such as blood vessels and ventricles while
             <p>
              following needle kinematics. The majority of planning solutions proposed in the literature use sampling-based algorithms. This paper introduces a Flexible Needle Path Generation framework with Non-Holonomic constraints (FNPG-NH), an extension of our FNPG framework. FNPG-NH uses deep Reinforcement Learning (RL) based methods such as Deep Deterministic Policy Gradient (DDPG), Proximal Policy Optimization (PPO), and Soft Actor-Critic (SAC) to obtain a kinematically feasible path for a bevel-tipped flexible needle using a nonholonomic model. RL algorithms presented in this work generate the control input for needle rotation based on the rewards generated by the
              <p>
               environment. The deep RL algorithms are trained on an environment that
               <p>
                consists of (1) ventricles segmented from T1 images of the healthy volunteers using atlas-based segmentation, (2) blood vessels segmented from MRA volumes of the same volunteer using thresholding, and (3) tumor volume from labeled BraTS 2020 dataset and placed at an anatomically relevant location. The paths generated by the reinforcement learning algorithm and the traditional sampling-based algorithm RRT are compared
                <p>
                 for various performance metrics. The reinforcement learning model was trained on 20 volumes and validated on 68 volumes, and RRT was evaluated on the same 68 validation volumes. The results show that the trajectories generated by the FNPG-NH framework are safer, shorter, and
                 <p>
                  take less time than RRT while avoiding critical structures such as ventricles and blood vessels.
                 </p>
                </p>
               </p>
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt7_04">
             18:15-18:30, Paper WeDT7.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('948'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Wheelchair Maneuvering with a Single-Spherical-Wheeled Balancing Mobile Manipulator
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#322941" title="Click to go to the Author Index">
             Dai, Cunxi
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#310587" title="Click to go to the Author Index">
             Liu, Xiaohan
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#196564" title="Click to go to the Author Index">
             Shu, Roberto
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100085" title="Click to go to the Author Index">
             Hollis, Ralph
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab948" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#service_robotics" title="Click to go to the Keyword Index">
               Service Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#humanoid_robot_systems" title="Click to go to the Keyword Index">
               Humanoid Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#dynamics" title="Click to go to the Keyword Index">
               Dynamics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this work, we present a control framework to effectively maneuver wheelchairs with a dynamically stable mobile manipulator. Wheelchairs are a type of nonholonomic cart system, maneuvering such systems with mobile manipulators (MM) is challenging mostly due to the following reasons: 1) These systems feature nonholonomic constraints and considerably varying inertial parameters that require online identification and adaptation. 2) These systems are widely used in human-centered environments, which demand the MM to operate in potentially crowded spaces while ensuring compliance for safe physical human-robot interaction (pHRI). We propose a control framework that plans whole-body motion based on quasi-static analysis to maneuver heavy nonholonomic carts while maintaining overall compliance. We validated our approach experimentally by maneuvering a wheelchair with a bimanual mobile manipulator, the CMU ballbot. The experiments demonstrate the proposed framework is able to track desired wheelchair velocity with loads varying from 11.8 kg to 79.4 kg at a maximum linear velocity of 0.45 m/s and angular velocity of 0.3 rad/s. Furthermore, we verified that the proposed method can generate human-like motion smoothness of the wheelchair while ensuring safe interactions with the environment.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wedt8">
             <b>
              WeDT8
             </b>
            </a>
           </td>
           <td class="r">
            Room 8
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wedt8" title="Click to go to the Program at a Glance">
             <b>
              Localization III
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#107437" title="Click to go to the Author Index">
             Lima, Pedro U.
            </a>
           </td>
           <td class="r">
            Instituto Superior Técnico - Institute for Systems and Robotics
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt8_01">
             17:30-17:45, Paper WeDT8.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3655'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Autonomous Vehicle Localization without Prior High-Definition Map (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#286458" title="Click to go to the Author Index">
             Lee, Sangmin
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102369" title="Click to go to the Author Index">
             Ryu, Jee-Hwan
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3655" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#place_recognition" title="Click to go to the Keyword Index">
               Place Recognition
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Accurate localization by which vehicles can arrive at their destination while accurately following a given route is one of the most important factors for autonomous driving. In recent years, numerous studies have been conducted to achieve accurate localization using high-definition (HD) maps. Based on the HD map information (e.g., spatial data, lane, and traffic sign), autonomous vehicles can localize themselves by matching the surrounding spatial information obtained from onboard sensors to the HD maps. However, generating HD maps is a time-consuming and costly task. This study introduces a time-saving, effective, and accurate localization method inspired by humans, using only onboard sensors and publicly available two-dimensional (2D) map information. Similar to the multi- level localization process performed by humans, the proposed method interprets and matches the surrounding spatial data to the publicly available 2D maps using deep-learning-based place recognition and simultaneous localization and mapping (SLAM), thereby enabling autonomous vehicles to localize even without prior HD maps. Through the proposed method, our framework enables autonomous vehicles to perform maximal
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt8_02">
             17:45-18:00, Paper WeDT8.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3668'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Forward Prediction of Target Localization Failure through Pose Estimation Artifact Modelling
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#336612" title="Click to go to the Author Index">
             Windsor, Morgan
            </a>
           </td>
           <td class="r">
            Queensland University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#240195" title="Click to go to the Author Index">
             Fontan, Alejandro
            </a>
           </td>
           <td class="r">
            Queensland University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#336858" title="Click to go to the Author Index">
             Pivonka, Peter
            </a>
           </td>
           <td class="r">
            Queensland University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106848" title="Click to go to the Author Index">
             Milford, Michael J
            </a>
           </td>
           <td class="r">
            Queensland University of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3668" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_medical_robotics" title="Click to go to the Keyword Index">
               Computer Vision for Medical Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             For safety critical applications the ability of localization systems to self-assess their own performance and know when they are failing is as important as absolute accuracy. Previous methods have self-assessed current system performance, identifying failure after it occurs. We propose to instead pre-emptively avoid failure by predicting likely localization performance at locations not yet explored by a robot. To achieve this, we propose an approach for supervising a target object localization system by modelling trends in internal pipeline artifacts that are predictive of localization accuracy. We use this model to predict where acceptable localization performance is possible and where failure is likely. We evaluate our approach with both off-line recorded datasets and live robot experiments in the context of an upper limb surgical task using human bone phantoms as localization targets. We demonstrate our approach implemented as both a Long Range Predictor for use in informing future planning, and a Next-Step Predictor, for ongoing task supervision to stop a robot before reaching localization failure. We show that our method provides significant improvement over a naive baseline achieving a mean increase in safe path length, or usable workspace, without localization failure of 84.1% for our long range predictor and 102.1% for our next-step predictor.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt8_03">
             18:00-18:15, Paper WeDT8.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3736'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Geo-Localization Based on Dynamically Weighted Factor-Graph
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#298731" title="Click to go to the Author Index">
             Muñoz-Bañón, Miguel Ángel
            </a>
           </td>
           <td class="r">
            University of Alicante
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#367867" title="Click to go to the Author Index">
             Olivas, Alejandro
            </a>
           </td>
           <td class="r">
            University of Alicante
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#232554" title="Click to go to the Author Index">
             Velasco Sánchez, Edison Patricio
            </a>
           </td>
           <td class="r">
            Universidad De Alicante
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#117343" title="Click to go to the Author Index">
             Candelas, Francisco A.
            </a>
           </td>
           <td class="r">
            University of Alicante
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#286636" title="Click to go to the Author Index">
             Torres Medina, Fernando
            </a>
           </td>
           <td class="r">
            Instituto Universitario De Investigación Informática (IUII). Uni
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3736" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Feature-based geo-localization relies on associating features extracted from aerial imagery with those detected by the vehicle's sensors. This requires that the type of landmarks must be observable from both sources. This lack of variety of feature types generates poor representations that lead to outliers and deviations produced by ambiguities and lack of detections, respectively. To mitigate these drawbacks, in this paper, we present a dynamically weighted factor graph model for the vehicle's trajectory estimation. The weight adjustment in this implementation depends on information quantification in the detections performed using a LiDAR sensor. Also, a prior (GNSS-based) error estimation is included in the model. Then, when the representation becomes ambiguous or sparse, the weights are dynamically adjusted to rely on the corrected prior trajectory, mitigating outliers and deviations in this way. We compare our method against state-of-the-art geo-localization ones in a challenging and ambiguous environment, where we also cause detection losses. We demonstrate mitigation of the mentioned drawbacks where the other methods fail.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt8_04">
             18:15-18:30, Paper WeDT8.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3763'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Triplet-Graph: Global Metric Localization Based on Semantic Triplet Graph for Autonomous Vehicles
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#314234" title="Click to go to the Author Index">
             Ma, Weixin
            </a>
           </td>
           <td class="r">
            The Hong Kong Polytechnic University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101879" title="Click to go to the Author Index">
             Huang, Shoudong
            </a>
           </td>
           <td class="r">
            University of Technology, Sydney
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#178095" title="Click to go to the Author Index">
             Sun, Yuxiang
            </a>
           </td>
           <td class="r">
            City University of Hong Kong
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3763" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Global metric localization is one of the fundamental capabilities for autonomous vehicles. Most existing methods rely on global navigation satellite systems (GNSS). Some methods relieve the need of GNSS by using 3-D LiDARs. They first achieve place recognition with a pre-built geo-referenced point-cloud database for coarse global localization, and then achieve 3-DoF/6-DoF pose estimation for fine-grained metric localization. However, these methods require accessing point-cloud features and raw point clouds, making them inefficient and hard to be deployed in large-scale environments. To provide a solution to this issue, we propose a global metric localization method with triplet-based histogram descriptors. Specifically, we first convert the input LiDAR point clouds into a semantic graph and describe the vertices in the graph with the proposed descriptor for vertex matching and pose estimation. These vertex descriptors are then selected and aggregated into a global descriptor to decide whether two places correspond to the same place according to a similarity score. Experimental results on the KITTI dataset demonstrate that our method generally outperforms the sate-of-the-art methods.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wedt9">
             <b>
              WeDT9
             </b>
            </a>
           </td>
           <td class="r">
            Room 9
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wedt9" title="Click to go to the Program at a Glance">
             <b>
              Motion and Path Planning III
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#100088" title="Click to go to the Author Index">
             Siegwart, Roland
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt9_01">
             17:30-17:45, Paper WeDT9.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('72'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              An Efficient Linear Programming-Based Time-Optimal Feedrate Planning Considering Kinematic and Dynamics Constraints of Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#271533" title="Click to go to the Author Index">
             Liu, Guanghui
            </a>
           </td>
           <td class="r">
            Shenyang University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#149603" title="Click to go to the Author Index">
             Li, Qiang
            </a>
           </td>
           <td class="r">
            Shenzhen Technology University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372069" title="Click to go to the Author Index">
             Yang, Bohan
            </a>
           </td>
           <td class="r">
            Shenyang Institute of Automation, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#276557" title="Click to go to the Author Index">
             Zhang, Hualiang
            </a>
           </td>
           <td class="r">
            Shenyang Institute of Automation, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#230174" title="Click to go to the Author Index">
             Fang, Lijin
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab72" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#constrained_motion_planning" title="Click to go to the Keyword Index">
               Constrained Motion Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper investigates the time-optimal trajectorygeneration for a six-degrees-of-freedom articulated robot moving along a given parametric path. In the generation procedure,besides the velocity, acceleration, and joint torque, the jerk is also constrained to enhance the smoothness of the robot’s motion.Meanwhile, the trajectory generation is formulated as a convex optimization problem with a nonlinear objective function and constraints. Then, the problem is solved with a typical linear programming (LP) approach by discretizing the continuous path into many sampling points. Specifically, the time-optimal problem is formulated as maximizing the sum of the velocities at all discrete points instead of minimizing time. Moreover, the time-optimal trajectory generation with nonlinear jerk constraints is decoupled into two sub-LP problems, and the solution of the first sub-LP is employed to scale the nonlinear constraints. Finally, the proposed method is verified through robotic experiments. The results indicate that the smoothness of the generated trajectory improves significantly. Also, the trajectory planning accuracy and computational efficiency are increased by 36% and 62%, respectively.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt9_02">
             17:45-18:00, Paper WeDT9.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('616'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Model-Based Trajectory Planning of a Hybrid Robot for Powerline Inspection
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#336632" title="Click to go to the Author Index">
             Li, Zhishuo
            </a>
           </td>
           <td class="r">
            Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#336633" title="Click to go to the Author Index">
             Tian, Yunong
            </a>
           </td>
           <td class="r">
            Institute of Automation, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#165588" title="Click to go to the Author Index">
             Yang, Guodong
            </a>
           </td>
           <td class="r">
            Institute of Automation, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#334760" title="Click to go to the Author Index">
             Zhang, Yanfeng
            </a>
           </td>
           <td class="r">
            Institute of Automation, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#165628" title="Click to go to the Author Index">
             Li, En
            </a>
           </td>
           <td class="r">
            Institute of Automation, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#165623" title="Click to go to the Author Index">
             Liang, Zize
            </a>
           </td>
           <td class="r">
            Institute of Automation, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102455" title="Click to go to the Author Index">
             Tan, Min
            </a>
           </td>
           <td class="r">
            Institute of Automation, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab616" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#constrained_motion_planning" title="Click to go to the Keyword Index">
               Constrained Motion Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This letter presents the first trajectory planning method for hybrid robot to perform powerline inspection involving obstacle crossing and landing. We develop a geometric model that incorporates constraints for landing the hybrid robot on a powerline, obstacle avoidance, and objectives that maximize the visibility of the powerline during flight. The trajectory generation is achieved via solving a multiple shooting nonlinear programming problem with respect to system dynamics and geometric constraints. The formulation of the problem accommodates both powerline-to-powerline and air-to-powerline trajectory planning scenarios. It runs onboard and is capable of generating trajectories within 50 ms, regardless of whether the hybrid robot's initial state is positioned on the powerline or hovering above it. Through simulation experiments, we illustrate the impact of our proposed geometric model on trajectory planning. Furthermore, real-world experimental results validate the efficacy of the proposed planning method. Compared with the existing feedback-control-based work, the landing and obstacle crossing time are significantly reduced.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt9_03">
             18:00-18:15, Paper WeDT9.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('60'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Geometry-Aware Safety-Critical Local Reactive Controller for Robot Navigation in Unknown and Cluttered Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#339738" title="Click to go to the Author Index">
             Li, Yulin
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology(HKUST)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#380463" title="Click to go to the Author Index">
             Tang, Xindong
            </a>
           </td>
           <td class="r">
            Hong Kong Baptist University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#285922" title="Click to go to the Author Index">
             Chen, Kai
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#380449" title="Click to go to the Author Index">
             Zheng, Chunxin
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology(Guangzhou)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#352797" title="Click to go to the Author Index">
             Liu, Haichao
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#182083" title="Click to go to the Author Index">
             Ma, Jun
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab60" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This work proposes a safety-critical local reactive controller that enables the robot to navigate in unknown and cluttered environments. In particular, the trajectory tracking task is formulated as a constrained polynomial optimization problem. Then, safety constraints are imposed on the control variables invoking the notion of polynomial positivity certificates in conjunction with their Sum-of-Squares (SOS) approximation, thereby confining the robot motion inside the locally extracted convex free region. It is noteworthy that, in the process of devising the proposed safety constraints, the geometry of the robot can be approximated using any shape that can be characterized with a set of polynomial functions. The optimization problem is further convexified into a semidefinite program (SDP) leveraging truncated multi-sequences (tms) and moment relaxation, which favorably facilitates the effective use of off-the-shelf conic programming solvers, such that real-time performance is attainable. Various robot navigation tasks are investigated to demonstrate the effectiveness of the proposed approach in terms of safety and tracking performance.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt9_04">
             18:15-18:30, Paper WeDT9.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3693'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              GMPC: Geometric Model Predictive Control for Wheeled Mobile Robot Trajectory Tracking
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#297049" title="Click to go to the Author Index">
             Tang, Jiawei
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#333413" title="Click to go to the Author Index">
             Wu, Shuang
            </a>
           </td>
           <td class="r">
            Huawei
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#370576" title="Click to go to the Author Index">
             Lan, Bo
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#370577" title="Click to go to the Author Index">
             Dong, Yahui
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#312381" title="Click to go to the Author Index">
             Jin, Yuqiang
            </a>
           </td>
           <td class="r">
            Zhejiang University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#371276" title="Click to go to the Author Index">
             Tian, Guangjian
            </a>
           </td>
           <td class="r">
            Huawei
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#198532" title="Click to go to the Author Index">
             Zhang, Wen-An
            </a>
           </td>
           <td class="r">
            Zhejiang University of Technology, China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#146878" title="Click to go to the Author Index">
             Shi, Ling
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3693" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The configuration of most robotic systems lies in continuous transformation groups. However, in mobile robot trajectory tracking, many recent works still naively utilize optimization methods for elements in vector space without considering the manifold constraint of the robot configuration. In this letter, we propose a geometric model predictive control (MPC) framework for wheeled mobile robot trajectory tracking. We first derive the error dynamics of the wheeled mobile robot trajectory tracking by considering its manifold constraint and kinematic constraint simultaneously. After that, we utilize the relationship between the Lie group and Lie algebra to convexify the tracking control problem, which enables us to solve the problem efficiently. Thanks to the Lie group formulation, our method tracks the trajectory more smoothly than existing nonlinear MPC. Simulations and physical experiments verify the effectiveness of our proposed methods. Our pure Python-based simulation platform will be available to benefit further research in the community.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wedt10">
             <b>
              WeDT10
             </b>
            </a>
           </td>
           <td class="r">
            Room 10
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wedt10" title="Click to go to the Program at a Glance">
             <b>
              Machine Learning for Vision
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#117516" title="Click to go to the Author Index">
             Sugiura, Komei
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt10_01">
             17:30-17:45, Paper WeDT10.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('248'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Mobile-Seed: Joint Semantic Segmentation and Boundary Detection for Mobile Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#363045" title="Click to go to the Author Index">
             Liao, Martin
            </a>
           </td>
           <td class="r">
            Wuhan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#384266" title="Click to go to the Author Index">
             Kang, Shuhao
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#349094" title="Click to go to the Author Index">
             Jianping, Li
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#384288" title="Click to go to the Author Index">
             Liu, Yang
            </a>
           </td>
           <td class="r">
            King's College of London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#217619" title="Click to go to the Author Index">
             Liu, Yun
            </a>
           </td>
           <td class="r">
            Agency for Science, Technology and Research (A*STAR)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#226426" title="Click to go to the Author Index">
             Dong, Zhen
            </a>
           </td>
           <td class="r">
            Wuhan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#384259" title="Click to go to the Author Index">
             Yang, Bisheng
            </a>
           </td>
           <td class="r">
            Wuhan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#215437" title="Click to go to the Author Index">
             Chen, Xieyuanli
            </a>
           </td>
           <td class="r">
            National University of Defense Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab248" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Precise and rapid delineation of sharp boundaries and robust semantics
             <p>
              is essential for numerous downstream robotic tasks, such as robot grasping and manipulation, real-time semantic mapping, and online sensor calibration performed on edge computing units. Although boundary
              <p>
               detection and semantic segmentation are complementary tasks, most studies focus on lightweight models for semantic segmentation but overlook the critical role of boundary detection. In this work, we introduce Mobile-Seed, a lightweight, dual-task framework tailored for simultaneous semantic segmentation and boundary detection. Our framework features a two-stream encoder, an active fusion decoder (AFD)
               <p>
                and a dual-task regularization approach. The encoder is divided into two pathways: one captures category-aware semantic information, while the other discerns boundaries from multi-scale features. The AFD module
                <p>
                 dynamically adapts the fusion of semantic and boundary information by learning channel-wise relationships, allowing for precise weight assignment of each channel. Furthermore, we introduce a regularization loss to mitigate the conflicts in dual-task learning and deep diversity
                 <p>
                  supervision. Compared to existing methods, the proposed Mobile-Seed offers a lightweight framework to simultaneously improve semantic segmentation performance and accurately locate object boundaries. Experiments on the Cityscapes dataset have shown that Mobile-Seed achieves notable improvement over the state-of-the-art (SOTA) baseline by 2.2 percentage points (pp) in mIoU and 4.2 pp in mF-score, while maintaining an online inference speed of 23.9 frames-per-second (FPS) with 1024boldsymbol{times}2048 resolution input on an RTX 2080 Ti GPU. Additional experiments on CamVid and PASCAL Context da
                 </p>
                </p>
               </p>
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt10_02">
             17:45-18:00, Paper WeDT10.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3757'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Exploring Recurrent Long-Term Temporal Fusion for Multi-View 3D Perception
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#385421" title="Click to go to the Author Index">
             Han, Chunrui
            </a>
           </td>
           <td class="r">
            MEGVII Technolegy
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#336233" title="Click to go to the Author Index">
             Yang, Jinrong
            </a>
           </td>
           <td class="r">
            Huazhong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#385455" title="Click to go to the Author Index">
             Sun, Jianjian
            </a>
           </td>
           <td class="r">
            Megvii Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#363133" title="Click to go to the Author Index">
             Ge, Zheng
            </a>
           </td>
           <td class="r">
            Waseda University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#385424" title="Click to go to the Author Index">
             Dong, Runpei
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#363135" title="Click to go to the Author Index">
             Zhou, Hongyu
            </a>
           </td>
           <td class="r">
            MEGVII Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#345437" title="Click to go to the Author Index">
             Mao, Weixin
            </a>
           </td>
           <td class="r">
            Waseda University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#385446" title="Click to go to the Author Index">
             Peng, Yuang
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#247146" title="Click to go to the Author Index">
             Li, Xiaoping
            </a>
           </td>
           <td class="r">
            Huazhong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#385453" title="Click to go to the Author Index">
             Zhang, Xiangyu
            </a>
           </td>
           <td class="r">
            Megvii Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3757" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#recognition" title="Click to go to the Keyword Index">
               Recognition
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Long-term temporal fusion is a crucial but often overlooked technique in camera-based Bird's-Eye-View (BEV) 3D perception. Existing methods are mostly in a parallel manner. While parallel fusion can benefit from long-term information, it suffers from increasing computational and memory overheads as the fusion window size grows. Alternatively, BEVFormer adopts a recurrent fusion pipeline so that history information can be efficiently integrated, yet it fails to benefit from longer temporal frames. In this paper, we explore an embarrassingly simple long-term recurrent fusion strategy built upon the LSS-based methods and find it already able to enjoy the merits from both sides, i.e., rich long-term information and efficient fusion pipeline. A temporal embedding module is further proposed to improve the model's robustness against occasionally missed frames in practical scenarios. We name this simple but effective fusing pipeline VideoBEV. Experimental results on the nuScenes benchmark show that VideoBEV obtains strong performance on various camera-based 3D perception tasks, including object detection (55.4% mAP and 62.9% NDS), segmentation (48.6% vehicle mIoU), tracking (54.8% AMOTA), and motion prediction (0.80m minADE and 0.463 EPA).
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt10_03">
             18:00-18:15, Paper WeDT10.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3536'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SACNet: A Scattered Attention-Based Network with Feature Compensator for Visual Localization
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#141164" title="Click to go to the Author Index">
             Wang, Ke
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#343109" title="Click to go to the Author Index">
             Jiang, Zhiqiang
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#312448" title="Click to go to the Author Index">
             Dai, Kun
            </a>
           </td>
           <td class="r">
            HIT
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#307554" title="Click to go to the Author Index">
             Xie, Tao
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#371667" title="Click to go to the Author Index">
             Jin, Ducheng
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#141271" title="Click to go to the Author Index">
             Li, Ruifeng
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#142000" title="Click to go to the Author Index">
             Zhao, Lijun
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#371670" title="Click to go to the Author Index">
             Chen, Xiao
            </a>
           </td>
           <td class="r">
            Wuhu HIT Robot Industry Technology Research Institute
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3536" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#transfer_learning" title="Click to go to the Keyword Index">
               Transfer Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Visual localization, an integral component of a vast array of computer applications, has been effectively resolved by scene coordinate regression (SCoRe) methods. However, due to the limited receptive field
             <p>
              of convolutional neural networks (CNNs), current SCoRe methods possess headaches in distinguishing comparable image patches in repetitive texture scenes, thus impairing localization performance. Recently, transformer exhibits remarkable capability in modelling long-range dependencies, which provides a remedy to the aforementioned problem. Whereas the transformer alleviates the deficiencies of CNNs, the quadratically computational cost of transformer leaves it incapable of handling intensive regression tasks, such as scene coordinates prediction. Towards this end, we introduce SACNet, a sparse attention-based network for efficient and accurate visual localization.
              <p>
               We overhaul the core designs of vanilla transformer and further propose
               <p>
                a multiple scattered transformer (MST) with linear complexity. MST consists of a multiple scattered attention (MSA) layer and a filtered feed-forward network (F-FFN).The MSA layer calculates the attention matrix along the channel dimension and adaptively retains the most profitable attention values for feature consolidation such that the consolidated features can better foster scene coordinate regression. F-FFN utilizes a gate mechanism that suppresses less pertinent features, where multi-scale depth-wise convolutions are further used to
                <p>
                 promote the information flow. After MST, SACNet develops a feature compensator (FC) that combines local geometry features with global context information to predict element-wise soft attention mask, thus enabling the network to adaptively reconcile the importance of local and gl
                </p>
               </p>
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt10_04">
             18:15-18:30, Paper WeDT10.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('38'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning-To-Rank Approach for Identifying Everyday Objects Using a Physical-World Search Engine
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#349995" title="Click to go to the Author Index">
             Kaneda, Kanta
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#368025" title="Click to go to the Author Index">
             Nagashima, Shunya
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#334315" title="Click to go to the Author Index">
             Korekata, Ryosuke
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#295707" title="Click to go to the Author Index">
             Kambara, Motonari
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#117516" title="Click to go to the Author Index">
             Sugiura, Komei
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab38" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#learning_categories_and_concepts" title="Click to go to the Keyword Index">
               Learning Categories and Concepts
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Domestic service robots offer a solution to the increasing demand for daily care and support. A human-in-the-loop approach that combines automation and operator intervention is considered to be a realistic approach to their use in society. Therefore, we focus on the task of retrieving target objects from open-vocabulary user instructions in a human-in-the-loop setting, which we define as the learning-to-rank physical objects (LTRPO) task. For example, given the instruction "Please go to the dining room which has a round table. Pick up the bottle on it,"	the model is required to output a ranked list of target objects that the operator/user can select. In this paper, we propose MultiRankIt, which is a novel approach for the LTRPO task. MultiRankIt introduces the Crossmodal Noun Phrase Encoder to model the relationship between phrases that contain referring expressions and the target bounding box, and the Crossmodal Region Feature Encoder to model the relationship between the target object and multiple images of its surrounding contextual environment. Additionally, we built a new dataset for the LTRPO task that consists of instructions with complex referring expressions accompanied by real indoor environmental images that feature various target objects. We validated our model on the dataset and it outperformed the baseline method in terms of the mean reciprocal rank and recall@k. Furthermore, we conducted physical experiments in a setting where a domestic service robot retrieved everyday objects in a standardized domestic environment, based on users' instruction in a human-in-the-loop setting. The experimental results demonstrate that the success rate for object retrieval achieved 80%.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wedt11">
             <b>
              WeDT11
             </b>
            </a>
           </td>
           <td class="r">
            Room 11
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wedt11" title="Click to go to the Program at a Glance">
             <b>
              Multi-Robot Systems III
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#195781" title="Click to go to the Author Index">
             Alzugaray, Ignacio
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#147435" title="Click to go to the Author Index">
             Ferrante, Eliseo
            </a>
           </td>
           <td class="r">
            Vrije Universiteit Amsterdam
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt11_01">
             17:30-17:45, Paper WeDT11.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3634'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Distributed Simultaneous Localisation and Auto-Calibration Using Gaussian Belief Propagation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#266777" title="Click to go to the Author Index">
             Murai, Riku
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#195781" title="Click to go to the Author Index">
             Alzugaray, Ignacio
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#179606" title="Click to go to the Author Index">
             Kelly, Paul H J
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105540" title="Click to go to the Author Index">
             Davison, Andrew J
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3634" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#distributed_robot_systems" title="Click to go to the Keyword Index">
               Distributed Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#calibration_and_identification" title="Click to go to the Keyword Index">
               Calibration and Identification
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present a novel scalable, fully distributed, and online method for simultaneous localisation and extrinsic calibration for multi-robot setups. Individual a priori unknown robot's poses are probabilistically inferred as robots sense each other while simultaneously calibrating their sensors and markers extrinsic using Gaussian Belief Propagation. In the presented experiments, we show how our method not only yields accurate robot localisation and auto-calibration but also is able to perform under challenging circumstances such as highly noisy measurements, significant communication failures or limited communication range.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt11_02">
             17:45-18:00, Paper WeDT11.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('27'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Distributed Optimization Methods for Multi-Robot Systems: Part II — a Survey (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#251686" title="Click to go to the Author Index">
             Shorinwa, Ola
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#215343" title="Click to go to the Author Index">
             Halsted, Trevor
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#219764" title="Click to go to the Author Index">
             Yu, Javier
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106233" title="Click to go to the Author Index">
             Schwager, Mac
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab27" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#distributed_robot_systems" title="Click to go to the Keyword Index">
               Distributed Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Although the field of distributed optimization is well-developed, relevant literature focused on the application of distributed optimization to multi-robot problems is limited. This survey constitutes the second part of a two-part series on distributed optimization applied to multi-robot problems. In this paper, we survey three main classes of distributed optimization algorithms --- distributed first-order methods, distributed sequential convex programming methods, and alternating direction method of multipliers (ADMM) methods --- focusing on fully-distributed methods that do not require coordination or computation by a central computer. We describe the fundamental structure of each category and note important variations around this structure, designed to address its associated drawbacks. Further, we provide practical implications of noteworthy assumptions made by distributed optimization algorithms, noting the classes of robotics problems suitable for these algorithms. Moreover, we identify important open research challenges in distributed optimization, specifically for robotics problem.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt11_03">
             18:00-18:15, Paper WeDT11.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('70'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Distributed Optimization Methods for Multi-Robot Systems: Part I — a Tutorial (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#251686" title="Click to go to the Author Index">
             Shorinwa, Ola
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#215343" title="Click to go to the Author Index">
             Halsted, Trevor
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#219764" title="Click to go to the Author Index">
             Yu, Javier
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106233" title="Click to go to the Author Index">
             Schwager, Mac
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab70" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#distributed_robot_systems" title="Click to go to the Keyword Index">
               Distributed Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Distributed optimization provides a framework for deriving distributed algorithms for a variety of multi-robot problems. This tutorial constitutes the first part of a two-part series on distributed optimization applied to multi-robot problems, which seeks to advance the application of distributed optimization in robotics. In this tutorial, we demonstrate that many canonical multi-robot problems can be cast within the distributed optimization framework, such as multi-robot simultaneous localization and planning (SLAM), multi-robot target tracking, and multi-robot task assignment problems. We identify three broad categories of distributed optimization algorithms: distributed first-order methods, distributed sequential convex programming, and the alternating direction method of multipliers (ADMM). We provide representative algorithms within each category. We then work through a simulation case study of multiple drones collaboratively tracking a ground vehicle. We compare solutions to this problem using a number of different distributed optimization algorithms. In addition, we implement a distributed optimization algorithm in hardware.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt11_04">
             18:15-18:30, Paper WeDT11.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3787'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Fast Swarming of UAVs in GNSS-Denied Feature-Poor Environments without Explicit Communication
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#321026" title="Click to go to the Author Index">
             Horyna, Jiri
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#257250" title="Click to go to the Author Index">
             Kratky, Vit
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#290671" title="Click to go to the Author Index">
             Pritzl, Vaclav
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#335046" title="Click to go to the Author Index">
             Baca, Tomas
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague FEE
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#147435" title="Click to go to the Author Index">
             Ferrante, Eliseo
            </a>
           </td>
           <td class="r">
            Vrije Universiteit Amsterdam
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#113384" title="Click to go to the Author Index">
             Saska, Martin
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3787" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#swarm_robotics" title="Click to go to the Keyword Index">
               Swarm Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#distributed_robot_systems" title="Click to go to the Keyword Index">
               Distributed Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             A decentralized swarm approach for the fast cooperative flight of Unmanned Aerial Vehicles (UAVs) in feature-less environments without any external localization and communication is introduced in this paper. A novel model of a UAV neighborhood is proposed to achieve robust onboard mutual perception and flocking state feedback control, which is designed to decrease the inter-agent oscillations common in standard reactive swarm models employed in fast collective motion. The novel swarming methodology is supplemented with an enhanced Multi-Robot State Estimation (MRSE) strategy to increase the reliability of the purely onboard localization, which may be unreliable in real environments. Although MRSE and the neighborhood model may rely on information exchange between agents, we introduce a communication-less version of the swarming framework based on estimating communicated states to decrease dependence on the often unreliable communication networks of large swarms. The proposed solution has been verified by a set of complex real world experiments to demonstrate its overall capability in different conditions, including a UAV interception-motivated task with a group velocity reaching the physical limits of the individual hardware platforms.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wedt12">
             <b>
              WeDT12
             </b>
            </a>
           </td>
           <td class="r">
            Room 12
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wedt12" title="Click to go to the Program at a Glance">
             <b>
              Imitation Learning I
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#101828" title="Click to go to the Author Index">
             Ogata, Tetsuya
            </a>
           </td>
           <td class="r">
            Waseda University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt12_01">
             17:30-17:45, Paper WeDT12.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('46'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Uncertainty-Aware Haptic Shared Control with Humanoid Robots for Flexible Object Manipulation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#361416" title="Click to go to the Author Index">
             Hara, Takumi
            </a>
           </td>
           <td class="r">
            Kyoto University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#361455" title="Click to go to the Author Index">
             Sato, Takashi
            </a>
           </td>
           <td class="r">
            Kyoto University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101828" title="Click to go to the Author Index">
             Ogata, Tetsuya
            </a>
           </td>
           <td class="r">
            Waseda University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#296486" title="Click to go to the Author Index">
             Awano, Hiromitsu
            </a>
           </td>
           <td class="r">
            Kyoto University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab46" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#haptics_and_haptic_interfaces" title="Click to go to the Keyword Index">
               Haptics and Haptic Interfaces
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_centered_automation" title="Click to go to the Keyword Index">
               Human-Centered Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We propose a haptic shared control system that predicts human manipulation intentions using a neural network and adaptively presents haptic guidance to achieve smooth robot control remotely. Although the haptic shared control has garnered increasing attention as a method to improve operability in remote operations, incorrect guidance can worsen operability. In this study, we dynamically switch the strength of haptic guidance presentation depending on the uncertainty of the inference results of the neural network. Thus, we weaken the haptic guidance presentation strength for predictions in which the neural network lacks confidence and strengthen it for those with high confidence, thereby achieving guidance presentation that does not impede human manipulation. As a result of experiments using the Nextage OPEN upper-body humanoid robot, in a task involving folding a flexible object, we succeeded in reducing task execution time by 17.1% compared to that with an existing method that determines the strength of haptic guidance presentation without considering the confidence of the neural network.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt12_02">
             17:45-18:00, Paper WeDT12.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3652'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Multi-Task Adaptive Gating Network for Trajectory Distilled Control Prediction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#296615" title="Click to go to the Author Index">
             Azam, Shoaib
            </a>
           </td>
           <td class="r">
            Aalto University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105044" title="Click to go to the Author Index">
             Kyrki, Ville
            </a>
           </td>
           <td class="r">
            Aalto University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3652" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensorimotor_learning" title="Click to go to the Keyword Index">
               Sensorimotor Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             End-to-end autonomous driving is often categorized based on output into
             <p>
              trajectory prediction or control prediction. Each type of approach provides benefits in different contexts, resulting in recent studies on
              <p>
               how to combine them. However, the current proposals are based on heuristic choices that only partially capture the complexities of varying driving conditions. How to best fuse these sources of information remains an open research question.	To address this, we introduce MAGNet, a Multi-Task Adaptive Gating Network for Trajectory Distilled Control Prediction. This framework employs a multi-task learning strategy to combine trajectory and direct control prediction. Our key insight is to design a gating network that learns how to optimally combine the outputs of trajectory and control predictions in each situation. Using the CARLA simulator, we evaluate MAGNet in closed-loop settings with challenging scenarios. Results show that MAGNet outperforms the state-of-the-art on two publicly available CARLA
               <p>
                benchmarks, Town05 Long and Longest6.
               </p>
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt12_03">
             18:00-18:15, Paper WeDT12.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2024'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Leveraging Demonstrator-Perceived Precision for Safe Interactive Imitation Learning of Clearance-Limited Tasks
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#287896" title="Click to go to the Author Index">
             Oh, Hanbit
            </a>
           </td>
           <td class="r">
            National Institute of Advanced Industrial Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#122480" title="Click to go to the Author Index">
             Matsubara, Takamitsu
            </a>
           </td>
           <td class="r">
            Nara Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2024" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Interactive imitation learning is an efficient, model-free method through which a robot can learn a task by repetitively iterating an execution of a learning policy and a data collection by querying human demonstrations. However, deploying unmatured policies for clearance-limited tasks, like industrial insertion, poses significant collision risks. For such tasks, a robot should detect the collision risks and request intervention by ceding control to a human when collisions are imminent. The former requires an accurate model of the environment, a need that significantly limits the scope of IIL applications. In contrast, humans implicitly demonstrate environmental precision by adjusting their behavior to avoid collisions when performing tasks. Inspired by human behavior, this paper presents a novel interactive learning method that uses demonstrator-perceived precision as a criterion for human intervention called Demonstrator-perceived Precision-aware Interactive Imitation Learning (DPIIL). DPIIL captures precision by observing the speed-accuracy trade-off exhibited in human demonstrations and cedes control to a human to avoid collisions in states where high precision is estimated. DPIIL improves the safety of interactive policy learning and ensures efficiency without explicitly providing precise information of the environment. We assessed DPIIL's effectiveness through simulations and real-robot experiments that trained a UR5e 6-DOF robotic arm to perform assembly tasks. Our results significantly improved training safety, and our best performance compared favorably with other learning methods.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt12_04">
             18:15-18:30, Paper WeDT12.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3703'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              MoVEInt: Mixture of Variational Experts for Learning Human-Robot Interactions from Demonstrations
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#205320" title="Click to go to the Author Index">
             Prasad, Vignesh
            </a>
           </td>
           <td class="r">
            TU Darmstadt
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#167165" title="Click to go to the Author Index">
             Kshirsagar, Alap
            </a>
           </td>
           <td class="r">
            Technische Universität Darmstadt
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#190438" title="Click to go to the Author Index">
             Koert, Dorothea
            </a>
           </td>
           <td class="r">
            Technische Universitaet Darmstadt
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#289393" title="Click to go to the Author Index">
             Stock-Homburg, Ruth
            </a>
           </td>
           <td class="r">
            Technical University of Darmstadt
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104326" title="Click to go to the Author Index">
             Peters, Jan
            </a>
           </td>
           <td class="r">
            Technische Universität Darmstadt
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#168538" title="Click to go to the Author Index">
             Chalvatzaki, Georgia
            </a>
           </td>
           <td class="r">
            Technische Universität Darmstadt
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3703" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#physical_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical Human-Robot Interaction
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Shared dynamics models are important for capturing the complexity and variability inherent in Human-Robot Interaction (HRI). Therefore, learning such shared dynamics models can enhance coordination and adaptability to enable successful reactive interactions with a human partner. In this work, we propose a novel approach for learning a shared latent space representation for HRIs from demonstrations in a Mixture of Experts fashion for reactively generating robot actions from human observations. We train a Variational Autoencoder (VAE) to learn robot motions regularized using an informative latent space prior that captures the multimodality of the human observations via a Mixture Density Network (MDN). We show how our formulation derives from a Gaussian Mixture Regression formulation that is typically used approaches for learning HRI from demonstrations such as using an HMM/GMM for learning a joint distribution over the actions of the human and the robot. We further incorporate an additional regularization to prevent mode collapse, a common phenomenon when using latent space mixture models with VAEs. We find that our approach of using an informative MDN prior from human observations for a VAE generates more accurate robot motions compared to previous HMM-based or recurrent approaches of learning shared latent representations, which we validate on various HRI datasets involving interactions such as handshakes, fistbumps, waving, and handovers. Further experiments in a real-world human-to-robot handover scenario show the efficacy of our approach for generating successful interactions with four different human interaction partners.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wedt13">
             <b>
              WeDT13
             </b>
            </a>
           </td>
           <td class="r">
            Room 13
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wedt13" title="Click to go to the Program at a Glance">
             <b>
              Sensor Fusion I
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#101954" title="Click to go to the Author Index">
             Pb, Sujit
            </a>
           </td>
           <td class="r">
            IISER Bhopal
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt13_01">
             17:30-17:45, Paper WeDT13.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3740'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Co-Occ: Coupling Explicit Feature Fusion with Volume Rendering Regularization for Multi-Modal 3D Semantic Occupancy Prediction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#365271" title="Click to go to the Author Index">
             Pan, Jingyi
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology (Guangzhou)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#388466" title="Click to go to the Author Index">
             Wang, Zipeng
            </a>
           </td>
           <td class="r">
            HKUST(GZ)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#256235" title="Click to go to the Author Index">
             Wang, Lin
            </a>
           </td>
           <td class="r">
            HKUST
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3740" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             3D semantic occupancy prediction is a pivotal task in the field of autonomous driving. Recent approaches have great advances in 3D semantic occupancy predictions on a single modality. However, multi-modal semantic occupancy prediction approaches have encountered difficulties in dealing with the modality heterogeneity, modality misalignment, and insufficient modality interactions that arise during the fusion of different modalities data, which may result in the loss of important geometric and semantic information. This letter presents a novel multi-modal, i.e., LiDAR-camera 3D semantic occupancy prediction framework, dubbed Co-Occ, which couples explicit LiDAR-camera feature fusion with implicit volume rendering regularization. The key insight is that volume rendering in the feature space can proficiently bridge the gap between 3D LiDAR sweeps and 2D images while serving as a physical regularization to enhance LiDAR-camera fused volumetric representation. Specifically, we first propose a Geometric- and Semantic-aware Fusion (GSFusion) module to explicitly enhance LiDAR features by incorporating neighboring camera features through a K-nearest neighbors (KNN) search. Then, we employ volume rendering to project the fused feature back to the image planes for reconstructing color and depth maps. These maps are then supervised by input images from the camera and depth estimations derived from LiDAR, respectively. Extensive experiments on the popular nuScenes and SemanticKITTI benchmarks verify the effectiveness of our Co-Occ for 3D semantic occupancy prediction. The project page is available at https://rorisis.github.io/Co-Occ_project-page/
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt13_02">
             17:45-18:00, Paper WeDT13.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3766'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Visual-Force-Tactile Fusion for Gentle Intricate Insertion Tasks
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#284730" title="Click to go to the Author Index">
             Jin, Piaopiao
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#158712" title="Click to go to the Author Index">
             Huang, Bidan
            </a>
           </td>
           <td class="r">
            Tencent
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#253097" title="Click to go to the Author Index">
             Lee, Wangwei
            </a>
           </td>
           <td class="r">
            Tencent RoboticsX Lab
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#219358" title="Click to go to the Author Index">
             Li, Tiefeng
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#256679" title="Click to go to the Author Index">
             Yang, Wei
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3766" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             <p>
              This paper proposes a new approach for improving robotic manipulation tasks that require both precision and high compliance through multisensory fusion. By integrating visual, force, and tactile feedback, our approach enhances performance in delicate insertion tasks. We introduce a unified framework that combines information from these sensors to guide the entire manipulation strategies. Experiments in simulated and physical environments demonstrate that our method outperforms traditional single and dual-modality approaches regarding precision, gentle interactions, and robustness. We also provide a detailed analysis of the results to examine the role of each modality during manipulation. The experiment videos and code are available at https://sites.google.com/view/vft-fusion-insertion.
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt13_03">
             18:00-18:15, Paper WeDT13.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3778'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              LIV-GaussMap: LiDAR-Inertial-Visual Fusion for Real-Time 3D Radiance Field Map Rendering
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#353331" title="Click to go to the Author Index">
             Hong, Sheng
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#385916" title="Click to go to the Author Index">
             He, Junjie
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#386497" title="Click to go to the Author Index">
             Zheng, Xinhu
            </a>
           </td>
           <td class="r">
            The HongKong University of Science and Technology (Guangzhou)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#289062" title="Click to go to the Author Index">
             Liu, Kangcheng
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#288528" title="Click to go to the Author Index">
             Zheng, Chunran
            </a>
           </td>
           <td class="r">
            The University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#142354" title="Click to go to the Author Index">
             Shen, Shaojie
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3778" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#virtual_reality_and_interfaces" title="Click to go to the Keyword Index">
               Virtual Reality and Interfaces
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We introduce an integrated precise LiDAR, Inertial, and Visual (LIV) multimodal sensor fused mapping system that builds on the differentiable Gaussians to improve the mapping fidelity, quality, and structural accuracy. Notably, this is also a novel form of tightly coupled map for LiDAR-visual-inertial sensor fusion.
             <p>
              This system leverages the complementary characteristics of LiDAR and visual data to capture the geometric structures of large-scale 3D scenes and restore their visual surface information with high fidelity. The initialization for the scene's surface Gaussians and the sensor's poses of each frame are obtained using a LiDAR-inertial system with the feature of size-adaptive voxels. Then, we optimized and refined the Gaussians using visual-derived photometric gradients to optimize their quality and density.
              <p>
               Our method is compatible with various types of LiDAR, including solid-state and mechanical LiDAR, supporting both repetitive and non-repetitive scanning modes. Bolstering structure construction through LiDAR and facilitating real-time generation of photorealistic renderings across diverse LIV datasets. It showcases notable resilience and versatility in generating real-time photorealistic scenes potentially for digital twins and virtual reality, while also holding potential applicability in real-time SLAM and robotics domains.
               <p>
                We release our software and hardware and self-collected datasets on Github to benefit the community.
               </p>
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt13_04">
             18:15-18:30, Paper WeDT13.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('47'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Event and Frame-Based Visual-Inertial Odometry with Adaptive Filtering Based on 8-DOF Warping Uncertainty
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#342338" title="Click to go to the Author Index">
             Lee, Min Seok
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#255404" title="Click to go to the Author Index">
             Jung, Jaehyung
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#342335" title="Click to go to the Author Index">
             Kim, Ye Jun
            </a>
           </td>
           <td class="r">
            Hyundai Motor Group
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#257109" title="Click to go to the Author Index">
             Park, Chan Gook
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab47" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#visual_inertial_slam" title="Click to go to the Keyword Index">
               Visual-Inertial SLAM
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this letter, we present an event- and frame-based visual-inertial odometry (VIO) algorithm that fuses frames, events, and inertial measurement in a robust and adaptive manner. Frames from standard cameras provide rich context of the scene at a fixed rate. Event cameras on the other hand asynchronously produce events at a pixel-level when changes in intensity occur, and thus are resilient to motion blur and have high dynamic range. To harness the advantages of the two sensors, our frontend fuses their outputs by creating brightness increment patches of each output and minimize the differences with an 8-DOF warping model. The warping model and the optimization process allow for robust feature tracking in the frontend of the algorithm. The minimized residual is then used in the multi-state filter-based backend where the measurement update is adaptively performed depending on the size of the residual for accurate
             <p>
              estimation, reflecting the quality of the tracked features. Comparative
              <p>
               evaluation on two publicly available datasets reveals that our method outperforms the state-of-the-art event-based VIO algorithms in pose estimation accuracy.
              </p>
             </p>
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wei3n">
             <b>
              WeI3N
             </b>
            </a>
           </td>
           <td class="r">
            Poster Area
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wei3n" title="Click to go to the Program at a Glance">
             <b>
              Interactive Session 3
             </b>
            </a>
           </td>
           <td class="r">
            Interactive Poster session
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wef4o">
             <b>
              WeF4O
             </b>
            </a>
           </td>
           <td class="r">
            Auditorium
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wef4o" title="Click to go to the Program at a Glance">
             <b>
              Forum 4 - Robotics in Africa
             </b>
            </a>
           </td>
           <td class="r">
            Forum
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#149314" title="Click to go to the Author Index">
             Ekenna, Chinwe
            </a>
           </td>
           <td class="r">
            University at Albany
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wef4o_01">
             15:30-18:30, Paper WeF4O.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Robotics in Africa Forum
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#149314" title="Click to go to the Author Index">
             Ekenna, Chinwe
            </a>
           </td>
           <td class="r">
            University at Albany
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#217025" title="Click to go to the Author Index">
             Mbanisi, Kenechukwu Churchill
            </a>
           </td>
           <td class="r">
            Worcester Polytechnic Institute (WPI)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#311638" title="Click to go to the Author Index">
             Adebola, Simeon Oluwafunmilore
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#168741" title="Click to go to the Author Index">
             Taddese, Addisu
            </a>
           </td>
           <td class="r">
            Vanderbilt University
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="wef5o">
             <b>
              WeF5O
             </b>
            </a>
           </td>
           <td class="r">
            Room 17/18
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#wef5o" title="Click to go to the Program at a Glance">
             <b>
              Forum 5 - Robotics &amp; AI in the UAE: Research Innovation and
              <br/>
              Entrepreneurship
             </b>
            </a>
           </td>
           <td class="r">
            Forum
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#370007" title="Click to go to the Author Index">
             McCarthy, Thomas Gerard
            </a>
           </td>
           <td class="r">
            ASPIRE UAE
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wef5o_01">
             15:30-18:30, Paper WeF5O.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Robotics &amp; AI in the UAE: Research Innovation and Entrepreneurship
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#370007" title="Click to go to the Author Index">
             McCarthy, Thomas Gerard
            </a>
           </td>
           <td class="r">
            ASPIRE UAE
           </td>
          </tr>
         </table>
        </div>
        <p>
         <br/>
        </p>
        <p>
         <br/>
        </p>
        <p>
         <p>
         </p>
        </p>
       </td>
       <td height="100%" style="background-color:#9F7F59;" width="5">
       </td>
      </tr>
      <tr>
       <td alt="" border="0" colspan="4" height="16" style="background-color:#9F7F59;" valign="center" width="100%">
        <p align="center">
         <span style="font-size:8pt;line-height:10pt;color:#ffffff;">
          Technical Content © IEEE Robotics &amp; Automation Society
         </span>
        </p>
       </td>
      </tr>
      <tr>
       <td colspan="4" width="100%">
        <p align="right">
         <span style="text-decoration:none;">
          <img align="right" border="0" src="/images/pc_logo_small.jpg" style="margin-left: 10px; margin-right: 10px"/>
          This site is protected
by copyright and trademark laws under US and International law.
          <br/>
          All rights
reserved. © 2002-2024 PaperCept, Inc.
          <br/>
          Page generated 2024-10-05  01:22:01 PST
          <a href="" onclick="window.open('/conferences/scripts/about.pl','tc','width=1000,scrollbars=yes'); return false">
           Terms of use
          </a>
         </span>
        </p>
       </td>
      </tr>
     </table>
    </body>
   </div>
  </form>
 </body>
</html>
