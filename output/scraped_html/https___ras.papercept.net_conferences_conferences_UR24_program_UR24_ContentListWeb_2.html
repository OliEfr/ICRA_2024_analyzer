<!DOCTYPE HTML>
<html>
 <head>
  <meta content="en-us" http-equiv="Content-Language"/>
  <meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
  <meta content="width=device-width" name="viewport"/>
  <script src="https://ras.papercept.net/conferences/scripts/dom-drag.js" type="text/javascript">
  </script>
  <script src="jquery-1.11.1.min.js">
  </script>
  <title>
   UR 2024 Program | Tuesday June 25, 2024
  </title>
  <style type="text/css">
   body, table, td, th{
	Font-Family : sans-serif;
	Font-Size : 10pt;
}
.r {text-align: right}
.blue {color: #0000FF;}
td {vertical-align: top; text-align: left}
.c {text-align: center}
table.s {
	border-collapse:collapse;
	border-width: 1px;
}
table.s td{
	border-width: 1px;
	padding: 4px;
	border-style: solid;
	border-color: gray;
}
table.t {
	border-collapse: collapse;
	border-width: 0px;
}
table.t td{
	border-width: 0px;
	padding: 4px;
	border-style: solid;
	border-color: gray;
}
.dots {
    background:url('./images/dot.gif') repeat-x center;
}
.field {
    background-color: #FFFFFF;
}
#pTitle { /* Page title */
   font-size: 14pt;
   line-height: 1.5em;
}
#pSubTitle { /* Page subtitle */
   color: #909090;
   font-size: 10pt; 
   line-height: 1.5em;
}
#container {
	position: absolute;
	width: 100%;
	margin-top: 2px;
/*	overflow: hidden; */
}

.sHdr {   /* Session header Content list */
   background-color: #F0E68C
}
      
.sSHdr {   /* Subsession header Content list */
   background-color: #f8f3c6 
}
      
table.trk { /* Track table Content list */
   border-collapse: collapse;
   border-width: 0px;
   margin: auto;
/**   width: 640px; **/
   width: 720px;
}
table.trk td{
   border-width: 0px;
   padding: 4px;
   border-style: solid;
   border-color: gray;
 }
      
.pHdr {  /* Paper header Content list */
   background-color: #E6E6FA;
   color: black;
}
hr.thin { /* Horizontal rule content list */
   border: 0px; 
   height: .8px; 
   background-color: #8888FF;
}
      
.pTtl {  /* Paper title Content list */
   font-size: 11pt;
   font-style: italic;
}
      
.ssHdr {  /* Subsession header container session Content list */
   background-color: #DDDDDD;
   color: black;
}
      
.ssTtl {  /* Subsession title container session Content list */
   font-size: 10pt;
   font-style: normal;
   font-weight: bold;
}
  </style>
  <script language="JavaScript">
   function initXMLHttp(){
   var oRequest = false;
   try {
      oRequest = new XMLHttpRequest();
   }  catch (trymicrosoft) {
      try {
         oRequest = new ActiveXObject("Msxml2.XMLHTTP");
      }  catch (othermicrosoft) {
         try {
            oRequest = new ActiveXObject("Microsoft.XMLHTTP");
         }  catch (failed) {
            oRequest = false;
         }
      }
   }
   if (!oRequest){
      alert("Error initializing XMLHttpRequest! Your browser does not support AJAX");
   }
   return oRequest;
}
function modify(number,kk){
   var check = document.getElementById('mod' + kk).checked;
   if (check){
      action = 'Add';
   }
   else{
      action = 'Delete';
   }
   
//   url = 'https://ras.papercept.net/conferences/scripts/myprogram.pl?ConfID=445&' + action + number;
//   window.open(url,'myprogrampage');

   modifyItem("https://ras.papercept.net/conferences/scripts/myprogram_aja.pl","445",action,number)

}


function modifyItem(url,ConfID,action,number){
   var oRequest = initXMLHttp();
   if (!oRequest){return;}
   
   // Send the request

   oRequest.open("post",url, true);
   var sParams = 'ConfID=' + ConfID + '&Action=' + action + '&Number=' + number;
   document.body.style.cursor = 'wait';
   oRequest.send(sParams);

   // Process the response
   
   oRequest.onreadystatechange = function(){ 
      if (oRequest && oRequest.readyState && oRequest.readyState == 4){
         document.body.style.cursor = 'auto';
         var responseText = oRequest.responseText;
         if (responseText.substring(0,5) == 'Error'){
            alert(responseText);
         }
         else{
         
//            alert(responseText);

         }
      }
   } 
}

var iIntervalId;  // Global variable
function modsession(id,kk){
   var check = document.getElementById('mod' + kk).checked;
   if (check){
      action = 'AddSession';
   }
   else{
      action = 'DelSession';
   }

//   url = 'https://ras.papercept.net/conferences/scripts/myprogram.pl?ConfID=445&' + action + id;
//   window.open(url,'myprogrampage');

   modifySession("https://ras.papercept.net/conferences/scripts/myprogram_aja.pl","445",action,id)

}

function modifySession(url,ConfID,action,id){
   var oRequest = initXMLHttp();
   if (!oRequest){return;}
   
   // Send the request

   oRequest.open("post",url, true);
   var sParams = 'ConfID=' + ConfID + '&Action=' + action + '&ID=' + id;
   document.body.style.cursor = 'wait';
   oRequest.send(sParams);

   // Process the response
   
   oRequest.onreadystatechange = function(){ 
      if (oRequest && oRequest.readyState && oRequest.readyState == 4){
         document.body.style.cursor = 'auto';
         var responseText = oRequest.responseText;
         if (responseText.substring(0,5) == 'Error'){
            alert(responseText);
         }
         else{
         
//            alert(responseText);

         }
      }
   } 
}

function getCookie(sName){
   var sRE = "(?:; )?" + sName + "=([^;]*);?";   
   var oRE = new RegExp(sRE);
   if (oRE.test(document.cookie)){
      return decodeURIComponent(RegExp["$1"]);}
   else{
      return null;
   }
}
function loadprogram(){
   var list = getCookie("UR24");
   if (list){
      var List = list.split(",");
      for (var i=0; i<List.length; i++){
         var names = document.getElementsByName('modify' + List[i]);
         if (names.length){
            for (var j=0; j<names.length; j++){
               names[j].checked = true;
            }
         }
      }
   }
}
function reset(){

   // Uncheck all modify and addsession checkboxes

   var ins = document.getElementsByTagName('input');
   for (var i=0; i<ins.length; i++){
      if (ins[i].type == 'checkbox' && ins[i].id && ins[i].id.substring(0,3) == 'mod'){
         ins[i].checked = false;
      }
   }
   
   // Reload the program
   
   loadprogram();
}
function startreset(){
   iIntervalId = setInterval(reset,2000);
}
function viewAbstract(number){
   var box = document.getElementById('Ab' + number);
   if (box.style.display == 'block'){
      box.style.display = 'none';
   }
   else if (box && box.style.display == 'none'){
      box.style.display = 'block';
   }
}
function openAllAbstracts(){
   var d = document.getElementsByTagName('div');
   var count = d.length;
   if (count == 0){return;}
   for (var i=0; i<d.length; i++){
      if (d[i].id && d[i].id.substring(0,2) == 'Ab' && d[i].style.display == 'none'){
         d[i].style.display = 'block';
      }
   }
}
function closeAllAbstracts(){
   var d = document.getElementsByTagName('div');
   for (var i=0; i<d.length; i++){
      if (d[i].id && d[i].id.substring(0,2) == 'Ab'){
         d[i].style.display = 'none';
      }
   }
}
var uhash;
var pColor;
$(function() { 

   // Check for URL hash

   uhash = location.hash.substring(1);
   if (uhash.slice(-1) == '_'){
      uhash = null;
   }
   if (uhash){
   
      // Mark the session
   
      pColor = $('#' + uhash).parent().css('backgroundColor');
      $('#' + uhash).parent().css('backgroundColor','#FF8888');
   }
});
  </script>
 </head>
 <body>
  <form action="https://ras.papercept.net/conferences/scripts/myprogram.pl" name="myprogram">
   <div id="container">
    <body leftmargin="0" marginheight="0" marginwidth="0" topmargin="0">
     <table border="0" cellpadding="0" cellspacing="0" width="100%">
      <tr>
       <td alt="" height="140" style="background-color:#2E5286;" width="100%">
        <img alt="" border="0" height="140px" src="/images/ur/ur24.webp" style="position: absolute; margin: 0; left:0px;top:0px;"/>
       </td>
      </tr>
      <tr>
       <td height="0px" style="background-color:#2E5286;" width="100%">
       </td>
      </tr>
     </table>
     <table border="0" cellpadding="0" cellspacing="0" height="80%" width="100%">
      <tr>
       <td height="100%" style="background-color:#2E5286;" width="5">
       </td>
       <td width="5">
       </td>
       <td height="100%" valign="top" width="100%">
        <br/>
        <div class="c" id="TheTop">
         <span id="pTitle">
          <a href="http://2024.ubiquitousrobots.org" target="_blank">
           <b>
            2024 21st International Conference on Ubiquitous Robots (UR)
           </b>
          </a>
          <br/>
         </span>
         <span id="pSubTitle">
          <b>
           June 24-27, 2024, NYU, Manhattan, New York, USA
          </b>
         </span>
         <br/>
         <br/>
        </div>
        <div class="c" style="position: relative">
         <a href="UR24_ProgramAtAGlanceWeb.html">
          Program at a Glance
         </a>
         <a href="UR24_ContentListWeb_1.html">
          Monday
         </a>
         <a href="UR24_ContentListWeb_2.html">
          Tuesday
         </a>
         <a href="UR24_ContentListWeb_3.html">
          Wednesday
         </a>
         <a href="UR24_AuthorIndexWeb.html">
          Author Index
         </a>
         <a href="UR24_KeywordIndexWeb.html">
          Keyword Index
         </a>
        </div>
        <div class="c">
         <p style="color: gray">
          Last updated on May 13, 2024. This conference program is tentative and subject to change
         </p>
        </div>
        <div class="c">
         <h3>
          Technical Program for Tuesday June 25, 2024
         </h3>
        </div>
        <p class="c">
        </p>
        <div class="c">
         <span style="color:gray ">
          To show or hide the keywords and abstract (text summary) of a paper (if available), click on the paper title
         </span>
         <br/>
         <a href="javascript:openAllAbstracts()" title="Click to open all abstracts">
          Open all abstracts
         </a>
         <a href="javascript:closeAllAbstracts()" title="Click to close all abstracts">
          Close all abstracts
         </a>
        </div>
        <div class="c">
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="to2a">
             <b>
              TO2A
             </b>
            </a>
           </td>
           <td class="r">
            Rosenthal
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="UR24_ProgramAtAGlanceWeb.html#to2a" title="Click to go to the Program at a Glance">
             <b>
              Human-Robot Interaction I
             </b>
            </a>
           </td>
           <td class="r">
            Regular
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="UR24_AuthorIndexWeb.html#118310" title="Click to go to the Author Index">
             Kyung, Ki-Uk
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science &amp; Technology (KAIST)
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="UR24_AuthorIndexWeb.html#244953" title="Click to go to the Author Index">
             Frederiksen, Morten Roed
            </a>
           </td>
           <td class="r">
            IT-University of Copenhagen
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to2a_01">
             -, Paper TO2A.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('26'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Novel Design of Thin Flexible Force Myography Sensor Using Weaved Optical Fiber: A Proof-Of-Concept Study
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#315613" title="Click to go to the Author Index">
             Chung, Chongyoung
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology (KAIST)
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#363256" title="Click to go to the Author Index">
             Mun, Heeju
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#135381" title="Click to go to the Author Index">
             Atashzar, S. Farokh
            </a>
           </td>
           <td class="r">
            New York University (NYU), US
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#118310" title="Click to go to the Author Index">
             Kyung, Ki-Uk
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science &amp; Technology (KAIST)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab26" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#physical_and_cognitive_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical and Cognitive Human-Robot Interaction
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#soft_robotics" title="Click to go to the Keyword Index">
               Soft Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Motion recognition and tracking is one of the crucial features for intuitive and direct human-robot interaction (HRI), prompting researchers to explore various sensor types. In this paper, we proposed a sleeve-type force myography (FMG) system using new type of thin and flexible FMG sensor utilizing weaved optical fiber. This study introduces a novel design for a thin and flexible FMG sensor using weaved plastic optical fibers for motion recognition and tracking. The proposed sensor demonstrates a compact form factor (15 mm width, 25 mm height, and 2 mm thickness) with high flexibility, making it suitable for embedding in clothing without causing discomfort. Evaluations confirm its high sensitivity, wide force sensing range (&gt;10 N). Accuracy of the estimating force using the proposed sensor was approximately 99.17% or higher and the response time of 85 ms ensures its effectiveness in real-time applications, emphasizing its potential for applications like prosthetics and virtual reality (VR) interactions. To conduct the proof of concept for the FMG sensor, elbow flexion angle estimation was performed focusing solely on the bicep muscle, and high-precision flexion angle tracking was achieved with 94.27% of correlation coefficient. Overall, the proposed FMG sensor presents a promising solution for intuitive and accurate motion recognition in various HRI applications.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to2a_02">
             10:30-11:30, Paper TO2A.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('25'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              The Effect of Use of Social Robot NAO on Children's Motivation and Emotional States in Special Education
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#386727" title="Click to go to the Author Index">
             Namlısesli, Deniz
            </a>
           </td>
           <td class="r">
            Yeditepe University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#386725" title="Click to go to the Author Index">
             Baş, Hale Nur
            </a>
           </td>
           <td class="r">
            Medipol University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#386724" title="Click to go to the Author Index">
             Bostancı, Hilal
            </a>
           </td>
           <td class="r">
            Medipol University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#318510" title="Click to go to the Author Index">
             Coşkun, Buket
            </a>
           </td>
           <td class="r">
            Yeditepe University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#105706" title="Click to go to the Author Index">
             Erol Barkana, Duygun
            </a>
           </td>
           <td class="r">
            Yeditepe University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#386723" title="Click to go to the Author Index">
             Tarakci, Devrim
            </a>
           </td>
           <td class="r">
            Medipol University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab25" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#social_and_socially_assistive_robotics" title="Click to go to the Keyword Index">
               Social and Socially Assistive Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The utilization of social robots in therapeutic and educational settings offers promising advancements, especially for children with special needs. 21 children receiving special education at Dilbade Special Education and Rehabilitation Center were evaluated under two conditions: sessions led by special education teachers and those supported by the social robot NAO. The Pediatric Motivation Scale (PMS) results demonstrate that special education sessions involving the social robot NAO increased the children's motivation compared to traditional sessions. Moreover, statistical features from the physiological signals, including Blood Volume Pulse (BVP), Electrodermal Activity (EDA), and Skin Temperature (ST) were found. Notably, all significant features from BVP, EDA, and ST have increased, which indicated that children were excited and felt positive during the sessions involving the social robot NAO. Furthermore, the subjective evaluations from children, families, and special education teachers supported the quantitative findings, with a majority expressing enthusiasm for including the social robot NAO in special education.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to2a_03">
             10:30-11:30, Paper TO2A.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('44'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Toward Anxiety-Reducing Pocket Robots for Children
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#244953" title="Click to go to the Author Index">
             Frederiksen, Morten Roed
            </a>
           </td>
           <td class="r">
            IT-University of Copenhagen
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#108002" title="Click to go to the Author Index">
             Stoy, Kasper
            </a>
           </td>
           <td class="r">
            IT University of Copenhagen
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#106165" title="Click to go to the Author Index">
             Mataric, Maja
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab44" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#physical_and_cognitive_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical and Cognitive Human-Robot Interaction
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#social_and_socially_assistive_robotics" title="Click to go to the Keyword Index">
               Social and Socially Assistive Robotics
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             A common denominator for most therapy treatments for children who suffer from an anxiety disorder is daily practice routines to learn techniques needed to overcome anxiety. However, applying those techniques while experiencing anxiety can be highly challenging. This paper presents the design, implementation, and pilot study of a tactile hand-held pocket robot “AffectaPocket”, designed to work alongside therapy as a focus object to facilitate coping during an anxiety attack. The robot does not require daily practice to be used, has a small form factor, and has been designed for children 7 to 12 years old. The pocket robot works by sensing when it is being held and attempts to shift the child's focus by presenting them with a simple three-note rhythm-matching game. We conducted a pilot study of the pocket robot involving four children aged 7 to 10 years, and then a main study with 18 children aged 6 to 8 years; neither study involved children with anxiety. Both studies aimed to assess the reliability of the robot's sensor configuration, its design, and the effectiveness of the user tutorial. The results indicate that the morphology and sensor setup performed adequately and the tutorial process enabled the children to use the robot with little practice. This work demonstrates that the presented pocket robot could represent a step toward developing low-cost accessible technologies to help children suffering from anxiety disorders.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to2a_04">
             10:30-11:30, Paper TO2A.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('82'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Advancing Interactive Robot Learning: A User Interface Leveraging Mixed Reality and Dual Quaternions
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#377212" title="Click to go to the Author Index">
             Feith, Nikolaus
            </a>
           </td>
           <td class="r">
            Montanuniversität Leoben
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#176888" title="Click to go to the Author Index">
             Rueckert, Elmar
            </a>
           </td>
           <td class="r">
            Montanuniversitaet Leoben
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab82" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#physical_and_cognitive_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical and Cognitive Human-Robot Interaction
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#learning_from_humans" title="Click to go to the Keyword Index">
               Learning From Humans
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper proposes an innovative mixed reality (MR) user interface using dual quaternions (DQ) to enhance interactive robot learning (IntRL). The interface, developed for Microsoft Hololens2, facilitates intuitive interaction and visualization of robot pose trajectories in 3D space. It is designed with three main modes: Subscribe, for observing robot movements; Publish, for controlling robot actions; and Interaction, the main feature that allows users to adjust and refine trajectories. The use of DQ in this context provides a robust and efficient way to represent complex spatial relationships and motion. By bridging the gap between human operators and robotic systems, this interface aims to simplify complex robotic manipulations and demonstrates potential for broader applications in interactive learning environments, offering a novel approach in the field of robotics.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to2a_05">
             10:30-11:30, Paper TO2A.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('87'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Kinesthetic Skill Refinement for Error Recovery in Skill-Based Robotic Systems
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387122" title="Click to go to the Author Index">
             Kowalski, Victor
            </a>
           </td>
           <td class="r">
            German Aerospace Center (DLR)
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#207952" title="Click to go to the Author Index">
             Eiband, Thomas
            </a>
           </td>
           <td class="r">
            German Aerospace Center (DLR)
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#104647" title="Click to go to the Author Index">
             Lee, Dongheui
            </a>
           </td>
           <td class="r">
            Technische Universität Wien (TU Wien)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab87" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#physical_and_cognitive_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical and Cognitive Human-Robot Interaction
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#robotic_systems_architectures_and_programming" title="Click to go to the Keyword Index">
               Robotic Systems Architectures and Programming
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#learning_from_humans" title="Click to go to the Keyword Index">
               Learning From Humans
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Skill-based robotic systems can perform tasks more flexibly than typical industrial manipulators. These systems are equipped with a repertoire of reusable skills and take advantage of a knowledge base about their workspace. That being so, the robot can execute tasks composed of a combination of different skills, tools, and objects without having to be reprogrammed explicitly for each task. Despite its advantages, these systems are affected by modeling errors and an inaccurate knowledge base. Such issues lead to failures in production. Since automated error detection is still an open problem, they often have to be solved by a robot operator. That is generally done by accessing the implementation of the faulty task and determining what to change to achieve the desired outcome, which is time-consuming and requires expertise. The proposed work aims to provide the robot operator with a faster and more intuitive error recovery method for a skill-based system via GUI-assisted kinesthetic refinement of robot skills. Furthermore, partially automated error recovery strategies are included. First, the targeted skills can be composed of an arbitrary number of steps with corresponding reversion behaviors. Second, consecutive human corrections on different parts of a given object are analyzed to infer a possible object pose error. Experiments show that our method takes one-fourth of the time required for conventional manual correction.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to2a_06">
             10:30-11:30, Paper TO2A.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('166'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              An Intuitive Framework to Minimize Cognitive Load in Robotic Control: A Comparative Evaluation of Body Parts
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#347330" title="Click to go to the Author Index">
             Kim, Joonhyun
            </a>
           </td>
           <td class="r">
            Hanyang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#388500" title="Click to go to the Author Index">
             Lee, Jungsoo
            </a>
           </td>
           <td class="r">
            Hanyang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#127992" title="Click to go to the Author Index">
             Kim, Wansoo
            </a>
           </td>
           <td class="r">
            Hanyang University ERICA
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab166" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#physical_and_cognitive_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical and Cognitive Human-Robot Interaction
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#wheeled_mobile_robots" title="Click to go to the Keyword Index">
               Wheeled Mobile Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Within the domain of robotic control frameworks, a critical consideration is the minimization of cognitive load for the operator. Many past studies have aimed to achieve this by incorporating human motion into control systems. However, these methods often relied on motion capture systems, necessitating the cumbersome procedure of wearing equipment and calibrating sensors. This paper introduces an intuitive framework that utilizes raw values from a single Inertial Measurement Unit (IMU) sensor to capture the operator’s intent for robot control, thereby eliminating the need for complex sensor configurations and lengthy setup procedures. Furthermore, our study includes a comparative evaluation to determine the most effective body part - wrist, torso, or head - compared to traditional joystick control, in terms of minimizing cognitive load and maximizing intuitiveness. The evaluation criteria include stability, cognitive load, usability, and task completion time, with experiments involving both expert and non-expert users. Our findings indicate that wrist-based control is most beneficial for experts, improving stability, cognitive load management, usability, and completion speed. In contrast, non- experts prefer torso-based control for its intuitive nature, ease of use, and stability. Notably, the wrist and torso controls, which were most favored by the subjects, are assessed as more user- friendly than traditional joystick controls due to their hands- free operation capability. The practicality of our proposed framework is underscored by its potential compatibility with commonly available smart devices, paving the way for future research in realistic application scenarios.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="to2b">
             <b>
              TO2B
             </b>
            </a>
           </td>
           <td class="r">
            KC905
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="UR24_ProgramAtAGlanceWeb.html#to2b" title="Click to go to the Program at a Glance">
             <b>
              Medical Robotics
             </b>
            </a>
           </td>
           <td class="r">
            Regular
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="UR24_AuthorIndexWeb.html#252450" title="Click to go to the Author Index">
             Nguyen, Nhan Huu
            </a>
           </td>
           <td class="r">
            Japan Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="UR24_AuthorIndexWeb.html#102562" title="Click to go to the Author Index">
             Lee, Deukhee
            </a>
           </td>
           <td class="r">
            KIST
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to2b_01">
             -, Paper TO2B.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('112'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Haptic-Enhanced Virtual Reality Simulator for Robot-Assisted Femur Fracture Surgery
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#297415" title="Click to go to the Author Index">
             Alruwaili, Fayez
            </a>
           </td>
           <td class="r">
            Rowan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#382544" title="Click to go to the Author Index">
             Halim-Banoub, David
            </a>
           </td>
           <td class="r">
            Rowan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#382543" title="Click to go to the Author Index">
             Rodgers, Jessica
            </a>
           </td>
           <td class="r">
            Rowan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#382542" title="Click to go to the Author Index">
             Dalkilic, Adam
            </a>
           </td>
           <td class="r">
            Rowan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387171" title="Click to go to the Author Index">
             Haydel, Christopher
            </a>
           </td>
           <td class="r">
            Orthopedic Trauma Surgery with Virtua Health
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387172" title="Click to go to the Author Index">
             Javad, Parvizi
            </a>
           </td>
           <td class="r">
            Rothman Orthopedic Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#108549" title="Click to go to the Author Index">
             Iordachita, Ioan Iulian
            </a>
           </td>
           <td class="r">
            Johns Hopkins University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#214469" title="Click to go to the Author Index">
             Abedin-Nasab, Mohammad
            </a>
           </td>
           <td class="r">
            Rowan University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab112" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#robotic_systems_architectures_and_programming" title="Click to go to the Keyword Index">
               Robotic Systems Architectures and Programming
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#medical_robotics_and_computer_integrated_surgery" title="Click to go to the Keyword Index">
               Medical Robotics and Computer-Integrated Surgery
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#haptics" title="Click to go to the Keyword Index">
               Haptics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we develop a haptic-enhanced virtual reality (VR) simulator for the Robossis robot-assisted femur fracture surgery. Given the complex nature of robot-assisted surgery and its steep learning curve, a dedicated training tool is vital for equipping surgeons with the necessary skills to effectively operate the surgical system. We develop the Robossis Surgical Simulator (RSS) to closely replicate the surgical environment of the Robossis system. The user interacts with the RSS using external hardware that includes the Sigma-7 Haptic Controller and the Meta Quest VR headset. Further, we extended the implementation of the separating axis theorem to retrieve the collision between the distal and proximal bone segment and, hence, determine the required haptic feedback that restricts the bone-bone collision. This development demonstrates a promising avenue and a novel approach to enhance the training protocol for the Robossis system.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to2b_02">
             10:30-11:30, Paper TO2B.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('152'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Konjac Glucomannan-Based Soft Sensorized Phantom Simulator for Detection of Cutting Action
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#252450" title="Click to go to the Author Index">
             Nguyen, Nhan Huu
            </a>
           </td>
           <td class="r">
            Japan Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#122439" title="Click to go to the Author Index">
             Ho, Van
            </a>
           </td>
           <td class="r">
            Japan Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab152" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#soft_robotics" title="Click to go to the Keyword Index">
               Soft Robotics
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#medical_robotics_and_computer_integrated_surgery" title="Click to go to the Keyword Index">
               Medical Robotics and Computer-Integrated Surgery
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             As automation machines continue to integrate into various industrial sectors, the rise of soft robotic technologies holds promise for their application in everyday human life. In light of concerns about the environmental impact of this transition, including energy consumption and pollution, sustainability has become a key focus for the soft robotics community. This study introduces an innovative solution using a biodegradable material derived from Konjac Glucomannan (KGM) powder combined with Gelatin (referred to as KGE) for the development of eco-friendly soft devices. Tensile testing demonstrates that KGE possesses mechanical integrity comparable to commonly used hydrogels. Additionally, we present the inaugural implementation of medical simulators designed to replicate the skin's response during surgical procedures. An Electrical Impedance Tomography (EIT) system is employed to track incision trails and physical damages on the simulated skin. Experimental testing across various injury types reveals the system's ability to capture the wound's shape, albeit with limited precision in localization. This research marks a significant step toward expanding the utilization of KGM in the creation of a new generation of sustainable soft machines.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to2b_03">
             10:30-11:30, Paper TO2B.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('172'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Admittance Control for Adaptive Remote Center of Motion in Robotic Laparoscopic Surgery
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#343445" title="Click to go to the Author Index">
             Nasiri, Ehsan
            </a>
           </td>
           <td class="r">
            Stevens Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#146612" title="Click to go to the Author Index">
             Wang, Long
            </a>
           </td>
           <td class="r">
            Stevens Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab172" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#medical_robotics_and_computer_integrated_surgery" title="Click to go to the Keyword Index">
               Medical Robotics and Computer-Integrated Surgery
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#rehabilitation_and_healthcare_robotics" title="Click to go to the Keyword Index">
               Rehabilitation and Healthcare Robotics
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In laparoscopic robot-assisted minimally invasive surgery, the kinematic control of the robot is subject to the remote center of motion (RCM) constraint at the port of entry (e.g., trocar) into the patient’s body. During surgery, after the instrument is inserted through the trocar, intrinsic physiological movements such as the patient’s heartbeat, breathing process, and/or other purposeful body repositioning may deviate the position of the port of entry. This can cause a conflict between the registered RCM and the moved port of entry.
             <p>
              To mitigate this conflict, we seek to utilize the interaction forces at the RCM. We develop a novel framework that integrates admittance control into a redundancy resolution method for the RCM kinematic constraint. Using the force/torque sensory feedback at the base of the instrument driving mechanism (IDM), the proposed framework estimates the forces at RCM, rejects forces applied on other locations along the instrument, and uses them in the admittance controller. In this paper, we report analysis from kinematic simulations to validate the proposed framework. In addition, a hardware platform has been completed, and future work is planned for experimental validation.
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to2b_04">
             10:30-11:30, Paper TO2B.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('70'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Automatic Exposure Control for HoloLens 2 Camera: Detection of Reflective Markers for Robust Tool Tracking under Surgical Light
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387051" title="Click to go to the Author Index">
             Diana, Nova Eka
            </a>
           </td>
           <td class="r">
            KIST School, University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#102562" title="Click to go to the Author Index">
             Lee, Deukhee
            </a>
           </td>
           <td class="r">
            KIST
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab70" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#medical_robotics_and_computer_integrated_surgery" title="Click to go to the Keyword Index">
               Medical Robotics and Computer-Integrated Surgery
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#computer_vision_and_visual_servoing" title="Click to go to the Keyword Index">
               Computer Vision and Visual Servoing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Introduction of surgical navigation into the operating room presents challenges related to lighting. While augmented reality (AR) has the potential to aid in surgery, most research on this subject have been conducted in preclinical settings with controlled lighting. HL2 (HoloLens 2), an OST-HMD (optical see-through head-mounted device) for AR commonly used in surgery, experiences performance limitations when exposed to direct and intense lighting. To tackle this problem, our research presents a real-time method to modify the exposure settings of the HL2 camera and cater to alterations in lighting conditions. The proposed algorithm identifies the brightest spot in a series of frames and then calculates its luminance level. Using this information, the process automatically determines the exposure time at a predefined ISO value while minimizing image artifacts. To assess the efficacy of this approach, we conducted experiments utilizing two different surgical lights and two distinct marker designs, both under static and dynamic conditions. The experimental findings suggest that both luminaires can achieve a detection rate of 93.59 ± 7.58% (p = 0.001*) for smaller marker geometries. Conversely, for larger geometries, the detection rate was 91.90±9.02%, with p-values of 0.0137* and 0.0189*, respectively, under each luminaire source, respectively, can be achieved.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to2b_05">
             10:30-11:30, Paper TO2B.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('110'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Realistic Surgical Simulator for Non-Rigid and Contact-Rich Manipulation in Surgeries with the Da Vinci Research Kit
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#344350" title="Click to go to the Author Index">
             Ou, Yafei
            </a>
           </td>
           <td class="r">
            University of Alberta
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#378500" title="Click to go to the Author Index">
             Zargarzadeh, Sadra
            </a>
           </td>
           <td class="r">
            University of Alberta
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#366166" title="Click to go to the Author Index">
             Sedighi, Paniz
            </a>
           </td>
           <td class="r">
            University of Alberta
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#104138" title="Click to go to the Author Index">
             Tavakoli, Mahdi
            </a>
           </td>
           <td class="r">
            University of Alberta
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab110" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#medical_robotics_and_computer_integrated_surgery" title="Click to go to the Keyword Index">
               Medical Robotics and Computer-Integrated Surgery
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#telerobotics" title="Click to go to the Keyword Index">
               Telerobotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Realistic real-time surgical simulators play an increasingly important role in surgical robotics research, such as surgical robot learning and automation, and surgical skills assessment. Although there are a number of existing surgical simulators for research, they generally lack the ability to simulate the diverse types of objects and contact-rich manipulation tasks typically present in surgeries, such as tissue cutting and blood suction. In this work, we introduce CRESSim, a realistic surgical simulator based on PhysX 5 for the da Vinci Research Kit (dVRK) that enables simulating various contact-rich surgical tasks involving different surgical instruments, soft tissue, and body fluids. The real-world dVRK console and the master tool manipulator (MTM) robots are incorporated into the system to allow for teleoperation through virtual reality (VR). To showcase the advantages and potentials of the simulator, we present three examples of surgical tasks, including tissue grasping and deformation, blood suction, and tissue cutting. These tasks are performed using the simulated surgical instruments, including the large needle driver, suction irrigator, and curved scissor, through VR-based teleoperation.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="to2c">
             <b>
              TO2C
             </b>
            </a>
           </td>
           <td class="r">
            KC907
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="UR24_ProgramAtAGlanceWeb.html#to2c" title="Click to go to the Program at a Glance">
             <b>
              Reasoning and Cognition
             </b>
            </a>
           </td>
           <td class="r">
            Regular
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="UR24_AuthorIndexWeb.html#332505" title="Click to go to the Author Index">
             Sørensen, Sune Lundø
            </a>
           </td>
           <td class="r">
            University of Southern Denmark
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="UR24_AuthorIndexWeb.html#231831" title="Click to go to the Author Index">
             Yumbla, Francisco
            </a>
           </td>
           <td class="r">
            ESPOL Polytechnic University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to2c_01">
             -, Paper TO2C.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('6'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Perceptual Anchoring for Gaze-Tracking Wearables and Robot-Mounted Sensors
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#332505" title="Click to go to the Author Index">
             Sørensen, Sune Lundø
            </a>
           </td>
           <td class="r">
            University of Southern Denmark
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#154213" title="Click to go to the Author Index">
             Huang, Shouren
            </a>
           </td>
           <td class="r">
            University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#325928" title="Click to go to the Author Index">
             Cao, Yongpeng
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#296610" title="Click to go to the Author Index">
             Mikkel, Kjærgaard
            </a>
           </td>
           <td class="r">
            University of Southern Denmark
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab6" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#world_modelling" title="Click to go to the Keyword Index">
               World Modelling
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#physical_and_cognitive_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical and Cognitive Human-Robot Interaction
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#rehabilitation_and_healthcare_robotics" title="Click to go to the Keyword Index">
               Rehabilitation and Healthcare Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             For persons with motor disabilities, robots have a great potential to improve the quality of daily interactions. A fully-fledged solution requires addressing many different challenges. Gaze-tracking wearables provides a new input modality for such solutions. In this paper we address the challenge of building and maintaining a world model using robot and gaze-tracking sensing data. We construct a world modeling pipeline consisting of a data association step and an anchoring step. In the data association step we compare four different methods. The results show that three possible data association methods outperform a geometric baseline. However, the results have potential for improvement, and thus future work to enhance the performance of the pipeline is needed. To guide future work, we have investigated potential factors which affect the performance of both the data association and the anchoring process, and found that the positions of detected objects have a significant impact.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to2c_02">
             10:30-11:30, Paper TO2C.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('11'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Semi-Autonomous Fast Object Segmentation and Tracking Tool for Industrial Applications
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#385416" title="Click to go to the Author Index">
             Neubauer, Melanie
            </a>
           </td>
           <td class="r">
            Montanuniversität Leoben
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#176888" title="Click to go to the Author Index">
             Rueckert, Elmar
            </a>
           </td>
           <td class="r">
            Montanuniversitaet Leoben
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab11" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#computer_vision_and_visual_servoing" title="Click to go to the Keyword Index">
               Computer Vision and Visual Servoing
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#object_recognition" title="Click to go to the Keyword Index">
               Object Recognition
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In the domain of deep learning in computer vision, minimizing the annotation workload for data is crucial. Due to the uniqueness of individual objects, comprehensive data annotation is essential for training deep neural networks. To streamline this process, a partially automated video annotation approach is proposed. The idea is to segment and classify each object with a single click, enabling automatic annotation through interpolating and tracking across subsequent frames, where the object is visible. In this paper, we developed a Fast Object Segmentation and Tracking Tool (FOST), which significantly reduces the labor-intensive nature of labeling image data from videos. Compared to other annotation tools, ours has the capability to automatically segment pre-selected objects in subsequent frames through the utilization of optical flow calculations. FOST is evaluated on three industrial applications. In our tests, we achieve significant results, with segmentation times ranging from approximately 0.14 to 0.29 seconds per frame, contingent on the number of segmented objects within each frame.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to2c_03">
             10:30-11:30, Paper TO2C.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('28'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Mobile Robot Based Personalized Thermal Comfort Scheme
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#349938" title="Click to go to the Author Index">
             Kim, Hyunju
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#349880" title="Click to go to the Author Index">
             Kim, Geon
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#349940" title="Click to go to the Author Index">
             Lee, Dongman
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab28" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#behavior_based_systems" title="Click to go to the Keyword Index">
               Behavior-Based Systems
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#ai_reasoning_methods_for_robotics" title="Click to go to the Keyword Index">
               AI Reasoning Methods for Robotics
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#wheeled_mobile_robots" title="Click to go to the Keyword Index">
               Wheeled Mobile Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Indoor thermal control is a crucial technique for ensuring user comfort and efficient energy usage, and typically relies on conventional methods that standardize the indoor thermal environment, neglecting individual personalized preferences. Mobile robots have emerged as a potential solution for personalizing temperature comfort. However, the existing research often falls short in considering factors like robot movement control, user activities, human states, and potential disturbance to users, leading to inaccurate estimations of a user's temperature adjustment needs. This paper introduces a mobile robot-based personalized thermal control system, designed to enhance the accuracy in recognizing human states relevant to thermal comfort in real indoor environments. This system achieves accurate thermal comfort estimation using vision-based recognition while reducing robot movement to decrease user inconvenience. The robot dynamically navigates to optimal positions, guided by the confidence level in vision-based human state recognition. We train the robot's movement control policy using a Deep Reinforcement Learning-based model. Real-world evaluation shows the system's success in accurately recognizing human states with minimal movement trajectories and reduced user discomfort. The proposed robot-based approach offers a significant advancement in personalized thermal control, allowing for more accurate thermal comfort estimation.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to2c_04">
             10:30-11:30, Paper TO2C.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Action2Code: Transforming Video Demonstrations into Sequential Robotic Instructions
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#340812" title="Click to go to the Author Index">
             Upadhyay, Abhinav
            </a>
           </td>
           <td class="r">
            Accenture Labs
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387141" title="Click to go to the Author Index">
             Mortala, Gautam Reddy
            </a>
           </td>
           <td class="r">
            Indraprastha Institute of Information Techonology Delhi
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#341598" title="Click to go to the Author Index">
             Dubey, Alpana
            </a>
           </td>
           <td class="r">
            Accenture
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387127" title="Click to go to the Author Index">
             Saurav, Shubham
            </a>
           </td>
           <td class="r">
            Accenture
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#341841" title="Click to go to the Author Index">
             Sengupta, Shubhashis
            </a>
           </td>
           <td class="r">
            Accenture Solutions Pvt. Ltd.
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to2c_05">
             10:30-11:30, Paper TO2C.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('153'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              TSP-Bot: Robotic TSP Pen Art Using High-DoF Manipulators
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#210737" title="Click to go to the Author Index">
             Song, Daeun
            </a>
           </td>
           <td class="r">
            Ewha Womans University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#340521" title="Click to go to the Author Index">
             Lim, Eunjung
            </a>
           </td>
           <td class="r">
            Ewha Womans University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#333878" title="Click to go to the Author Index">
             Park, Jiyoon
            </a>
           </td>
           <td class="r">
            Ewha Womans University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#340528" title="Click to go to the Author Index">
             Jung, Minjung
            </a>
           </td>
           <td class="r">
            Ewha Womans University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#104431" title="Click to go to the Author Index">
             Kim, Young J.
            </a>
           </td>
           <td class="r">
            Ewha Womans University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab153" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#contact__modeling__sensing_and_control_" title="Click to go to the Keyword Index">
               Contact: Modeling, Sensing and Control
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#foundations_of_sensing_and_estimation" title="Click to go to the Keyword Index">
               Foundations of Sensing and Estimation
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#robotic_systems_architectures_and_programming" title="Click to go to the Keyword Index">
               Robotic Systems Architectures and Programming
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             TSP art is an art form for drawing an image using piecewise-continuous line segments. We present TSP-Bot, a robotic pen drawing system capable of creating complicated TSP pen art on a planar surface using multiple colors. The system begins by converting a colored raster image into a set of points that represent the image's tone, which can be controlled by adjusting the point density. Next, the system finds a piecewise-continuous linear path that visits each point exactly once, which is equivalent to solving a Traveling Salesman Problem (TSP). The path is simplified with fewer points using bounded approximation and smoothed and optimized using Bezier spline curves with bounded curvature. Our robotic drawing system consisting of single or dual manipulators with fingered grippers and a mobile platform performs the drawing task by following the resulting complex and sophisticated path composed of thousands of TSP sites. As a result, our system can draw complicated and visually pleasing TSP pen art.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to2c_06">
             10:30-11:30, Paper TO2C.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('184'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              MARVIN: Mobile Autonomous Robot Vehicle for Investigation &amp; Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#388589" title="Click to go to the Author Index">
             Andrade Proaño, Luis Alberto
            </a>
           </td>
           <td class="r">
            Escuela Superior Politecnica Del Litoral
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#388582" title="Click to go to the Author Index">
             Fajardo-Pruna, Marcelo
            </a>
           </td>
           <td class="r">
            Escuela Superior Politécnica Del Litoral, ESPOL
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#388584" title="Click to go to the Author Index">
             Tutivén, Chritian Javier
            </a>
           </td>
           <td class="r">
            Escuela Superior Politécnica Del Litoral
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#328568" title="Click to go to the Author Index">
             Valarezo Añazco, Edwin
            </a>
           </td>
           <td class="r">
            Escuela Superior Politecnica Del Litoral
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#388580" title="Click to go to the Author Index">
             Recalde, Angel
            </a>
           </td>
           <td class="r">
            Escuela Superior Politécnica Del Litoral
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#388606" title="Click to go to the Author Index">
             Cajo, Ricardo
            </a>
           </td>
           <td class="r">
            Escuela Superior Politecnica Del Litoral (ESPOL)
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#231831" title="Click to go to the Author Index">
             Yumbla, Francisco
            </a>
           </td>
           <td class="r">
            ESPOL Polytechnic University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab184" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#wheeled_mobile_robots" title="Click to go to the Keyword Index">
               Wheeled Mobile Robots
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#intelligent_robotic_vehicles" title="Click to go to the Keyword Index">
               Intelligent Robotic Vehicles
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#motion_planning_and_obstacle_avoidance" title="Click to go to the Keyword Index">
               Motion Planning and Obstacle Avoidance
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Self-driving vehicles are a rising field for investigation; both in the commercial and academic world, but most framework platforms currently are not designed for the Latin American infrastructure environment, especially in manufacturing costs and their implementation. Therefore, this project involves designing, building, and programming a scaled self-driving vehicle based on the ROS2 infrastructure to make a more economical alternative for this market. SLAM tools were implemented in the prototype so that it could map its environment in real-time and self-navigate through it. In addition, a 3D model and a Gazebo based simulation were developed as the real environment test, so that the user can test the prototype in a simulated. All this research including the list of the parts necessary for the development of the car and the open-source architecture are uploaded to a GitHub repository. The final cost is comparably lower than its competition, therefore, this product can be considered a viable alternative as a learning platform in the actual market maintaining the characteristics of autonomous vehicles.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="to2d">
             <b>
              TO2D
             </b>
            </a>
           </td>
           <td class="r">
            KC909
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="UR24_ProgramAtAGlanceWeb.html#to2d" title="Click to go to the Program at a Glance">
             <b>
              Automation &amp; Industrial Robots
             </b>
            </a>
           </td>
           <td class="r">
            Regular
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to2d_01">
             -, Paper TO2D.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('97'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Hybrid Force Motion Control with Estimated Surface Normal for Manufacturing Applications
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#343445" title="Click to go to the Author Index">
             Nasiri, Ehsan
            </a>
           </td>
           <td class="r">
            Stevens Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#146612" title="Click to go to the Author Index">
             Wang, Long
            </a>
           </td>
           <td class="r">
            Stevens Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab97" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#industrial_robots" title="Click to go to the Keyword Index">
               Industrial Robots
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#contact__modeling__sensing_and_control_" title="Click to go to the Keyword Index">
               Contact: Modeling, Sensing and Control
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#manipulation_planning_and_control" title="Click to go to the Keyword Index">
               Manipulation Planning and Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper proposes a hybrid force-motion framework that utilizes real-time surface normal updates. The surface normal is estimated via a novel method that leverages force sensing measurements and velocity commands to compensate the friction bias. This approach is critical for robust execution of precision force-controlled tasks in manufacturing, such as thermoplastic tape replacement that traces surfaces or paths on a workpiece subject to uncertainties deviated from the model.
             <p>
              We formulated the proposed method and implemented the framework in ROS2 environment. The approach was validated using kinematic simulations and a hardware platform. Specifically, we demonstrated the approach on a 7-DoF manipulator equipped with a force/torque sensor at the end-effector.
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to2d_02">
             10:30-11:30, Paper TO2D.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Exploring the Effect of Anthropomorphic Design on Trust in Industrial Robots: Insights from a Metaverse Cobot Experiment
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#356160" title="Click to go to the Author Index">
             Wittmann, Maximilian
            </a>
           </td>
           <td class="r">
            Friedrich-Alexander-Universität Erlangen-Nürnberg
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#industrial_robots" title="Click to go to the Keyword Index">
               Industrial Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Collaborative robot (cobot) solutions offer several benefits, among them their cost-effectiveness, easy implementation on the shop floor, and the ability to automate repetitive processes. Increasingly, these systems are powered by Artificial Intelligence (AI). Cognitive and emotional barriers, however, often prevent a widespread introduction of AI-powered cobot solutions. One potential remedy for this lack of trust may be anthropomorphism, which has been empirically shown to improve the likeability of systems and affect the trust perception of human users. We developed a metaverse collaboration game set in a final assembly environment. At the example of an industrial robotic use case, we investigate the impact of anthropomorphic design on trust in the cobot. We ran a between-subject experiment with a sample size of 65 participants who interacted with a mechanical robot version or the anthropomorphized robot. The perception of the robot’s reliability, functionality, helpfulness, and trust increased within each group. Contrary to our assumptions, however, there were no significant differences in the median trust ratings between the anthropomorphically and the nonanthropomorphically designed robot. We discuss the ramifications for industrial human-robot interaction.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to2d_03">
             10:30-11:30, Paper TO2D.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('40'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Practical Evaluation of Multi-Agent Pathfinding in Automated Warehouse
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#349048" title="Click to go to the Author Index">
             Park, Chanwook
            </a>
           </td>
           <td class="r">
            LG Electronics
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#386874" title="Click to go to the Author Index">
             Nam, Moonsik
            </a>
           </td>
           <td class="r">
            LG Electronics
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#386937" title="Click to go to the Author Index">
             Mun, Hyeongil
            </a>
           </td>
           <td class="r">
            LG Electronics
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#349054" title="Click to go to the Author Index">
             Kim, Youngjae
            </a>
           </td>
           <td class="r">
            LG Electronics
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab40" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#industrial_robots" title="Click to go to the Keyword Index">
               Industrial Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Multi-agent pathfinding (MAPF) has drawn more attention with the increasing demand for deploying multi-robot applications in industry. Warehouse automation is one particular application of MAPF that is led by global logistics companies. In this application, a fleet of robots simultaneously navigates to their goal locations without collisions among themselves. The key purpose is to optimize operation efficiency in terms of throughput and operation costs. An increasing number of robots initially leads to higher throughput, but inefficiency in path-planning becomes unavoidable due to the dense robot population. In this work, we suggest a novel evaluation metric for automated warehouse applications, called a multi-agent efficiency factor. This metric attempts to quantify the efficiency of multi-robot operations in terms of time or energy consumption in congested environments. We simulate the lifelong version of MAPF in several environments using CCBS-PGA, a highly adaptive MAPF algorithm. Then we evaluate the efficiency of the multi-robot operations using the proposed factor, together with the throughput per agent. Our experiments demonstrate the effectiveness of the multi-agent efficiency factor as an evaluation metric for lifelong MAPF. Finally, we discuss the importance of agent density in designing multi-robot applications.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to2d_04">
             10:30-11:30, Paper TO2D.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('51'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Identification of Belt Conveyor Malfunctions Using Machine Learning with Diverse Anomalous Sound Data
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#386968" title="Click to go to the Author Index">
             Yoon, Jiyoung
            </a>
           </td>
           <td class="r">
            Korea Polytechnics
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#360869" title="Click to go to the Author Index">
             Kim, Do-Yoon
            </a>
           </td>
           <td class="r">
            WITHROBOT Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#105435" title="Click to go to the Author Index">
             Kim, Hyun-Don
            </a>
           </td>
           <td class="r">
            Robot Campus of Korea Polytechnic
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab51" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#industrial_robots" title="Click to go to the Keyword Index">
               Industrial Robots
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#ai_reasoning_methods_for_robotics" title="Click to go to the Keyword Index">
               AI Reasoning Methods for Robotics
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#robotic_systems_architectures_and_programming" title="Click to go to the Keyword Index">
               Robotic Systems Architectures and Programming
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This study introduces a novel approach to identifying belt conveyor malfunctions through the application of machine learning techniques, utilizing diverse anomalous sound data as training input. Traditional methods often rely on specific fault sound data for training, limiting their adaptability to unforeseen anomalies. In contrast, the methodology of this study utilizes machine learning algorithms trained on various abnormal sounds such as glass breaking or screams to identify malfunctions of the belt conveyor. The study focuses on the collection and curation of a diverse dataset encompassing various anomalous sounds, ensuring a comprehensive representation of potential disturbances in an industrial setting. Machine learning models, including deep neural networks, are trained on this heterogeneous dataset, enabling them to recognize abnormal patterns associated with belt conveyor faults. Experimental results demonstrate the efficacy of the proposed approach in accurately identifying belt conveyor malfunctions, even when the learned models are exposed to novel and previously unseen anomalies. The versatility of the method showcases its potential for real-world applications where conventional fault-specific training data may be insufficient. This study not only contributes to the advancement of anomaly detection in industrial settings but also highlights the importance of leveraging diverse sound data for enhanced machine learning-based fault identification.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to2d_05">
             10:30-11:30, Paper TO2D.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('83'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Markov Decision Process Approach for Battery Charging of an Automated Guided Vehicle
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#328493" title="Click to go to the Author Index">
             Lee, Min Seok
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#175199" title="Click to go to the Author Index">
             Hwang, Illhoe
            </a>
           </td>
           <td class="r">
            DAIM Research, Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#386841" title="Click to go to the Author Index">
             Jang, Sungwook
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387027" title="Click to go to the Author Index">
             Im, Nakjoon
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#155829" title="Click to go to the Author Index">
             Jang, Young Jae
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab83" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#industrial_robots" title="Click to go to the Keyword Index">
               Industrial Robots
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#wheeled_mobile_robots" title="Click to go to the Keyword Index">
               Wheeled Mobile Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The escalating automation of operations in manufacturing systems has seen a notable rise in the utilization of automated guided vehicles (AGVs) within automated material handling systems. AGVs, reliant on battery power, necessitate strategic charging policies to avert battery depletion during operations. However, prevailing heuristic approaches often yield inefficiencies. This study formulates the AGV charging problem as a Markov decision process (MDP) model, considering the uncertainty and geometric information of the environment. Relative value iteration has been implemented to optimize the MDP model. The proposed charging policy undergoes rigorous analysis and comparison with existing heuristics through simulation experiments. This process establishes its efficacy in advancing AGV charging efficiency.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to2d_06">
             10:30-11:30, Paper TO2D.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('175'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Off-The-Shelf Bin Picking Workcell with Visual Pose Estimation: A Case Study on the World Robot Summit 2018 Kitting Task
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#190969" title="Click to go to the Author Index">
             Hagelskjær, Frederik
            </a>
           </td>
           <td class="r">
            University of Southern Denmark
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#268687" title="Click to go to the Author Index">
             Høj Lorenzen, Kasper
            </a>
           </td>
           <td class="r">
            University of Southern Denmark
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#103860" title="Click to go to the Author Index">
             Kraft, Dirk
            </a>
           </td>
           <td class="r">
            University of Southern Denmark
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab175" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#industrial_robots" title="Click to go to the Keyword Index">
               Industrial Robots
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#object_recognition" title="Click to go to the Keyword Index">
               Object Recognition
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The World Robot Summit 2018 Assembly Challenge included four different tasks. The kitting task, which required bin-picking, was the task in which the fewest points were obtained. However, bin-picking is a vital skill that can significantly increase the flexibility of robotic set-ups, and is, therefore, an important research field. In recent years advancements have been made in sensor technology and pose estimation algorithms. These advancements allow for better performance when performing visual pose estimation.
             <p>
              This paper shows that by utilizing new vision sensors and pose estimation algorithms pose estimation in bins can be performed successfully. We also implement a workcell for bin picking along with a force based grasping approach to perform the complete bin picking. Our set-up is tested on the World Robot Summit 2018 Assembly Challenge and successfully obtains a higher score compared with all teams at the competition. This demonstrate that current technology can perform bin-picking at a much higher level compared with previous results.
             </p>
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="to2e">
             <b>
              TO2E
             </b>
            </a>
           </td>
           <td class="r">
            KC912
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="UR24_ProgramAtAGlanceWeb.html#to2e" title="Click to go to the Program at a Glance">
             <b>
              Aerial and Flying Robots
             </b>
            </a>
           </td>
           <td class="r">
            Regular
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="UR24_AuthorIndexWeb.html#219352" title="Click to go to the Author Index">
             Geckeler, Christian
            </a>
           </td>
           <td class="r">
            ETH Zürich
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="UR24_AuthorIndexWeb.html#385091" title="Click to go to the Author Index">
             Wilfried Yves Hamilton, Adoni
            </a>
           </td>
           <td class="r">
            Helmholtz-Zentrum Dresden-Rossendorf - (HZDR)
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to2e_01">
             -, Paper TO2E.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('102'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              User-Centric Payload Design and Usability Testing for Agricultural Sensor Placement and Retrieval Using Off-The-Shelf Micro Aerial Vehicles
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#219352" title="Click to go to the Author Index">
             Geckeler, Christian
            </a>
           </td>
           <td class="r">
            ETH Zürich
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387116" title="Click to go to the Author Index">
             Kong, Iris
            </a>
           </td>
           <td class="r">
            Technical University of Denmark
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#148776" title="Click to go to the Author Index">
             Mintchev, Stefano
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab102" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#aerial_and_flying_robots" title="Click to go to the Keyword Index">
               Aerial and Flying Robots
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#telerobotics" title="Click to go to the Keyword Index">
               Telerobotics
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#mechanism_and_design" title="Click to go to the Keyword Index">
               Mechanism and Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Increased flight time and advanced sensors are making MAVs easier to use, facilitating their widespread adoption in fields such as precision agriculture or environmental monitoring. However, current applications are limited mainly to passive visual observation from far above; to enable the next generation of aerial robot applications, MAVs must begin to directly physically interact with objects in the environment, such as placing and collecting sensors. Enabling these applications for a wide spectrum of end-users is only possible if the mechanism is safe and easy to use, without overburdening the user with complex integration, complicated control, or overwhelming and convoluted feedback. To this end we propose a self-sufficient passive payload system to enable both the deployment and retrieval of sensors for agriculture. This mechanism can be simply mechanically attached to a commercial, off-the-shelf MAV, without requiring further electrical or software integration. The user-centric design and mechanical intelligence of the system facilitates ease of use through simplified control with targeted perceptual feedback. The usability of the system is validated quantitatively and qualitatively in a user study demonstrating sensor deployment and collection. All participants were able to deploy and collect at least four sensors both within 10 minutes in visual line-of-sight and within 12 minutes in beyond visual line-of-sight, after only three minutes of practice. Enabling MAVs to physically interact with their environment will usher in the next stage of MAV utility and applications. Complex tasks, such as sensor deployment and retrieval, can be realized relatively simply, by relying on a mechanically passive system designed with the user in mind, these payloads can enable such applications to be more widely available and inclusive to end-users.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to2e_02">
             10:30-11:30, Paper TO2E.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('174'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              QuadFormer: Real-Time Unsupervised Power Line Segmentation with Transformer-Based Domain Adaptation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#307959" title="Click to go to the Author Index">
             Rao, Pratyaksh
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#350406" title="Click to go to the Author Index">
             Qiao, Feng
            </a>
           </td>
           <td class="r">
            Autel Robotics
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#353323" title="Click to go to the Author Index">
             Weide, Zhang
            </a>
           </td>
           <td class="r">
            Autel Robotics
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#113892" title="Click to go to the Author Index">
             Xu, Yiliang
            </a>
           </td>
           <td class="r">
            Autel Robotics
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#353329" title="Click to go to the Author Index">
             Deng, Yong
            </a>
           </td>
           <td class="r">
            Autel Robotics
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#353342" title="Click to go to the Author Index">
             Wu, Guangbin
            </a>
           </td>
           <td class="r">
            Autel Robotics
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#353338" title="Click to go to the Author Index">
             Zhang, Qiang
            </a>
           </td>
           <td class="r">
            Autel Robotics
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#142369" title="Click to go to the Author Index">
             Loianno, Giuseppe
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab174" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#computer_vision_and_visual_servoing" title="Click to go to the Keyword Index">
               Computer Vision and Visual Servoing
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#ai_reasoning_methods_for_robotics" title="Click to go to the Keyword Index">
               AI Reasoning Methods for Robotics
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#aerial_and_flying_robots" title="Click to go to the Keyword Index">
               Aerial and Flying Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Accurately identifying power lines (PL) is crucial for ensuring the safety of aerial vehicles. Despite the potential of recent deep learning approaches, obtaining high-quality ground truth annotations remains a challenging and labor-intensive task. Unsupervised domain adaptation (UDA) emerges as a promising solution, leveraging knowledge from labeled synthetic data to improve performance on unlabeled real images. However, existing UDA methods often suffer from its huge computation costs, limiting their deployment on real-time embedded systems commonly utilized in aerial vehicles. To mitigate this problem, this paper introduces QuadFormer, a real-time framework designed for unsupervised semantic segmentation within the UDA paradigm. QuadFormer integrates a lightweight transformer-based segmentation model with a cross-attention mechanism to narrow the domain gap. Additionally, we propose a novel pseudo label scheme to enhance the segmentation accuracy of the unlabelled real data. Furthermore, to facilitate the evaluation of our framework and promote reserach in powerline segemntation, we present two new datasets: AutelPL Synthetic and AutelPL Real. Experimental results demonstrate that QuadFormer achieves state-of-the-art performance on both AutelPL Synthetic rightarrow TTPLA and AutelPL Synthetic rightarrow AutelPL Real tasks. We will publicly release the dataset to the research community.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to2e_03">
             10:30-11:30, Paper TO2E.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('183'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Particle Swarm Optimization for Training Quadrotor PID Controller
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#388593" title="Click to go to the Author Index">
             Rodriguez, Eric
            </a>
           </td>
           <td class="r">
            The University of Texas at Rio Grande Valley
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#189075" title="Click to go to the Author Index">
             Lu, Qi
            </a>
           </td>
           <td class="r">
            The University of Texas Rio Grande Valley
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab183" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#aerial_and_flying_robots" title="Click to go to the Keyword Index">
               Aerial and Flying Robots
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#dynamics_and_control" title="Click to go to the Keyword Index">
               Dynamics and Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Energy expenditure for quadrotor control has a likelihood of being costly given parameter-dependent controllers that are less than optimal. The cost can grow proportionally when applied to multiple quadrotors for tracking and collaborative navigation tasks. This research aims to establish a basic approach to tuning PID (Proportional-Integral-Derivative) parameters for a simulated quadrotor drone. A PID controller for autonomy provides a straightforward method for correcting robotic movement based on its current state. However, applying a PID system to a flight controller poses challenges with an inherently under-actuated system, which includes the likelihood of large overshoots and lengthy adjustment times. To address this, we utilize PSO (Particle Swarm Optimization) for optimizing PID parameters in a simulated quadrotor. The PSO is employed to find optimal PID values for thrust, yaw, and translational movement on x- and y-positions by identifying converging values across randomly created particles. We conducted a set of experiments and compared it to the default PID controller. The experiments demonstrate converging properties for particles that achieve minimal fitness scores, particularly in reducing overshoot. The results indicate that the optimized PID controller outperforms the default PID controller without optimization. Using optimized PID controllers can decrease the amount of positional error during flight and when adjusting position with collaborative navigation and collision avoidance algorithms.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to2e_04">
             10:30-11:30, Paper TO2E.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('191'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Collision Dynamics of Motorized Deformable Propellers for Drones
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#382612" title="Click to go to the Author Index">
             Pham, Tien Hung
            </a>
           </td>
           <td class="r">
            Japan Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#244379" title="Click to go to the Author Index">
             Nguyen, Dinh
            </a>
           </td>
           <td class="r">
            Hanoi University of Industry
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#299740" title="Click to go to the Author Index">
             Bui, Son
            </a>
           </td>
           <td class="r">
            Hanoi University of Industry
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#142369" title="Click to go to the Author Index">
             Loianno, Giuseppe
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#122439" title="Click to go to the Author Index">
             Ho, Van
            </a>
           </td>
           <td class="r">
            Japan Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab191" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#aerial_and_flying_robots" title="Click to go to the Keyword Index">
               Aerial and Flying Robots
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#soft_robotics" title="Click to go to the Keyword Index">
               Soft Robotics
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#modeling__identification__calibration" title="Click to go to the Keyword Index">
               Modeling, Identification, Calibration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper investigates and analyzes the behavior of a deformable propeller during and after collisions. The experimental setup includes a deformable propeller, a BLDC motor, and a collision initiated while the propeller is rotating steadily. Here, we examine the changes in propeller’s angular velocity over time from the start of the collision until it fully recovers its initial velocity. This variation will be compared between the experimentally measured wing velocity using an encoder and the calculated propeller’s angular velocity in the simulation. The constructed model describes the relationship between propeller’s angular velocity and the input voltage supplied to the motor based on the Lagrange method. The study confirmed the shape transformation process and full restoration of the propeller’s original shape following collisions through high-speed video analysis. The results demonstrate consistent monitoring of collision initiation and the subsequent recovery process. This research enhances comprehension of the collision dynamics, thereby contributing to a deeper understanding of the fundamental physics governing deformable propellers, ultimately enhancing safety for drones.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to2e_05">
             10:30-11:30, Paper TO2E.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('198'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Autotarget*: A Distributed Robot Operating System Framework for Autonomous Aerial Swarms
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#385091" title="Click to go to the Author Index">
             Wilfried Yves Hamilton, Adoni
            </a>
           </td>
           <td class="r">
            Helmholtz-Zentrum Dresden-Rossendorf - (HZDR)
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#399968" title="Click to go to the Author Index">
             Fareedh-Shaik, Junaidh
            </a>
           </td>
           <td class="r">
            Helmholtz-Institut Freiberg Für Ressourcentechnologie
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#399965" title="Click to go to the Author Index">
             Lorenz, Sandra
            </a>
           </td>
           <td class="r">
            Helmholtz-Institut Freiberg Für Ressourcentechnologie
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#399967" title="Click to go to the Author Index">
             Richard, Richard Gloaguen
            </a>
           </td>
           <td class="r">
            Helmholtz-Institut Freiberg Für Ressourcentechnologie
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#399970" title="Click to go to the Author Index">
             Thomas D., Kühne
            </a>
           </td>
           <td class="r">
            Center for Advanced Systems Understanding -(HZDR-CASUS)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab198" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#aerial_and_flying_robots" title="Click to go to the Keyword Index">
               Aerial and Flying Robots
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#robotic_systems_architectures_and_programming" title="Click to go to the Keyword Index">
               Robotic Systems Architectures and Programming
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robot Operating System (ROS) has proven itself as a viable framework for developing robot-related applications. It offers features such as hardware abstraction, low-level device support, inter-process communication, and useful libraries for autonomous robot systems. Concerning aerial robots, commonly called unmanned aerial vehicles (UAV) or drones, ROS provides unfortunately very basic functions. Moreover, it does not guarantee real-time operation, as it runs under Linux. Consequently, it is difficult to implement advanced ROS applications that involve a swarm of drones that need to communicate with each other to carry out a common mission. This paper proposes an extended version of the ROS framework called autotarget∗, which provides a set of efficient functions designed for distributed operation on multiple UAVs flying at the same time. autotarget∗ relies on a multi-tier architecture with a decentralized communication layer, enabling intra-UAV messaging as well as the scalability of swarm UAVs. It has a set of daemons whose feature is to regulate the swarm’s consensus control and failover policy to ensure convergence towards a common goal. Experiments with real-world swarms revealed that autotarget∗ is portable and satisfies performance requirements for collaborative mission applications. We further conducted a coverage planning mission using the parallel back-and-forth algorithm, which demonstrated the efficiency of the framework in terms of time and energy. Our work should pave the way for an open-source environment dedicated to simplifying collaborative ROS application development, particularly for multi-UAV systems.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="to4a">
             <b>
              TO4A
             </b>
            </a>
           </td>
           <td class="r">
            Rosenthal
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="UR24_ProgramAtAGlanceWeb.html#to4a" title="Click to go to the Program at a Glance">
             <b>
              Human-Robot Interaction II
             </b>
            </a>
           </td>
           <td class="r">
            Regular
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to4a_01">
             -, Paper TO4A.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('20'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Safety-Optimized Strategy for Grasp Detection in High-Clutter Scenarios
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#386510" title="Click to go to the Author Index">
             Li, Chenghao
            </a>
           </td>
           <td class="r">
            Japan Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#386602" title="Click to go to the Author Index">
             Zhou, Peiwen
            </a>
           </td>
           <td class="r">
            Japan Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#102527" title="Click to go to the Author Index">
             Chong, Nak Young
            </a>
           </td>
           <td class="r">
            Japan Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab20" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The detection accuracy and speed of grasp detection models on benchmarks are the focal points of concern in the robotic grasping community. Especially in a collaborative robot setting, the safety of the model is an essential aspect that cannot be overlooked. In this paper, we explore how to enhance the safety of grasp detection models in autonomous vision-guided grasping. Specifically, we propose a simple yet practical Safety-optimized Strategy, which consists of two parts. The first part involves depth prioritization, optimizing the grasp sequence from top to bottom based on the order of depth values, which can mitigate the issue of grasp collisions that may arise when the depth value of the object with the highest grasp quality is significantly higher than that of other objects in high-clutter scenarios. The second part is false-positive protection, where we introduce the robust ArUco marker as the lowest grasp priority. The marker is fixed at certain positions within the camera's field of view, enabling the robot to halt its movement, thereby restraining the robot from grasping objects that should not be grasped. Once the marker disappears, the robot can resume its operations. We validate our method through real grasping experiments with a parallel-jaw gripper and an industrial robotic arm, demonstrating its effectiveness in high-clutter scenarios.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to4a_02">
             -, Paper TO4A.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('85'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Mixed Reality-Based Teleoperation of Mobile Robotic Arm: System Apparatus and Experimental Case Study
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387105" title="Click to go to the Author Index">
             Annalisa, Jarecki
            </a>
           </td>
           <td class="r">
            Texas A&amp;M University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#103527" title="Click to go to the Author Index">
             Lee, Kiju
            </a>
           </td>
           <td class="r">
            Texas A&amp;M University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab85" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#human_robot_augmentation" title="Click to go to the Keyword Index">
               Human-Robot Augmentation
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#wheeled_mobile_robots" title="Click to go to the Keyword Index">
               Wheeled Mobile Robots
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#telerobotics" title="Click to go to the Keyword Index">
               Telerobotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a system apparatus for supporting the remote operation of a mobile robot arm using a mixed reality (MR)-based user interface (UI). The presented system is based on Robot Operating System 2, utilizing newly developed and existing software packages for gesture-based control of the mobile base and the robotic arm. An experimental case study was designed to evaluate the system-level integration and usability. The case study involved seven participants completing a simple sequence of remote operation tasks using two different UI modalities, the MR device and a conventional computer interface (i.e., a 2D display and a keyboard). The results showed that the MR-based UI might be perceived by participants as more intuitive than the conventional control interfaces, while some limitations, such as gesture sensitivity and increased task load due to unfamiliarity, were also identified.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to4a_03">
             -, Paper TO4A.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('117'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Preliminary Study of the Mobile Robot-Based Cooperative System for Outdoor Hazardous Testing Spaces
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#386138" title="Click to go to the Author Index">
             Kim, Boseong
            </a>
           </td>
           <td class="r">
            ADD
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387197" title="Click to go to the Author Index">
             Kim, Yoonkeon
            </a>
           </td>
           <td class="r">
            ADD
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387199" title="Click to go to the Author Index">
             Kim, Eungsoo
            </a>
           </td>
           <td class="r">
            ADD
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387200" title="Click to go to the Author Index">
             Kang, Jaeun
            </a>
           </td>
           <td class="r">
            ADD
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387204" title="Click to go to the Author Index">
             Kim, Kihoon
            </a>
           </td>
           <td class="r">
            Newtech Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387201" title="Click to go to the Author Index">
             Jo, Younghyun
            </a>
           </td>
           <td class="r">
            Innotech Inc
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab117" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#robotics_in_hazardous_applications" title="Click to go to the Keyword Index">
               Robotics in Hazardous Applications
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#wheeled_mobile_robots" title="Click to go to the Keyword Index">
               Wheeled Mobile Robots
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#robot_surveillance_and_security" title="Click to go to the Keyword Index">
               Robot Surveillance and Security
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Unlike the diverse improvement efforts actively ongoing in general industrial sites, military development product that involves explosives and propellants demand a high level of operational reliability and safety to their specificity. In this paper, a mobile robot-based cooperative testing system has been proposed and developed as an attempt to mitigate various threats that may arise during firearm and ammunition testing. The robot is designed to autonomously execute the procedures necessary for firearm preparation, relying on a configuration of both commercially available and self-developed sensors. a vision-based automatic sorting algorithm has been implemented to self-detect variations in the reference azimuth angle during live firing test. To verify the ammunition loading safety of the developed system, a measurement environment was configured to measure the impact force on the ammunition using PCB PIEZOTRONICS 350C03 sensors and the Dewetron DEWE-2072 data acquisition system. The analysis results show a 70% reduction in impulse compared to manual loading cases, demonstrating the safety effectiveness of the proposed system. Moreover, the feasibility of the mobile robot-based testing technique has also been verified in the live firing test.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to4a_04">
             14:20-15:20, Paper TO4A.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('123'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Data Collection Scheme to Develop Future Autonomous Manipulation for Military Applications
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#221701" title="Click to go to the Author Index">
             Kim, Dongbin
            </a>
           </td>
           <td class="r">
            United States Military Academy
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#293960" title="Click to go to the Author Index">
             Manjunath, Pratheek
            </a>
           </td>
           <td class="r">
            United States Army
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#289743" title="Click to go to the Author Index">
             Adeniran, Emmanuel
            </a>
           </td>
           <td class="r">
            Yale University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387189" title="Click to go to the Author Index">
             Davis, Joseph
            </a>
           </td>
           <td class="r">
            United States Military Academy
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab123" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#telerobotics" title="Click to go to the Keyword Index">
               Telerobotics
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#human_robot_augmentation" title="Click to go to the Keyword Index">
               Human-Robot Augmentation
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#learning_from_humans" title="Click to go to the Keyword Index">
               Learning From Humans
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The U.S. Department of Defense is advancing mobile robotic manipulation to conduct dangerous tasks such as Explosive Ordnance Disposal (EOD) and hazardous materials (HazMat) handling, where current autonomous systems fall short. In a battlefield environment, contested communications may prohibit the use of telemanipulation, thus establishing the need for highly dexterous autonomous mobile manipulation robots. This paper presents a data collection scheme using telemanipulation, comprised of a Mixed Reality (MR) control interface, enabling a human in the loop to remotely execute a specialized task. The user-interaction data collected is instrumental in developing advanced, predictive, and adaptive control systems via machine learning algorithms. These systems enhance robot autonomy while ensuring operator oversight, particularly critical in military settings. We detail an initial pick-and-place task with novice cadet researchers, analyzing the results and setting the stage for future research in autonomous mobile manipulation for battlefield applications.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to4a_05">
             14:20-15:20, Paper TO4A.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('131'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Usability Study of a Human-Robot Tele-Collaboration System for Nuclear Glove Boxes and Isolators
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#225526" title="Click to go to the Author Index">
             Kim, BaekSeok
            </a>
           </td>
           <td class="r">
            University of Nevada, Las Vegas
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#317470" title="Click to go to the Author Index">
             Kassai, Nathan
            </a>
           </td>
           <td class="r">
            University of Nevada, Las Vegas
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#100181" title="Click to go to the Author Index">
             Oh, Paul Y.
            </a>
           </td>
           <td class="r">
            University of Nevada, Las Vegas (UNLV)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab131" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#telerobotics" title="Click to go to the Keyword Index">
               Telerobotics
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#human_robot_augmentation" title="Click to go to the Keyword Index">
               Human-Robot Augmentation
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#physical_and_cognitive_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical and Cognitive Human-Robot Interaction
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper describes our ongoing research to develop a Human Robot Tele-Collaboration System. The goal is to enhance the usability of Glove Boxes commonly used in various nuclear facilities through the collaboration of robots and humans. In many cases, Glove Box operators have limited visibility and cannot reach the entire workspace, necessitating the use of additional tools inside the Glove Box. While attempts exist to solve these issues by placing robots inside the Glove Box, remotely operating a robot to perform fine tasks remains a challenging problem. This paper presents a Tele-Collaboration System that utilizes robots placed inside the Glove Box to overcome the limited workspace issues of the Operator. Moreover, glove Box operators can complement the robot's lacking dexterity, enabling more effective task performance.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to4a_06">
             14:20-15:20, Paper TO4A.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('165'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Integrating Human Expertise in Continuous Spaces: A Novel Interactive Bayesian Optimization Framework with Preference Expected Improvement
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#377212" title="Click to go to the Author Index">
             Feith, Nikolaus
            </a>
           </td>
           <td class="r">
            Montanuniversität Leoben
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#176888" title="Click to go to the Author Index">
             Rueckert, Elmar
            </a>
           </td>
           <td class="r">
            Montanuniversitaet Leoben
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab165" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#learning_from_humans" title="Click to go to the Keyword Index">
               Learning From Humans
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#physical_and_cognitive_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical and Cognitive Human-Robot Interaction
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Interactive Machine Learning (IML) seeks to integrate human expertise into machine learning processes. However, most existing algorithms cannot be applied to real world scenarios because their state spaces and/or action spaces are limited to discrete values. Furthermore, the interaction is limited to either a binary, good or bad, decision or the choice of which of the proposed solutions is the best. We therefore propose a novel framework based on Bayesian Optimization (BO). Interactive Bayesian Optimization (IBO) captures user preferences and provides an interface for users to shape the strategy by hand. Additionally, we've incorporated a new acquisition function, Preference Expected Improvement (PEI), to refine the system's efficiency using a probabilistic model of the user preferences. Our approach is geared towards ensuring that machines can benefit from human expertise, aiming for a more aligned and effective learning process. In the course of this work, we applied our method to simulations and in a real world task using a Franka Panda robot to show human-robot collaboration.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="to4b">
             <b>
              TO4B
             </b>
            </a>
           </td>
           <td class="r">
            KC905
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="UR24_ProgramAtAGlanceWeb.html#to4b" title="Click to go to the Program at a Glance">
             <b>
              Rehabilitation and Healthcare Robotics
             </b>
            </a>
           </td>
           <td class="r">
            Regular
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="UR24_AuthorIndexWeb.html#403545" title="Click to go to the Author Index">
             Park, Young-Bin
            </a>
           </td>
           <td class="r">
            Ulsan National Institute of Science and Technology
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to4b_01">
             -, Paper TO4B.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('101'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Investigating the Generalizability of Assistive Robots Models Over Various Tasks
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#348580" title="Click to go to the Author Index">
             Osooli, Hamid
            </a>
           </td>
           <td class="r">
            University of Massachusetts Lowell
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387147" title="Click to go to the Author Index">
             Coco, Christopher
            </a>
           </td>
           <td class="r">
            University of Massachusetts Lowell
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387146" title="Click to go to the Author Index">
             Spanos, Jonathan
            </a>
           </td>
           <td class="r">
            University of Massachusetts Lowell
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#338161" title="Click to go to the Author Index">
             Majdi, Amin
            </a>
           </td>
           <td class="r">
            University of Massachusetts Lowell
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#160355" title="Click to go to the Author Index">
             Azadeh, Reza
            </a>
           </td>
           <td class="r">
            University of Massachusetts Lowell
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab101" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#rehabilitation_and_healthcare_robotics" title="Click to go to the Keyword Index">
               Rehabilitation and Healthcare Robotics
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#modeling__identification__calibration" title="Click to go to the Keyword Index">
               Modeling, Identification, Calibration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In the domain of assistive robotics, the significance of effective modeling is well acknowledged. Prior research has primarily focused on enhancing model accuracy or involved the collection of extensive, often impractical amounts of data. While improving individual model accuracy is beneficial, it necessitates constant remodeling for each new task and user interaction. In this paper, we investigate the generalizability of different modeling methods. We focus on constructing the dynamic model of an assistive exoskeleton using six data-driven regression algorithms. Six tasks are considered in our experiments, including horizontal, vertical, diagonal from left leg to the right eye and the opposite, as well as eating and pushing. We constructed thirty-six unique models applying different regression methods to data gathered from each task. Each trained model's performance was evaluated in a cross-validation scenario, utilizing five folds for each dataset. These trained models are then tested on the other tasks that the model is not trained with. Finally the models in our study are assessed in terms of generalizability. Results show the superior generalizability of the task model performed along the horizontal plane, and decision tree based algorithms.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to4b_02">
             -, Paper TO4B.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('148'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Quantification of Shoulder Joint Impedance During Dynamic Motion: A Pilot Study Using a Parallel-Actuated Shoulder Exoskeleton Robot
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#294627" title="Click to go to the Author Index">
             Hwang, Seunghoon
            </a>
           </td>
           <td class="r">
            Arizona State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387033" title="Click to go to the Author Index">
             Chan, Edward
            </a>
           </td>
           <td class="r">
            Arizona State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#110705" title="Click to go to the Author Index">
             Lee, Hyunglae
            </a>
           </td>
           <td class="r">
            Arizona State University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab148" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#rehabilitation_and_healthcare_robotics" title="Click to go to the Keyword Index">
               Rehabilitation and Healthcare Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Previous studies characterizing shoulder joint impedance were either strictly limited to 2D planar motion or static postures in 3D space. It is still not clear how shoulder joint impedance is regulated during dynamic motion in 3D space. To address this knowledge gap, this study presents our initial efforts to quantify shoulder joint impedance during dynamic shoulder motion using a parallel-actuated shoulder exoskeleton robot. The robot's 4-bar spherical parallel manipulation mechanism, characterized by low inertia, allows for transparent and natural arm motion in 3D space and applies rapid perturbations to the upper arm during dynamic shoulder motion. Two unimpaired individuals participated in an experiment involving repeated shoulder flexion and extension motions at a fixed horizontal shoulder extension angle of 45 degrees. Shoulder impedance was quantified by estimating the relationship between the kinematics of input position perturbations, which were applied in the orthogonal direction of the arm motion, and the output torque responses resulting from these perturbations. This relationship was approximated by a second-order model consisting of inertia, damping, and stiffness. Both subjects showed high reliability in impedance quantification during shoulder flexion and extension movements, evidenced by a high percentage Variance Accounted For that exceeds 96%. The experimental results showed the following notable trends. First, the contribution of stiffness to the shoulder torque was greater than that of the other two impedance parameters. Next, damping was larger during shoulder extension (downward motion) as opposed to flexion (upward motion). Lastly, inertia remained relatively constant regardless of shoulder motions. This pilot study validated the reliability of the presented robotic approach, paving the way for future shoulder impedance studies involving various dynamic motions in 3D space.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to4b_03">
             -, Paper TO4B.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('182'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Hybrid CNN-LSTM Network with Attention Mechanism for Myoelectric Control in Upper Limb Exoskeletons
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#366166" title="Click to go to the Author Index">
             Sedighi, Paniz
            </a>
           </td>
           <td class="r">
            University of Alberta
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#388409" title="Click to go to the Author Index">
             Marey, Amr Mohamed Fawzy
            </a>
           </td>
           <td class="r">
            University of Alberta
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#165039" title="Click to go to the Author Index">
             Golabchi, Ali
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#296366" title="Click to go to the Author Index">
             Li, Xingyu
            </a>
           </td>
           <td class="r">
            University of Alberta
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#104138" title="Click to go to the Author Index">
             Tavakoli, Mahdi
            </a>
           </td>
           <td class="r">
            University of Alberta
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab182" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#rehabilitation_and_healthcare_robotics" title="Click to go to the Keyword Index">
               Rehabilitation and Healthcare Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper introduces a novel attention-based sequence-to-sequence network for predicting upper-limb exoskeleton joint angles, enhancing the control of assistive technologies for individuals with upper limb impairments. By integrating EMG and IMU signals, our model facilitates real-time decoding of user intentions, generating precise movement trajectories for a 3-DoF cable-driven upper-limb exoskeleton. The implementation of an attention mechanism within an encoder-decoder architecture allows for the dynamic prioritization of the most pertinent EMG features and historical angular positions, significantly improving prediction accuracy and system responsiveness. This approach not only offers a tailored response to varying sequence lengths and compensates for sensor unreliability but also introduces a level of personalization and adaptability previously unattainable in robotic rehabilitation and assistive devices. Through this model, we demonstrate a more effective, user-specific method of enhancing motor function recovery and facilitating daily activities, setting a new standard for assistive exoskeleton technology.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to4b_04">
             14:20-15:20, Paper TO4B.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('77'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Human-Robot Interactive Control for Knee Exoskeleton Using Feedback Torque and Adjustable Stiffness
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387064" title="Click to go to the Author Index">
             Du, Zhao-Ning
            </a>
           </td>
           <td class="r">
            Shenzhen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#222181" title="Click to go to the Author Index">
             Cao, Guang-Zhong
            </a>
           </td>
           <td class="r">
            Shenzhen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#295447" title="Click to go to the Author Index">
             Zhang, Yue-Peng
            </a>
           </td>
           <td class="r">
            Shenzhen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#318694" title="Click to go to the Author Index">
             Li, Ling-Long
            </a>
           </td>
           <td class="r">
            Shenzhen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#222186" title="Click to go to the Author Index">
             Huang, Su-Dan
            </a>
           </td>
           <td class="r">
            Shenzhen University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab77" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#rehabilitation_and_healthcare_robotics" title="Click to go to the Keyword Index">
               Rehabilitation and Healthcare Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Aiming at the problem that the rigid exoskeleton has insufficient compliance due to mechanical vibration in the human-robot cooperation motion and can only move within a small range of designed trajectories, the user's active motion intention cannot be fully expressed. In this paper, a human-robot cooperation control method using compliance factor with feedback torque and adjustable stiffness is proposed, which can arbitrarily change the current motion trajectory according to the user's active intention torque, while the knee exoskeleton can maintain the compliance and stability of the motion. The compliance factor includes stiffness adjustment items and torque adjustment items. The stiffness change feedback based on SEA improves the flexibility. The intention amplification function is designed to enhance the user's active intention. The proposed method is validated by the designed knee exoskeleton. When feedback compliance factor, knee exoskeleton has good compliance and flexibility. In extension and flexion, the highest γ values (γ reflects the intensity of the subject's initiative) are 3.390 and 3.705, respectively.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to4b_05">
             14:20-15:20, Paper TO4B.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Bionic Design and Kinematic Evaluation of a Stiffness-Adjustable Spinal Exoskeleton for Trunk Support
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#384303" title="Click to go to the Author Index">
             Yin, Yuhan
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#222113" title="Click to go to the Author Index">
             Zhu, Aibin
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#385735" title="Click to go to the Author Index">
             Xu, Peng
            </a>
           </td>
           <td class="r">
            Honghui Hospital, Xi'an Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#318050" title="Click to go to the Author Index">
             Zhang, Jing
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387094" title="Click to go to the Author Index">
             Liu, Jie
            </a>
           </td>
           <td class="r">
            Yanshan University
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="to4c">
             <b>
              TO4C
             </b>
            </a>
           </td>
           <td class="r">
            KC907
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="UR24_ProgramAtAGlanceWeb.html#to4c" title="Click to go to the Program at a Glance">
             <b>
              AI Reasoning Methods for Robotics
             </b>
            </a>
           </td>
           <td class="r">
            Regular
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to4c_01">
             -, Paper TO4C.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('186'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Is It Safe to Cross? Interpretable Risk Assessment with GPT-4V for Safety-Aware Street Crossing
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#226416" title="Click to go to the Author Index">
             Hwang, Hochul
            </a>
           </td>
           <td class="r">
            University of Massachusetts Amherst
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#388605" title="Click to go to the Author Index">
             Kwon, Sunjae
            </a>
           </td>
           <td class="r">
            UMass Amherst
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#388609" title="Click to go to the Author Index">
             Kim, Yekyung
            </a>
           </td>
           <td class="r">
            University of Masachusetts, Amherst
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#168080" title="Click to go to the Author Index">
             Kim, Donghyun
            </a>
           </td>
           <td class="r">
            University of Massachusetts Amherst
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab186" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#ai_reasoning_methods_for_robotics" title="Click to go to the Keyword Index">
               AI Reasoning Methods for Robotics
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#computer_vision_and_visual_servoing" title="Click to go to the Keyword Index">
               Computer Vision and Visual Servoing
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#object_recognition" title="Click to go to the Keyword Index">
               Object Recognition
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Safely navigating street intersections is a complex challenge for blind and low-vision individuals, as it requires a nuanced understanding of the surrounding context -- a task heavily reliant on visual cues. Traditional methods for assisting in this decision-making process often fall short, lacking the ability to provide a comprehensive scene analysis and safety level. This paper introduces an innovative approach that leverages vision-language models (VLMs) to interpret complex street crossing scenes, offering a potential advancement over conventional traffic signal recognition techniques. By generating a safety score and scene description in natural language, our method supports safe decision-making for blind and low-vision individuals. We collected crosswalk intersection data that contains multiview egocentric images captured by a quadruped robot and annotated the images with corresponding safety scores based on our predefined safety score categorization. Grounded on the visual knowledge, extracted from images and text prompts, we evaluate a VLM for safety score prediction and scene description. Our findings highlight the reasoning and safety score prediction capabilities of the VLM, activated by various prompts, as a pathway to developing a trustworthy system, crucial for applications requiring reliable decision-making support.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to4c_02">
             -, Paper TO4C.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Methodology of Stable 6-DoF Grasp Detection for Complex Shaped Object Using End-To-End Network
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#385370" title="Click to go to the Author Index">
             Jeong, Woojin
            </a>
           </td>
           <td class="r">
            LG Electronics
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#385371" title="Click to go to the Author Index">
             Gu, Yongwoo
            </a>
           </td>
           <td class="r">
            LG Electronics
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#385374" title="Click to go to the Author Index">
             Lee, Jaewook
            </a>
           </td>
           <td class="r">
            LG Electronics
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#231157" title="Click to go to the Author Index">
             Yi, June-Sup
            </a>
           </td>
           <td class="r">
            LG Electronics
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#ai_reasoning_methods_for_robotics" title="Click to go to the Keyword Index">
               AI Reasoning Methods for Robotics
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#foundations_of_sensing_and_estimation" title="Click to go to the Keyword Index">
               Foundations of Sensing and Estimation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The proﬁcient grasping of objects is a signiﬁcant challenge in robotics, particularly in dynamic environments. Deep learning-based approaches have shown promise in adapting to changing situations and achieving successful grasping. Previous research utilizing deep learning to generate grasp candidates can be categorized into two approaches based on the degrees of freedom of a grasp: the 4-DoF (top-down) and 6-DoF methods. Due to the 4-DoF approach is limited by its lack of gripper orientation ﬂexibility, the 6-DoF approach offers more accuracy and precision in grasping objects. This paper proposes improvements to the GSNet network, which is an open-source state-of-the-art network for 6-DoF grasping, through parameter tuning and the application of stable score and Multiscale Cylinder Grouping strategies. Detailed explanations are also provided on the method of applying different strategies to a single network and on the approaches of parameter tuning. By the implementation process, there were improvements for grasping complex-shaped objects and small objects. To validate the improvements, experiments were conducted to measure the AP in the scenes of the GraspNet-1Billion dataset. The results indicate that the maximum AP achieved in the case of novel objects is 27.92, which is higher than that of the original network. Additionally, the experimental results showed a success rate of 90.9% for bin picking with cluttered objects, demonstrating the practical utility of our network even in real-world environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to4c_03">
             -, Paper TO4C.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('7'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Transparent Object Depth Reconstruction Framework for Mixed Scenes with Transparent and Opaque Objects
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#385370" title="Click to go to the Author Index">
             Jeong, Woojin
            </a>
           </td>
           <td class="r">
            LG Electronics
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#385371" title="Click to go to the Author Index">
             Gu, Yongwoo
            </a>
           </td>
           <td class="r">
            LG Electronics
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#385374" title="Click to go to the Author Index">
             Lee, Jaewook
            </a>
           </td>
           <td class="r">
            LG Electronics
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#231157" title="Click to go to the Author Index">
             Yi, June-Sup
            </a>
           </td>
           <td class="r">
            LG Electronics
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab7" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#ai_reasoning_methods_for_robotics" title="Click to go to the Keyword Index">
               AI Reasoning Methods for Robotics
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#object_recognition" title="Click to go to the Keyword Index">
               Object Recognition
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The increasing demand for autonomous robots necessitates the recognition and handling of transparent objects commonly found in daily life. Recognizing transparent objects through sensors is challenging due to their partial transmission and refraction of light, resulting in inaccurate depth measurements. Through testing, we checked that previous studies on transparent object depth reconstruction yielded inaccurate results in scenes where transparent and opaque objects are mixed, as well as false-positive results in scenes without transparent objects. We propose a framework that performs transparent object depth reconstruction even in scenes where both transparent and opaque objects coexist, while avoiding false-positive results in scenes without transparent objects. We utilize the structure of ClearGrasp, which has separate networks for different roles, allowing easy modifications. The Translab network, which is trained using the Trans10K-v2 dataset, is used for transparent object segmentation during the inference process. For the Depth Completion network, we utilized a network with a self-attention mechanism that effectively completes significant depth differences in the surroundings. Additionally, we design and apply the Depth Modification module to enhance depth input of the Depth Completion network by retaining accurate depth values in transparent object regions. The experimental results showed that our network achieved a lower depth estimation RMSE of 0.019 for real-novel objects compared to existing state-of-the-art networks. Furthermore, the experimental results showed a success rate of 94.1% for bin picking with cluttered objects.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to4c_04">
             14:20-15:20, Paper TO4C.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('98'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Curiosity-Driven Learning for Visual Control of Nonholonomic Mobile Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387093" title="Click to go to the Author Index">
             Soualhi, Takieddine
            </a>
           </td>
           <td class="r">
            Belfort-Montbéliard University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#179017" title="Click to go to the Author Index">
             Crombez, Nathan
            </a>
           </td>
           <td class="r">
            Université De Technologie De Belfort-Montbéliard
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387114" title="Click to go to the Author Index">
             Lombard, Alexandre
            </a>
           </td>
           <td class="r">
            Université De Technologie De Belfort-Montbéliard, Laboratoire Co
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#339846" title="Click to go to the Author Index">
             Galland, Stephane
            </a>
           </td>
           <td class="r">
            Université De Technologie De Belfort Montvéliard
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#127659" title="Click to go to the Author Index">
             Ruichek, Yassine
            </a>
           </td>
           <td class="r">
            University of Technology of Belfort-Montbeliard - France
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab98" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#ai_reasoning_methods_for_robotics" title="Click to go to the Keyword Index">
               AI Reasoning Methods for Robotics
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#computer_vision_and_visual_servoing" title="Click to go to the Keyword Index">
               Computer Vision and Visual Servoing
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#wheeled_mobile_robots" title="Click to go to the Keyword Index">
               Wheeled Mobile Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we study the problem of visual servoing of nonholonomic mobile robots. Achieving precise positioning becomes particularly challenging within the classical approaches of visual servoing, primarily due to motion and field-of-view constraints. Previous work has demonstrated the effectiveness of deep reinforcement learning in addressing visual servoing tasks for robotic manipulators. In light of this, we propose a novel deep reinforcement learning framework that integrates deep recurrent policies and curiosity-driven learning to tackle the problem of visual servoing of nonholonomic mobile robots. First, we analyze the influence of the nonholonomic constraints on control policy learning, and subsequently, we evaluate our approach on both simulated and real-world environments. Our results demonstrate the superiority of our model in terms of spatial trajectories and convergence accuracy compared to the existing approaches.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to4c_05">
             14:20-15:20, Paper TO4C.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('111'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Relational Q-Functionals: Multi-Agent Learning to Recover from Unforeseen Robot Malfunctions in Continuous Action Domains
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#351039" title="Click to go to the Author Index">
             Findik, Yasin
            </a>
           </td>
           <td class="r">
            University of Massachusetts Lowell
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#128212" title="Click to go to the Author Index">
             Robinette, Paul
            </a>
           </td>
           <td class="r">
            University of Massachusetts Lowell
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#199416" title="Click to go to the Author Index">
             Jerath, Kshitij
            </a>
           </td>
           <td class="r">
            University of Massachusetts Lowell
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#160355" title="Click to go to the Author Index">
             Azadeh, Reza
            </a>
           </td>
           <td class="r">
            University of Massachusetts Lowell
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab111" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#performance_evaluation_and_optimization" title="Click to go to the Keyword Index">
               Performance Evaluation and Optimization
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#ai_reasoning_methods_for_robotics" title="Click to go to the Keyword Index">
               AI Reasoning Methods for Robotics
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#behavior_based_systems" title="Click to go to the Keyword Index">
               Behavior-Based Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Cooperative multi-agent learning methods are essential in developing effective cooperation strategies in multi-agent domains. In robotics, these methods extend beyond multi-robot scenarios to single-robot systems, where they enable coordination among different robot modules (e.g., robot legs or joints). However, current methods often struggle to quickly adapt to unforeseen failures, such as a malfunctioning robot leg, especially after the algorithm has converged to a strategy. To overcome this, we introduce the Relational Q-Functionals (RQF) framework. RQF leverages a relational network, representing agents' relationships, to enhance adaptability, providing resilience against malfunction(s). Our algorithm also efficiently handles continuous state-action domains, making it adept for robotic learning tasks. Our empirical results show that RQF enables agents to use these relationships effectively to facilitate cooperation and recover from an unexpected malfunction in single-robot systems with multiple interacting modules. Thus, our approach offers promising applications in multi-agent systems, particularly in scenarios with unforeseen malfunctions.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to4c_06">
             14:20-15:20, Paper TO4C.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('128'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Seq2Act: A Sequence-To-Action Framework for Novel Shapes in Robotic Peg-In-Hole Assembly
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#274378" title="Click to go to the Author Index">
             Lee, Geonhyup
            </a>
           </td>
           <td class="r">
            Gwangju Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#274396" title="Click to go to the Author Index">
             Lee, Joosoon
            </a>
           </td>
           <td class="r">
            Gwangju Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#100825" title="Click to go to the Author Index">
             Lee, Kyoobin
            </a>
           </td>
           <td class="r">
            Gwangju Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab128" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#ai_reasoning_methods_for_robotics" title="Click to go to the Keyword Index">
               AI Reasoning Methods for Robotics
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#dynamics_and_control" title="Click to go to the Keyword Index">
               Dynamics and Control
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#industrial_robots" title="Click to go to the Keyword Index">
               Industrial Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robotic peg-in-hole assembly is a critical task in manufacturing that often faces misalignment issues due to sensor inaccuracies and control mechanisms. Traditional methods for addressing these issues, while effective, have limitations in flexibility and efficiency. This paper presents Seq2Act, a new framework for generating sequential peg-in-hole data to address the challenges mentioned above, using physical simulation and imitation learning. The framework is powered by a transformer model that predicts the next action for insertion. By leveraging simulation, the framework generates data and strategies for peg-in-hole insertion across a wide range of shapes, from quadrilaterals to decagons. The model anticipates peg movements for alignment and insertion, achieving impressive success rates of 87.7% and 81.4% for seen and unseen shapes, respectively. This highlights its adaptability without heavy reliance on reinforcement learning or human-guided demonstrations. Our approach represents a significant advancement in robotic assembly, providing a solution that is both data-driven and adaptable to a variety of shapes and sizes.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="to4d">
             <b>
              TO4D
             </b>
            </a>
           </td>
           <td class="r">
            KC909
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="UR24_ProgramAtAGlanceWeb.html#to4d" title="Click to go to the Program at a Glance">
             <b>
              Intelligent Robotic Vehicles
             </b>
            </a>
           </td>
           <td class="r">
            Regular
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to4d_01">
             -, Paper TO4D.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('155'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              An Efficient Method for Solving Routing Problems with Energy Constraints Using Reinforcement Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#273266" title="Click to go to the Author Index">
             Do, Haggi
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387113" title="Click to go to the Author Index">
             Son, Hakmo
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science &amp;Technology (KAIST)
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#162950" title="Click to go to the Author Index">
             Kim, Jinwhan
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab155" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#intelligent_robotic_vehicles" title="Click to go to the Keyword Index">
               Intelligent Robotic Vehicles
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             With the increasing popularity of electric vehicles (EVs), the research field of planning efficient routes for these vehicles is gaining growing attention. As there are a limited number of charging stations for EVs compared to gas stations for fossil fuel vehicles, EV routing requires careful consideration of energy constraints and replenishment. The classical traveling salesperson problem (TSP) and vehicle routing problem (VRP) are known to be NP-hard, which means that the electric vehicle routing problem (EVRP), a similar problem with added energy constraints, is computationally even more challenging. Recently, reinforcement learning (RL) is being suggested as an effective tool that can alleviate the computational burden of challenging problems. This paper presents a RL-based method for solving routing problems with energy constraints. Multi-head attention mechanisms are employed for both the encoder and decoder, and a masking scheme is applied at the decoding phase in order to compute a feasible solution and minimize the energy constraint violation. This method generates an efficient route in which all task nodes are visited while meeting the energy requirements by visiting the charging stations when needed. The performance of the methodology is demonstrated through a Monte Carlo simulation, and the results are discussed and analyzed.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to4d_02">
             -, Paper TO4D.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('81'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Buoy Light Detection and Pattern Classification for Unmanned Surface Vehicle Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#270221" title="Click to go to the Author Index">
             Lee, Junseok
            </a>
           </td>
           <td class="r">
            GIST(Gwangju Institute of Science and Technology)
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#347512" title="Click to go to the Author Index">
             Kim, Taeri
            </a>
           </td>
           <td class="r">
            Gwangju Institute of Science and Technology(GIST)
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#274398" title="Click to go to the Author Index">
             Lee, Seongju
            </a>
           </td>
           <td class="r">
            Gwangju Institue of Science and Technology (GIST)
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#311198" title="Click to go to the Author Index">
             Park, Jumi
            </a>
           </td>
           <td class="r">
            Gwangju Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#100825" title="Click to go to the Author Index">
             Lee, Kyoobin
            </a>
           </td>
           <td class="r">
            Gwangju Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab81" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#object_recognition" title="Click to go to the Keyword Index">
               Object Recognition
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#intelligent_robotic_vehicles" title="Click to go to the Keyword Index">
               Intelligent Robotic Vehicles
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#ai_reasoning_methods_for_robotics" title="Click to go to the Keyword Index">
               AI Reasoning Methods for Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Buoys and beacons indicate information about dangers in coastal navigation. At night, owing to challenging visibility, buoy lights are employed instead of buoys and beacons. For safe navigation, it is crucial to comprehend these lights, and autonomous vessels require algorithms capable of classifying buoy lights without human intervention, particularly during the night. To address this, we propose a Buoy Light Detection and Classification Network (BLDCNet), which combines buoy light detection and pattern classification. BLDCNet is applied to the Temporal Shift Module (TSM), known for its excellent performance in video understanding, to achieve precise classification based on the continuous light patterns in sequential images. We evaluate the performance of BLDCNet using a synthetic dataset generated to resemble real maritime environments and a real-world dataset obtained by capturing buoy light pattern videos onshore. BLDCNet achieved a classification performance of 89.21% for 11 different buoy light patterns.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to4d_03">
             -, Paper TO4D.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('46'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Improving Multi-Robot Visual Navigation Using Cooperative Consensus
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#108565" title="Click to go to the Author Index">
             Lyons, Damian
            </a>
           </td>
           <td class="r">
            Fordham University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#338873" title="Click to go to the Author Index">
             Rahouti, Mohamed
            </a>
           </td>
           <td class="r">
            Fordham University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab46" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#computer_vision_and_visual_servoing" title="Click to go to the Keyword Index">
               Computer Vision and Visual Servoing
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#intelligent_robotic_vehicles" title="Click to go to the Keyword Index">
               Intelligent Robotic Vehicles
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             WAVN (Wide Area Visual Navigation) is an approach to robot team navigation that uses the current visual information from all team members to allow any team member to cooperatively navigate to a distant (out of view) destination. Neither map nor robot position information is needed. Current applications include agriculture and forestry, particularly in remote locations. However, increasingly ubiquitous camera sensors indicate that WAVN could be used as a lightweight navigation paradigm for robot teams in households, offices, public areas, and manufacturing applications. In this paper, we propose and evaluate a novel synergy of navigation and blockchain methodologies: A novel robot-centric blockchain consensus mechanism based on common visual landmarks between pairs of robots. We show how this mechanism guarantees specific navigability properties for the ledger, resulting in an improved WAVN navigation algorithm, Randomly Shortened Chain (RSC), and we present navigation performance results to demonstrate the improved efficiency due to cooperation.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to4d_04">
             14:20-15:20, Paper TO4D.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('125'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Adaptive Dynamic Window Approach for Robot Navigation in Disturbance Vector Fields
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#163828" title="Click to go to the Author Index">
             Redwan Newaz, Abdullah Al
            </a>
           </td>
           <td class="r">
            University of New Orleans
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#180622" title="Click to go to the Author Index">
             Alam, Tauhidul
            </a>
           </td>
           <td class="r">
            Louisiana State University Shreveport
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab125" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#intelligent_robotic_vehicles" title="Click to go to the Keyword Index">
               Intelligent Robotic Vehicles
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#motion_planning_and_obstacle_avoidance" title="Click to go to the Keyword Index">
               Motion Planning and Obstacle Avoidance
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#dynamics_and_control" title="Click to go to the Keyword Index">
               Dynamics and Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Reliable autonomous robot navigation in dynamic environments with external disturbances remains challenging. The Dynamic Window Approach (DWA) generates collision-free trajectories by optimizing over sensor observations and motion constraints. However, the DWA lacks the ability to account for unpredictable disturbances, making robot navigation unreliable. We propose an enhanced planning and control approach that incorporates learned disturbance models to improve adaptability. Our key idea is to represent disturbances as parametric vector fields. By learning the vector field online, we capture environmental flows to be leveraged during planning. We integrate the learned model into the DWA objective to generate optimized trajectories through disturbance flows while avoiding obstacles. The proposed adaptive planning framework is validated in simulations and real-world experiments with ground and aquatic robots. Different case studies demonstrate the approach’s ability to produce smooth, collision-free robot navigation in varied disturbance fields and environments. Compared to the standard DWA, our planner handles uncertainties and changing conditions better by learning online. Thus,this disturbance-incorporated planning enables more reliable autonomous navigation in uncertain, dynamic environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to4d_05">
             14:20-15:20, Paper TO4D.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('135'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              3D Spatial Information Restoration Based on G-ICP Approach with LiDAR and Camera Mounted on an Autonomous Surface Vehicle
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#349763" title="Click to go to the Author Index">
             Heo, Suhyeon
            </a>
           </td>
           <td class="r">
            KRISO, Korea Research Institute of Ships &amp; Ocean Engineering
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#319846" title="Click to go to the Author Index">
             Kang, Minju
            </a>
           </td>
           <td class="r">
            Korea Research Institute of Ships &amp; Ocean Engineering
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#104653" title="Click to go to the Author Index">
             Choi, Jinwoo
            </a>
           </td>
           <td class="r">
            KRISO, Korea Research Institute of Ships &amp; Ocean Engineering
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#171826" title="Click to go to the Author Index">
             Park, Jeonghong
            </a>
           </td>
           <td class="r">
            KRISO
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab135" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#multisensor_data_fusion" title="Click to go to the Keyword Index">
               Multisensor Data Fusion
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#intelligent_robotic_vehicles" title="Click to go to the Keyword Index">
               Intelligent Robotic Vehicles
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this study, we proposed a 3D spatial information restoration approach using LiDAR and camera to improve the autonomy level of autonomous surface vehicles (ASVs). The preprocessing phase was designed for removal of inherence noise corresponding to data obtained from LiDAR and camera. Because RGB color information is sensitive to changes in illumination, a gamma correction and dark channel prior (DCP) approach was applied to minimize the rate of change of color information due to environmental factors. In addition, because using the LiDAR point cloud data (PCD) source as is would take a long time to process the data, and noise would reduce the accuracy of the data processing, we went through a preprocessing process to remove noise and outliers through filters. Then, the relative coordinate information between the LiDAR and camera was used to calibrate each data in advance, so that the RGB color information was projected on the filtered PCD. Subsequently, accumulated using generalized iterative closest point (G-ICP) approach in order to generate 3D spatial information. The field data obtained in an inland water environment was used to demonstrate the validity of the proposed approach, its results were described.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to4d_06">
             14:20-15:20, Paper TO4D.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('168'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Randomized Multi-Robot Patrolling with Unidirectional Visibility
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387195" title="Click to go to the Author Index">
             Echefu, Louis
            </a>
           </td>
           <td class="r">
            Louisiana State University, Shreveport
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#180622" title="Click to go to the Author Index">
             Alam, Tauhidul
            </a>
           </td>
           <td class="r">
            Louisiana State University Shreveport
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#163828" title="Click to go to the Author Index">
             Redwan Newaz, Abdullah Al
            </a>
           </td>
           <td class="r">
            University of New Orleans
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab168" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#robot_surveillance_and_security" title="Click to go to the Keyword Index">
               Robot Surveillance and Security
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#intelligent_robotic_vehicles" title="Click to go to the Keyword Index">
               Intelligent Robotic Vehicles
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Patrolling an adversarial environment with multiple robots equipped with vision sensors poses challenges, such as the potential for wireless communication jamming and limited visibility ranges. Early methods relying on deterministic paths are susceptible to predictability by adversaries. Conversely, recent non-deterministic approaches work in discrete environments but overlook sensor footprints and require synchronization. Therefore, this paper proposes an approach to compute patrolling policies for multiple distributed robots that monitor any polygonal environment leveraging limited unidirectional visibility regions in a continuous space and randomized patrolling paths. A visibility roadmap graph is initially constructed from a given environment through its recursive decomposition to account for unidirectional visibility. Our proposed multi-robot task allocation method then partitions the constructed visibility roadmap graph into a set of disjoint subgraphs (areas) and allocates them to multiple robots. Distributed randomized patrolling policies are finally computed in the form of Markov chains, utilizing convex optimization to minimize the average expected commute times for all pairs of locations in allocated areas. We present multiple simulation results to demonstrate the effectiveness of our visibility-based randomized patrolling approach. We also analyze the performance of our approach in detecting targets by robots through a series of simulation runs while they follow the computed policies during patrolling.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="to4e">
             <b>
              TO4E
             </b>
            </a>
           </td>
           <td class="r">
            KC912
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="UR24_ProgramAtAGlanceWeb.html#to4e" title="Click to go to the Program at a Glance">
             <b>
              Robotic Mechanism and Design
             </b>
            </a>
           </td>
           <td class="r">
            Regular
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="UR24_AuthorIndexWeb.html#189075" title="Click to go to the Author Index">
             Lu, Qi
            </a>
           </td>
           <td class="r">
            The University of Texas Rio Grande Valley
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="UR24_AuthorIndexWeb.html#191032" title="Click to go to the Author Index">
             Bae, Jangho
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to4e_01">
             -, Paper TO4E.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('106'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Design and Fabrication of Multi-Functional Optical Microbots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#306306" title="Click to go to the Author Index">
             Jamil, Md Faiyaz
            </a>
           </td>
           <td class="r">
            The Ohio State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387109" title="Click to go to the Author Index">
             Konara, Menaka
            </a>
           </td>
           <td class="r">
            University of Massachusetts Dartmouth
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#305798" title="Click to go to the Author Index">
             Pokharel, Mishal
            </a>
           </td>
           <td class="r">
            University of Massachusetts, Dartmouth
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#138424" title="Click to go to the Author Index">
             Park, Kihan
            </a>
           </td>
           <td class="r">
            University of Massachusetts Dartmouth
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab106" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#micro_nano_robots" title="Click to go to the Keyword Index">
               Micro/Nano Robots
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#micro_nanosystems" title="Click to go to the Keyword Index">
               Micro/nanosystems
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#mechanism_and_design" title="Click to go to the Keyword Index">
               Mechanism and Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Microrobotics has evolved as an interesting research area with the development of new microfabrication techniques and the applicability of these micro units to real-world applications. Among the other types of micro-robotics, the light-actuated microbot is widely studied for its promise of biocompatibility, real-time control, live feedback, etc. With regards to optically controlled microbots, they utilize tightly focused laser beams for micro/nano-scale motion. A microbot that can perform different tasks improves the applicability of these micro-agents to different applications from micro-manipulation to some interesting biomedical applications. Many researchers believe that, with proper engineering, these microbots can be used for cancer treatment and diagnosis in a non-invasive manner. In this study, multi-functional microbots have been developed mainly focusing on biomedical applications such as targeted drug delivery, cell characterization, and cell manipulation. Two-photon polymerization has been utilized for fabricating three-dimensional microbots using bio-compatible materials. Multiple optical traps were generated using a low-cost modular optical tweezer system and time-shared optical trapping is used to control the microbots. This study gives a glimpse into the future possibilities of using light-actuated microbots to perform complex therapeutic tasks.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to4e_02">
             -, Paper TO4E.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('108'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Advancing Planar Magnetic Microswimmers: Swimming, Channel Navigation, and Surface Motion
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#321139" title="Click to go to the Author Index">
             Duygu, Yasin Cagatay
            </a>
           </td>
           <td class="r">
            Southern Methodist University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#275567" title="Click to go to the Author Index">
             Kararsiz, Gokhan
            </a>
           </td>
           <td class="r">
            Southern Methodist University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387794" title="Click to go to the Author Index">
             Liu, Austin
            </a>
           </td>
           <td class="r">
            The Harker School
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#223454" title="Click to go to the Author Index">
             Cheang, U Kei
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology (SUSTech)
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#274684" title="Click to go to the Author Index">
             Leshansky, Alexander
            </a>
           </td>
           <td class="r">
            Technion
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#123365" title="Click to go to the Author Index">
             Kim, MinJun
            </a>
           </td>
           <td class="r">
            Southern Methodist University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab108" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#micro_nano_robots" title="Click to go to the Keyword Index">
               Micro/Nano Robots
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#micro_nanosystems" title="Click to go to the Keyword Index">
               Micro/nanosystems
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#dynamics_and_control" title="Click to go to the Keyword Index">
               Dynamics and Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Planar magnetic microswimmers are well-suited for in vivo biomedical applications due to their cost-effective mass production through standard photolithography techniques. The precise control of their motion in diverse environments is a critical aspect of their application. This study demonstrates the control of these swimmers individually and as a swarm, exploring navigation through channels and showcasing their functional capabilities for future biomedical settings. We also introduce the capability of microswimmers for surface motion, complementing their traditional fluid-based propulsion and extending their functionality. Our research reveals that microswimmers with varying magnetization directions exhibit unique trajectory patterns, enabling complex swarm tasks. This study further delves into the behavior of these microswimmers in intricate environments, assessing their adaptability and potential for advanced applications. The findings suggest that these microswimmers could be pivotal in areas such as targeted drug delivery and precision medical procedures, marking significant progress in the biomedical and micro-robotic fields and offering new insights into their control and behavior in diverse environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to4e_03">
             -, Paper TO4E.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('146'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Introducing H4ND: Hyper-Resilient, 4-Fingered, Nimble, Dexterous Anthropomorphic Robot Hand Optimized for Research
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#317469" title="Click to go to the Author Index">
             Kosanovic, Nicolas
            </a>
           </td>
           <td class="r">
            University of Louisville
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#215308" title="Click to go to the Author Index">
             Chagas Vaz, Jean
            </a>
           </td>
           <td class="r">
            University of Louisville
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab146" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#robotic_hands" title="Click to go to the Keyword Index">
               Robotic Hands
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#mechanism_and_design" title="Click to go to the Keyword Index">
               Mechanism and Design
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#biomimetic_and_bioinspired_robots" title="Click to go to the Keyword Index">
               Biomimetic and Bioinspired Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             General-purpose grasping is a vital component of robotic manipulation that requires resilient and sophisticated gripper hardware. Anthropomorphic robot hands try to address this need by imitating the universal manipulation abilities of human hands; however, such technology tends to be more mechanically complex, expensive, and fragile than simpler grippers. This work presents the H4ND—an inventive, next-generation servo-driven 3D printed robotic hand designed to be repeatedly damaged and repaired at never-beforeseen rates. Unlike its servo-driven counterparts (e.g. Allegrohand, HDHM, LEAP Hand), the H4ND uses size-optimized sacrificial linkages to shift its point-of-failure onto a laughably inexpensive, massively manufacturable, 3D-printed part. Hence, this grasping platform can suffer merciless abuse during experimentation, undergo a quick-and-easy repair process, and be fully functional again. This is demonstrated in experiments featuring telepresence control and heavy object manipulation. With a 4.50 kg maximum payload, 0.25 s finger closing time, 0.590 kg weight, 16 Degrees of Freedom, humanoid form factor, a 500 USD price tag, and less than a 5-minute mean repair time, the H4ND is a hyper-resilient, inexpensive, and potentially market-disrupting solution to robotic grasping. Therefore, the H4ND can empower researchers to spend less time worrying about their hardware’s cost/longevity, and more time doing research.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to4e_04">
             14:20-15:20, Paper TO4E.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('178'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Detection and Mitigation of Misleading Pheromone Trails in Foraging Robot Swarms
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#355022" title="Click to go to the Author Index">
             Luna, Ryan
            </a>
           </td>
           <td class="r">
            The University of Texas Rio Grande Valley
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#189075" title="Click to go to the Author Index">
             Lu, Qi
            </a>
           </td>
           <td class="r">
            The University of Texas Rio Grande Valley
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab178" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#robot_surveillance_and_security" title="Click to go to the Keyword Index">
               Robot Surveillance and Security
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This study addresses the overlooked aspect of security in swarm robotics by exploring the vulnerabilities of pheromone-based foraging robot swarms to deceptive pheromone trail attacks. Simulating scenarios where detractor robots lay misleading trails to capture benign foraging robots in the swarm. We analyze the impact of the attack on the swarm and evaluate the foraging efficiency. We introduce a defense mechanism using distance-based clustering (DBSCAN) along with a cluster grouping mechanism to isolate large batches of detractors at a time. The isolation strategy also incorporates an adaptive timing mechanism to identify detractors by computing the estimated travel time of pheromone trails. Our experiments show a decline in resource collection and an increase in forager robots captured with more detractors. However, the defense strategy effectively counters this challenge. It can isolate all detractors early on in the simulation, significantly reducing forager capture rates, and preserving the foraging performance of the swarm. This research highlights the security vulnerabilities in pheromone-based foraging algorithms and proposes a robust defense mechanism, contributing significantly to the development of more resilient foraging algorithms in swarm robotics. These findings are pivotal for deploying secure and efficient swarm robotics systems in real-world scenarios where both efficiency and security are paramount.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="to4e_05">
             14:20-15:20, Paper TO4E.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Design, Modeling and Experiment of a Eccentric Mass-Driven Spherical Robot
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#250748" title="Click to go to the Author Index">
             Mao, Han
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387225" title="Click to go to the Author Index">
             Xie, Tongtong
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#222113" title="Click to go to the Author Index">
             Zhu, Aibin
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#319497" title="Click to go to the Author Index">
             Li, Cheng
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong University
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="ti5a">
             <b>
              TI5A
             </b>
            </a>
           </td>
           <td class="r">
            Rosenthal
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="UR24_ProgramAtAGlanceWeb.html#ti5a" title="Click to go to the Program at a Glance">
             <b>
              Poster Sesssion I
             </b>
            </a>
           </td>
           <td class="r">
            Interactive
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_01">
             -, Paper TI5A.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('8'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Toward 6D Velocity Estimation for Legged Robot Using Rolling Motion
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#311328" title="Click to go to the Author Index">
             Jung, Sangwoo
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#126962" title="Click to go to the Author Index">
             Kim, Ayoung
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab8" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#simultaneous_localization_and_mapping__slam_" title="Click to go to the Keyword Index">
               Simultaneous Localization and Mapping (SLAM)
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#multisensor_data_fusion" title="Click to go to the Keyword Index">
               Multisensor Data Fusion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recent advances in quadruped robot SLAM have demonstrated significant progress by integrating contact sensors and joint sensors. Whereas existing methods assumed the contact frame to be stationary on the ground during the contact states, ignoring the effect of rolling motion and its drift. In this work, we propose leveraging the rolling motion of the contact frame to compute the instantaneous velocity of a legged robot base relative to the world frame. We estimate 6D velocity by exploiting IMU and forward kinematics through this derivation. The efficacy of our approach is validated through real-world experiments, particularly for z-axis precision.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_02">
             -, Paper TI5A.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('13'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              ﻿Design of Control System for the Antarctic Exploration Robot
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#222368" title="Click to go to the Author Index">
             Uhm, Taeyoung
            </a>
           </td>
           <td class="r">
            Korean Institute of Robotics and Technology Convergence
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#386157" title="Click to go to the Author Index">
             Kwon, Ji-Wook
            </a>
           </td>
           <td class="r">
            Korea Institute of Robotics and Technology Convergence(KIRO)
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#349322" title="Click to go to the Author Index">
             Lee, JongDeuk
            </a>
           </td>
           <td class="r">
            Korea Institute of Robotics &amp; Technology Convergence(KIRO)
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#319539" title="Click to go to the Author Index">
             Kim, Jong Chan
            </a>
           </td>
           <td class="r">
            Korea Institute of Robotics &amp; Technology Convergenc
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#319536" title="Click to go to the Author Index">
             Hyojun, Lee
            </a>
           </td>
           <td class="r">
            Korea Institute of Robotics &amp; Technology Convergence
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#222411" title="Click to go to the Author Index">
             Choi, Young-Ho
            </a>
           </td>
           <td class="r">
            Korean Institute of Robot and Convergence
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab13" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#robotics_in_hazardous_applications" title="Click to go to the Keyword Index">
               Robotics in Hazardous Applications
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#wheeled_mobile_robots" title="Click to go to the Keyword Index">
               Wheeled Mobile Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             ﻿Recently, research is being conducted to explore extreme cold regions such as Antarctica by operating unmanned robots. In order to operate unmanned robots, a system that can monitor and remotely control multiple robots is required. Therefore, in this paper, we propose a control system designed to enable remote monitoring and control of robots and command exploration missions using a wide area (about 50km) communication network in wide areas such as extreme cold regions. The proposed system was tested with the robot and showed its usefulness.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_03">
             -, Paper TI5A.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('14'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Targeted Delivery of Deployable Therapeutic Sheets Using Magnetically Actuated Capsule
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#289041" title="Click to go to the Author Index">
             Lee, Jihun
            </a>
           </td>
           <td class="r">
            Daegu Gyeongbuk Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#101183" title="Click to go to the Author Index">
             Park, Sukho
            </a>
           </td>
           <td class="r">
            DGIST
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab14" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#micro_nano_robots" title="Click to go to the Keyword Index">
               Micro/Nano Robots
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#medical_robotics_and_computer_integrated_surgery" title="Click to go to the Keyword Index">
               Medical Robotics and Computer-Integrated Surgery
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#rehabilitation_and_healthcare_robotics" title="Click to go to the Keyword Index">
               Rehabilitation and Healthcare Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This study proposes a new target-delivery method using deployable therapeutic sheets (TheraSs) into the gastrointestinal (GI) tract using a magnetically actuated capsule. The TheraS is designed for GI-tract treatments and comprises therapeutic (chitosan–catechol), guard (triethylene glycol dimethacrylate), and unrolling (polyethylene glycol dimethacrylate) layers. Four rolled TheraSs are equipped in the four-channeled capsule and individually delivered to the targeted sites by magnetic actuation. TheraS maintains its rolled state until it contacts GI fluid, and when it contacts the GI fluids that cause it to unroll and adhere to the GI tract surface. Additionally, TheraS induces hyperthermia and drug release under an alternating magnetic field (AMF) as magnetic nanoparticles and drugs are loaded onto its therapeutic layer. Herein, TheraS is characterized morphologically and the deliverability of TheraS to the GI tract is verified through ex vivo tests. Finally, the cancer cell-killing performance of the TheraS was confirmed through cytotoxic therapy. Multiple TheraS delivery to multiple GI-tract lesion sites through the proposed capsule is confirmed, while therapeutic functionalities are verified by hyperthermia and drug release under AMF.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_04">
             -, Paper TI5A.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('24'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Ground-Relative Positioning in 3D Pose Estimation: A Novel Approach for Real-World Alignment of Skeleton Data
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#385067" title="Click to go to the Author Index">
             Kim, Myeongseop
            </a>
           </td>
           <td class="r">
            Korea Electronics Technology Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#386560" title="Click to go to the Author Index">
             Taehyeon, Kim
            </a>
           </td>
           <td class="r">
            Korea Electronics Technology Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#179403" title="Click to go to the Author Index">
             Oh, Jean
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#386623" title="Click to go to the Author Index">
             Lee, Kyu In
            </a>
           </td>
           <td class="r">
            University of Houston
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#386645" title="Click to go to the Author Index">
             Lee, Kyung-Taek
            </a>
           </td>
           <td class="r">
            Korea Electronics Technology Institute
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab24" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#physical_and_cognitive_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical and Cognitive Human-Robot Interaction
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#human_robot_augmentation" title="Click to go to the Keyword Index">
               Human-Robot Augmentation
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#performance_evaluation_and_optimization" title="Click to go to the Keyword Index">
               Performance Evaluation and Optimization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a novel Dynamic Ground Alignment (DGA) algorithm, revolutionizing 3D pose estimation for enhanced ground-relative positioning in both real-world and digital twin environments. Our approach, integrating with the Mediapipe Pose framework, focuses on a body-centered coordinate system and employs 3D pose landmarks to accurately align digital characters with the ground plane in virtual settings. This method addresses the common issue of unrealistic character grounding, often found in traditional pose estimation techniques, by dynamically recalibrating the character's Y-position to maintain realistic grounding and interaction within the virtual environment. The application of DGA in various fields, including animation, virtual reality, sports science, physical therapy, and ergonomic studies, significantly improves the fidelity of digital avatars and models, offering a more integrated and realistic interpretation of human movement. While our study primarily demonstrates the efficacy of DGA through visual comparisons, it lays the groundwork for future research in quantitative validation and broader applications in human-computer interaction and digital human modeling.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_05">
             15:20-17:00, Paper TI5A.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('29'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Preliminary Research on Underwater Object Recognition and Localization Using Stereo Hand Eye System
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#156200" title="Click to go to the Author Index">
             Park, Daegil
            </a>
           </td>
           <td class="r">
            Korea Research Institute of Ships &amp; Ocean Engineering (KRISO)
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#386921" title="Click to go to the Author Index">
             Pyo, Seunghyun
            </a>
           </td>
           <td class="r">
            UST KRISO School
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#173356" title="Click to go to the Author Index">
             Lee, Yeongjun
            </a>
           </td>
           <td class="r">
            Korea Research Institute of Ships and Ocean Engineering
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab29" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#underwater_robotics" title="Click to go to the Keyword Index">
               Underwater Robotics
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#computer_vision_and_visual_servoing" title="Click to go to the Keyword Index">
               Computer Vision and Visual Servoing
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#object_recognition" title="Click to go to the Keyword Index">
               Object Recognition
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recently, the necessity of marine autonomous work robots is emerging due to the shortage of manpower and aging of fishing villages. However, underwater object perception and recognition are much more difficult than on the ground. Underwater sonar sensors are difficult to utilize at close range, and vision sensors are difficult to use in water because not only short sensing range, but also the feature point uncertainty depending on turbidity, light intensity and direction. In this paper, we proposed a stereo hand eye system by mounting a camera on the end-tip of dual manipulators and changing the relative distance and direction between end-tip and object so that the feature points are picked up uniformly. In order to verify this system, the proposed system explored a certain target area in the water tank environment and tracked the target object. And then, the proposed system precisely estimated the underwater object position using the stereo vision algorithms.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_06">
             15:20-17:00, Paper TI5A.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('55'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Pressure-Based EGaIn Soft Sensor with Three-Layer Structure
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#275274" title="Click to go to the Author Index">
             Cho, Geun Sik
            </a>
           </td>
           <td class="r">
            Kangwon National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#139385" title="Click to go to the Author Index">
             Park, Yong-Jai
            </a>
           </td>
           <td class="r">
            Kangwon National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab55" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#soft_robotics" title="Click to go to the Keyword Index">
               Soft Robotics
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recent studies focusing on wearables aim to assist human movement and conserve energy, leading to a growing interest in developing various soft sensors for these applications. This research contains the utilization of diverse materials and fabrication methods. Among the various materials under exploration, EGaIn, a conductive eutectic gallium-indium alloy, has attracted significant attention. This paper focuses on the development of a three-layer structure pressure sensor utilizing EGaIn. This research investigates the performance of these sensors, particularly examining the impact of cone-shaped protrusions in the pathways where EGaIn is located. The fabricated sensors with these inserted protrusions have been subjected to testing. It was observed that the sensors incorporating protrusions demonstrated more stable resistance changes and could measure higher pressures.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_07">
             15:20-17:00, Paper TI5A.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('61'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Pose Estimation Method for Depth Camera Using Indoor 3D Map and 3D Registration
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#385056" title="Click to go to the Author Index">
             Jung, Sukwoo
            </a>
           </td>
           <td class="r">
            Korea Electronics Technology Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#385067" title="Click to go to the Author Index">
             Kim, Myeongseop
            </a>
           </td>
           <td class="r">
            Korea Electronics Technology Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#386560" title="Click to go to the Author Index">
             Taehyeon, Kim
            </a>
           </td>
           <td class="r">
            Korea Electronics Technology Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#386645" title="Click to go to the Author Index">
             Lee, Kyung-Taek
            </a>
           </td>
           <td class="r">
            Korea Electronics Technology Institute
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab61" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#simultaneous_localization_and_mapping__slam_" title="Click to go to the Keyword Index">
               Simultaneous Localization and Mapping (SLAM)
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#multisensor_data_fusion" title="Click to go to the Keyword Index">
               Multisensor Data Fusion
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#object_recognition" title="Click to go to the Keyword Index">
               Object Recognition
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recent research in sensor pose estimation has gained considerable attention due to its wide-ranging applicability in various domains, including robotics, Virtual Reality (VR), and Augmented Reality (AR). Current sensor pose estimation methods typically rely on sensor data such as visual odometry, Inertial Measurement Unit (IMU), Wi-Fi, or Bluetooth. In this study, we introduce an innovative approach that diverges from conventional techniques, which often depend solely on images or IMU sensors for pose estimation. Instead, we take advantage of pre-reconstructed 3D maps to significantly enhance pose estimation accuracy. To accomplish this, we employ high-precision indoor maps obtained through the use of a LiDAR scanner. These pre-reconstructed 3D maps serve not only to sense the initial position of the sensor but also to accurately calculate positional coordinates by applying a 3D registration algorithm alongside the acquired data from the depth camera sensor. The algorithm's potential has been validated in this paper, and further experiments are planned in the future to confirm its effectiveness.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_08">
             15:20-17:00, Paper TI5A.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('75'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Reinforcement Learning Based Control for a Continuum Mechanism Actuated by Pneumatic Artificial Muscles
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#118329" title="Click to go to the Author Index">
             Kang, Bongsoo
            </a>
           </td>
           <td class="r">
            Hannam University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab75" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#soft_robotics" title="Click to go to the Keyword Index">
               Soft Robotics
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#actuation_and_actuators" title="Click to go to the Keyword Index">
               Actuation and Actuators
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#ai_reasoning_methods_for_robotics" title="Click to go to the Keyword Index">
               AI Reasoning Methods for Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, a reinforcement learning technique is applied to control an internal continuum mechanism driven by pneumatic artificial muscles. Pneumatic artificial muscles are lightweight and can produce large forces, but their complex dynamic characteristics make mathematical modeling difficult. Therefore, it is not easy for conventional model-based control schemes to achieve desired motions of the mechanism, so reinforcement learning, similar to human behavior, is implemented to perform given tasks through iterative processing. In particular, experimental results showed that the proposed reinforcement learning incorporating deep learning techniques yielded good performance even when uncertainty of the environment was numerous.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_09">
             15:20-17:00, Paper TI5A.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('93'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Integrating Robotic Navigation with Blockchain: A Novel PoS-Based Approach for Heterogeneous Robotic Teams
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387119" title="Click to go to the Author Index">
             Paykari, Nasim
            </a>
           </td>
           <td class="r">
            Fordham University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387138" title="Click to go to the Author Index">
             Alfatemi, Ali
            </a>
           </td>
           <td class="r">
            Fordham University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#108565" title="Click to go to the Author Index">
             Lyons, Damian
            </a>
           </td>
           <td class="r">
            Fordham University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#338873" title="Click to go to the Author Index">
             Rahouti, Mohamed
            </a>
           </td>
           <td class="r">
            Fordham University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab93" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#dynamics_and_control" title="Click to go to the Keyword Index">
               Dynamics and Control
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#computer_vision_and_visual_servoing" title="Click to go to the Keyword Index">
               Computer Vision and Visual Servoing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This project explores a novel integration of blockchain methodologies with Wide Area Visual Navigation (WAVN) to address challenges in visual navigation for a heterogeneous team of mobile robots deployed for unstructured applications in agriculture, forestry etc. Focusing on overcoming challenges such as GPS independence, environmental changes, and computational limitations, the study introduces the Proof of Stake (PoS) mechanism, commonly used in blockchain systems, into the WAVN framework. This integration aims to enhance the cooperative navigation capabilities of robotic teams by prioritizing robot contributions based on their navigation reliability. The methodology involves a stake weight function, consensus score with PoS, and a navigability function, addressing the computational complexities of robotic cooperation and data validation. This innovative approach promises to optimize robotic teamwork by leveraging blockchain principles, offering insights into the scalability, efficiency, and overall system performance. The project anticipates significant advancements in autonomous navigation and the broader application of blockchain technology beyond its traditional financial context.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_10">
             15:20-17:00, Paper TI5A.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('116'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Design of Fuzzy Logic Parameter Tuners for Upper-Limb Assistive Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387147" title="Click to go to the Author Index">
             Coco, Christopher
            </a>
           </td>
           <td class="r">
            University of Massachusetts Lowell
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387146" title="Click to go to the Author Index">
             Spanos, Jonathan
            </a>
           </td>
           <td class="r">
            University of Massachusetts Lowell
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#348580" title="Click to go to the Author Index">
             Osooli, Hamid
            </a>
           </td>
           <td class="r">
            University of Massachusetts Lowell
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#160355" title="Click to go to the Author Index">
             Azadeh, Reza
            </a>
           </td>
           <td class="r">
            University of Massachusetts Lowell
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab116" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#rehabilitation_and_healthcare_robotics" title="Click to go to the Keyword Index">
               Rehabilitation and Healthcare Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Assistive Exoskeleton Robots are helping restore functions to people suffering from underlying medical conditions. These robots require precise tuning of hyper-parameters to feel natural to the user. The device hyper-parameters often need to be re-tuned from task to task, which can be tedious and require expert knowledge. To address this issue, we develop a fuzzy logic controller that can dynamically tune robot gain parameters to adapt its sensitivity to the user's intention determined from muscle activation. The designed fuzzy controllers benefit from a set of expert-defined rules and do not rely on extensive amounts of training data. We evaluate the designed controller with three different tasks and compare our results against the manually tuned system. Our preliminary results show that our controller reduces the amount of fighting between the device and the human, measured using a set of pressure sensors.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_11">
             15:20-17:00, Paper TI5A.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('151'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Soft Wearable Thermotouch Haptic Actuator
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387814" title="Click to go to the Author Index">
             Lee, Seohu
            </a>
           </td>
           <td class="r">
            Korea University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387824" title="Click to go to the Author Index">
             Jang, Seongkwan
            </a>
           </td>
           <td class="r">
            Korea University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#146365" title="Click to go to the Author Index">
             Cha, Youngsu
            </a>
           </td>
           <td class="r">
            Korea University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab151" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#haptics" title="Click to go to the Keyword Index">
               Haptics
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#soft_robotics" title="Click to go to the Keyword Index">
               Soft Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we present a soft wearable thermotouch haptic actuator to produce both touch and thermal tactile feedback simultaneously and independently. The actuator is a two-layer structure of a pneumatic actuator and a thermoelectric device. The significantly different two parts are assembled by a novel design. A wearable air pump based on an origami pattern is also proposed to replace a bulky external air compressor. The pneumatic actuator for touch haptic feedback is also specially designed, tailored to the air pump.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_12">
             15:20-17:00, Paper TI5A.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('181'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Determination of Calf Contact Point in Ultrasound Examination for Diagnosis of Chronic Venous Insufficiency
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#331736" title="Click to go to the Author Index">
             Choi, ByeongSeon
            </a>
           </td>
           <td class="r">
            JeonBuk National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#104627" title="Click to go to the Author Index">
             Park, Jaebyung
            </a>
           </td>
           <td class="r">
            Jeonbuk National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab181" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#computer_vision_and_visual_servoing" title="Click to go to the Keyword Index">
               Computer Vision and Visual Servoing
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#rehabilitation_and_healthcare_robotics" title="Click to go to the Keyword Index">
               Rehabilitation and Healthcare Robotics
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#medical_robotics_and_computer_integrated_surgery" title="Click to go to the Keyword Index">
               Medical Robotics and Computer-Integrated Surgery
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Chronic venous insufficiency (CVI) induces discomfort through symptoms such as lower extremity edema and venous hypertension. This paper proposes a method for determining calf contact points in ultrasound examination during the robotic CVI diagnosis process. The proposed perception system integrates image and point cloud processing to precisely identify contact points on calf models. We firstly utilize a color filtering technique to extract regions of interest from images. The filtered images are then combined with depth information to generate point cloud structure. For efficiency in data processing, points beyond one meter from the camera are removed. Subsequently, a planar patch detection technique is applied to the point cloud data to identify the shapes of the calf models. Utilizing the center point coordinates and xyz extents of the detected patches, the robot determines the path to perform the ultrasound examination. Our approach establishes a foundation for efficient and accurate CVI diagnosis by enabling the robot to identify contact points for ultrasound examination.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_13">
             15:20-17:00, Paper TI5A.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('18'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Development of Variable Scaling Teleoperation Framework for Robotic Spine Surgery System
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#288983" title="Click to go to the Author Index">
             Lee, Hunjo
            </a>
           </td>
           <td class="r">
            Korea University of Science and Technology, Korea Institute of I
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#106009" title="Click to go to the Author Index">
             Yang, Gi-Hun
            </a>
           </td>
           <td class="r">
            KITECH
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab18" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#telerobotics" title="Click to go to the Keyword Index">
               Telerobotics
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#medical_robotics_and_computer_integrated_surgery" title="Click to go to the Keyword Index">
               Medical Robotics and Computer-Integrated Surgery
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#robotic_systems_architectures_and_programming" title="Click to go to the Keyword Index">
               Robotic Systems Architectures and Programming
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper introduces a variable scaling teleoperation framework for intuitive robotic surgery. Different characteristics between master and slave, and limited information from remote environment are important issues which make a teleoperation difficult and unintuitive. Therefore, the variable scaling teleoperation framework is necessary to improve manipulation abilities of surgeons. In this study, we proposed the variable scaling framework which can modulate a motion scale or stiffness scale of a slave robot in real-time according to a current process. We used a grip force to represent a motion intention of operators and adjust the scale factors. The relationship between a grip force and the scale factors are based on instinctive skill of human. The proposed framework makes surgeons execute the robotic surgery intuitively. Our future study aims to implement the proposed system in real surgical environment and verify its effectiveness.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_14">
             15:20-17:00, Paper TI5A.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('19'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Optimization of Navigating Magnetic Particles in Blood Vessels Using FFP in Open-Type EMA System
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#350202" title="Click to go to the Author Index">
             Yang, Seungun
            </a>
           </td>
           <td class="r">
            DGIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#312264" title="Click to go to the Author Index">
             Kee, Hyeonwoo
            </a>
           </td>
           <td class="r">
            DGIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#223040" title="Click to go to the Author Index">
             Nguyen, Kim Tien
            </a>
           </td>
           <td class="r">
            Korean Institute of Medical Microrobotics
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#133064" title="Click to go to the Author Index">
             Kim, Jayoung
            </a>
           </td>
           <td class="r">
            Korea Institute of Medical Microrobotics
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#101183" title="Click to go to the Author Index">
             Park, Sukho
            </a>
           </td>
           <td class="r">
            DGIST
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab19" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#micro_nano_robots" title="Click to go to the Keyword Index">
               Micro/Nano Robots
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#micro_nanosystems" title="Click to go to the Keyword Index">
               Micro/nanosystems
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#medical_robotics_and_computer_integrated_surgery" title="Click to go to the Keyword Index">
               Medical Robotics and Computer-Integrated Surgery
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Many papers have proposed steering magnetic microparticles (MMPs) using magnetic fields for target drug delivery. In particular, current research is actively conducted on both steering and particle tracking of magnetic particles using a field-free point (FFP). However, existing studies use a closed-type electromagnetic actuation (EMA) coil system, making it difficult to apply it to an actual surgical environment and using external imaging devices such as X-rays together. In this study, we aim to overcome the limitations of closed-type EMA systems by using an open-type EMA system. However, an open-type EMA system has some challenges of magnetic force reduction with distance and magnetic field anisotropy. To solve this problem, this study proposes an optimization of an open-type EMA system, an improved FFP generation method, and a logic to steer multiple magnetic particles in blood vessels using anisotropic FFP. Finally, through simulations and experiments with a channel phantom, we validate the feasibility of navigating MMPs using FFPs within an open-type EMA system.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_15">
             15:20-17:00, Paper TI5A.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('22'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Antenna Tracking System Application for Seamless UAV Flight Based on oneM2M IoT Platform
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#349675" title="Click to go to the Author Index">
             Lee, Jiho
            </a>
           </td>
           <td class="r">
            Korea Electronics Technology Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#349676" title="Click to go to the Author Index">
             Park, Jong-Hong
            </a>
           </td>
           <td class="r">
            Korea Electronics Technology Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#349680" title="Click to go to the Author Index">
             Ahn, Il-Yeop
            </a>
           </td>
           <td class="r">
            Korea Electronics Technology Institute
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab22" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#aerial_and_flying_robots" title="Click to go to the Keyword Index">
               Aerial and Flying Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Unmanned Aerial Vehicles (UAVs) are a revolutionary technology with the potential to impact civil environments in the near future. For seamless and safe UAV operations, both RF-based local communication and LTE-based global communication operating environments are essential. To achieve this, reliable connectivity for UAVs, even in communication shadow areas is indispensable. The aim of this paper is to provide dependable connectivity between UAV, the drone, and GCS (Ground Control System) using an autonomous antenna tracker with RF and LTE communication. The proposed system and application will enable safe operation of multiple heterogeneous UAVs operating in communication shadow areas, low altitude airspace and remote control beyond line of sight.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_16">
             15:20-17:00, Paper TI5A.16
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('30'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Analysis and Classification of Car Door Torque Profile for Hybrid Haptic Device Development
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#363812" title="Click to go to the Author Index">
             Kim, Ji-Sung
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#244519" title="Click to go to the Author Index">
             Ma, Jihyeong
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#118310" title="Click to go to the Author Index">
             Kyung, Ki-Uk
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science &amp; Technology (KAIST)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab30" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#haptics" title="Click to go to the Keyword Index">
               Haptics
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#physical_and_cognitive_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical and Cognitive Human-Robot Interaction
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#mechanism_and_design" title="Click to go to the Keyword Index">
               Mechanism and Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Designing car doors to provide optimal haptic sensations is essential for enhancing user experience. Consequently, research has focused on simulating these haptic sensations using haptic devices during the design phase. However, the virtual implementation of car door mechanisms presents unique challenges, including significant resistive torque, self-opening and closing behavior, and variable torque profiles during the opening and closing phases. Therefore, analyzing the characteristics of the torque components that constitute the car door torque profile and developing suitable devices for their rendering is necessary. This paper presents the measurement of the car door torque profile and introduces a method that classifies the torque into active and passive components, based on whether they aid or impede rotation. By employing each torque component as an active actuator (motor) and a passive actuator (brake), we will design a suitable hybrid haptic device and can realistically implement the haptic feeling of a car door.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_17">
             15:20-17:00, Paper TI5A.17
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('31'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Development of a Gripping System for Sorting Agricultural Produce Post Harvest
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#386872" title="Click to go to the Author Index">
             Kim, Myeongjin
            </a>
           </td>
           <td class="r">
            Korea Institute of Industrial Technology (KITECH)
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#386873" title="Click to go to the Author Index">
             Kim, Jiwoong
            </a>
           </td>
           <td class="r">
            Korea Institute of Industrial Technology (KITECH)
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#386886" title="Click to go to the Author Index">
             Yun, Dongho
            </a>
           </td>
           <td class="r">
            Korea Institute of Industrial Technology (KITECH)
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#211875" title="Click to go to the Author Index">
             Ju, Chanyoung
            </a>
           </td>
           <td class="r">
            Korea Institute of Industrial Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab31" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#mechanism_and_design" title="Click to go to the Keyword Index">
               Mechanism and Design
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#robotic_hands" title="Click to go to the Keyword Index">
               Robotic Hands
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             With the recent advancements in agricultural technology and the increasing demand for agricultural products, research on grippers for the purpose of sorting agricultural produce has been actively progressing. This paper addresses the conceptual design of a sorting system and grippers specifically tailored for identifying and sorting spoiled agricultural produce, such as onions and apples. The proposed sorting system, based on a camera, tracks the positions of deteriorated crops and employs a gripper attached to a delta robot to remove them. In this context, the gripper proposed in this paper envelops the entire deteriorated crop using gripper fingers and a rubber membrane, ensuring that contaminants are not introduced to high-quality produce during the sorting process. The paper covers the mechanism design for developing such grippers and presents conceptual diagrams of the sorting system. Additionally, insights into potential applications of the proposed system and suggestions for future research directions are provided.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_18">
             15:20-17:00, Paper TI5A.18
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('33'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Study on the Development of Guidelines for Evaluation of Usability of Care Robots for Lift and Transfer
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#386870" title="Click to go to the Author Index">
             Oh, Hyejung
            </a>
           </td>
           <td class="r">
            Korea Orthopedics &amp; Rehabilitaion Engineering Center
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#349623" title="Click to go to the Author Index">
             Jung, Sungbae
            </a>
           </td>
           <td class="r">
            Korea Orthopedics and Rehabilitation Engineering Center
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#349423" title="Click to go to the Author Index">
             Yuk, Sunwoo
            </a>
           </td>
           <td class="r">
            Korea Orthopedics &amp; Rehabilitaion Engineering Center
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab33" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#rehabilitation_and_healthcare_robotics" title="Click to go to the Keyword Index">
               Rehabilitation and Healthcare Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             With the aging of the population, the development of IT, and the 4th Industrial Revolution, various care robots are being developed. A 'care robot' is a robot or a device to which robot technology is applied that provides physical and emotional assistance to the elderly or the disabled who have difficulties in their daily lives. When it comes to selecting or using a care robot, the safety and convenience of the product are very important factors. Accordingly, this study intends to develop guidelines for evaluating the usability of care robots. In this study, the usability evaluation guideline index of care robots for mobility is developed, and the effectiveness, efficiency, and satisfaction of the product are evaluated by analyzing the usability evaluation and collected data. There were a total of 11 usability evaluation scenarios, and usability evaluation was conducted for the elderly and caregivers. Questionnaires were distributed with opinions collected. The results of the usability evaluation are as follows: - Regarding safety, many viewed that it was satisfactory because there was no part that might cause harm to the user of the product. - Regarding effectiveness, there were no evaluators who felt very difficult in using the product, but there were opinions that skills were needed. - Regarding convenience, there were comments on the need for improvement of the battery weight and charging guidance.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_19">
             15:20-17:00, Paper TI5A.19
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('45'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A New Adaptive Robotic Finger with the Selectively Actuatable Passive Joint Mechanism
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#122448" title="Click to go to the Author Index">
             Park, Jongwoo
            </a>
           </td>
           <td class="r">
            Korea Institue of Machinery &amp; Materials
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#122714" title="Click to go to the Author Index">
             Jeong, Hyunhwan
            </a>
           </td>
           <td class="r">
            Korea University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab45" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#robotic_hands" title="Click to go to the Keyword Index">
               Robotic Hands
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#mechanism_and_design" title="Click to go to the Keyword Index">
               Mechanism and Design
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we introduce a new type of robotic finger with an under-actuated adaptive joint mechanism. The proposed finger mechanism has three joints with just one active joint. The proposed finger mechanism is equipped with gear trains through links to transfer torque from a single actuator to all passive joints. The clutch brake in each joint is selectively engaged to control each joint independently. In order to realize the proposed mechanism, the modeling and design are conducted. Then, its prototype robotic gripper hardware equipped with three proposed robotic finger mechanisms is developed. The feasibility of the proposed robotic finger mechanism is verified by conducting initial experiments with actual hardware.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_20">
             15:20-17:00, Paper TI5A.20
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('49'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Camber-Changing Flapping Hydrofoils for Efficient and Environmental-Safe Water Propulsion System
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#373269" title="Click to go to the Author Index">
             Romanello, Luca
            </a>
           </td>
           <td class="r">
            TUM
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#386961" title="Click to go to the Author Index">
             Hohaus, Leonard
            </a>
           </td>
           <td class="r">
            Technische Universität München
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#386956" title="Click to go to the Author Index">
             Schmitt, David-Marian
            </a>
           </td>
           <td class="r">
            Technical University Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#196333" title="Click to go to the Author Index">
             Armanini, Sophie Franziska
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab49" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#underwater_robotics" title="Click to go to the Keyword Index">
               Underwater Robotics
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#mechanism_and_design" title="Click to go to the Keyword Index">
               Mechanism and Design
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#biomimetic_and_bioinspired_robots" title="Click to go to the Keyword Index">
               Biomimetic and Bioinspired Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This research introduces a novel hydrofoil-based propulsion framework for unmanned aquatic robots, inspired by the undulating locomotion observed in select aquatic species. The proposed system incorporates a camber-modulating mechanism to enhance hydrofoil efficiency and propulsive force generation. Through dynamic simulations, we validate the effectiveness of the camber-adjusting hydrofoil compared to a symmetric counterpart. The results demonstrate a significant improvement in horizontal thrust, emphasizing the potential of the cambering approach to enhance propulsive performance. Additionally, a prototype flipper design is presented, featuring individual control of heave and pitch motions, as well as a camber-adjustment mechanism. The integrated system not only provides efficient water-based propulsion but also offers the capacity for generating vertical forces during take-off maneuvers for seaplanes. The design is tailored to harness wave energy, contributing to the exploration of alternative energy resources. This work advances the understanding of bionic oscillatory principles for aquatic robots and provides a foundation for future developments in environmentally safe and agile underwater exploration.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_21">
             15:20-17:00, Paper TI5A.21
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('56'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Estimating Vertical Forces on a Trampoline Using Shadow Images of a Foot-Shaped Jig Mounted on a Robotic Manipulator
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#349354" title="Click to go to the Author Index">
             Park, Gunseok
            </a>
           </td>
           <td class="r">
            Korea Institute of Industrial Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#349352" title="Click to go to the Author Index">
             Choi, Seung-Hwan
            </a>
           </td>
           <td class="r">
            Korea Institute of Industrial Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#142861" title="Click to go to the Author Index">
             Kim, Min Young
            </a>
           </td>
           <td class="r">
            Kyungpook National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#281829" title="Click to go to the Author Index">
             Lee, Suwoong
            </a>
           </td>
           <td class="r">
            Korea Institute of Industrial Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab56" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#contact__modeling__sensing_and_control_" title="Click to go to the Keyword Index">
               Contact: Modeling, Sensing and Control
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#computer_vision_and_visual_servoing" title="Click to go to the Keyword Index">
               Computer Vision and Visual Servoing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Trampoline exercise is recognized as a beneficial activity for rehabilitation and fitness, contributing significantly to lower limb strength enhancement, overall physical conditioning, and rehabilitation therapy. Traditionally, collecting data involved attaching sensors to the trampoline equipment or users, a method that carried the risk of sensor malfunction due to continuous use of the trampoline. This study proposes a new approach using a camera sensor installed beneath the trampoline to estimate the vertical forces exerted solely through shadow images of a foot-shaped jig. The camera sensor captured shadow images from various points under the trampoline using a foot-shaped jig mounted on a robotic manipulator placed on the trampoline. These images were processed using Convolutional Neural Network (CNN) models, such as ResNet50, VGG16, DenseNet121, and AlexNet, through transfer learning. After a comprehensive evaluation of performance, the ResNet50 and DenseNet121 model exhibited the superior results.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_22">
             15:20-17:00, Paper TI5A.22
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('57'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Study on Fault Detection in Rotating Machines Using STFT Image of Time-Series Current Data
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#349352" title="Click to go to the Author Index">
             Choi, Seung-Hwan
            </a>
           </td>
           <td class="r">
            Korea Institute of Industrial Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#281829" title="Click to go to the Author Index">
             Lee, Suwoong
            </a>
           </td>
           <td class="r">
            Korea Institute of Industrial Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab57" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#contact__modeling__sensing_and_control_" title="Click to go to the Keyword Index">
               Contact: Modeling, Sensing and Control
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#industrial_robots" title="Click to go to the Keyword Index">
               Industrial Robots
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#performance_evaluation_and_optimization" title="Click to go to the Keyword Index">
               Performance Evaluation and Optimization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper proposes a method for detecting faults in rotating machines. Typically, fault detection in rotating machines is carried out by attaching an accelerometer to collect vibration data, which is then applied to a fault detection algorithm. In this study, we present and experimentally validate a method of detecting faults using current data collected from endurance tests of driving modules, which are commonly used in rotating machines. In the experiment, the collected current and vibration data were transformed into short time Fourier transform (STFT) image data, which were then applied to the convolutional neural network (CNN) DenseNet model, for fault detection and performance comparison. The experimental results confirmed that the current data demonstrated fault detection performance comparable to that of the vibration data, thereby validating the effectiveness of this method.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_23">
             15:20-17:00, Paper TI5A.23
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('58'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Nonlinear Identification of Unknown Object Dynamics for Human-Robot Collaborative Tasks
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387006" title="Click to go to the Author Index">
             Kim, Hakjun
            </a>
           </td>
           <td class="r">
            Kyung Hee University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#160839" title="Click to go to the Author Index">
             Kim, Sanghyun
            </a>
           </td>
           <td class="r">
            Kyung Hee University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#148185" title="Click to go to the Author Index">
             Park, Jinseong
            </a>
           </td>
           <td class="r">
            Korea Institute of Machinery and Materials
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab58" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#modeling__identification__calibration" title="Click to go to the Keyword Index">
               Modeling, Identification, Calibration
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#physical_and_cognitive_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical and Cognitive Human-Robot Interaction
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, the Sparse Identification of Nonlinear Dynamic (SINDy) method was adopted to identify the dynamics of an object when it held by a human and a robot together for collaborative tasks. A non-threatening perturbation that satisfies the persistence excitation criterion is generated to improve the estimation accuracy. With simulation results, the estimation performance was compared with the results obtained by extended Kalman filter.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_24">
             15:20-17:00, Paper TI5A.24
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('59'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Imaginary Meta Reinforcement Learning for Decision-Making in Autonomous Driving
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#305757" title="Click to go to the Author Index">
             Wen, Lu
            </a>
           </td>
           <td class="r">
            University of Michigan, Ann Arbor
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#386422" title="Click to go to the Author Index">
             Zhang, Songan
            </a>
           </td>
           <td class="r">
            Shanghai Jiaotong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab59" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#intelligent_robotic_vehicles" title="Click to go to the Keyword Index">
               Intelligent Robotic Vehicles
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#motion_planning_and_obstacle_avoidance" title="Click to go to the Keyword Index">
               Motion Planning and Obstacle Avoidance
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Meta reinforcement learning (Meta RL) has been amply explored to quickly learn an unseen task by transferring previously learned knowledge from similar tasks. However, most state-of-the-art Meta RL algorithms require the meta-training tasks to have a dense coverage of the task distribution and a great amount of data for each of them. In this paper, we propose MetaDreamer, a context-based Meta RL algorithm that requires less real training tasks and data by doing meta-imagination and MDP-imagination. We perform meta-imagination by interpolating on the learned latent context space with disentangled properties, as well as MDP-imagination through the generative world model where physical knowledge is introduced. Our experiments with various benchmarks show that MetaDreamer outperforms existing approaches in data efficiency and interpolated generalization.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_25">
             15:20-17:00, Paper TI5A.25
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('60'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              The Concept of the Automated Fit-Up System and CAD Based Work Pieces Detection Algorithm for Sub-Assembly of Ship Building
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#153963" title="Click to go to the Author Index">
             Kim, Han-Gyeol
            </a>
           </td>
           <td class="r">
            Korea Institute of Robotics &amp; Technology Convergence
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387044" title="Click to go to the Author Index">
             Jeong, Yujeong
            </a>
           </td>
           <td class="r">
            Korea Institute of Robotics and Technology Convergence
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387047" title="Click to go to the Author Index">
             Jang, Minwoo
            </a>
           </td>
           <td class="r">
            Korea Institute of Robotics and Technology Convergence
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#349772" title="Click to go to the Author Index">
             Baek, Jonghwan
            </a>
           </td>
           <td class="r">
            Korea Institute of Robotics and Technology Convergence
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#349783" title="Click to go to the Author Index">
             Lee, Jae Youl
            </a>
           </td>
           <td class="r">
            Korea Institute of Robotics and Technology Convergence
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab60" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#mechanism_and_design" title="Click to go to the Keyword Index">
               Mechanism and Design
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#object_recognition" title="Click to go to the Keyword Index">
               Object Recognition
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#industrial_robots" title="Click to go to the Keyword Index">
               Industrial Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The sub-assembly process significantly influences the quality of shipbuilding, prompting extensive research to enhance productivity through automation. However, progress in automating the fit-up process has been relatively slow due to its complex task involving recognition, transportation, fixation, and pre-welding of components. In this study, the concept of an automated fit-up system for shipbuilding subassembly is propose. While the fit-up process using the automated fit-up system is introduced. Additionally, an algorithm for recognizing plates placed on the assembly table is proposed. The algorithm was tested on a miniature testbed, demonstrating an accuracy of 98.8% based on the RMSE criterion.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_26">
             15:20-17:00, Paper TI5A.26
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('62'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              High Bandwidth Position Control of a Non-Collocated Tendon-Driven Manipulator
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#295695" title="Click to go to the Author Index">
             Kim, Nam Gyun
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#102369" title="Click to go to the Author Index">
             Ryu, Jee-Hwan
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab62" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#dynamics_and_control" title="Click to go to the Keyword Index">
               Dynamics and Control
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#manipulation_planning_and_control" title="Click to go to the Keyword Index">
               Manipulation Planning and Control
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#contact__modeling__sensing_and_control_" title="Click to go to the Keyword Index">
               Contact: Modeling, Sensing and Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Tendon-driven manipulators with non-collocated actuator placement provide numerous advantages. However, accurate high-bandwidth control of these manipulators remains a challenge. This paper proposes a high-bandwidth position control scheme for non-collocated tendon-driven manipulators. We modified the previously proposed successive stiffness increment (SSI) approach for higher-bandwidth position control by introducing a non-offset releasing path. Furthermore, the timedomain passivity approach was integrated with SSI to ensure the stability of the SSI-based high-bandwidth non-collocated control system. Consequently, the proposed dual-loop control scheme allows higher bandwidth in position tracking while ensuring stability and removing undesirable oscillations.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_27">
             15:20-17:00, Paper TI5A.27
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('63'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Steering Mechanism Via Tail Bias Effect for Soft Toroidal Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#334501" title="Click to go to the Author Index">
             Park, Shinwoo
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#295695" title="Click to go to the Author Index">
             Kim, Nam Gyun
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#102369" title="Click to go to the Author Index">
             Ryu, Jee-Hwan
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab63" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#mechanism_and_design" title="Click to go to the Keyword Index">
               Mechanism and Design
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#soft_robotics" title="Click to go to the Keyword Index">
               Soft Robotics
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#modeling__identification__calibration" title="Click to go to the Keyword Index">
               Modeling, Identification, Calibration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper introduces a novel soft toroidal robot made from nylon fabric, representing a significant advancement in soft robotics. The robot features a unique steering mechanism leveraging the tail bias effect of nylon, enabling effective navigation in various terrains while maintaining its soft nature. Experimental results validate the theoretical model, demonstrating that the restoring moment is linearly related to curvature and independent of pressure. Simulations and demonstrations, including a 90-degree T-shaped pipe test, confirm the robot's maneuverability and efficiency in steering, especially in confined spaces.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_28">
             15:20-17:00, Paper TI5A.28
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('64'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Image Processing Based on Deep Learning for Detecting Defect Problems in Ropeway Wire
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#349772" title="Click to go to the Author Index">
             Baek, Jonghwan
            </a>
           </td>
           <td class="r">
            Korea Institute of Robotics and Technology Convergence
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387045" title="Click to go to the Author Index">
             Kim, Namki
            </a>
           </td>
           <td class="r">
            Korea Institute of Robotics &amp; Technology Convergence
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#349814" title="Click to go to the Author Index">
             Lee, Eun-Bi
            </a>
           </td>
           <td class="r">
            Korea Institute of Robotics and Technology Convergence
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387044" title="Click to go to the Author Index">
             Jeong, Yujeong
            </a>
           </td>
           <td class="r">
            Korea Institute of Robotics and Technology Convergence
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#349827" title="Click to go to the Author Index">
             Jeong, Myeongsu
            </a>
           </td>
           <td class="r">
            Korea Institute of Robotics &amp; Technology Convergence
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#349783" title="Click to go to the Author Index">
             Lee, Jae Youl
            </a>
           </td>
           <td class="r">
            Korea Institute of Robotics and Technology Convergence
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab64" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#object_recognition" title="Click to go to the Keyword Index">
               Object Recognition
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#computer_vision_and_visual_servoing" title="Click to go to the Keyword Index">
               Computer Vision and Visual Servoing
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#ai_reasoning_methods_for_robotics" title="Click to go to the Keyword Index">
               AI Reasoning Methods for Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Continuous and regular inspections are necessary due to the old ropeway facilities, but current inspection methods that rely on professional workers have problems with safety accidents and manpower shortages. To solve this problem, attempts are being made to automatically inspect the rope surface, and low-cost, high-efficiency vision-based inspection is attracting attention. We propose a wire rope defect detection method using deep learning-based image processing installed in cableway facilities. In this paper, we introduce a method to separate wire ropes from the background, classify defects using deep learning inference, and analyze the classified defect area by processing images. The performance evaluation of our wire surface defect detection results showed results within an error of 0.4mm.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_29">
             15:20-17:00, Paper TI5A.29
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('65'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Study on Robotic Systems for Automatic Weld Condition Definition for Welded Joints in Ship Build Manufacturing
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387022" title="Click to go to the Author Index">
             Sung ho, Hong
            </a>
           </td>
           <td class="r">
            Korea Institute of Robotics &amp; Technology Convergence
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#349814" title="Click to go to the Author Index">
             Lee, Eun-Bi
            </a>
           </td>
           <td class="r">
            Korea Institute of Robotics and Technology Convergence
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387030" title="Click to go to the Author Index">
             Lee, Change Hee
            </a>
           </td>
           <td class="r">
            Korea Institute of Robotics and Technology Convergence
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#349783" title="Click to go to the Author Index">
             Lee, Jae Youl
            </a>
           </td>
           <td class="r">
            Korea Institute of Robotics and Technology Convergence
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387408" title="Click to go to the Author Index">
             Ju, Chungho
            </a>
           </td>
           <td class="r">
            Korea Institute for Robot Industry Advancement
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387028" title="Click to go to the Author Index">
             Yoo, Dong Joo
            </a>
           </td>
           <td class="r">
            Sunmoon University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab65" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#industrial_robots" title="Click to go to the Keyword Index">
               Industrial Robots
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#ai_reasoning_methods_for_robotics" title="Click to go to the Keyword Index">
               AI Reasoning Methods for Robotics
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#computer_vision_and_visual_servoing" title="Click to go to the Keyword Index">
               Computer Vision and Visual Servoing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Even experienced on-site welders in the shipbuilding industry may encounter trial and error, leading to the occurrence of welding defects despite their familiarity with welding tasks. When performing familiar welding tasks, it is necessary to set welding conditions by searching the database for welding parameters based on the shape and thickness of the welded component. This process includes configuring welding conditions based on the shape, material, and thickness of each component. Finding the optimal welding conditions often requires numerous iterations of initial welding to check and repeat the welding status. This study investigates a welding process support system to minimize such trial and error. This system is designed to assist in finding optimal welding conditions by inputting parameters related to welding form, material, and thickness. It proposes a system that finds optimal welding conditions based on machine learning by considering existing databases, welding conditions and welding environments (ambient temperature, humidity) of experienced welders in the field. This system can contribute to improving welding quality and increasing productivity.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_30">
             15:20-17:00, Paper TI5A.30
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('66'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Development of a Tele-Inspection Manipulation Robot for Sheave Liner Wear Inspection of Ropeway Wheels
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#349713" title="Click to go to the Author Index">
             Kim, Seolha
            </a>
           </td>
           <td class="r">
            Korea Institute of Robotics Technology Covergence
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#349772" title="Click to go to the Author Index">
             Baek, Jonghwan
            </a>
           </td>
           <td class="r">
            Korea Institute of Robotics and Technology Convergence
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387047" title="Click to go to the Author Index">
             Jang, Minwoo
            </a>
           </td>
           <td class="r">
            Korea Institute of Robotics and Technology Convergence
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#349827" title="Click to go to the Author Index">
             Jeong, Myeongsu
            </a>
           </td>
           <td class="r">
            Korea Institute of Robotics &amp; Technology Convergence
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387045" title="Click to go to the Author Index">
             Kim, Namki
            </a>
           </td>
           <td class="r">
            Korea Institute of Robotics &amp; Technology Convergence
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#349814" title="Click to go to the Author Index">
             Lee, Eun-Bi
            </a>
           </td>
           <td class="r">
            Korea Institute of Robotics and Technology Convergence
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#349783" title="Click to go to the Author Index">
             Lee, Jae Youl
            </a>
           </td>
           <td class="r">
            Korea Institute of Robotics and Technology Convergence
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab66" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#manipulation_planning_and_control" title="Click to go to the Keyword Index">
               Manipulation Planning and Control
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#motion_planning_and_obstacle_avoidance" title="Click to go to the Keyword Index">
               Motion Planning and Obstacle Avoidance
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#contact__modeling__sensing_and_control_" title="Click to go to the Keyword Index">
               Contact: Modeling, Sensing and Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             These days, inspection is conducted by specialized inspectors using visual inspection in the ropeway facilities with cable car, ski lift, etc. However, human visual inspection is conducted based on their experience, so inspectors may express varying opinions during the inspection process. In addition, ensuring safety in adverse climates and environments is challenging, leading to continual shortage of skilled inspectors. Accordingly, in this study, to inspect ropeway wheels, wear regularly regardless of climate, ropeway wheels remote monitoring inspection system was developed. To inspect the wheel wear, YOLOv5 and deep learning-based wheel detection method was used. The manipulator capable of inspecting the upper, lateral, and lower surfaces of the wheel was developed. Based on simulation, the appropriate link lengths and location were determined. Furthermore, manipulator posture and angles at the inspection position were determined through inverse kinematics calculations. The testbed was established for the wheel inspection and aimed to conduct operational tests of the actual manipulator using it. Based on this, the safety-assuring inspection system is aimed to be developed, to inspect the wheels even in adverse environment.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_31">
             15:20-17:00, Paper TI5A.31
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('192'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Automated Peg-In-Hole Insertion: A Supervised Learning-Based Approach to Misalignment Error Compensation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#361730" title="Click to go to the Author Index">
             Cho, Taeyeop
            </a>
           </td>
           <td class="r">
            Hanyang University, KITECH
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#242735" title="Click to go to the Author Index">
             Kim, Jinseok
            </a>
           </td>
           <td class="r">
            UST, KITECH
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#273535" title="Click to go to the Author Index">
             Choi, Iksu
            </a>
           </td>
           <td class="r">
            Sungkyunkwan University, KITECH
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#143938" title="Click to go to the Author Index">
             Pyo, Dongbum
            </a>
           </td>
           <td class="r">
            Korea Institute of Industrial Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab192" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#manipulation_planning_and_control" title="Click to go to the Keyword Index">
               Manipulation Planning and Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Tasks with frequent contact such as peg-in-hole assembly pose a risk of hazardous forces on the robot system due to uncertainty-induced collisions. To address this, we propose a regression learning model to infer the pose error angles of the peg and hole based on contact data. We demonstrate its effectiveness in overcoming jamming caused by misalignment in peg-in-hole insertion by a learned misalignment error compensation network (MEN). Experimental results show that the MEN achieves insertion independent of gain tuning with a 100% success rate compared to the single system, demonstrating stable peg-in-hole tasks without jamming.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_32">
             15:20-17:00, Paper TI5A.32
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('194'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Maritime Object Detection for Autonomous Surface Vehicles through Distinct Problem Understanding
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#130223" title="Click to go to the Author Index">
             Choi, Hyun-Taek
            </a>
           </td>
           <td class="r">
            Korea Research Institute of Ships and Oceans Engineering
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#171826" title="Click to go to the Author Index">
             Park, Jeonghong
            </a>
           </td>
           <td class="r">
            KRISO
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#104653" title="Click to go to the Author Index">
             Choi, Jinwoo
            </a>
           </td>
           <td class="r">
            KRISO, Korea Research Institute of Ships &amp; Ocean Engineering
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#319846" title="Click to go to the Author Index">
             Kang, Minju
            </a>
           </td>
           <td class="r">
            Korea Research Institute of Ships &amp; Ocean Engineering
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#361596" title="Click to go to the Author Index">
             Ha, Namhoon
            </a>
           </td>
           <td class="r">
            Korea Research Institute of Ships and Oceans Engineering
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#361718" title="Click to go to the Author Index">
             Choo, Ki-Beom
            </a>
           </td>
           <td class="r">
            Korea Research Institute of Ships &amp; Ocean Engineering(kriso)
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#162950" title="Click to go to the Author Index">
             Kim, Jinwhan
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab194" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#multisensor_data_fusion" title="Click to go to the Keyword Index">
               Multisensor Data Fusion
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#object_recognition" title="Click to go to the Keyword Index">
               Object Recognition
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#intelligent_robotic_vehicles" title="Click to go to the Keyword Index">
               Intelligent Robotic Vehicles
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In recent years, high-performance deep learning-based detection algorithms have been rapidly advancing, raising high expectations for autonomous vehicles, in particular, autonomous navigation. However, current detection studies primarily focus on improving the performance of general-purpose detection. Considering the performance limitations and resource constraints, the pursuit of detecting all maritime objects with the highest performance is not always practical. In this paper, we categorized detection performance into two objectives: (1) safe navigation and (2) surveillance/reconnaissance while describing characteristics of each objective in terms of purpose, priority, sensor weighting, and usage of additional information. Then we proposed a two-stage structure that can effectively handle these objectives. The designed algorithm in this structure selectively applied the 1st stage detection results to the corresponding objects based on the objective, allowing for efficient resource utilization for algorithm execution while still ensuring a minimum level of performance through the continuous operation of the 1st stage detection results. We have also provided example results to show the effectiveness of our proposed method.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_33">
             15:20-17:00, Paper TI5A.33
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Efficient In-Pipe Cleaning Using Planetary Gear Mechanism-Based Brush Module
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#386917" title="Click to go to the Author Index">
             Jeong, Byeongchan
            </a>
           </td>
           <td class="r">
            Sungkyunkwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#397073" title="Click to go to the Author Index">
             Hur, Jaehyuk
            </a>
           </td>
           <td class="r">
            Sungkyunkwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#396906" title="Click to go to the Author Index">
             Lee, Dong Young
            </a>
           </td>
           <td class="r">
            Sungkyunkwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#102438" title="Click to go to the Author Index">
             Choi, Hyouk Ryeol
            </a>
           </td>
           <td class="r">
            Sungkyunkwan University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_34">
             15:20-17:00, Paper TI5A.34
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('196'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Restoration of Underwater Vehicles Surface Pressure : Gappy POD Analysis of CFD Simulation Data
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#399535" title="Click to go to the Author Index">
             Kim, Jinwoo
            </a>
           </td>
           <td class="r">
            Seoul National University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#399536" title="Click to go to the Author Index">
             Kim, Gyurae
            </a>
           </td>
           <td class="r">
            Seoul National University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#111445" title="Click to go to the Author Index">
             Kim, Jinhyun
            </a>
           </td>
           <td class="r">
            Seoul National University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab196" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#underwater_robotics" title="Click to go to the Keyword Index">
               Underwater Robotics
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#multisensor_data_fusion" title="Click to go to the Keyword Index">
               Multisensor Data Fusion
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#range__sonar__gps_and_inertial_sensing" title="Click to go to the Keyword Index">
               Range, Sonar, GPS and Inertial Sensing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we employed the gappy POD (Proper Orthogonal Decomposition) technique to restore high-dimensional pressure data from the surface of an underwater vehicle. To utilize the gappy POD technique, Snapshot data was obtained through CFD (Computational Fluid Dynamics) simulations, capturing the motion of the underwater vehicle as it moved forward. We conducted an analysis of the singular values of the snapshot data and the corresponding POD modes. The restored data, utilizing only a few data points and three modes, exhibited a high level of accuracy when compared to the original dataset.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_35">
             15:20-17:00, Paper TI5A.35
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('199'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Multi-Agent 3D Scene Graph Framework in Real-Time
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#400434" title="Click to go to the Author Index">
             Kim, Yirum
            </a>
           </td>
           <td class="r">
            Gwang-Ju Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#194366" title="Click to go to the Author Index">
             Kim, Ue-Hwan
            </a>
           </td>
           <td class="r">
            Gwangju Institute of Science and Technology (GIST)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab199" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#simultaneous_localization_and_mapping__slam_" title="Click to go to the Keyword Index">
               Simultaneous Localization and Mapping (SLAM)
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             3D scene graphs effectively encapsulate spatial and semantic information of 3D environments, with nodes denoting objects and edges indicating the predicates between objects. Recent studies have primarily focused on the 3D scene graph prediction of a single agent—overlooking the practicality of multi-agent systems in the real world. In this work, we propose a multi-agent 3D scene graph (MA3DSG): a framework designed for large indoor environments where multiple agents collaboratively generate 3D scene graphs from RGB-D sequences in real-time. As a key component of the proposed framework, we introduce the sequential feature-based place recognition method using the graph neural network (GNN) to update nodes and edges for spaces previously visited by other agents. Besides, enhancing this place recognition and the overall 3D scene graph performance requires the extraction of more effective features. To this end, we propose to employ the kernel point convolution for the advancement of the point cloud encoder. Furthermore, we introduce a new benchmark for evaluating MA3DSG systems including a dataset, metrics, and baselines. Through comprehensive experiments, we showcase our framework’s ability to rapidly and efficiently construct hierarchical 3D scene graphs for extensive indoor spaces.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_36">
             15:20-17:00, Paper TI5A.36
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('200'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Development of Intelligent Situational Awareness System (iSAS) for Maritime Autonomous Surface Ships: Preliminary Field Tests at Sea
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#171826" title="Click to go to the Author Index">
             Park, Jeonghong
            </a>
           </td>
           <td class="r">
            KRISO
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#319846" title="Click to go to the Author Index">
             Kang, Minju
            </a>
           </td>
           <td class="r">
            Korea Research Institute of Ships &amp; Ocean Engineering
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#130223" title="Click to go to the Author Index">
             Choi, Hyun-Taek
            </a>
           </td>
           <td class="r">
            Korea Research Institute of Ships and Oceans Engineering
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#361596" title="Click to go to the Author Index">
             Ha, Namhoon
            </a>
           </td>
           <td class="r">
            Korea Research Institute of Ships and Oceans Engineering
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#361718" title="Click to go to the Author Index">
             Choo, Ki-Beom
            </a>
           </td>
           <td class="r">
            Korea Research Institute of Ships &amp; Ocean Engineering(kriso)
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#104653" title="Click to go to the Author Index">
             Choi, Jinwoo
            </a>
           </td>
           <td class="r">
            KRISO, Korea Research Institute of Ships &amp; Ocean Engineering
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab200" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#intelligent_robotic_vehicles" title="Click to go to the Keyword Index">
               Intelligent Robotic Vehicles
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#multisensor_data_fusion" title="Click to go to the Keyword Index">
               Multisensor Data Fusion
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#object_recognition" title="Click to go to the Keyword Index">
               Object Recognition
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents the development of an intelligent situational awareness system (iSAS) for the autonomous navigation of maritime autonomous surface ships (MASSs) maneuvering in a marine environment. A sensor fusion-based multimodal system including cameras, lidar, and radar was configured to seamlessly and reliably detect and identify various maritime objects at sea. In particular, Considering the unique characteristics of each sensor, we designed and implemented detection approaches to quickly detect objects. Subsequently, an extended Kalman filter (EKF)-based tracking filter technique was applied to estimate the detected objects' position, speed, and course information. Furthermore, considering a time-varying uncertainty contained in the estimated information, the estimated information was employed to evaluate a quantitative risk indicator of the potential collision risk on the predictive course of the MASS. Preliminary field tests were carried out at sea to demonstrate the practical feasibility of the developed iSAS, and their results were described.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_37">
             15:20-17:00, Paper TI5A.37
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('201'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Semantic Segmentation-Based Vision-Enabled Safe Landing Position Estimation Framework
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387088" title="Click to go to the Author Index">
             Jung, Yeondeuk
            </a>
           </td>
           <td class="r">
            Korea Aerospace Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#169562" title="Click to go to the Author Index">
             Cho, Sungwook
            </a>
           </td>
           <td class="r">
            Cheongju University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#298358" title="Click to go to the Author Index">
             Choi, Hyoung Sik
            </a>
           </td>
           <td class="r">
            KARI
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab201" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#computer_vision_and_visual_servoing" title="Click to go to the Keyword Index">
               Computer Vision and Visual Servoing
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#aerial_and_flying_robots" title="Click to go to the Keyword Index">
               Aerial and Flying Robots
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#robot_surveillance_and_security" title="Click to go to the Keyword Index">
               Robot Surveillance and Security
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper discusses the importance of safety in the emerging urban air mobility (UAM) industry, particularly for autonomous flying in urban areas. In detail, this paper presents a framework designed to improve emergency landing processes for drones and UAM vehicles while flying in the urban area. Our contribution uses advanced image processing techniques assisted by the deep neural network (DNN) and coarse-to-refine-based contour detection, to identify and refine potential emergency landing area. Through simulation results, the effectiveness of the proposed framework was verified, showing promise in addressing real-world challenges of image analysis and enhancing emergency response capabilities during flight.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_38">
             15:20-17:00, Paper TI5A.38
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('202'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Effects of Transfer-Assistive Robots on the Caregiver Burden
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#401036" title="Click to go to the Author Index">
             Shin, Yong Soon
            </a>
           </td>
           <td class="r">
            Hanyang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#401038" title="Click to go to the Author Index">
             Kim, Min-Jung
            </a>
           </td>
           <td class="r">
            Hanyang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab202" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#rehabilitation_and_healthcare_robotics" title="Click to go to the Keyword Index">
               Rehabilitation and Healthcare Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This study aimed to evaluate the effects of transfer-assistive robots on the caregiver burden. Thirty caregivers of people with severe disabilities and older adults used the transfer-assistive robot for 7 days. The transfer-assistive robots had significant reduction effect on caregiver burden.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_39">
             15:20-17:00, Paper TI5A.39
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('203'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Care Workers’ Caring Experience on Transfer-Assistive Robot in Long-Term Care Facility
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#401036" title="Click to go to the Author Index">
             Shin, Yong Soon
            </a>
           </td>
           <td class="r">
            Hanyang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#401055" title="Click to go to the Author Index">
             Jang, Hye-Young
            </a>
           </td>
           <td class="r">
            Hanyang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#401109" title="Click to go to the Author Index">
             Kim, Mi Young
            </a>
           </td>
           <td class="r">
            HANYANG UNIVERSITY
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#401112" title="Click to go to the Author Index">
             Park, So Seul
            </a>
           </td>
           <td class="r">
            Hanyang University, Seoul
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#401058" title="Click to go to the Author Index">
             Young A, Lee
            </a>
           </td>
           <td class="r">
            Hanyang Uriversity, Seoul, Korea
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab203" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#rehabilitation_and_healthcare_robotics" title="Click to go to the Keyword Index">
               Rehabilitation and Healthcare Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This study was conducted to explore the experience of using transfer-assistive robots. A focus group interview was conducted with 11 care workers who had experience using transfer-assistive robots. A total of two groups of FGIs were performed for two hours each, and the collected data were analyzed using content analysis. As a result of the analysis, 5 themes and 16 sub-themes were derived; 1) Experience of changes in caregiving, 2) Overcoming inconveniences, 3) Positive change in professional identity through care robots, 4) Enabling person-centered care through the use of care robots, 5) Crossing the boundary from current to future care. The significance of this study lies in confirming the possibility of person-centered care in nursing homes through the use of transfer-assistive robots.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_40">
             15:20-17:00, Paper TI5A.40
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('204'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              ﻿Educational Approach to Human-Centered Care for Care Robot Users
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#401036" title="Click to go to the Author Index">
             Shin, Yong Soon
            </a>
           </td>
           <td class="r">
            Hanyang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#401109" title="Click to go to the Author Index">
             Kim, Mi Young
            </a>
           </td>
           <td class="r">
            HANYANG UNIVERSITY
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#401055" title="Click to go to the Author Index">
             Jang, Hye-Young
            </a>
           </td>
           <td class="r">
            Hanyang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#401112" title="Click to go to the Author Index">
             Park, So Seul
            </a>
           </td>
           <td class="r">
            Hanyang University, Seoul
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#401058" title="Click to go to the Author Index">
             Young A, Lee
            </a>
           </td>
           <td class="r">
            Hanyang Uriversity, Seoul, Korea
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab204" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#learning_from_humans" title="Click to go to the Keyword Index">
               Learning From Humans
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#performance_evaluation_and_optimization" title="Click to go to the Keyword Index">
               Performance Evaluation and Optimization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             ﻿The global rise in the elderly population, alongside an increasing number of disabled individuals and the aging of this demographic, underscores significant societal trends.
             <p>
              This demographic shift amplifies the demand for care, particularly among the elderly and disabled communities. ﻿ This study explores the development of an education program for care robot users, integrating insights from academic experts and literature review. It identifies anticipated challenges, necessary caregiver competencies, and educational initiatives essential for safe and effective care robot utilization. Findings emphasize the importance of addressing ethical, legal, and practical considerations while promoting collaborative and humane care practices.
              <p>
               ﻿This study aimed to construct a care robot education program by engaging academic and practical experts. By incorporating expert discourse, the program can equip users with the necessary knowledge for proper usage, including humanities aspects. The study's findings serve as foundational data for developing the program's content. It is also expected that it can be used as educational material for users and professional educators for future care.
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_41">
             15:20-17:00, Paper TI5A.41
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('205'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Solving the Multi-Depot Vehicle Routing Problem with Acyclic Solution Using Deep Reinforcement Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#387113" title="Click to go to the Author Index">
             Son, Hakmo
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science &amp;Technology (KAIST)
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#273266" title="Click to go to the Author Index">
             Do, Haggi
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#162950" title="Click to go to the Author Index">
             Kim, Jinwhan
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab205" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#intelligent_robotic_vehicles" title="Click to go to the Keyword Index">
               Intelligent Robotic Vehicles
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a reinforcement learning (RL)-based solution that leverages an attention mechanism to enhance performance and cost-effectiveness in addressing the multi-depot vehicle routing problem (MDVRP). Similar to the traveling salesman problem (TSP) and the vehicle routing problem (VRP), the MDVRP is identified as a combinatorial optimization challenge and an NP-hard problem. RL techniques and the attention mechanism are introduced to navigate the complexities of optimizing logistics associated with delivery robots and unmanned systems. We demonstrate the potential utility and feasibility of the proposed method for its application in complex logistical applications, towards which our future research efforts will be directed.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="ti5a_42">
             15:20-17:00, Paper TI5A.42
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('206'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Development of a Rehabilitation Robot with Surface Electromyography-Based Guidance Force Feedback
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#233179" title="Click to go to the Author Index">
             Shin, Wonseok
            </a>
           </td>
           <td class="r">
            KITECH
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#389236" title="Click to go to the Author Index">
             Park, Seungtae
            </a>
           </td>
           <td class="r">
            Korea National University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#389238" title="Click to go to the Author Index">
             Kang, Jihun
            </a>
           </td>
           <td class="r">
            UST Graduate School
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#132135" title="Click to go to the Author Index">
             Ahn, Bummo
            </a>
           </td>
           <td class="r">
            Korea Institute of Industrial Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="UR24_AuthorIndexWeb.html#119994" title="Click to go to the Author Index">
             Kwon, Suncheol
            </a>
           </td>
           <td class="r">
            KITECH
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab206" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="UR24_KeywordIndexWeb.html#rehabilitation_and_healthcare_robotics" title="Click to go to the Keyword Index">
               Rehabilitation and Healthcare Robotics
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#neurorobotics" title="Click to go to the Keyword Index">
               Neurorobotics
              </a>
              ,
              <a href="UR24_KeywordIndexWeb.html#physical_and_cognitive_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical and Cognitive Human-Robot Interaction
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present a surface electromyography-based force feedback robot system that can be utilized in upper extremity rehabilitation. We hypothesized that providing electromyographic signal-based guidance force in line with the subject's intent during rehabilitation training can encourage more active muscle use. An upper limb rehabilitation robot that provides electromyographic signal-based guidance force only when the subject voluntarily attempts to correct the trajectory. As a feasibility test, a chronic phase stroke patient used the developed rehabilitation robot for 6 weeks. The results showed that the muscles required for the movement were more activated and the unnecessary muscles were less activated. The results demonstrate that the robotic guidance force feedback we proposed to induce muscle activation can be effective for upper limb rehabilitation training.
            </div>
           </td>
          </tr>
         </table>
        </div>
        <p>
         <br/>
        </p>
        <p>
         <br/>
        </p>
        <p>
         <p>
         </p>
        </p>
       </td>
       <td height="100%" style="background-color:#2E5286;" width="5">
       </td>
      </tr>
      <tr>
       <td alt="" border="0" colspan="4" height="16" style="background-color:#2E5286;" valign="center" width="100%">
        <p align="center">
         <span style="font-size:8pt;line-height:10pt;color:#ffffff;">
          Technical Content © IEEE Robotics &amp; Automation Society
         </span>
        </p>
       </td>
      </tr>
      <tr>
       <td colspan="4" width="100%">
        <p align="right">
         <span style="text-decoration:none;">
          <img align="right" border="0" src="/images/pc_logo_small.png" style="margin-left: 10px; margin-right: 10px"/>
          This site is protected
by copyright and trademark laws under US and International law.
          <br/>
          All rights
reserved. © 2002-2024 PaperCept, Inc.
          <br/>
          Page generated 2024-05-13  22:00:00 PST
          <a href="" onclick="window.open('/conferences/scripts/about.pl','tc','width=1000,scrollbars=yes'); return false">
           Terms of use
          </a>
         </span>
        </p>
       </td>
      </tr>
     </table>
    </body>
   </div>
  </form>
 </body>
</html>
